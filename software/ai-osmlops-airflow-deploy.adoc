---
sidebar: sidebar 
permalink: software/ai-osmlops-airflow-deploy.html 
keywords: AI, control plane, apache, airflow 
summary: MLOps open source con NetApp - Distribuzione di Apache Airflow 
---
= Distribuzione di Apache Airflow
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
Questa sezione descrive le attività che devi completare per distribuire Airflow nel tuo cluster Kubernetes.


NOTE: È possibile distribuire Airflow su piattaforme diverse da Kubernetes.  L'implementazione di Airflow su piattaforme diverse da Kubernetes esula dall'ambito di questa soluzione.



== Prerequisiti

Prima di eseguire l'esercizio di distribuzione descritto in questa sezione, diamo per scontato che tu abbia già eseguito le seguenti attività:

. Hai già un cluster Kubernetes funzionante.
. Hai già installato e configurato NetApp Trident nel tuo cluster Kubernetes.  Per maggiori dettagli su Trident, fare riferimento allink:https://docs.netapp.com/us-en/trident/index.html["Documentazione Trident"] .




== Installa Helm

Airflow viene distribuito tramite Helm, un noto gestore di pacchetti per Kubernetes.  Prima di distribuire Airflow, è necessario installare Helm sull'host di distribuzione.  Per installare Helm sull'host di distribuzione jump, seguire le istruzioni https://helm.sh/docs/intro/install/["istruzioni di installazione"^] nella documentazione ufficiale di Helm.



== Imposta la classe di archiviazione Kubernetes predefinita

Prima di distribuire Airflow, è necessario designare una StorageClass predefinita all'interno del cluster Kubernetes.  Il processo di distribuzione di Airflow tenta di effettuare il provisioning di nuovi volumi persistenti utilizzando la StorageClass predefinita.  Se non viene designata alcuna StorageClass come StorageClass predefinita, la distribuzione fallisce.  Per designare una StorageClass predefinita all'interno del cluster, seguire le istruzioni descritte inlink:ai-osmlops-kubeflow-deploy.html["Distribuzione di Kubeflow"] sezione.  Se hai già designato una StorageClass predefinita all'interno del tuo cluster, puoi saltare questo passaggio.



== Usa Helm per distribuire il flusso d'aria

Per distribuire Airflow nel cluster Kubernetes tramite Helm, eseguire le seguenti attività dall'host di jump di distribuzione:

. Distribuisci Airflow utilizzando Helm seguendo le istruzioni https://artifacthub.io/packages/helm/airflow-helm/airflow["istruzioni di distribuzione"^] per il grafico ufficiale del flusso d'aria su Artifact Hub.  I comandi di esempio che seguono mostrano la distribuzione di Airflow tramite Helm.  Modificare, aggiungere e/o rimuovere valori in `custom- values.yaml` file secondo necessità, a seconda dell'ambiente e della configurazione desiderata.
+
....
$ cat << EOF > custom-values.yaml
###################################
# Airflow - Common Configs
###################################
airflow:
  ## the airflow executor type to use
  ##
  executor: "CeleryExecutor"
  ## environment variables for the web/scheduler/worker Pods (for airflow configs)
  ##
  #
###################################
# Airflow - WebUI Configs
###################################
web:
  ## configs for the Service of the web Pods
  ##
  service:
    type: NodePort
###################################
# Airflow - Logs Configs
###################################
logs:
  persistence:
    enabled: true
###################################
# Airflow - DAGs Configs
###################################
dags:
  ## configs for the DAG git repository & sync container
  ##
  gitSync:
    enabled: true
    ## url of the git repository
    ##
    repo: "git@github.com:mboglesby/airflow-dev.git"
    ## the branch/tag/sha1 which we clone
    ##
    branch: master
    revision: HEAD
    ## the name of a pre-created secret containing files for ~/.ssh/
    ##
    ## NOTE:
    ## - this is ONLY RELEVANT for SSH git repos
    ## - the secret commonly includes files: id_rsa, id_rsa.pub, known_hosts
    ## - known_hosts is NOT NEEDED if `git.sshKeyscan` is true
    ##
    sshSecret: "airflow-ssh-git-secret"
    ## the name of the private key file in your `git.secret`
    ##
    ## NOTE:
    ## - this is ONLY RELEVANT for PRIVATE SSH git repos
    ##
    sshSecretKey: id_rsa
    ## the git sync interval in seconds
    ##
    syncWait: 60
EOF
$ helm install airflow airflow-stable/airflow -n airflow --version 8.0.8 --values ./custom-values.yaml
...
Congratulations. You have just deployed Apache Airflow!
1. Get the Airflow Service URL by running these commands:
   export NODE_PORT=$(kubectl get --namespace airflow -o jsonpath="{.spec.ports[0].nodePort}" services airflow-web)
   export NODE_IP=$(kubectl get nodes --namespace airflow -o jsonpath="{.items[0].status.addresses[0].address}")
   echo http://$NODE_IP:$NODE_PORT/
2. Open Airflow in your web browser
....
. Verificare che tutti i pod Airflow siano attivi e funzionanti.  Potrebbero essere necessari alcuni minuti prima che tutti i pod si avviino.
+
....
$ kubectl -n airflow get pod
NAME                                READY   STATUS    RESTARTS   AGE
airflow-flower-b5656d44f-h8qjk      1/1     Running   0          2h
airflow-postgresql-0                1/1     Running   0          2h
airflow-redis-master-0              1/1     Running   0          2h
airflow-scheduler-9d95fcdf9-clf4b   2/2     Running   2          2h
airflow-web-59c94db9c5-z7rg4        1/1     Running   0          2h
airflow-worker-0                    2/2     Running   2          2h
....
. Ottieni l'URL del servizio Web Airflow seguendo le istruzioni visualizzate sulla console quando hai distribuito Airflow tramite Helm nel passaggio 1.
+
....
$ export NODE_PORT=$(kubectl get --namespace airflow -o jsonpath="{.spec.ports[0].nodePort}" services airflow-web)
$ export NODE_IP=$(kubectl get nodes --namespace airflow -o jsonpath="{.items[0].status.addresses[0].address}")
$ echo http://$NODE_IP:$NODE_PORT/
....
. Conferma di poter accedere al servizio web Airflow.


image:aicp-010.png["Figura che mostra il dialogo di input/output o che rappresenta il contenuto scritto"]
