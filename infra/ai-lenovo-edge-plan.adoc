---
sidebar: sidebar 
permalink: infra/ai-lenovo-edge-plan.html 
keywords: test, plan, mlperf, inference, benchmarks 
summary: 'Questo documento segue il codice MLPerf Inference v0.7, il codice e le regole MLPerf Inference v1.1.  Abbiamo eseguito benchmark progettati per l"inferenza al limite, come definito nelle tabelle presentate in questa sezione.' 
---
= Piano di prova
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
Questo documento segue MLPerf Inference v0.7 https://github.com/mlperf/inference_results_v0.7/tree/master/closed/Lenovo["codice"^] , Inferenza MLPerf v1.1 https://github.com/mlcommons/inference_results_v1.1/tree/main/closed/Lenovo["codice"^] , E https://github.com/mlcommons/inference_policies/blob/master/inference_rules.adoc["regole"^] .  Abbiamo eseguito benchmark MLPerf progettati per l'inferenza al limite, come definito nella tabella seguente.

|===
| Zona | Compito | Modello | Set di dati | Dimensione QSL | Qualit√† | Vincolo di latenza multistream 


| Visione | Classificazione delle immagini | Resnet50v1.5 | ImageNet (224x224) | 1024 | 99% di FP32 | 50 ms 


| Visione | Rilevamento di oggetti (grandi) | SSD-ResNet34 | COCCO (1200x1200) | 64 | 99% di FP32 | 66 ms 


| Visione | Rilevamento di oggetti (piccoli) | SSD-MobileNetsv1 | COCCO (300x300) | 256 | 99% di FP32 | 50 ms 


| Visione | Segmentazione delle immagini mediche | 3D UNET | BraTS 2019 (224x224x160) | 16 | 99% e 99,9% di FP32 | n / a 


| Discorso | Sintesi vocale | RNNT | Librispeech dev-clean | 2513 | 99% di FP32 | n / a 


| Lingua | Elaborazione del linguaggio | BERT | SQuAD v1.1 | 10833 | 99% di FP32 | n / a 
|===
La tabella seguente presenta gli scenari di benchmark di Edge.

|===
| Zona | Compito | Scenari 


| Visione | Classificazione delle immagini | Singolo flusso, offline, multiflusso 


| Visione | Rilevamento di oggetti (grandi) | Singolo flusso, offline, multiflusso 


| Visione | Rilevamento di oggetti (piccoli) | Singolo flusso, offline, multiflusso 


| Visione | Segmentazione delle immagini mediche | Singolo flusso, offline 


| Discorso | Sintesi vocale-testo | Singolo flusso, offline 


| Lingua | Elaborazione del linguaggio | Singolo flusso, offline 
|===
Abbiamo eseguito questi benchmark utilizzando l'architettura di archiviazione in rete sviluppata in questa convalida e abbiamo confrontato i risultati con quelli delle esecuzioni locali sui server edge precedentemente inviati a MLPerf.  Il confronto serve a determinare l'impatto dell'archiviazione condivisa sulle prestazioni di inferenza.
