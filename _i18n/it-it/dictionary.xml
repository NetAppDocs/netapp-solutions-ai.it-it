<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="2b185d63fe43e391e79f2722fa9c01f4" category="summary">Leggi i blog su AI/ML che evidenziano le tendenze del settore, le innovazioni e l'impatto nel mondo reale, nonché risorse per sviluppatori, approfondimenti della community e strumenti pratici per lavorare con le soluzioni AI NetApp .</block>
  <block id="7a206e7f1f7bd7df4f649256e750768b" category="doc">Leggi i blog sulle soluzioni AI degli esperti NetApp</block>
  <block id="683be49e9105a56d06431bcdc1630cb6" category="paragraph">Leggi i blog AI/ML che evidenziano le tendenze del settore, le innovazioni e l'impatto nel mondo reale, nonché risorse per sviluppatori, approfondimenti della community e strumenti pratici per lavorare con le soluzioni AI NetApp .</block>
  <block id="5bbe94ba0a14c52be3cc9534b43f4713" category="paragraph-title">Tendenze dell'intelligenza artificiale e approfondimenti del settore</block>
  <block id="78463a384a5aa4fad5fa73e2f506ecfc" category="inline-link-macro">Inglese</block>
  <block id="69501f595c5bd3cdb17ea63c90291622" category="paragraph">Esplora le tendenze del settore, le innovazioni e l'impatto dell'intelligenza artificiale nel mondo reale in vari settori. <block ref="3b277c3e8740f32e48fe9dd888ed34aa" category="inline-link-macro-rx"></block> &amp;f:@facet_soultion_mktg=[AI,Analisi,intelligenza-artificiale]++[Leggi i blog sull'IA su NetApp.com^]</block>
  <block id="d5769d364696d52f17c7b56bd51573f8" category="paragraph-title">Risorse e comunità per sviluppatori</block>
  <block id="bb765a119d53333b43f301b6a00a388a" category="inline-link-macro">Leggi i blog sull'intelligenza artificiale sul Pub</block>
  <block id="43c273574ee7233878bcc9fc0bd893c9" category="paragraph">Approfondimenti tecnici, strumenti pratici e contenuti creati dalla community per i professionisti dell'intelligenza artificiale e dell'apprendimento automatico.<block ref="f89e2ffa35ae5933259a8ae6e49a69ad" category="inline-link-macro-rx"></block></block>
  <block id="e7ee239a021c71c67431ac1c23b9cf1e" category="summary">L'articolo fornisce una guida alla creazione di una pipeline MLOps con i servizi AWS, concentrandosi sulla riqualificazione automatizzata dei modelli, sulla distribuzione e sull'ottimizzazione dei costi.</block>
  <block id="b77650c231f63812b48a3802736172ae" category="doc">Parte 3 - Creazione di una pipeline MLOps semplificata (CI/CT/CD)</block>
  <block id="3fc6ea95b9f9aac82c7a39c3743664ba" category="paragraph">Questo articolo fornisce una guida alla creazione di una pipeline MLOps con i servizi AWS, concentrandosi sulla riqualificazione automatizzata dei modelli, sulla distribuzione e sull'ottimizzazione dei costi.</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">Introduzione</block>
  <block id="4c04d3884cafb85369c7a0a6b81d10b0" category="paragraph">In questo tutorial imparerai come sfruttare vari servizi AWS per costruire una semplice pipeline MLOps che comprende integrazione continua (CI), formazione continua (CT) e distribuzione continua (CD).  A differenza delle pipeline DevOps tradizionali, MLOps richiede considerazioni aggiuntive per completare il ciclo operativo.  Seguendo questo tutorial, imparerai come integrare CT nel ciclo MLOps, consentendo un addestramento continuo dei tuoi modelli e una distribuzione senza interruzioni per l'inferenza.  Il tutorial ti guiderà attraverso il processo di utilizzo dei servizi AWS per stabilire questa pipeline MLOps end-to-end.</block>
  <block id="76c3e002d3c052bd6a909366a8dc3845" category="section-title">Manifesto</block>
  <block id="e7e0038bb30579a3120d266861982881" category="cell">Funzionalità</block>
  <block id="49ee3087348e8d44e1feda1917443987" category="cell">Nome</block>
  <block id="0be8406951cdfda82f00f79328cf4efc" category="cell">Commento</block>
  <block id="dc21b082b0947a93d387b8c7e8f89ee5" category="cell">Archiviazione dei dati</block>
  <block id="f3eec26de1c09022af7c97255f0dfee6" category="cell">AWS FSx ONTAP</block>
  <block id="ae8cde6d64ec0b4ed71f7e4d5a28d65f" category="inline-link-macro">Parte 1 - Integrazione di Amazon FSx for NetApp ONTAP (FSx ONTAP) come bucket S3 privato in AWS SageMaker</block>
  <block id="273b64842c06632a1f361f1a341b8c24" category="cell">Fare riferimento a <block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block> .</block>
  <block id="4c5f43ed06df4b05c18ca410c7016249" category="cell">IDE di scienza dei dati</block>
  <block id="5a1439989b12745b5a4ed4b944539247" category="cell">AWS SageMaker</block>
  <block id="4c99a9cb175cf27f5edb2b2a9e21f32c" category="inline-link-macro">Parte 2 - Utilizzo di Amazon FSx for NetApp ONTAP (FSx ONTAP) come origine dati per l'addestramento del modello in SageMaker</block>
  <block id="077914145dbaab3cc9a1f25998b4b703" category="cell">Questo tutorial si basa sul notebook Jupyter presentato in<block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block> .</block>
  <block id="e1d9ae96a3cc2d87549ec614a5eea75b" category="cell">Funzione per attivare la pipeline MLOps</block>
  <block id="10740b99bf79c58d32e1a8e73062d05c" category="cell">Funzione AWS Lambda</block>
  <block id="336d5ebc5436534e61d16e63ddfca327" category="cell">-</block>
  <block id="0fc1223c31c6d7d5d233235c0a8f3ee0" category="cell">Trigger del lavoro cron</block>
  <block id="0abaf4e46241f987a0b4e6a434e596cd" category="cell">AWS EventBridge</block>
  <block id="e015867873eac103879d29f569610c66" category="cell">Framework di apprendimento profondo</block>
  <block id="95b88f180e9eb5678e0f9ebac2cbe643" category="cell">PyTorch</block>
  <block id="6af8c08e3948b664c72a8cc3c2709254" category="cell">SDK Python di AWS</block>
  <block id="6686853da3491a56c98917cc5c4ddea2" category="cell">boto3</block>
  <block id="4f465e36f699fcf0570d854d9f692508" category="cell">Linguaggio di programmazione</block>
  <block id="a7f5f35426b927411fc9231b56382173" category="cell">Pitone</block>
  <block id="cd9ec78e2cad962acfcab027dd62d904" category="cell">v3.10</block>
  <block id="925335f81021de4d22fde55ae7f0e86a" category="section-title">Prerequisito</block>
  <block id="368743a79699dd2e9a1db93cb728196a" category="list-text">Un file system FSx ONTAP preconfigurato.  Questo tutorial utilizza i dati memorizzati in FSx ONTAP per il processo di formazione.</block>
  <block id="73d970f5582fe283900cc4b125f71ab0" category="list-text">Un'*istanza di SageMaker Notebook* configurata per condividere la stessa VPC del file system FSx ONTAP menzionato sopra.</block>
  <block id="cd201faac7e3cf792faa46c93195c65b" category="list-text">Prima di attivare la *funzione AWS Lambda*, assicurarsi che l'*istanza SageMaker Notebook* sia nello stato *arrestato*.</block>
  <block id="238f736fdf6bcdcd7f397969fe6eb36e" category="list-text">Il tipo di istanza *ml.g4dn.xlarge* è necessario per sfruttare l'accelerazione GPU necessaria per i calcoli delle reti neurali profonde.</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="section-title">Architettura</block>
  <block id="2c03bdafce7f1816c8faa5db2e5d1258" category="paragraph"><block ref="2c03bdafce7f1816c8faa5db2e5d1258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e320ad9e531a78d8b06272138f0f29b7" category="paragraph">Questa pipeline MLOps è un'implementazione pratica che utilizza un cron job per attivare una funzione serverless, che a sua volta esegue un servizio AWS registrato con una funzione di callback del ciclo di vita.  *AWS EventBridge* funge da cron job.  Periodicamente richiama una *funzione AWS Lambda* responsabile della riqualificazione e della ridistribuzione del modello.  Questo processo prevede l'avvio dell'istanza *AWS SageMaker Notebook* per eseguire le attività necessarie.</block>
  <block id="2f53ab942978849d906d82a87554a1e2" category="section-title">Configurazione passo passo</block>
  <block id="ecce3b4394f7f06232bad571a96a0391" category="section-title">Configurazioni del ciclo di vita</block>
  <block id="8482e23b03456ee8ac2760d540c11442" category="paragraph">Per configurare la funzione di callback del ciclo di vita per l'istanza AWS SageMaker Notebook, è necessario utilizzare *Configurazioni del ciclo di vita*.  Questo servizio consente di definire le azioni necessarie da eseguire durante l'avvio dell'istanza del notebook.  Nello specifico, è possibile implementare uno script shell all'interno delle *configurazioni del ciclo di vita* per arrestare automaticamente l'istanza del notebook una volta completati i processi di formazione e distribuzione.  Questa è una configurazione obbligatoria poiché il costo è uno degli aspetti più importanti da considerare in MLOps.</block>
  <block id="79d14d6493dc1a7a7d33bf031166f9a9" category="paragraph">È importante notare che la configurazione per le *configurazioni del ciclo di vita* deve essere impostata in anticipo.  Pertanto, si consiglia di dare priorità alla configurazione di questo aspetto prima di procedere con l'altra configurazione della pipeline MLOps.</block>
  <block id="29beb103651093d4e75530e25a50f4bd" category="list-text">Per impostare le configurazioni del ciclo di vita, apri il pannello *Sagemaker* e vai a *Configurazioni del ciclo di vita* nella sezione *Configurazioni amministrative*.</block>
  <block id="e40d22b369f011035946ad31f47b655a" category="inline-image-macro">Pannello SageMaker</block>
  <block id="808aecfbb727487113195461863f7b8f" category="paragraph"><block ref="808aecfbb727487113195461863f7b8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="706c89d427897aa8c9093c9ea4ddf1cb" category="list-text">Selezionare la scheda *Istanza notebook* e fare clic sul pulsante *Crea configurazione*</block>
  <block id="6d548bb5536b7ca36996b9a2bf7f3fc9" category="inline-image-macro">Pagina di benvenuto della configurazione del ciclo di vita</block>
  <block id="533585f6e9e5ce51a2cd2322d75dfd10" category="paragraph"><block ref="533585f6e9e5ce51a2cd2322d75dfd10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bfce2cb9f46fa7b22c7f04d6aa38b9e" category="list-text">Incolla il codice sottostante nell'area di immissione.</block>
  <block id="a3c7be0a54a45c8a39d852df0ffe5795" category="list-text">Questo script esegue Jupyter Notebook, che gestisce il riaddestramento e la ridistribuzione del modello per l'inferenza.  Una volta completata l'esecuzione, il notebook si spegnerà automaticamente entro 5 minuti.  Per saperne di più sulla definizione del problema e sull'implementazione del codice, fare riferimento a<block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block> .</block>
  <block id="f8d2f79250f54a742eec560a47022213" category="inline-image-macro">Crea la configurazione del ciclo di vita</block>
  <block id="32868d8eaf16b0e5d6cc389594591fa8" category="paragraph"><block ref="32868d8eaf16b0e5d6cc389594591fa8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a835fb020d342258f64fe6be9b11cc29" category="list-text">Dopo la creazione, vai alle istanze del Notebook, seleziona l'istanza di destinazione e fai clic su *Aggiorna impostazioni* nel menu a discesa Azioni.</block>
  <block id="386c8dd530ade6b4cdc15f9f6ebad5c4" category="inline-image-macro">Aggiorna menu a discesa delle impostazioni</block>
  <block id="c2ba792fac24b100bacf8cb5998dfc1e" category="paragraph"><block ref="c2ba792fac24b100bacf8cb5998dfc1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f80499d713c8d9fe19313ec1dc9bd45" category="list-text">Selezionare la *Configurazione del ciclo di vita* creata e fare clic su *Aggiorna istanza del notebook*.</block>
  <block id="929b843b11b6f17c62198cd38020bfe6" category="inline-image-macro">Aggiorna la configurazione del ciclo di vita del notebook</block>
  <block id="e0dc07a964d60792b3ec801e8395ef77" category="paragraph"><block ref="e0dc07a964d60792b3ec801e8395ef77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a0f9cbbefa9b9603cf2241f33621e37" category="section-title">Funzione serverless AWS Lambda</block>
  <block id="4a799fa8d490fae92d630fe6cc65b928" category="paragraph">Come accennato in precedenza, la *funzione AWS Lambda* è responsabile dell'avvio dell'*istanza AWS SageMaker Notebook*.</block>
  <block id="be107f93440a41fcae408e1abec6403e" category="list-text">Per creare una *funzione AWS Lambda*, vai al pannello corrispondente, passa alla scheda *Funzioni* e fai clic su *Crea funzione*.</block>
  <block id="d28550fe1b16be91a51602ddd8c1d60f" category="inline-image-macro">Pagina di benvenuto della funzione AWS Lambda</block>
  <block id="627b95a2fda6260f5df8d487a291ceea" category="paragraph"><block ref="627b95a2fda6260f5df8d487a291ceea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a60f634c6f68222d8abaaa29bd057217" category="list-text">Si prega di compilare tutte le voci richieste nella pagina e di ricordarsi di impostare il Runtime su *Python 3.10*.</block>
  <block id="267b7733eb14e4bbd98146ea3f8501b1" category="inline-image-macro">Creare una funzione AWS Lambda</block>
  <block id="cce551decdf09efb16caf7432d6c7eba" category="paragraph"><block ref="cce551decdf09efb16caf7432d6c7eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bee22bc8ca787cbf1475d27ae7429d6" category="list-text">Verificare che il ruolo designato disponga dell'autorizzazione richiesta *AmazonSageMakerFullAccess* e fare clic sul pulsante *Crea funzione*.</block>
  <block id="3f6a1b36a855303ea55de235a44c52b0" category="inline-image-macro">Seleziona il ruolo di esecuzione</block>
  <block id="fa8e9001a3295e1f7a1f8d3ef3e92572" category="paragraph"><block ref="fa8e9001a3295e1f7a1f8d3ef3e92572" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcc43af2494337ee641b41a13f71fc46" category="list-text">Selezionare la funzione Lambda creata.  Nella scheda codice, copia e incolla il seguente codice nell'area di testo.  Questo codice avvia l'istanza del notebook denominata *fsxn-ontap*.</block>
  <block id="c2edd2bdf75433b7f31062be9571f528" category="list-text">Fare clic sul pulsante *Distribuisci* per applicare questa modifica al codice.</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="inline-image-macro">Distribuzione</block>
  <block id="64446fff99d978434b172f7c745ece52" category="paragraph"><block ref="64446fff99d978434b172f7c745ece52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9bb44167ffa5f5dc2d30616b32fe21b" category="list-text">Per specificare come attivare questa funzione AWS Lambda, fare clic sul pulsante Aggiungi trigger.</block>
  <block id="c8d04adc09d32f5c953177228f96826b" category="inline-image-macro">Aggiungi trigger di funzione AWS</block>
  <block id="6297ab474f745fe7abc72cd5f148311b" category="paragraph"><block ref="6297ab474f745fe7abc72cd5f148311b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ba138d79283b1a8aad0ef0cc35ce105" category="list-text">Selezionare EventBridge dal menu a discesa, quindi fare clic sul pulsante di opzione denominato Crea una nuova regola.  Nel campo espressione pianificazione, immettere<block ref="5bb28b828095c4a920fb3d34b89c2b84" prefix=" " category="inline-code"></block> e fai clic sul pulsante Aggiungi per creare e applicare questa nuova regola cron job alla funzione AWS Lambda.</block>
  <block id="4ab295fce5805d57b17ce3316bf007fa" category="inline-image-macro">Finalizza il trigger</block>
  <block id="46f9833b45661170323abab7808e6219" category="paragraph"><block ref="46f9833b45661170323abab7808e6219" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3643e50ab12ef03d2731f0654366409d" category="paragraph">Dopo aver completato la configurazione in due fasi, ogni giorno la *funzione AWS Lambda* avvierà *SageMaker Notebook*, eseguirà il riaddestramento del modello utilizzando i dati dal repository *FSx ONTAP*, ridistribuirà il modello aggiornato nell'ambiente di produzione e arresterà automaticamente l'*istanza di SageMaker Notebook* per ottimizzare i costi.  Ciò garantisce che il modello rimanga aggiornato.</block>
  <block id="0be5bfaeb8f14cd39a235e5050cecbc9" category="paragraph">Si conclude qui il tutorial sullo sviluppo di una pipeline MLOps.</block>
  <block id="fbf39511561166f560c51e6bdf601a0e" category="summary">Questa è la pagina introduttiva alla sezione FSx ONTAP MLOps.</block>
  <block id="28cd7fd0e401ee73677b7f7441149a51" category="doc">Amazon FSx for NetApp ONTAP (FSx ONTAP) per MLOps</block>
  <block id="fba7ee1ae1e1979f64e6e11317d235ff" category="paragraph">Questa sezione approfondisce l'applicazione pratica dello sviluppo dell'infrastruttura AI, fornendo una guida completa alla costruzione di una pipeline MLOps utilizzando FSx ONTAP.  Composto da tre esempi esaustivi, ti guida a soddisfare le tue esigenze MLOps tramite questa potente piattaforma di gestione dei dati.</block>
  <block id="e2e58416305212ecee9fc44a8a57e389" category="paragraph">Questi articoli si concentrano su:</block>
  <block id="a4f6db8ee799d71c8436c5d66421c857" category="list-text"><block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block></block>
  <block id="3f7fd29e3ed2add54c00cc8c8501cde7" category="list-text"><block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block></block>
  <block id="71b4f7c054c855f2e85df08fc5e39095" category="list-text"><block ref="71b4f7c054c855f2e85df08fc5e39095" category="inline-link-macro-rx"></block></block>
  <block id="8b34d4c412144b306293274a1964c465" category="paragraph">Al termine di questa sezione, avrai acquisito una solida comprensione di come utilizzare FSx ONTAP per semplificare i processi MLOps.</block>
  <block id="f3be583adfbfc01a44597d4c6f7e4ef5" category="summary">Questo post fornisce una guida sulla configurazione di FSx ONTAP come bucket S3 privato utilizzando AWS SageMaker.</block>
  <block id="405642837c20faf5ee6d81b4d039206f" category="paragraph">Questa sezione fornisce una guida sulla configurazione di FSx ONTAP come bucket S3 privato utilizzando AWS SageMaker.</block>
  <block id="8c52c9bdd7d9ef6a6f82004af97fae7b" category="paragraph">Utilizzando SageMaker come esempio, questa pagina fornisce indicazioni sulla configurazione di FSx ONTAP come bucket S3 privato.</block>
  <block id="69620f6919f430e72c0f67207535605b" category="inline-link-macro">Collegamento video</block>
  <block id="2b6442845e4dd1bf2e9140ac796e1a93" category="paragraph">Per maggiori informazioni su FSx ONTAP, dai un'occhiata a questa presentazione (<block ref="f781ab67717d91cabffd32c6ef2dd731" category="inline-link-macro-rx"></block> )</block>
  <block id="7a97419a6312bf2f5dcdb87d844f3d07" category="section-title">Guida per l'utente</block>
  <block id="2f5513954af7462427835c65fbeeac6d" category="section-title">Creazione del server</block>
  <block id="aa5fe14483191172e4fb6ae032e063db" category="section-title">Creare un'istanza di SageMaker Notebook</block>
  <block id="22a9741b15ba6b8515c1bcf1eb1e2424" category="list-text">Apri la console AWS.  Nel pannello di ricerca, cerca SageMaker e clicca sul servizio *Amazon SageMaker*.</block>
  <block id="f81ad91c4e9a7e4840e3c7a28ad316cb" category="inline-image-macro">Apri la console AWS</block>
  <block id="91ff4fb5f0a57e0f0b2c24cdefb4f12b" category="paragraph"><block ref="91ff4fb5f0a57e0f0b2c24cdefb4f12b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b8d9a34ee98c3b1e7231bdb38a022c7" category="list-text">Aprire le *Istanze del notebook* nella scheda Notebook, fare clic sul pulsante arancione *Crea istanza del notebook*.</block>
  <block id="519925d609277093d7d2ace0457f720a" category="inline-image-macro">Console dell'istanza AWS SageMaker Notebook</block>
  <block id="d8d17e525889b2a89d32645cb06938f6" category="paragraph"><block ref="d8d17e525889b2a89d32645cb06938f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b070f651df156f54539ea886d6fdb252" category="list-text">Nella pagina di creazione, inserisci il *Nome dell'istanza del notebook*. Espandi il pannello *Rete*. Lascia le altre voci predefinite e seleziona una *VPC*, una *Subnet* e un *Gruppo/i di sicurezza*.  (Questa *VPC* e *Subnet* verranno utilizzate in seguito per creare il file system FSx ONTAP ) Fare clic sul pulsante arancione *Crea istanza notebook* in basso a destra.</block>
  <block id="02ca97619a6b22b9a2f189b3ebb82b57" category="inline-image-macro">Crea istanza del notebook</block>
  <block id="39578328ea9c3b8e5a35ce1c48b45447" category="paragraph"><block ref="39578328ea9c3b8e5a35ce1c48b45447" category="inline-image-macro-rx" type="image"></block></block>
  <block id="08bf44c8870f044a9c29ec0decd4506f" category="section-title">Creare un file system FSx ONTAP</block>
  <block id="a0de53cada8c076391cb766a21d191f7" category="list-text">Apri la console AWS.  Nel pannello di ricerca, cerca Fsx e clicca sul servizio *FSx*.</block>
  <block id="f815343e909cc0c69784c51630a10b2d" category="inline-image-macro">Pannello FSx</block>
  <block id="eb780b87d03905721f4484288ab2cde0" category="paragraph"><block ref="eb780b87d03905721f4484288ab2cde0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55ecf05d044f8d3b179ea6daf134664f" category="list-text">Fare clic su *Crea file system*.</block>
  <block id="77d148bb10790640cfe7639dbc11e075" category="inline-image-macro">Crea file system</block>
  <block id="af10909a9067ddaba9079a1b5b37ca6d" category="paragraph"><block ref="af10909a9067ddaba9079a1b5b37ca6d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83c8e65862a92cd7eadb9812c8c5f780" category="list-text">Selezionare la prima scheda *FSx ONTAP* e fare clic su *Avanti*.</block>
  <block id="6277f28f413aee819a82e3e0058bc5ee" category="inline-image-macro">Seleziona il tipo di file system</block>
  <block id="03ad22f430d1bae0e9c295ff4191eac1" category="paragraph"><block ref="03ad22f430d1bae0e9c295ff4191eac1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b05d3465523c46c6ece6e36ff05bba" category="list-text">Nella pagina di configurazione dei dettagli.</block>
  <block id="720e4d0907f5f98d25c99b23a410c93c" category="list-text">Selezionare l'opzione *Creazione standard*.</block>
  <block id="fb23d0162f70b1382f3c50cb5b513f4d" category="inline-image-macro">Crea pannello file system</block>
  <block id="69ff48a0fa8eb8c1e7999c1ff581fe73" category="paragraph"><block ref="69ff48a0fa8eb8c1e7999c1ff581fe73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bea7f738749e0c476b2d1c016021ec5b" category="list-text">Immettere il *Nome del file system* e la *Capacità di archiviazione SSD*.</block>
  <block id="aad9529851b728c0fb560a0f7d9b8a5b" category="inline-image-macro">Specificare i dettagli del file system</block>
  <block id="1c15f13ef7a0d9e6720f0178a39c5dde" category="paragraph"><block ref="1c15f13ef7a0d9e6720f0178a39c5dde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5db4aeb81b94a1ba5cdcc12c96b36cb1" category="list-text">Assicurarsi di utilizzare la *VPC* e la *subnet* identiche per l'istanza di *SageMaker Notebook*.</block>
  <block id="84e88a3298035d04334f19541c31a16a" category="inline-image-macro">Configurazione di rete e sicurezza</block>
  <block id="3788a93ec701a347dfa0def01330fa09" category="paragraph"><block ref="1832dc909b2a82e8c4b70afb493963cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb695bdcb362931108f41ff0ec65293" category="list-text">Inserisci il nome della *macchina virtuale di archiviazione* e *specifica una password* per la tua SVM (macchina virtuale di archiviazione).</block>
  <block id="691a3c3a3ffee99887addcf66bcceeec" category="inline-image-macro">Configurazione predefinita della macchina virtuale di archiviazione</block>
  <block id="68cc70fed3a17a1a1caec811e0d01f03" category="paragraph"><block ref="68cc70fed3a17a1a1caec811e0d01f03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4c7ba1524cf2b18e8592e9ceb83df71" category="list-text">Lascia le altre voci predefinite e clicca sul pulsante arancione *Avanti* in basso a destra.</block>
  <block id="38f46900c7e5018a4d712fad6dde98ea" category="inline-image-macro">Conferma la configurazione</block>
  <block id="c715f26fb866d18303643cfaf886a63c" category="paragraph"><block ref="c715f26fb866d18303643cfaf886a63c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d5ce0306761971a734da357efdf9e6f" category="list-text">Fare clic sul pulsante arancione *Crea file system* in basso a destra nella pagina di revisione.</block>
  <block id="c0e0aca15b43c5f4360b8e6c8f2451d9" category="inline-image-macro">Rivedere la configurazione e confermare la creazione</block>
  <block id="29fe6a20d375efc9f6e4ae1a07258da3" category="paragraph"><block ref="29fe6a20d375efc9f6e4ae1a07258da3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c12346192a59739b1315d8d07143db6e" category="list-text">Potrebbero essere necessari circa *20-40 minuti* per avviare il file system FSx.</block>
  <block id="391b09977b768e724f35dad726f1f3ef" category="inline-image-macro">Ispezionare la console FSx</block>
  <block id="37f274b71add0d0952db64f7c20abd4f" category="paragraph"><block ref="37f274b71add0d0952db64f7c20abd4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01ecbbb2b353cf4d915bbe1c1cd5505c" category="section-title">Configurazione del server</block>
  <block id="d36647d06b353fcd6fedc60898e43187" category="section-title">Configurazione ONTAP</block>
  <block id="07afa2af969623c48103624cdb58551c" category="list-text">Aprire il file system FSx creato.  Assicurati che lo stato sia *Disponibile*.</block>
  <block id="69d4f895c19503f5e9f518c3b74993bb" category="inline-image-macro">Attendi la creazione del backend</block>
  <block id="a29e057394c30462c97d0a046428ccc6" category="paragraph"><block ref="a29e057394c30462c97d0a046428ccc6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6cbcfc771dc80f5ee77c4deba078b135" category="list-text">Selezionare la scheda *Amministrazione* e mantenere *Endpoint di gestione - Indirizzo IP* e *Nome utente amministratore ONTAP *.</block>
  <block id="a63e6273ab6f9d27c79b63c3e31a3f35" category="inline-image-macro">Console dei dettagli del file system</block>
  <block id="3a0eb32361b0c7bfba5fc5c8da00fec5" category="paragraph"><block ref="3a0eb32361b0c7bfba5fc5c8da00fec5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0164aebedfb5a99b6386ba01ffbc963" category="list-text">Aprire l'istanza *SageMaker Notebook* creata e fare clic su *Apri JupyterLab*.</block>
  <block id="5f42fc26006705fa3b9ffe25fe3d881d" category="inline-image-macro">Console dell'istanza AWS SageMaker Notebook</block>
  <block id="85c4a421924bf2d8fbb4d65b5fcd0317" category="paragraph"><block ref="85c4a421924bf2d8fbb4d65b5fcd0317" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12dbc394c66b065a1aef771f11914dad" category="list-text">Nella pagina Jupyter Lab, apri un nuovo *Terminale*.</block>
  <block id="f3970717b786c14ff186b01681be062f" category="inline-image-macro">Pagina di benvenuto di Jupyter Lab</block>
  <block id="6774664dc7058399d3db96209da79e83" category="paragraph"><block ref="6774664dc7058399d3db96209da79e83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ad2ec02537c0b93a2b5a7937ea89048" category="list-text">Immettere il comando ssh ssh &lt;nome utente amministratore&gt;@&lt; IP server ONTAP &gt; per accedere al file system FSx ONTAP .  (Il nome utente e l'indirizzo IP vengono recuperati dal passaggio 2) Utilizzare la password utilizzata durante la creazione della *macchina virtuale di archiviazione*.</block>
  <block id="7d71a86e3b4885ad307f3e18ba62c9cb" category="inline-image-macro">Terminale Jupyter Lab</block>
  <block id="3907af7edeccc904e748efdec97a698b" category="paragraph"><block ref="3907af7edeccc904e748efdec97a698b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7fe5b2fa5a8ec0c7d2b2e65bce4c302" category="list-text">Eseguire i comandi nel seguente ordine.  Utilizziamo *fsxn-ontap* come nome per il *nome del bucket S3 privato FSx ONTAP *.  Utilizzare *nome della macchina virtuale di archiviazione* per l'argomento *-vserver*.</block>
  <block id="9166665a24ce86a4cdc78ee5dc10b99e" category="inline-image-macro">Uscita del terminale Jupyter Lab</block>
  <block id="f953d25a23501b488d1729dde1bcbfec" category="paragraph"><block ref="f953d25a23501b488d1729dde1bcbfec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09b48d43c330baa7527d4d5b785ddc78" category="list-text">Eseguire i comandi seguenti per recuperare l'IP dell'endpoint e le credenziali per FSx ONTAP privato S3.</block>
  <block id="1025c82e986534d7a6a941036fce2afd" category="list-text">Conservare l'IP e le credenziali dell'endpoint per un utilizzo futuro.</block>
  <block id="8d5111b0ef521165f30cc6043e79b8b4" category="paragraph"><block ref="8d5111b0ef521165f30cc6043e79b8b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb11dcb3b0575af26386e753c028e37d" category="section-title">Configurazione del client</block>
  <block id="d885926aec2cdf1253c078102968eb8d" category="list-text">Nell'istanza di SageMaker Notebook, crea un nuovo notebook Jupyter.</block>
  <block id="6aa1a9a77e640f5f5edc06a932b6ed8a" category="inline-image-macro">Apri un nuovo notebook Jupyter</block>
  <block id="28f138d5d6604c9e1a6788b166239c3f" category="paragraph"><block ref="28f138d5d6604c9e1a6788b166239c3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e248de3aba6cefa5adacaaee03aaa6e8" category="inline-link-macro">fsxn_demo.ipynb</block>
  <block id="3161057d478204432fe5225e86346e57" category="list-text">Utilizzare il codice seguente come soluzione alternativa per caricare i file nel bucket S3 privato di FSx ONTAP .  Per un esempio di codice completo fare riferimento a questo notebook.<block ref="5926c62f2c3d59c789081e1f0aff3f08" category="inline-link-macro-rx"></block></block>
  <block id="9c715084d36062c3ee5a47d1e528cd94" category="paragraph">Questo conclude l'integrazione tra FSx ONTAP e l'istanza SageMaker.</block>
  <block id="6d8aee76fb8c09877162ad6d9e5fdac9" category="section-title">Lista di controllo utile per il debug</block>
  <block id="c00ea068fc81a9c0fcad0e38fbc7bb94" category="list-text">Assicurarsi che l'istanza di SageMaker Notebook e il file system FSx ONTAP si trovino nella stessa VPC.</block>
  <block id="2ec57b268e910c39ad70e1b259d09e1a" category="list-text">Ricordarsi di eseguire il comando *set dev* su ONTAP per impostare il livello di privilegio su *dev*.</block>
  <block id="5a7d7d5f81481db284cc081576a810b0" category="section-title">FAQ (aggiornato al 27 settembre 2023)</block>
  <block id="de9370dee0783c12eee2dcba49377c0c" category="paragraph">D: Perché ricevo l'errore "*Si è verificato un errore (NotImplemented) durante la chiamata dell'operazione CreateMultipartUpload: il comando s3 richiesto non è implementato*" quando carico file su FSx ONTAP?</block>
  <block id="b17f3ba7d3e19cd555784a4d2fd9e51b" category="paragraph">R: In quanto bucket S3 privato, FSx ONTAP supporta il caricamento di file fino a 100 MB.  Quando si utilizza il protocollo S3, i file più grandi di 100 MB vengono divisi in blocchi da 100 MB e viene chiamata la funzione 'CreateMultipartUpload'.  Tuttavia, l'attuale implementazione di FSx ONTAP private S3 non supporta questa funzione.</block>
  <block id="89551e14b23206a9d9d14f16530fc28d" category="paragraph">D: Perché ricevo l'errore "*Si è verificato un errore (Accesso negato) durante la chiamata delle operazioni PutObject: Accesso negato*" quando carico file su FSx ONTAP?</block>
  <block id="21ba2b927703c559d6b74e6dbc961ebb" category="paragraph">R: Per accedere al bucket S3 privato FSx ONTAP da un'istanza di SageMaker Notebook, sostituire le credenziali AWS con le credenziali FSx ONTAP .  Tuttavia, per concedere l'autorizzazione di scrittura all'istanza è necessaria una soluzione alternativa che prevede il montaggio del bucket e l'esecuzione del comando shell 'chmod' per modificare le autorizzazioni.</block>
  <block id="a713cfa91c4b5642352b00e081eca0ce" category="paragraph">D: Come posso integrare il bucket S3 privato FSx ONTAP con altri servizi SageMaker ML?</block>
  <block id="eae99a039ae09d5e28c061d7218d0efb" category="paragraph">R: Purtroppo, l'SDK dei servizi SageMaker non fornisce un modo per specificare l'endpoint per il bucket S3 privato.  Di conseguenza, FSx ONTAP S3 non è compatibile con i servizi SageMaker quali Sagemaker Data Wrangler, Sagemaker Clarify, Sagemaker Glue, Sagemaker Athena, Sagemaker AutoML e altri.</block>
  <block id="7892d93cdad4bcd1c3e8157592ed858e" category="summary">L'articolo è un tutorial sull'utilizzo di Amazon FSx for NetApp ONTAP (FSx ONTAP) per l'addestramento di modelli PyTorch in SageMaker, in particolare per un progetto di classificazione della qualità degli pneumatici.</block>
  <block id="ecccb638c3da2e33f2ce538fc895233a" category="doc">Parte 2 - Utilizzo di AWS Amazon FSx for NetApp ONTAP (FSx ONTAP) come origine dati per l'addestramento del modello in SageMaker</block>
  <block id="ca3ef01192dfa69eac50d8be997f6b51" category="paragraph">Questo articolo è un tutorial sull'utilizzo di Amazon FSx for NetApp ONTAP (FSx ONTAP) per l'addestramento di modelli PyTorch in SageMaker, in particolare per un progetto di classificazione della qualità degli pneumatici.</block>
  <block id="23851f05df4c2ebe4433cd559cf23e55" category="paragraph">Questo tutorial offre un esempio pratico di un progetto di classificazione della visione artificiale, fornendo un'esperienza pratica nella creazione di modelli di apprendimento automatico che utilizzano FSx ONTAP come origine dati all'interno dell'ambiente SageMaker.  Il progetto si concentra sull'utilizzo di PyTorch, un framework di deep learning, per classificare la qualità degli pneumatici in base alle immagini degli stessi.  Si concentra sullo sviluppo di modelli di apprendimento automatico utilizzando FSx ONTAP come origine dati in Amazon SageMaker.</block>
  <block id="516bec227f44816f7ecc2d58aae01bb2" category="section-title">Che cos'è FSx ONTAP</block>
  <block id="e586360cf616ba9b2800383d7e36b444" category="paragraph">Amazon FSx ONTAP è effettivamente una soluzione di storage completamente gestita offerta da AWS.  Sfrutta il file system ONTAP di NetApp per fornire uno storage affidabile e ad alte prestazioni.  Grazie al supporto di protocolli come NFS, SMB e iSCSI, consente un accesso senza interruzioni da diverse istanze di elaborazione e container.  Il servizio è progettato per offrire prestazioni eccezionali, garantendo operazioni sui dati rapide ed efficienti.  Offre inoltre elevata disponibilità e durabilità, garantendo che i tuoi dati rimangano accessibili e protetti.  Inoltre, la capacità di archiviazione di Amazon FSx ONTAP è scalabile, consentendoti di adattarla facilmente in base alle tue esigenze.</block>
  <block id="05ec336213c5aa3c3a49c743c5fbad19" category="section-title">Ambiente di rete</block>
  <block id="9e7ee35cf251304984a47d590762e1d2" category="inline-image-macro">Ambiente di rete</block>
  <block id="8ebf7b35e6a40f5a75092ae4b590f9d1" category="paragraph"><block ref="8ebf7b35e6a40f5a75092ae4b590f9d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a431daf3a478d96ed5ffc10a4056228" category="paragraph">FSx ONTAP (Amazon FSx ONTAP) è un servizio di archiviazione AWS.  Include un file system in esecuzione sul sistema NetApp ONTAP e una macchina virtuale (SVM) gestita da AWS che si connette ad esso.  Nel diagramma fornito, il server NetApp ONTAP gestito da AWS si trova all'esterno della VPC.  L'SVM funge da intermediario tra SageMaker e il sistema NetApp ONTAP , ricevendo le richieste operative da SageMaker e inoltrandole allo storage sottostante.  Per accedere a FSx ONTAP, SageMaker deve essere posizionato nella stessa VPC della distribuzione FSx ONTAP .  Questa configurazione garantisce la comunicazione e l'accesso ai dati tra SageMaker e FSx ONTAP.</block>
  <block id="f8aacfa5c683858912c498f517c9b457" category="section-title">Accesso ai dati</block>
  <block id="70385d02db6379c01d4b7b17101f2004" category="paragraph">In scenari reali, gli scienziati dei dati in genere utilizzano i dati esistenti archiviati in FSx ONTAP per creare i loro modelli di apprendimento automatico.  Tuttavia, a scopo dimostrativo, poiché il file system FSx ONTAP è inizialmente vuoto dopo la creazione, è necessario caricare manualmente i dati di addestramento.  Ciò può essere ottenuto montando FSx ONTAP come volume su SageMaker.  Una volta montato correttamente il file system, puoi caricare il tuo set di dati nella posizione montata, rendendolo accessibile per l'addestramento dei tuoi modelli nell'ambiente SageMaker.  Questo approccio consente di sfruttare la capacità di archiviazione e le funzionalità di FSx ONTAP mentre si lavora con SageMaker per lo sviluppo e la formazione dei modelli.</block>
  <block id="23ea498668d1fa717fb7cfb600bf3238" category="inline-link-macro">Parte 1 - Integrazione di Amazon FSx for NetApp ONTAP (FSx ONTAP)) come bucket S3 privato in AWS SageMaker</block>
  <block id="95d89db7f4a106e280e1c30cde658610" category="paragraph">Il processo di lettura dei dati prevede la configurazione di FSx ONTAP come bucket S3 privato.  Per apprendere le istruzioni di configurazione dettagliate, fare riferimento a<block ref="8e7379c67a0724b1a49308a7ae6ac3d5" category="inline-link-macro-rx"></block></block>
  <block id="30eaeebc8f9611f55e018d1dd51789ba" category="section-title">Panoramica sull'integrazione</block>
  <block id="7ffc912d31a398685c5667622bb5ed7f" category="inline-image-macro">Flusso di lavoro di formazione</block>
  <block id="29e5f040e75c8e4e628e90efc594e3ef" category="paragraph"><block ref="29e5f040e75c8e4e628e90efc594e3ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da4169484addf29c5d1d35a28a5073fd" category="paragraph">Il flusso di lavoro per l'utilizzo dei dati di training in FSx ONTAP per creare un modello di deep learning in SageMaker può essere riassunto in tre passaggi principali: definizione del caricatore dati, training del modello e distribuzione.  Ad alto livello, questi passaggi costituiscono la base di una pipeline MLOps.  Tuttavia, ogni fase prevede diversi sotto-fasi dettagliati per un'implementazione completa.  Questi sotto-passaggi comprendono varie attività, quali la pre-elaborazione dei dati, la suddivisione del set di dati, la configurazione del modello, l'ottimizzazione degli iperparametri, la valutazione del modello e l'implementazione del modello.  Questi passaggi garantiscono un processo completo ed efficace per la creazione e l'implementazione di modelli di deep learning utilizzando i dati di training di FSx ONTAP all'interno dell'ambiente SageMaker.</block>
  <block id="2870e83ec05413b09bc7de07f60f54fa" category="section-title">Integrazione passo dopo passo</block>
  <block id="e3364bc8e125077137411ae17c13b771" category="section-title">Loader dati</block>
  <block id="220b880a3d218e80d8fde5901827649a" category="paragraph">Per addestrare una rete di deep learning PyTorch con i dati, viene creato un caricatore di dati per facilitare l'alimentazione dei dati.  Il caricatore dati non solo definisce la dimensione del batch, ma determina anche la procedura per la lettura e la preelaborazione di ciascun record all'interno del batch.  Configurando il caricatore di dati, possiamo gestire l'elaborazione dei dati in batch, consentendo l'addestramento della rete di deep learning.</block>
  <block id="cc0322e5278f21d6001e3995e46e2810" category="paragraph">Il caricatore dati è composto da 3 parti.</block>
  <block id="0cee527e2a952dcfca00fb6de192e2a1" category="section-title">Funzione di pre-elaborazione</block>
  <block id="50a46eb952358276ed306b6d88aadc7d" category="paragraph">Il frammento di codice sopra riportato illustra la definizione delle trasformazioni di pre-elaborazione delle immagini utilizzando il modulo *torchvision.transforms*.  In questo tutorial, l'oggetto preprocess viene creato per applicare una serie di trasformazioni.  Innanzitutto, la trasformazione *ToTensor()* converte l'immagine in una rappresentazione tensoriale.  Successivamente, la trasformazione *Resize((224,224))* ridimensiona l'immagine a una dimensione fissa di 224x224 pixel.  Infine, la trasformazione *Normalize()* normalizza i valori del tensore sottraendo la media e dividendo per la deviazione standard lungo ciascun canale.  I valori di media e deviazione standard utilizzati per la normalizzazione sono comunemente impiegati nei modelli di reti neurali pre-addestrati.  Nel complesso, questo codice prepara i dati dell'immagine per un'ulteriore elaborazione o per l'inserimento in un modello pre-addestrato, convertendoli in un tensore, ridimensionandoli e normalizzando i valori dei pixel.</block>
  <block id="578a55cb1cfe6e1363a1c73fec7d9c6f" category="section-title">La classe del set di dati PyTorch</block>
  <block id="7895a195c178ff4c5e59638a3c762dd2" category="paragraph">Questa classe fornisce funzionalità per ottenere il numero totale di record nel set di dati e definisce il metodo per leggere i dati per ciascun record.  All'interno della funzione *__getitem__*, il codice utilizza l'oggetto bucket S3 boto3 per recuperare i dati binari da FSx ONTAP.  Lo stile del codice per l'accesso ai dati da FSx ONTAP è simile a quello per la lettura dei dati da Amazon S3.  La spiegazione successiva approfondisce il processo di creazione dell'oggetto S3 privato *bucket*.</block>
  <block id="76d805ebfad939474c22611b1a64ec91" category="section-title">FSx ONTAP come repository S3 privato</block>
  <block id="3d67de2c700f42063d686e92a37a82aa" category="paragraph">Per leggere i dati da FSx ONTAP in SageMaker, viene creato un gestore che punta allo storage FSx ONTAP utilizzando il protocollo S3.  Ciò consente di trattare FSx ONTAP come un bucket S3 privato.  La configurazione del gestore include la specifica dell'indirizzo IP dell'SVM FSx ONTAP , del nome del bucket e delle credenziali necessarie.  Per una spiegazione completa su come ottenere questi elementi di configurazione, fare riferimento al documento all'indirizzo<block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block> .</block>
  <block id="ac5d6406e8dadcbc23e9cf65fe528510" category="paragraph">Nell'esempio menzionato sopra, l'oggetto bucket viene utilizzato per istanziare l'oggetto dataset PyTorch.  L'oggetto dataset verrà spiegato più dettagliatamente nella sezione successiva.</block>
  <block id="e03717a5c1692689919250506bf382a0" category="section-title">Il Loader dati PyTorch</block>
  <block id="0c919f2bf87f2c6df41e7bbc52c68d04" category="paragraph">Nell'esempio fornito, viene specificata una dimensione batch pari a 64, a indicare che ogni batch conterrà 64 record.  Combinando la classe PyTorch *Dataset*, la funzione di pre-elaborazione e la dimensione del batch di addestramento, otteniamo il caricatore di dati per l'addestramento.  Questo caricatore di dati semplifica il processo di iterazione del set di dati in batch durante la fase di addestramento.</block>
  <block id="74415cec8ae4d65c228c7fa8da8eae8a" category="section-title">Formazione del modello</block>
  <block id="74492eb8210f5168d9ee3eff7524ecde" category="paragraph">Questo codice implementa un processo di addestramento PyTorch standard.  Definisce un modello di rete neurale denominato *TyreQualityClassifier* che utilizza livelli convoluzionali e un livello lineare per classificare la qualità degli pneumatici.  Il ciclo di addestramento esegue iterazioni su batch di dati, calcola la perdita e aggiorna i parametri del modello utilizzando la backpropagation e l'ottimizzazione.  Inoltre, stampa l'ora corrente, l'epoca, il lotto e la perdita a scopo di monitoraggio.</block>
  <block id="4d2e185dfba9f3df542300054ad07998" category="section-title">Distribuzione del modello</block>
  <block id="6116a0f9a85671aec95cc56a205cf186" category="paragraph">Il codice salva il modello PyTorch su *Amazon S3* perché SageMaker richiede che il modello venga archiviato in S3 per la distribuzione.  Caricando il modello su *Amazon S3*, questo diventa accessibile a SageMaker, consentendo la distribuzione e l'inferenza sul modello distribuito.</block>
  <block id="075e4fb3d67ee1fb4bc39dbc5d72b129" category="paragraph">Questo codice facilita l'implementazione di un modello PyTorch su SageMaker.  Definisce un serializzatore personalizzato, *TyreQualitySerializer*, che preelabora e serializza i dati di input come un tensore PyTorch.  La classe *TyreQualityPredictor* è un predittore personalizzato che utilizza il serializzatore definito e un *JSONDeserializer*.  Il codice crea anche un oggetto *PyTorchModel* per specificare la posizione S3 del modello, il ruolo IAM, la versione del framework e il punto di ingresso per l'inferenza.  Il codice genera un timestamp e costruisce un nome di endpoint basato sul modello e sul timestamp.  Infine, il modello viene distribuito utilizzando il metodo deploy, specificando il conteggio delle istanze, il tipo di istanza e il nome dell'endpoint generato.  Ciò consente di distribuire il modello PyTorch e di renderlo accessibile per l'inferenza su SageMaker.</block>
  <block id="bfc7647fbfe6e589911d2da73377b475" category="section-title">Inferenza</block>
  <block id="99e1766840e675b2dbd8230be049188f" category="paragraph">Questo è un esempio di utilizzo dell'endpoint distribuito per eseguire l'inferenza.</block>
  <block id="727c63651b565bca2eb7d8a48e0fefd9" category="summary">Questa sezione riassume il documento riguardante le soluzioni di storage NetApp per Apache Spark.</block>
  <block id="6f8b794f3246b0c1e1780bb4d4d5dc53" category="doc">Conclusione</block>
  <block id="900200cfc3f2577215c327d16f34840a" category="paragraph">In questo documento, analizziamo l'architettura di Apache Spark, i casi d'uso dei clienti e il portfolio di storage NetApp in relazione a big data, analisi moderne, intelligenza artificiale, apprendimento automatico e apprendimento automatico (ML) e apprendimento automatico (DL).  Nei nostri test di convalida delle prestazioni basati su strumenti di benchmarking standard del settore e sulla domanda dei clienti, le soluzioni NetApp Spark hanno dimostrato prestazioni superiori rispetto ai sistemi Hadoop nativi.  Una combinazione dei casi d'uso dei clienti e dei risultati delle prestazioni presentati in questo report può aiutarti a scegliere la soluzione Spark più adatta alla tua implementazione.</block>
  <block id="ca052b24845534e817869836d49d519a" category="summary">Questo documento si concentra sull'architettura di Apache Spark, sui casi d'uso dei clienti e sul portafoglio di storage NetApp correlato all'analisi dei big data e all'intelligenza artificiale.  Presenta inoltre vari risultati di test effettuati utilizzando strumenti di intelligenza artificiale, apprendimento automatico e apprendimento profondo standard del settore su un tipico sistema Hadoop, in modo da poter scegliere la soluzione Spark più adatta.</block>
  <block id="58b2293adcda372fb415412d23f01a8e" category="doc">TR-4570: Soluzioni di storage NetApp per Apache Spark: architettura, casi d'uso e risultati delle prestazioni</block>
  <block id="057e5f9ddc5d049ab86855dceffd6d14" category="paragraph">Rick Huang, Karthikeyan Nagalingam, NetApp</block>
  <block id="550fd771b94cb8eb3739d16af31243f3" category="paragraph">Questo documento si concentra sull'architettura di Apache Spark, sui casi d'uso dei clienti e sul portafoglio di storage NetApp correlato all'analisi dei big data e all'intelligenza artificiale (IA).  Presenta inoltre vari risultati di test effettuati utilizzando strumenti di intelligenza artificiale, apprendimento automatico (ML) e apprendimento profondo (DL) standard del settore su un tipico sistema Hadoop, in modo da poter scegliere la soluzione Spark più adatta.  Per iniziare, hai bisogno di un'architettura Spark, di componenti appropriati e di due modalità di distribuzione (cluster e client).</block>
  <block id="9e19cfda234e917201ce19469f25275b" category="paragraph">Questo documento fornisce inoltre casi d'uso dei clienti per risolvere problemi di configurazione e fornisce una panoramica del portafoglio di storage NetApp rilevante per l'analisi dei big data e l'intelligenza artificiale, l'apprendimento automatico e il apprendimento automatico con Spark.  Concludiamo quindi con i risultati dei test derivati dai casi d'uso specifici di Spark e dal portafoglio di soluzioni NetApp Spark.</block>
  <block id="d4612e7dc1347f1ccbfd5e470dda2295" category="section-title">Sfide dei clienti</block>
  <block id="ce663ffc6a85b2c97e60368b5a9c76e3" category="paragraph">Questa sezione si concentra sulle sfide dei clienti relative all'analisi dei big data e all'intelligenza artificiale, al machine learning e al digital learning nei settori in cui i dati crescono, come la vendita al dettaglio, il marketing digitale, il settore bancario, la produzione discreta, la produzione di processo, la pubblica amministrazione e i servizi professionali.</block>
  <block id="8a5bab0d8f4c0d1b73de5ada6b1c91e6" category="section-title">Prestazioni imprevedibili</block>
  <block id="9790dc49aa09b4759e4c6ebc65fb4c42" category="paragraph">Le distribuzioni Hadoop tradizionali utilizzano in genere hardware di base.  Per migliorare le prestazioni, è necessario ottimizzare la rete, il sistema operativo, il cluster Hadoop, i componenti dell'ecosistema come Spark e l'hardware.  Anche se si ottimizza ogni livello, può essere difficile raggiungere i livelli di prestazioni desiderati perché Hadoop viene eseguito su hardware di base che non è stato progettato per prestazioni elevate nel tuo ambiente.</block>
  <block id="b496a0269649d7b570c2052646fd23b6" category="section-title">Guasti dei media e dei nodi</block>
  <block id="21af95409591262fb36555acb96262d8" category="paragraph">Anche in condizioni normali, l'hardware di base è soggetto a guasti.  Se un disco su un nodo dati si guasta, per impostazione predefinita il master Hadoop considera quel nodo non funzionante.  Quindi copia dati specifici da quel nodo attraverso la rete dalle repliche a un nodo sano.  Questo processo rallenta i pacchetti di rete per qualsiasi attività Hadoop.  Il cluster deve quindi copiare nuovamente i dati e rimuovere i dati sovrareplicati quando il nodo non funzionante torna a uno stato funzionante.</block>
  <block id="03d4836e0d1deb07679d400b8c88a880" category="section-title">Blocco del fornitore Hadoop</block>
  <block id="bb33286c56b053ae85ab21a377bd4347" category="paragraph">I distributori Hadoop dispongono di una propria distribuzione Hadoop con il proprio controllo delle versioni, che vincola il cliente a tali distribuzioni.  Tuttavia, molti clienti necessitano di supporto per l'analisi in memoria che non vincoli il cliente a specifiche distribuzioni Hadoop.  Hanno bisogno della libertà di modificare le distribuzioni e continuare a portare con sé le proprie analisi.</block>
  <block id="a940c960f38c44b75bf1da78215690c2" category="section-title">Mancanza di supporto per più di una lingua</block>
  <block id="65a27ee7da3f8c68004d31f60ab65e55" category="paragraph">Oltre ai programmi MapReduce Java, spesso i clienti necessitano del supporto per più lingue per eseguire i loro lavori.  Opzioni come SQL e script offrono maggiore flessibilità per ottenere risposte, più possibilità per organizzare e recuperare i dati e modi più rapidi per spostare i dati in un framework di analisi.</block>
  <block id="f3e2f69098f73bd8bb3cf61330433955" category="section-title">Difficoltà d'uso</block>
  <block id="e2bdfb6bb3e956b38b6aacde957996df" category="paragraph">Da un po' di tempo le persone si lamentano della difficoltà di utilizzo di Hadoop.  Sebbene Hadoop sia diventato più semplice e potente con ogni nuova versione, questa critica persiste.  Hadoop richiede la conoscenza dei modelli di programmazione Java e MapReduce, una sfida per gli amministratori di database e per chi ha competenze di scripting tradizionali.</block>
  <block id="5f5f8f99cf4c6ebc0b81445be5328bf6" category="section-title">Framework e strumenti complicati</block>
  <block id="74faacaf156cd022099bed5469595b3e" category="paragraph">I team di intelligenza artificiale delle aziende devono affrontare molteplici sfide.  Anche con conoscenze specialistiche in materia di data science, gli strumenti e i framework per diversi ecosistemi di distribuzione e applicazioni potrebbero non essere facilmente traducibili dall'uno all'altro.  Una piattaforma di data science dovrebbe integrarsi perfettamente con le corrispondenti piattaforme big data basate su Spark, con facilità di spostamento dei dati, modelli riutilizzabili, codice pronto all'uso e strumenti che supportano le migliori pratiche per la prototipazione, la convalida, il controllo delle versioni, la condivisione, il riutilizzo e la rapida distribuzione dei modelli in produzione.</block>
  <block id="067be0651f3de8fd60ec45827a4078ed" category="section-title">Perché scegliere NetApp?</block>
  <block id="8ff43bcedde084850831da9cdcc5a43a" category="paragraph">NetApp può migliorare la tua esperienza Spark nei seguenti modi:</block>
  <block id="dc5106ccf618944587be46565f5585cd" category="list-text">L'accesso diretto NFS NetApp (mostrato nella figura sottostante) consente ai clienti di eseguire attività di analisi di big data sui propri dati NFSv3 o NFSv4 nuovi o esistenti senza dover spostare o copiare i dati.  Impedisce la creazione di copie multiple dei dati ed elimina la necessità di sincronizzare i dati con una fonte.</block>
  <block id="38bc62edaebd471500fa64a4758f7f04" category="list-text">Archiviazione più efficiente e minore replicazione del server.  Ad esempio, la soluzione NetApp E-Series Hadoop richiede due anziché tre repliche dei dati, mentre la soluzione FAS Hadoop richiede un'origine dati ma nessuna replica o copia dei dati.  Le soluzioni di storage NetApp generano inoltre meno traffico tra server.</block>
  <block id="2fc945668748ad0173e63b5db34773e7" category="list-text">Miglioramento del lavoro Hadoop e del comportamento del cluster in caso di guasti di unità e nodi.</block>
  <block id="343500ea6d724fe727d127f6409b86c2" category="list-text">Migliori prestazioni di acquisizione dei dati.</block>
  <block id="109f256618c8d9037bb2cd6cc28f5959" category="inline-image-macro">Configurazioni alternative di Apache Spark.</block>
  <block id="0c0038bcea5bace3c716607bdf5ea55f" category="paragraph"><block ref="0c0038bcea5bace3c716607bdf5ea55f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40771867b1bf0db74b9505757197a17a" category="paragraph">Ad esempio, nel settore finanziario e sanitario, lo spostamento dei dati da un luogo all'altro deve rispettare obblighi di legge, il che non è un compito facile.  In questo scenario, l'accesso diretto NFS NetApp analizza i dati finanziari e sanitari dalla loro posizione originale.  Un altro vantaggio fondamentale è che l'utilizzo dell'accesso diretto NFS NetApp semplifica la protezione dei dati Hadoop mediante l'utilizzo di comandi Hadoop nativi e l'abilitazione di flussi di lavoro di protezione dei dati con il ricco portafoglio di gestione dei dati di NetApp.</block>
  <block id="a9e81b3240a7c1ae64fc23e96c84f4ea" category="paragraph">L'accesso diretto NFS NetApp offre due tipi di opzioni di distribuzione per i cluster Hadoop/Spark:</block>
  <block id="4e8fe573a9fe74b6429508c87337b99b" category="list-text">Per impostazione predefinita, i cluster Hadoop o Spark utilizzano Hadoop Distributed File System (HDFS) per l'archiviazione dei dati e il file system predefinito.  L'accesso diretto a NFS NetApp può sostituire l'HDFS predefinito con l'archiviazione NFS come file system predefinito, consentendo l'analisi diretta sui dati NFS.</block>
  <block id="071998ed00d39b3ff27f5410b196f9cc" category="list-text">In un'altra opzione di distribuzione, l'accesso diretto a NetApp NFS supporta la configurazione di NFS come storage aggiuntivo insieme a HDFS in un singolo cluster Hadoop o Spark.  In questo caso, il cliente può condividere i dati tramite esportazioni NFS e accedervi dallo stesso cluster insieme ai dati HDFS.</block>
  <block id="c1923befca33cfe6cc9ace80af8580b6" category="paragraph">I principali vantaggi dell'utilizzo dell'accesso diretto NFS NetApp includono quanto segue:</block>
  <block id="91221d408b0c171556751f29fb9d8071" category="list-text">Analizzando i dati dalla loro posizione attuale, si evita il compito, dispendioso in termini di tempo e prestazioni, di spostare i dati analitici su un'infrastruttura Hadoop come HDFS.</block>
  <block id="1675635f440b61b7219bf7ed2bb2ed27" category="list-text">Riduzione del numero di repliche da tre a una.</block>
  <block id="16f81b84f137a7a52da9ba8d798af622" category="list-text">Consentire agli utenti di disaccoppiare elaborazione e archiviazione per scalarli in modo indipendente.</block>
  <block id="71946d3c421aea3a8238a481bebe1919" category="list-text">Garantire la protezione dei dati aziendali sfruttando le avanzate funzionalità di gestione dei dati di ONTAP.</block>
  <block id="abebb9b977d736f599ab76c517961b24" category="list-text">Certificazione con la piattaforma dati Hortonworks.</block>
  <block id="3c41c2d3511fa95c83687fae6fb57754" category="list-text">Abilitazione di implementazioni di analisi dei dati ibride.</block>
  <block id="05550a44691e53e07f81616af5d58e20" category="list-text">Riduzione dei tempi di backup sfruttando la capacità multithread dinamica.</block>
  <block id="6a604a825549ac87ecf8a00412ee6365" category="inline-link-macro">TR-4657: Soluzioni dati cloud ibride NetApp - Spark e Hadoop basate sui casi d'uso dei clienti</block>
  <block id="c5153856e4d13c48696624c702620995" category="paragraph">Vedere<block ref="46ae0631eaa2b1a19769e051f280e3cf" category="inline-link-macro-rx"></block> per il backup dei dati Hadoop, il backup e il disaster recovery dal cloud all'ambiente locale, abilitando DevTest sui dati Hadoop esistenti, la protezione dei dati e la connettività multicloud e accelerando i carichi di lavoro di analisi.</block>
  <block id="3100ca44a05fa97ed5f07875f442084e" category="paragraph">Le sezioni seguenti descrivono le capacità di archiviazione importanti per i clienti Spark.</block>
  <block id="da2518ef48c60077e2b2c0be7fed7193" category="section-title">Livelli di archiviazione</block>
  <block id="d9a83ca3a623dce37a2f84027f1495ce" category="paragraph">Grazie alla suddivisione in livelli di archiviazione di Hadoop, è possibile archiviare i file con diversi tipi di archiviazione in base a una policy di archiviazione.  I tipi di archiviazione includono<block ref="27369b3bf4483e8dcfd85ba9a39a947f" prefix=" " category="inline-code"></block> ,<block ref="75e52a0ecfafeda17a34fc60111c1f0b" prefix=" " category="inline-code"></block> ,<block ref="a957a3153eb7126b1c5f8b6aac35de53" prefix=" " category="inline-code"></block> ,<block ref="714f8e54e71566bd1c2e29328288a62c" prefix=" " category="inline-code"></block> ,<block ref="7fc1aa11178f33b4f796d69c73f7f0b4" prefix=" " category="inline-code"></block> , E<block ref="fa4fdcc80e19a0848c6360538fdd86ef" prefix=" " category="inline-code"></block> .</block>
  <block id="c2398745386edbb0221cc4ee496ff79f" category="paragraph">Abbiamo eseguito la convalida della suddivisione in livelli di archiviazione Hadoop su un controller di archiviazione NetApp AFF e un controller di archiviazione E-Series con unità SSD e SAS con diverse policy di archiviazione.  Il cluster Spark con AFF-A800 ha quattro nodi di elaborazione, mentre il cluster con E-Series ne ha otto.  Lo scopo principale è confrontare le prestazioni delle unità a stato solido (SSD) rispetto ai dischi rigidi (HDD).</block>
  <block id="36edc8f5974bdf6ad51a220254b99dfb" category="paragraph">La figura seguente mostra le prestazioni delle soluzioni NetApp per un SSD Hadoop.</block>
  <block id="d09520ed9b4a17ada38e70314907675f" category="inline-image-macro">È il momento di ordinare 1 TB di dati.</block>
  <block id="12b6622989087d668bc9d1da31e9fb70" category="paragraph"><block ref="12b6622989087d668bc9d1da31e9fb70" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2f530d95c6332b106d86a53b41e4a36" category="inline-link">TR-3969 Soluzione NetApp E-Series per Hadoop</block>
  <block id="bd9ad8221382748a4f008c3af02731bd" category="list-text">La configurazione NL-SAS di base utilizzava otto nodi di elaborazione e 96 unità NL-SAS.  Questa configurazione ha generato 1 TB di dati in 4 minuti e 38 secondi.  Vedere<block ref="264d8d379e3a34fdac32f9057509bf65" category="inline-link-rx"></block> per i dettagli sulla configurazione del cluster e dello storage.</block>
  <block id="f895fa75cdc40f4e672bba6f7a873e25" category="list-text">Utilizzando TeraGen, la configurazione SSD ha generato 1 TB di dati 15,66 volte più velocemente rispetto alla configurazione NL-SAS.  Inoltre, la configurazione SSD utilizzava la metà del numero di nodi di elaborazione e la metà del numero di unità disco (24 unità SSD in totale).  In base al tempo di completamento del lavoro, è stato quasi il doppio più veloce della configurazione NL-SAS.</block>
  <block id="459f180fc71a8f8bb773d3c879314e39" category="list-text">Utilizzando TeraSort, la configurazione SSD ha ordinato 1 TB di dati 1138,36 volte più velocemente rispetto alla configurazione NL-SAS.  Inoltre, la configurazione SSD utilizzava la metà del numero di nodi di elaborazione e la metà del numero di unità disco (24 unità SSD in totale).  Pertanto, per unità, era circa tre volte più veloce della configurazione NL-SAS.</block>
  <block id="52be2edb04819f386804af38bd53a55d" category="list-text">La conclusione è che il passaggio dai dischi rotanti a quelli completamente flash migliora le prestazioni.  Il collo di bottiglia non era il numero di nodi di elaborazione.  Grazie allo storage all-flash di NetApp, le prestazioni di runtime sono ben scalabili.</block>
  <block id="8cc25131075ed11b8263304fceebc5c6" category="list-text">Con NFS, i dati erano funzionalmente equivalenti a essere raggruppati tutti insieme, il che può ridurre il numero di nodi di elaborazione a seconda del carico di lavoro.  Gli utenti del cluster Apache Spark non devono ribilanciare manualmente i dati quando cambiano il numero di nodi di elaborazione.</block>
  <block id="c13c2e056adb51078f3067ba570d2780" category="section-title">Scalabilità delle prestazioni - Scalabilità orizzontale</block>
  <block id="beb08cca1e99e0bdbf11c74ebb62d5ea" category="paragraph">Quando è necessaria una maggiore potenza di calcolo da un cluster Hadoop in una soluzione AFF , è possibile aggiungere nodi dati con un numero appropriato di controller di archiviazione.  NetApp consiglia di iniziare con quattro nodi dati per array di controller di storage e di aumentare il numero a otto nodi dati per controller di storage, a seconda delle caratteristiche del carico di lavoro.</block>
  <block id="431bd1a68814e184bc49ff7231450049" category="paragraph">AFF e FAS sono perfetti per l'analisi in loco.  In base ai requisiti di calcolo, è possibile aggiungere gestori di nodi e le operazioni non disruptive consentono di aggiungere un controller di storage su richiesta senza tempi di inattività.  Offriamo funzionalità avanzate con AFF e FAS, come supporto multimediale NVME, efficienza garantita, riduzione dei dati, QOS, analisi predittiva, cloud tiering, replicazione, distribuzione cloud e sicurezza.  Per aiutare i clienti a soddisfare le loro esigenze, NetApp offre funzionalità quali analisi del file system, quote e bilanciamento del carico integrato, senza costi di licenza aggiuntivi.  NetApp offre prestazioni migliori in termini di numero di processi contemporanei, latenza inferiore, operazioni più semplici e throughput di gigabyte al secondo più elevato rispetto ai nostri concorrenti.  Inoltre, NetApp Cloud Volumes ONTAP è compatibile con tutti e tre i principali provider cloud.</block>
  <block id="ccfed4ad520d8db8b13dc91438d30680" category="section-title">Scalabilità delle prestazioni - Scalabilità verticale</block>
  <block id="9341bdabe891be81d2be3440a4c413b5" category="paragraph">Le funzionalità di scalabilità consentono di aggiungere unità disco ai sistemi AFF, FAS ed E-Series quando è necessaria ulteriore capacità di archiviazione.  Con Cloud Volumes ONTAP, il ridimensionamento dello storage al livello PB è una combinazione di due fattori: il livellamento dei dati utilizzati raramente nello storage di oggetti dallo storage a blocchi e l'accumulo di licenze Cloud Volumes ONTAP senza elaborazione aggiuntiva.</block>
  <block id="1a4f71bef2c7cfcc6846e82e9e0e0331" category="section-title">Protocolli multipli</block>
  <block id="11d6ae97757031ae53e1437c9c9b61bd" category="paragraph">I sistemi NetApp supportano la maggior parte dei protocolli per le distribuzioni Hadoop, tra cui SAS, iSCSI, FCP, InfiniBand e NFS.</block>
  <block id="98ed4f29e9a08c43fe10dda6782e567e" category="section-title">Soluzioni operative e supportate</block>
  <block id="464e596f1568de8e5f19e16e09beaaa8" category="inline-link">Hortonworks</block>
  <block id="f1fd1913c968a1c383c88631e335a7ca" category="inline-link">certificazione</block>
  <block id="7454739e907f5595ae61d84b8547f574" category="inline-link">partner</block>
  <block id="24cd9f53ddcc21c3360cfbf1ab787373" category="paragraph">Le soluzioni Hadoop descritte in questo documento sono supportate da NetApp.  Queste soluzioni sono inoltre certificate dai principali distributori Hadoop.  Per informazioni, vedere il<block ref="030fa12946d3d4653223853ac09b7183" category="inline-link-rx"></block> sito e Cloudera<block ref="110185abc20d52e7eb83135b84742416" category="inline-link-rx"></block> E<block ref="a573734769be98dedf1aa2242c0eb40c" category="inline-link-rx"></block> siti.</block>
  <block id="7e838102a13e780977b21c90f648a5d0" category="summary">Questa sezione descrive la natura e i componenti di Apache Spark e il modo in cui contribuiscono a questa soluzione.</block>
  <block id="8f4c7939e8a42e023939df947aba54f6" category="doc">Tecnologia delle soluzioni</block>
  <block id="f4387c90411f7b92618497bc53b16256" category="paragraph">Apache Spark è un framework di programmazione diffuso per la scrittura di applicazioni Hadoop che funziona direttamente con Hadoop Distributed File System (HDFS).  Spark è pronto per la produzione, supporta l'elaborazione di dati in streaming ed è più veloce di MapReduce.  Spark dispone di una cache dei dati in memoria configurabile per un'iterazione efficiente e la shell Spark è interattiva per l'apprendimento e l'esplorazione dei dati.  Con Spark puoi creare applicazioni in Python, Scala o Java.  Le applicazioni Spark sono costituite da uno o più lavori che hanno una o più attività.</block>
  <block id="6a696023a577a0d26763ef9c382b4b1f" category="paragraph">Ogni applicazione Spark ha un driver Spark.  In modalità YARN-Client, il driver viene eseguito localmente sul client.  In modalità YARN-Cluster, il driver viene eseguito nel cluster sul master dell'applicazione.  Nella modalità cluster, l'applicazione continua a funzionare anche se il client si disconnette.</block>
  <block id="5e8f0f670e38fbdf628b0883f946934f" category="inline-image-macro">Figura che mostra il dialogo di input/output o che rappresenta il contenuto scritto</block>
  <block id="bb21b729c47dce20f94160002efec039" category="paragraph"><block ref="bb21b729c47dce20f94160002efec039" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6feb0bd2b4db4693572a9fc2e517e888" category="paragraph">Esistono tre gestori di cluster:</block>
  <block id="4c79d7007667a60b712836e2f93d6bfc" category="list-text">*Autonomo.*  Questo gestore fa parte di Spark e semplifica la configurazione di un cluster.</block>
  <block id="c0a5bce529ff277ee2735538a7b43913" category="list-text">*Apache Mesos.*  Si tratta di un gestore di cluster generale che esegue anche MapReduce e altre applicazioni.</block>
  <block id="24683e4dfc33dc5b20a0d9a75c0ff150" category="list-text">*FILATO Hadoop.*  Questo è un gestore di risorse in Hadoop 3.</block>
  <block id="569531fd384ec251943946598eb00dcb" category="paragraph">Il set di dati distribuito resiliente (RDD) è il componente principale di Spark.  RDD ricrea i dati persi e mancanti dai dati archiviati nella memoria del cluster e memorizza i dati iniziali che provengono da un file o sono creati a livello di programmazione.  Gli RDD vengono creati da file, dati in memoria o un altro RDD.  La programmazione Spark esegue due operazioni: trasformazione e azioni.  La trasformazione crea un nuovo RDD basato su uno esistente.  Le azioni restituiscono un valore da un RDD.</block>
  <block id="1af693ed22a2df92eb5adff8c506d0ef" category="paragraph">Le trasformazioni e le azioni si applicano anche ai dataset e ai dataframe Spark.  Un set di dati è una raccolta distribuita di dati che offre i vantaggi degli RDD (tipizzazione forte, utilizzo delle funzioni lambda) con i vantaggi del motore di esecuzione ottimizzato di Spark SQL.  Un set di dati può essere costruito da oggetti JVM e poi manipolato utilizzando trasformazioni funzionali (map, flatMap, filter e così via).  Un DataFrame è un set di dati organizzato in colonne denominate.  Concettualmente è equivalente a una tabella in un database relazionale o a un data frame in R/Python.  I DataFrame possono essere creati da una vasta gamma di fonti, come file di dati strutturati, tabelle in Hive/HBase, database esterni in locale o nel cloud o RDD esistenti.</block>
  <block id="89d836212e4c5086ebcd9e5fbd6a4b37" category="paragraph">Le applicazioni Spark includono uno o più lavori Spark.  I lavori eseguono le attività negli esecutori e gli esecutori vengono eseguiti nei contenitori YARN.  Ogni esecutore viene eseguito in un singolo contenitore e gli esecutori esistono per tutta la durata di un'applicazione.  Un esecutore viene fissato dopo l'avvio dell'applicazione e YARN non ridimensiona il contenitore già allocato.  Un esecutore può eseguire attività contemporaneamente sui dati in memoria.</block>
  <block id="bd8f37587e7778e9d19d350dd4bd6d3a" category="summary">Questa sezione descrive chi potrebbe essere interessato al contenuto di questa soluzione.</block>
  <block id="bf8dd94f74c5878ba969abeeef0286d1" category="doc">Pubblico di destinazione</block>
  <block id="49997701037fef2c24b57a2e7186d0ab" category="paragraph">Il mondo dell'analisi e della scienza dei dati tocca molteplici discipline dell'IT e del business:</block>
  <block id="cddde51824956f407b4c02c1e4bc8004" category="list-text">Lo scienziato dei dati ha bisogno della flessibilità necessaria per utilizzare gli strumenti e le librerie che preferisce.</block>
  <block id="310a768ecb4689bcaf80072231d73e83" category="list-text">L'ingegnere dei dati deve sapere come fluiscono i dati e dove risiedono.</block>
  <block id="529ac4605b034914d0e8b489a81e45e0" category="list-text">Un ingegnere DevOps ha bisogno degli strumenti per integrare nuove applicazioni di intelligenza artificiale e apprendimento automatico nelle proprie pipeline di CI e CD.</block>
  <block id="090e55ccd8633a454f9d471ca3ed004d" category="list-text">Gli amministratori e gli architetti cloud devono essere in grado di configurare e gestire le risorse cloud ibride.</block>
  <block id="3cb782c6019ddcbb4e7f6bf8ae154d40" category="list-text">Gli utenti aziendali desiderano avere accesso ad applicazioni di analisi, intelligenza artificiale, apprendimento automatico e apprendimento automatico.</block>
  <block id="3dfd24951a51ec1661b0294f59bea86e" category="paragraph">In questo report tecnico descriviamo come NetApp AFF, E-Series, StorageGRID, NFS direct access, Apache Spark, Horovod e Keras aiutano ciascuno di questi ruoli a portare valore al business.</block>
  <block id="49c9a66d1f76b5f264fea5d54130b82a" category="summary">Abbiamo utilizzato gli script TeraSort e TeraValidate nello strumento di benchmarking TeraGen per misurare la convalida delle prestazioni di Spark con le configurazioni E5760, E5724 e AFF-A800.  Sono stati inoltre testati tre principali casi d'uso: pipeline Spark NLP e formazione distribuita TensorFlow, formazione distribuita Horovod e apprendimento approfondito multi-worker mediante Keras per la previsione CTR con DeepFM.</block>
  <block id="41be8de44faa8ba43210d7494ee095d2" category="doc">Risultati dei test</block>
  <block id="60637296d8b6dcd84aaff3afc778241d" category="paragraph">Abbiamo utilizzato gli script TeraSort e TeraValidate nello strumento di benchmarking TeraGen per misurare la convalida delle prestazioni di Spark con le configurazioni E5760, E5724 e AFF-A800.  Sono stati inoltre testati tre principali casi d'uso: pipeline Spark NLP e formazione distribuita TensorFlow, formazione distribuita Horovod e apprendimento approfondito multi-worker mediante Keras per la previsione CTR con DeepFM.</block>
  <block id="653a9ba51c0af0c11aab6af3ecfdc8c6" category="paragraph">Per la convalida di E-Series e StorageGRID , abbiamo utilizzato il fattore di replicazione Hadoop 2.  Per la convalida AFF , abbiamo utilizzato una sola fonte di dati.</block>
  <block id="6cdf0c4c6177a49f44f3688dd2a5b9ad" category="paragraph">Nella tabella seguente è elencata la configurazione hardware per la convalida delle prestazioni di Spark.</block>
  <block id="a1fa27779242b4902f7ae3bdd5c6d508" category="cell">Tipo</block>
  <block id="00e536f9715964bf964b4961d7287f95" category="cell">Nodi worker Hadoop</block>
  <block id="ce1dc110e77caccbe12e51dce2d1c9b7" category="cell">Tipo di unità</block>
  <block id="c8fafade5cff4119459018fc205beed1" category="cell">Unità per nodo</block>
  <block id="bb43878952414106e66a5d3e8902dd46" category="cell">Controllore di archiviazione</block>
  <block id="c69ff1785c16ab7db216e04b62e5ef4f" category="cell">SG6060</block>
  <block id="a87ff679a2f3e71d9181a67b7542122c" category="cell">4</block>
  <block id="2db46c628cfb3bd1545d3b5a14b4a9c5" category="cell">SAS</block>
  <block id="c20ad4d76fe97759aa27a0c99bff6710" category="cell">12</block>
  <block id="d748fcab9e84c60a5a7b1e5ed2d052c8" category="cell">Singola coppia ad alta disponibilità (HA)</block>
  <block id="fb5e436e0878dfd2227011932c4eb93c" category="cell">E5760</block>
  <block id="072b030ba126b2f4b2374f342be9ed44" category="cell">60</block>
  <block id="6303aa59a000812ac121a6f5238d6c2c" category="cell">Singola coppia HA</block>
  <block id="83ac07c2ad3d90f5c6608cfaa2eec573" category="cell">E5724</block>
  <block id="1ff1de774005f8da13f42943881c655f" category="cell">24</block>
  <block id="26b9fff68b23131979be5c2d9a456454" category="cell">AFF800</block>
  <block id="34df20bab5e85dc75bfc94ef569cced9" category="cell">SSD</block>
  <block id="1679091c5a880faf6fb5e6087eb1b2dc" category="cell">6</block>
  <block id="bddda15d92b567df6d8aa197c281ddc4" category="paragraph">Nella tabella seguente sono elencati i requisiti software.</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">Software</block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">Versione</block>
  <block id="8b6f93f33bce541c7f50f8aff637e2e1" category="cell">RHEL</block>
  <block id="299e5505ce975112afaefec130cc83e0" category="cell">7,9</block>
  <block id="bedb19167c4cde670f36a4985efbadd2" category="cell">Ambiente di runtime OpenJDK</block>
  <block id="4fda350b2148254bcd9e67bbdbecdc93" category="cell">1.8.0</block>
  <block id="b185818332a596af6cda9cae4dc594f6" category="cell">Macchina virtuale server OpenJDK a 64 bit</block>
  <block id="681eea6b2a996d12035edc50dc4cb4c2" category="cell">25,302</block>
  <block id="0bcc70105ad279503e31fe7b3f47b665" category="cell">Git</block>
  <block id="30a2ec41610037af662087fe85d19a4d" category="cell">2.24.1</block>
  <block id="87f16b82c65c9274a67305d08b5dfecb" category="cell">GCC/G++</block>
  <block id="b87ed8b82b1cf2cb4e4ddaa75ec9e0e4" category="cell">11.2.1</block>
  <block id="8cde774d6f7333752ed72cacddb05126" category="cell">Scintilla</block>
  <block id="f2f87b58be0d57ecf71ada8df361a2d9" category="cell">3.2.1</block>
  <block id="17e918efeeeb8f100c695e284d5c0a08" category="cell">PySpark</block>
  <block id="1f4e00506ff9fb5fe179f2ba1c60ff61" category="cell">3.1.2</block>
  <block id="401534b4a193f467279a370076ccb955" category="cell">SparkNLP</block>
  <block id="de8a4e99bb5f22ded6d686cfd948274b" category="cell">3.4.2</block>
  <block id="074dd699710da0ec1eb45f13b31788e3" category="cell">TensorFlow</block>
  <block id="0d6f7e6ce6f1553544acb14682c8eb07" category="cell">2.9.0</block>
  <block id="7fee7bb66f4294c3e32783efa7d9bafc" category="cell">Keras</block>
  <block id="f5f1c35a78d5584cdb787d4e3b6b10b6" category="cell">Horovod</block>
  <block id="35a0c5fdc22109515a67a96e5e7fb914" category="cell">0.24.3</block>
  <block id="14bdb1335d2386afb42f726416a2a83b" category="section-title">Analisi del sentiment finanziario</block>
  <block id="494027a6b5e9fc8bb84443d03b97a9b7" category="inline-link-macro">TR-4910: Analisi del sentiment dalle comunicazioni con i clienti con NetApp AI</block>
  <block id="74bef786b12cb9d03a6c04df1f605181" category="inline-link">Kit di strumenti NetApp DataOps</block>
  <block id="559cf37b505e9001d46e6d6bd73e746c" category="inline-link">NVIDIA Riva SDK</block>
  <block id="e65b49198d65919095402991b0cf5624" category="inline-link">Quadro Tao</block>
  <block id="460926218a6b1ab3e124f410ee69f408" category="paragraph">Abbiamo pubblicato<block ref="d791c48f7898bbaecde983abed6ac7c1" category="inline-link-macro-rx"></block> , in cui è stata costruita una pipeline di intelligenza artificiale conversazionale end-to-end utilizzando<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block> , archiviazione AFF e sistema NVIDIA DGX.  La pipeline esegue l'elaborazione del segnale audio in batch, il riconoscimento vocale automatico (ASR), l'apprendimento del trasferimento e l'analisi del sentiment sfruttando il DataOps Toolkit,<block ref="8702bd0254f484bdfe9f1ec1c2a853b1" category="inline-link-rx"></block> , e il<block ref="bba656873bd8ccd45c0c4fc908390474" category="inline-link-rx"></block> .  Estendendo il caso d'uso dell'analisi del sentiment al settore dei servizi finanziari, abbiamo creato un flusso di lavoro SparkNLP, caricato tre modelli BERT per varie attività NLP, come il riconoscimento di entità denominate, e ottenuto il sentiment a livello di frase per le call sugli utili trimestrali delle 10 principali aziende del NASDAQ.</block>
  <block id="ffeb7ccd27ad1e7d783757733dadec57" category="paragraph">Il seguente script<block ref="e313c2865ad76497c3eaf980ccfa3d03" prefix=" " category="inline-code"></block> utilizza il modello FinBERT per elaborare le trascrizioni in HDFS e produrre conteggi di sentiment positivi, neutri e negativi, come mostrato nella tabella seguente:</block>
  <block id="077259b584adffb379f7f2638be91edc" category="paragraph">La tabella seguente elenca l'analisi del sentiment a livello di frase, nelle conference call sui risultati finanziari, per le 10 principali società del NASDAQ dal 2016 al 2020.</block>
  <block id="30702e828192097c5634358e6047d0cf" category="cell">Conteggi e percentuali del sentimento</block>
  <block id="7838fb6ed7918fca8c7797b3b68952d2" category="cell">Tutte le 10 aziende</block>
  <block id="8b10e4ae9eeb5684921a9ab27e4d87aa" category="cell">AAPL</block>
  <block id="48af4341f745163f945fa838eeabb062" category="cell">AMD</block>
  <block id="261fd26b0151a81370d097e4ed4c6505" category="cell">AMZN</block>
  <block id="85fd1bb0e226da6a33e9b5dc1a4952f1" category="cell">CSCO</block>
  <block id="e15ce71ff533c9125f11a46c09e2412b" category="cell">GOOGLE</block>
  <block id="fc39dab34bbe435680d30933db783ba0" category="cell">INTC</block>
  <block id="b004b3ecde24c85e32c1923f10d3fb62" category="cell">MSFT</block>
  <block id="7f5f6a07b14840f4d8a22caa3df2aed0" category="cell">NVDA</block>
  <block id="4f65a47dc5d0d8a27379f2b1b4d9281b" category="cell">Conteggi positivi</block>
  <block id="9e6adb1432c4a75a33d48693328e4159" category="cell">7447</block>
  <block id="18d10dc6e666eab6de9215ae5b3d54df" category="cell">1567</block>
  <block id="5c572eca050594c7bc3c36e7e8ab9550" category="cell">743</block>
  <block id="f90f2aca5c640289d0a29417bcb63a37" category="cell">290</block>
  <block id="08d98638c6fcd194a4b1e6992063e944" category="cell">682</block>
  <block id="795c7a7a5ec6b460ec00c5841019b9e9" category="cell">826</block>
  <block id="677e09724f0e2df9b6c000b75b5da10d" category="cell">824</block>
  <block id="f47d0ad31c4c49061b9e505593e3db98" category="cell">904</block>
  <block id="41ae36ecb9b3eee609d05b90c14222fb" category="cell">417</block>
  <block id="be201b8b1b0b81005e46d49fd301124c" category="cell">Conteggi neutrali</block>
  <block id="1ab0418ab8dc5325176cd1e26660234f" category="cell">64067</block>
  <block id="34ad9bc83e3c72c62281cb2c744ac966" category="cell">6856</block>
  <block id="1796a48fa1968edd5c5d10d42c7b1813" category="cell">7596</block>
  <block id="71e63ef5b7249cfc60852f0e0f5bf4c8" category="cell">5086</block>
  <block id="126c2da128e5b044dc53405c25b4d8de" category="cell">6650</block>
  <block id="dd5bfdeb57f7c75d400de61e99d78e2e" category="cell">5914</block>
  <block id="80c0e8c4457441901351e4abbcf8c75c" category="cell">6099</block>
  <block id="6e4243f5511fd6ef0f03e9f386d54403" category="cell">5715</block>
  <block id="67ba02d73c54f0b83c05507b7fb7267f" category="cell">6189</block>
  <block id="e65849536f4b2170d6b42c8309222fac" category="cell">Conteggi negativi</block>
  <block id="d860bd12ce9c026814bbdfc1c573f0f5" category="cell">1787</block>
  <block id="c24cd76e1ce41366a4bbe8a49b02a028" category="cell">253</block>
  <block id="979d472a84804b9f647bc185a877a8b5" category="cell">213</block>
  <block id="68d30a9594728bc39aa24be94b319d21" category="cell">84</block>
  <block id="a2557a7b2e94197ff767970b67041697" category="cell">189</block>
  <block id="e2ef524fbf3d9fe611d5a8e90fefdc9c" category="cell">97</block>
  <block id="6a9aeddfc689c1d0e3b9ccc3ab651bc5" category="cell">282</block>
  <block id="854d6fae5ee42911677c739ee1734486" category="cell">202</block>
  <block id="7647966b7343c29048673252e490f736" category="cell">89</block>
  <block id="691ec36991472d115c60f32cd84bfc5b" category="cell">Conteggi non categorizzati</block>
  <block id="084b6fbb10729ed4da8c3d3f5a3ae7c9" category="cell">196</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="fbd7939d674997cdb4692d34de8633c4" category="cell">76</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1</block>
  <block id="2706e1e04688749582425d394866306e" category="cell">(conteggi totali)</block>
  <block id="b72e37e992d9e460ce2a491a974d13b5" category="cell">73497</block>
  <block id="9f6f2381bc56ef668e94f6d1fb4f6309" category="cell">8676</block>
  <block id="a563b6d5abbf137175059d6bb14672cc" category="cell">8552</block>
  <block id="1134ac57b5b1d38b7d70c1b6feaa28cf" category="cell">5536</block>
  <block id="e1e1f667ce4596e5644be6fab627c226" category="cell">7521</block>
  <block id="176bf6219855a6eb1f3a30903e34b6fb" category="cell">6837</block>
  <block id="75da5036f659fe64b53f3d9b39412967" category="cell">7205</block>
  <block id="e6be4c22a5963ab00dfe8f3b695b5332" category="cell">6822</block>
  <block id="2ea1202aed1e0ce30d41be4919b0cc99" category="cell">6695</block>
  <block id="14d1ed13bbef7783a73cfb9346480ce2" category="paragraph">In termini percentuali, la maggior parte delle frasi pronunciate dai CEO e dai CFO sono basate sui fatti e quindi trasmettono un sentimento neutrale.  Durante una conference call sui risultati finanziari, gli analisti pongono domande che possono trasmettere un sentimento positivo o negativo.  Vale la pena approfondire l'analisi quantitativa di come il sentiment negativo o positivo influenzi i prezzi delle azioni nello stesso giorno di negoziazione o in quello successivo.</block>
  <block id="3957e5ecad1215aa086504cf2c9ba9cc" category="paragraph">Nella tabella seguente è riportata l'analisi del sentiment a livello di frase per le prime 10 aziende del NASDAQ, espressa in percentuale.</block>
  <block id="e8a6f3527192d64ba338192ce83f6283" category="cell">Percentuale di sentimento</block>
  <block id="3289297424e01eda5b788c083bbf3147" category="cell">Positivo</block>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="doc"></block>
  <block id="3e263985564016f5774bfb75e31efb0d" category="paragraph">10,13%</block>
  <block id="d983b23f5dc08dfb28a31a898b6fbb6a" category="cell">18,06%</block>
  <block id="ed5f9ec0b398f0f53408828898412855" category="cell">8,69%</block>
  <block id="4d8e8cc0a97724584c1cd94c9485d555" category="cell">5,24%</block>
  <block id="d43cdfa633a84f9ca5043f4eb9363a38" category="cell">9,07%</block>
  <block id="a134c476ebd0c219b3cc879185d436ce" category="cell">12,08%</block>
  <block id="27cd80a0bdc79a724fdc31fa8841e19b" category="cell">11,44%</block>
  <block id="e954976d9376dfe5860acd553772a6df" category="cell">13,25%</block>
  <block id="d30929e6786318e19a22c88447dcc97c" category="cell">6,23%</block>
  <block id="e9bb5320b3890b6747c91b5a71ae5a01" category="cell">Neutro</block>
  <block id="6c3d5ec0fc8197d1a8f8366e142e37aa" category="cell">87,17%</block>
  <block id="578429551436bef848f19eccdd93fb73" category="cell">79,02%</block>
  <block id="bd443bde0360eb444a5906bea9d081b0" category="cell">88,82%</block>
  <block id="97840fcb1a1f07bef3a12ef2d7975f09" category="cell">91,87%</block>
  <block id="32edca53c1f1f00d865543b435d4ce3a" category="cell">88,42%</block>
  <block id="407967ec786c26ce4ee7608c076fa6d7" category="cell">86,50%</block>
  <block id="9784395b081e78ec535161a5ba0ffd1e" category="cell">84,65%</block>
  <block id="5d4b03024bcea7385ffc5808dd9c3b74" category="cell">83,77%</block>
  <block id="b73c3663139621b36cfdafbeab44fae9" category="cell">92,44%</block>
  <block id="ffb9356ff2b7da85c75c92fa7ea03b8b" category="cell">Negativo</block>
  <block id="672484e7c4fb5894b2ec75fd7e277fe4" category="cell">2,43%</block>
  <block id="c1fbc8ff600d3f571e0c440833db1a10" category="cell">2,92%</block>
  <block id="161a790eac04cd27fc3e4ffd23ba452d" category="cell">2,49%</block>
  <block id="5fd44dd7fb1198b1903141531424bb54" category="cell">1,52%</block>
  <block id="6916237a9f5c4ed45ddfff6fe37f45e7" category="cell">2,51%</block>
  <block id="43045dfce9b4c190cfa4dad2e4bf9457" category="cell">1,42%</block>
  <block id="248199b9ac50bd355476016ad093ac09" category="cell">3,91%</block>
  <block id="1cdf97682ca1bcd645e8dbcebb105529" category="cell">2,96%</block>
  <block id="8098f29a2cea86e839d8ca03f50d52ce" category="cell">1,33%</block>
  <block id="0d015d96f63a8c12d96b8399482b593f" category="cell">Non categorizzato</block>
  <block id="1291f0b93a9f9d5a7e7391a09b5ec0cc" category="cell">0,27%</block>
  <block id="9f1ef07877f9d85a82bd500f408b4814" category="cell">0%</block>
  <block id="6a040d1ee7200a1dc349a598a163cc38" category="cell">1,37%</block>
  <block id="d9fd62085e1ade721df051f8bc4c320d" category="cell">0,01%</block>
  <block id="28bf86a8e29245437d4ad59ea6e80962" category="paragraph">In termini di runtime del flusso di lavoro, abbiamo visto un miglioramento significativo di 4,78 volte rispetto<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> modalità a un ambiente distribuito in HDFS e un ulteriore miglioramento dello 0,14% sfruttando NFS.</block>
  <block id="87509d62c8804cdab48bea9e54013be4" category="paragraph">Come mostra la figura seguente, il parallelismo dei dati e dei modelli ha migliorato la velocità di elaborazione dei dati e di inferenza del modello distribuito TensorFlow.  L'ubicazione dei dati in NFS ha prodotto un tempo di esecuzione leggermente migliore perché il collo di bottiglia del flusso di lavoro è il download dei modelli pre-addestrati.  Se aumentiamo la dimensione del dataset delle trascrizioni, il vantaggio di NFS diventa più evidente.</block>
  <block id="493d0790c882abcf160f461d269c7ec5" category="inline-image-macro">Runtime del flusso di lavoro end-to-end per l'analisi del sentiment di Spark NLP.</block>
  <block id="44ec3b18d4516fc85f1a9789d47bd91c" category="paragraph"><block ref="44ec3b18d4516fc85f1a9789d47bd91c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3484d035679c83a95496eb633ffde0d3" category="section-title">Formazione distribuita con prestazioni Horovod</block>
  <block id="43fc68a998702bc80e46c46de6c28621" category="inline-link-macro">Script Python per ogni caso d'uso principale</block>
  <block id="1bdfd0f4247bc70668e65a97471adcb5" category="paragraph">Il seguente comando ha prodotto informazioni di runtime e un file di registro nel nostro cluster Spark utilizzando un singolo<block ref="eb0a191797624dd3a48fa681d3061212" prefix=" " category="inline-code"></block> nodo con 160 esecutori, ciascuno con un core.  La memoria dell'esecutore è stata limitata a 5 GB per evitare errori di memoria insufficiente.  Vedi la sezione<block ref="bda46a99ea3f7d5775466396b660e993" category="inline-link-macro-rx"></block> per maggiori dettagli riguardanti l'elaborazione dei dati, l'addestramento del modello e il calcolo dell'accuratezza del modello in<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> .</block>
  <block id="6281f693bbc375a45312622b626d3bcd" category="paragraph">Il tempo di esecuzione risultante con dieci epoche di addestramento è stato il seguente:</block>
  <block id="842bc4f8403cd2df9f22939e3df59aee" category="paragraph">Ci sono voluti più di 43 minuti per elaborare i dati di input, addestrare un modello DNN, calcolare l'accuratezza e produrre i checkpoint TensorFlow e un file CSV per i risultati delle previsioni.  Abbiamo limitato il numero di epoche di addestramento a 10, che nella pratica è spesso impostato su 100 per garantire una precisione soddisfacente del modello.  Il tempo di addestramento in genere varia in modo lineare con il numero di epoche.</block>
  <block id="1e580bbdb11118035631867d15ad9f25" category="paragraph">Successivamente abbiamo utilizzato i quattro nodi worker disponibili nel cluster ed eseguito lo stesso script in<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> modalità con dati in HDFS:</block>
  <block id="3661bcf870f3d2b11b0489ed7f0585a7" category="paragraph">Il tempo di esecuzione risultante è stato migliorato come segue:</block>
  <block id="68b0154732e3239041317d0c7d4ac636" category="paragraph">Con il modello di Horovod e il parallelismo dei dati in Spark, abbiamo visto un'accelerazione del runtime di 5,29 volte<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> contro<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> modalità con dieci epoche di allenamento.  Ciò è mostrato nella figura seguente con le legende<block ref="99c35850ff7cf7e436b03acedd4c59b3" prefix=" " category="inline-code"></block> E<block ref="509820290d57f333403f490dde7316f4" prefix=" " category="inline-code"></block> .  L'addestramento del modello DNN TensorFlow sottostante può essere ulteriormente accelerato con le GPU, se disponibili.  Abbiamo intenzione di condurre questi test e di pubblicare i risultati in un futuro rapporto tecnico.</block>
  <block id="216851565edc166c4409515484cac08b" category="paragraph">Il nostro test successivo ha confrontato i tempi di esecuzione con dati di input residenti in NFS rispetto a HDFS.  Il volume NFS sull'AFF AFF A800 è stato montato su<block ref="e5f5dfd1cb98e0a4c27a3ce6df3ca358" prefix=" " category="inline-code"></block> attraverso i cinque nodi (un master, quattro worker) nel nostro cluster Spark.  Abbiamo eseguito un comando simile a quello dei test precedenti, con il<block ref="97a9c2c856bc676ba715d3eecc314be6" prefix=" " category="inline-code"></block> parametro che ora punta al montaggio NFS:</block>
  <block id="3ba4d622f15813cc383c433722b46d27" category="paragraph">Il runtime risultante con NFS era il seguente:</block>
  <block id="7e1d2a49ae0a0e06a39a62e2c7c74877" category="paragraph">Si è verificato un ulteriore aumento di velocità di 1,43 volte, come mostrato nella figura seguente.  Pertanto, con uno storage all-flash NetApp connesso al proprio cluster, i clienti possono usufruire dei vantaggi di un rapido trasferimento e distribuzione dei dati per i flussi di lavoro di Horovod Spark, ottenendo una velocità 7,55 volte superiore rispetto all'esecuzione su un singolo nodo.</block>
  <block id="88caa92ecc3ebb345f81205aa696e3ac" category="inline-image-macro">Runtime del flusso di lavoro Horovod Spark.</block>
  <block id="aab5160a7c41d499723acfc13e430eef" category="paragraph"><block ref="aab5160a7c41d499723acfc13e430eef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b32c8309a0c0ca3edc35cb1597b9182c" category="section-title">Modelli di apprendimento profondo per le prestazioni di previsione del CTR</block>
  <block id="6ff877f80b732c197c0a432029ad1920" category="paragraph">Per i sistemi di raccomandazione progettati per massimizzare il CTR, è necessario apprendere le interazioni sofisticate delle funzionalità alla base dei comportamenti degli utenti, che possono essere calcolate matematicamente dal livello più basso a quello più alto.  Per un buon modello di deep learning, sia le interazioni tra le caratteristiche di ordine basso che quelle di ordine alto dovrebbero essere ugualmente importanti, senza sbilanciarsi verso l'una o l'altra.  Deep Factorization Machine (DeepFM), una rete neurale basata su macchine di fattorizzazione, combina macchine di fattorizzazione per la raccomandazione e apprendimento profondo per l'apprendimento delle caratteristiche in una nuova architettura di rete neurale.</block>
  <block id="a22645195470eca2abbe24e7d40cde8e" category="inline-link">Modelli larghi e profondi</block>
  <block id="8a7e0c5a65151889fa193b20e6ea6484" category="paragraph">Sebbene le macchine di fattorizzazione convenzionali modellino le interazioni delle caratteristiche a coppie come un prodotto interno di vettori latenti tra caratteristiche e possano teoricamente catturare informazioni di ordine elevato, in pratica, gli esperti di apprendimento automatico solitamente utilizzano solo interazioni delle caratteristiche di secondo ordine a causa dell'elevata complessità di calcolo e di archiviazione.  Varianti di reti neurali profonde come quelle di Google<block ref="6c51a2ff49c9929908a73e863a1421f0" category="inline-link-rx"></block> d'altro canto, apprende interazioni sofisticate tra le caratteristiche in una struttura di rete ibrida combinando un modello lineare ampio e un modello profondo.</block>
  <block id="a22f6dcc8bc499f7332ab04cdb36fcf9" category="paragraph">Questo modello Wide &amp; Deep prevede due input, uno per il modello wide sottostante e l'altro per quello deep; quest'ultima parte richiede ancora un'ingegneria delle funzionalità da parte di esperti e rende quindi la tecnica meno generalizzabile ad altri domini.  A differenza del modello Wide &amp; Deep, DeepFM può essere addestrato in modo efficiente con feature grezze senza alcuna progettazione delle feature, poiché la sua parte ampia e quella profonda condividono lo stesso input e lo stesso vettore di incorporamento.</block>
  <block id="fa3406903536d0cf09bf8e66ae33aebf" category="inline-link-macro">Script Python per ogni caso d'uso principale.</block>
  <block id="e78769fdc1aff8f5383517c0dc3ec750" category="paragraph">Abbiamo prima elaborato il Criteo<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> (11 GB) file in un file CSV denominato<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> memorizzato in un mount NFS<block ref="17d831727f14e5379e2f4773837ccfa4" prefix=" " category="inline-code"></block> usando<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block> dalla sezione<block ref="b6cb6fe53e443d0379ed59c804a7a30d" category="inline-link-macro-rx"></block> All'interno di questo script, la funzione<block ref="000f75d2ea65c8a3d82d62e405ce82ee" prefix=" " category="inline-code"></block> esegue diversi metodi stringa per rimuovere le tabulazioni e inserirle<block ref="433beb9a090abf694184e96d76b3046d" prefix=" " category="inline-code"></block> come delimitatore e<block ref="11b282e345a74511901532f5c84b59ee" prefix=" " category="inline-code"></block> come nuova riga.  Nota che devi elaborare solo l'originale<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> una volta, in modo che il blocco di codice venga visualizzato come commento.</block>
  <block id="02aeed17192e292b1708094a50785b65" category="paragraph">Per i seguenti test di diversi modelli DL, abbiamo utilizzato<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> come file di input.  Nelle successive esecuzioni di test, il file CSV di input è stato letto in uno Spark DataFrame con schema contenente un campo di<block ref="182ea3b4ea8b947ba1626831aa9debbe" prefix=" " category="inline-code"></block> , caratteristiche dense intere<block ref="2c94c76f60323031573497e25961744a" prefix=" " category="inline-code"></block> e caratteristiche sparse<block ref="57fae172685844997d173fa4248d66f8" prefix=" " category="inline-code"></block> .  Il seguente<block ref="78d07f07ead3482e696c0c224c2a7ed5" prefix=" " category="inline-code"></block> il comando accetta un CSV di input, addestra i modelli DeepFM con una suddivisione del 20% per la convalida incrociata e sceglie il modello migliore dopo dieci epoche di addestramento per calcolare l'accuratezza della previsione sul set di test:</block>
  <block id="52703dd8fd8c710b0aed616d19ddc0fb" category="paragraph">Si noti che poiché il file di dati<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> è superiore a 11 GB, è necessario impostare un numero sufficiente<block ref="af770896b1954b7c355d9becfe487e40" prefix=" " category="inline-code"></block> maggiore della dimensione del set di dati per evitare errori.</block>
  <block id="650f108a9978f10b1e3b0a8cbdcd6ac1" category="inline-link">Freccia Apache</block>
  <block id="caa01fc7f9a1a61f1bc803760af8e97f" category="paragraph">In quanto sopra<block ref="0ce62b6d4610e91242b63139adeb9432" prefix=" " category="inline-code"></block> configurazione che abbiamo anche abilitato<block ref="d19d750623d06d371730c4055a0fbbbf" category="inline-link-rx"></block> , che converte uno Spark DataFrame in un Pandas DataFrame con<block ref="5d77cff4a1fdffb38c875e9a11a310fb" prefix=" " category="inline-code"></block> metodo.</block>
  <block id="e20380d4fed48eae6cd24a0df1477ba7" category="paragraph">Dopo la suddivisione casuale, ci sono oltre 36 milioni di righe nel set di dati di addestramento e 9 milioni di campioni nel set di test:</block>
  <block id="a390a463e93dd87edffb2c8b23242507" category="paragraph">Poiché questo report tecnico è incentrato sui test della CPU senza l'utilizzo di GPU, è fondamentale compilare TensorFlow con flag di compilazione appropriati.  Questo passaggio evita di richiamare librerie accelerate dalla GPU e sfrutta appieno le Advanced Vector Extensions (AVX) e le istruzioni AVX2 di TensorFlow.  Queste funzionalità sono progettate per calcoli algebrici lineari come l'addizione vettorizzata, le moltiplicazioni di matrici all'interno di un addestramento DNN feed-forward o back-propagation.  L'istruzione Fused Multiply Add (FMA) disponibile con AVX2 che utilizza registri in virgola mobile (FP) a 256 bit è ideale per codice intero e tipi di dati, con un conseguente aumento della velocità fino a 2 volte.  Per il codice FP e i tipi di dati, AVX2 raggiunge un aumento di velocità dell'8% rispetto ad AVX.</block>
  <block id="6c396013ff0ebff6a2a96cdc20a4ba4c" category="inline-link">Bazel</block>
  <block id="97139e366bae36e316c93ce5b5e7e10b" category="paragraph">Per creare TensorFlow dalla sorgente, NetApp consiglia di utilizzare<block ref="0bf1f7ee55f693a3c117cb75493ba615" category="inline-link-rx"></block> .  Per il nostro ambiente, abbiamo eseguito i seguenti comandi nel prompt della shell per installare<block ref="ffd93b30364fb8893d5bbb6fdb312666" prefix=" " category="inline-code"></block> ,<block ref="1208feb4bf9c4dd21156d8231d098ba1" prefix=" " category="inline-code"></block> e Bazel.</block>
  <block id="29fe549665f940a68b9303eae3e3a61e" category="paragraph">È necessario abilitare GCC 5 o versioni successive per utilizzare le funzionalità C++17 durante il processo di compilazione, fornite da RHEL con Software Collections Library (SCL).  I seguenti comandi installano<block ref="188b06575e77785e6b73e5e85b8e6ada" prefix=" " category="inline-code"></block> e GCC 11.2.1 sul nostro cluster RHEL 7.9:</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">articolo</block>
  <block id="d4b82f54dfee1e5c527d0d5f8cb0d7aa" category="paragraph">Nota che gli ultimi due comandi abilitano<block ref="1dde0514b51c7c8f49cc63e4b54b8b37" prefix=" " category="inline-code"></block> , che utilizza<block ref="03fec70ce2bd12477f18ac0667e43d67" prefix=" " category="inline-code"></block> (GCC 11.2.1).  Inoltre, assicurati che il tuo<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> la versione è successiva alla 1.8.3 (inclusa in RHEL 7.9).  Fare riferimento a questo<block ref="7d93914bddb4046675adee0145ba45bd" category="inline-link-rx"></block> per l'aggiornamento<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> a 2.24.1.</block>
  <block id="ba89c701879ec1f07e28185e3446d252" category="inline-link-macro">Script Python per ogni caso d'uso principale,</block>
  <block id="a33b7755e5f9b504d2d038eaca4ff28d" category="inline-link">CUDA</block>
  <block id="e63cc75a56452201d199b8b0694ad9c1" category="paragraph">Supponiamo che tu abbia già clonato l'ultimo repository master di TensorFlow.  Quindi crea un<block ref="1629dee48cc4e53161f9b2be8614e062" prefix=" " category="inline-code"></block> directory con un<block ref="09498dbadf45966909850dc8a47ebb13" prefix=" " category="inline-code"></block> file per compilare TensorFlow dal codice sorgente con AVX, AVX2 e FMA.  Esegui il<block ref="e2d5a00791bce9a01f99bc6fd613a39d" prefix=" " category="inline-code"></block> file e specificare la posizione corretta del binario Python.<block ref="be1c72ed18fb5f637a2d34d959decb73" category="inline-link-rx"></block> è disabilitato per i nostri test perché non abbiamo utilizzato una GPU.  UN<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> il file viene generato in base alle tue impostazioni.  Inoltre, abbiamo modificato il file e impostato<block ref="4e1b2fd49a68e112bae6de1bc453f18c" prefix=" " category="inline-code"></block> per abilitare il supporto HDFS.  Fare riferimento a<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> nella sezione<block ref="f76831928c99e33a4e51e1e38bb9ab3c" category="inline-link-macro-rx"></block> per un elenco completo delle impostazioni e dei flag.</block>
  <block id="8329b0f29ec7368fd026b86d981f9dc7" category="paragraph">Dopo aver creato TensorFlow con i flag corretti, esegui lo script seguente per elaborare il set di dati Criteo Display Ads, addestrare un modello DeepFM e calcolare l'area sotto la curva ROC (AUC) dai punteggi di previsione.</block>
  <block id="d5a94c8db568912353007fdff822667e" category="paragraph">Dopo dieci epoche di addestramento, abbiamo ottenuto il punteggio AUC sul set di dati di test:</block>
  <block id="e3c9ed451390735cd8c4f8e5eb0e31f5" category="paragraph">In modo simile ai casi d'uso precedenti, abbiamo confrontato il runtime del flusso di lavoro Spark con dati residenti in posizioni diverse.  La figura seguente mostra un confronto della previsione CTR del deep learning per un runtime di flussi di lavoro Spark.</block>
  <block id="3737826be0460f743becdc4c64050946" category="inline-image-macro">Confronto della previsione CTR del deep learning per un runtime di flussi di lavoro Spark.</block>
  <block id="f68ffbfae290c4d8a7f8381ad0cad4ff" category="paragraph"><block ref="f68ffbfae290c4d8a7f8381ad0cad4ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edeeafbd44ff39ea2ff14f5de4488b69" category="summary">In questa pagina vengono descritti i diversi ambiti in cui è possibile utilizzare questa soluzione.</block>
  <block id="bf9bdab57c82171f2cc9bcebdc37b2c2" category="doc">Riepilogo del caso d'uso</block>
  <block id="badfbf9255d6b555592b41ab34e4efc6" category="section-title">dati in streaming</block>
  <block id="4cc7dbb8e0e56a0e190e0ad588a8ba78" category="paragraph">Apache Spark può elaborare dati in streaming, utilizzati per i processi di estrazione, trasformazione e caricamento (ETL), arricchimento dei dati, attivazione del rilevamento di eventi e analisi di sessioni complesse:</block>
  <block id="35658693f34a1c5dc8b752f79caeb198" category="list-text">*Streaming ETL.*  I dati vengono costantemente puliti e aggregati prima di essere inseriti negli archivi dati.  Netflix utilizza Kafka e Spark Streaming per creare una soluzione di monitoraggio dei dati e di raccomandazione di film online in tempo reale, in grado di elaborare miliardi di eventi al giorno provenienti da diverse fonti di dati.  Tuttavia, l'ETL tradizionale per l'elaborazione batch viene trattato in modo diverso.  Questi dati vengono prima letti e poi convertiti in un formato di database prima di essere scritti nel database.</block>
  <block id="1e8d9d663f583499f32f92ca2486e7df" category="list-text">*Arricchimento dei dati.*  Lo streaming Spark arricchisce i dati live con dati statici per consentire un'analisi dei dati più accurata in tempo reale.  Ad esempio, gli inserzionisti online possono fornire annunci personalizzati e mirati, basati sulle informazioni relative al comportamento dei clienti.</block>
  <block id="c8fc01958b8b24afef85387342bc2aef" category="list-text">*Rilevamento dell'evento trigger.*  Lo streaming Spark consente di rilevare e reagire rapidamente a comportamenti insoliti che potrebbero indicare problemi potenzialmente gravi.  Ad esempio, gli istituti finanziari utilizzano i trigger per rilevare e bloccare le transazioni fraudolente, mentre gli ospedali li utilizzano per rilevare pericolosi cambiamenti di salute rilevati nei parametri vitali di un paziente.</block>
  <block id="af8f12b6a4cff696802c46442e36e264" category="list-text">*Analisi di sessioni complesse.*  Spark Streaming raccoglie eventi quali l'attività dell'utente dopo l'accesso a un sito web o a un'applicazione, che vengono poi raggruppati e analizzati.  Ad esempio, Netflix utilizza questa funzionalità per fornire consigli sui film in tempo reale.</block>
  <block id="22f51db51c9641d5358726fa5e03f67b" category="inline-link-macro">TR-4912: Linee guida sulle best practice per l'archiviazione a livelli Confluent Kafka con NetApp</block>
  <block id="519be207be9b1131f1e8524db61cf335" category="paragraph">Per ulteriori configurazioni di dati in streaming, verifica di Confluent Kafka e test delle prestazioni, vedere<block ref="474863345040f8931cecadcc38733702" category="inline-link-macro-rx"></block> .</block>
  <block id="2a80513f40f0c2a9c11009fa83049bd9" category="section-title">Apprendimento automatico</block>
  <block id="c2e9a1abebd45c1d446eb49fb690afd7" category="paragraph">Il framework integrato Spark consente di eseguire query ripetute sui set di dati utilizzando la libreria di apprendimento automatico (MLlib).  MLlib viene utilizzato in ambiti quali il clustering, la classificazione e la riduzione della dimensionalità per alcune comuni funzioni di big data, come l'intelligenza predittiva, la segmentazione dei clienti per scopi di marketing e l'analisi del sentiment.  MLlib viene utilizzato nella sicurezza di rete per condurre ispezioni in tempo reale dei pacchetti di dati alla ricerca di indicazioni di attività dannose.  Aiuta i fornitori di servizi di sicurezza a conoscere le nuove minacce e a restare un passo avanti agli hacker, proteggendo al contempo i propri clienti in tempo reale.</block>
  <block id="03d3e10f072ae25d491b55767b4fc37e" category="section-title">Apprendimento profondo</block>
  <block id="b45690b6bb62bd55da7e1911ed880ec6" category="paragraph">TensorFlow è un framework di deep learning molto diffuso e utilizzato in tutto il settore.  TensorFlow supporta la formazione distribuita su un cluster CPU o GPU.  Questa formazione distribuita consente agli utenti di eseguirla su una grande quantità di dati con molti livelli profondi.</block>
  <block id="9981faa66d13ca7ba415a6c70dc52893" category="paragraph">Fino a poco tempo fa, se volevamo utilizzare TensorFlow con Apache Spark, dovevamo eseguire tutti gli ETL necessari per TensorFlow in PySpark e poi scrivere i dati su un archivio intermedio.  Tali dati verrebbero poi caricati sul cluster TensorFlow per il processo di addestramento vero e proprio.  Questo flusso di lavoro richiedeva all'utente di gestire due cluster diversi, uno per ETL e uno per la formazione distribuita di TensorFlow.  L'esecuzione e la manutenzione di più cluster erano solitamente operazioni noiose e dispendiose in termini di tempo.</block>
  <block id="082ad29f115c5cd4ab167c596b90688c" category="paragraph">I DataFrame e gli RDD nelle versioni precedenti di Spark non erano adatti al deep learning perché l'accesso casuale era limitato.  In Spark 3.0 con Project Hydrogen, è stato aggiunto il supporto nativo per i framework di deep learning.  Questo approccio consente una pianificazione non basata su MapReduce sul cluster Spark.</block>
  <block id="44cd5d1ec9ffc51f82d838faf685ef6e" category="section-title">Analisi interattiva</block>
  <block id="9650da7c8eb40c14055202b3dd7f4443" category="paragraph">Apache Spark è sufficientemente veloce da eseguire query esplorative senza campionamento con linguaggi di sviluppo diversi da Spark, tra cui SQL, R e Python.  Spark utilizza strumenti di visualizzazione per elaborare dati complessi e visualizzarli in modo interattivo.  Spark con streaming strutturato esegue query interattive su dati in tempo reale nell'analisi web, consentendo di eseguire query interattive sulla sessione corrente di un visitatore web.</block>
  <block id="d89f01bf7c0ceacaf30849bab08e0939" category="section-title">Sistema di raccomandazione</block>
  <block id="38c79706797b854a06f30876828ee766" category="paragraph">Nel corso degli anni, i sistemi di raccomandazione hanno apportato enormi cambiamenti alle nostre vite, poiché aziende e consumatori hanno reagito ai radicali cambiamenti nello shopping online, nell'intrattenimento online e in molti altri settori.  Questi sistemi rappresentano infatti tra i casi di successo più evidenti dell'intelligenza artificiale nella produzione.  In molti casi d'uso pratici, i sistemi di raccomandazione vengono combinati con l'intelligenza artificiale conversazionale o con chatbot interfacciati con un backend NLP per ottenere informazioni rilevanti e produrre inferenze utili.</block>
  <block id="6346d11f3fda24eb2d12fa4ac478fe3b" category="paragraph">Oggigiorno molti rivenditori stanno adottando nuovi modelli di business, come l'acquisto online e il ritiro in negozio, il ritiro sul marciapiede, il self-checkout, lo scan-and-go e molto altro.  Questi modelli sono diventati importanti durante la pandemia di COVID-19, rendendo gli acquisti più sicuri e comodi per i consumatori.  L'intelligenza artificiale è fondamentale per queste tendenze digitali in crescita, che sono influenzate dal comportamento dei consumatori e viceversa.  Per soddisfare le crescenti esigenze dei consumatori, ampliare l'esperienza del cliente, migliorare l'efficienza operativa e aumentare i ricavi, NetApp aiuta i suoi clienti aziendali e le aziende a utilizzare algoritmi di apprendimento automatico e profondo per progettare sistemi di raccomandazione più rapidi e accurati.</block>
  <block id="b32f1d719ba1fea2cad3538a4795c552" category="paragraph">Esistono diverse tecniche diffuse per fornire raccomandazioni, tra cui il filtraggio collaborativo, i sistemi basati sui contenuti, il modello di raccomandazione basato sull'apprendimento profondo (DLRM) e le tecniche ibride.  In precedenza i clienti utilizzavano PySpark per implementare il filtraggio collaborativo per la creazione di sistemi di raccomandazione.  Spark MLlib implementa i minimi quadrati alternati (ALS) per il filtraggio collaborativo, un algoritmo molto diffuso tra le aziende prima dell'avvento del DLRM.</block>
  <block id="9389b39b238fbd5ad61de2fea371853d" category="section-title">Elaborazione del linguaggio naturale</block>
  <block id="18bfab6309a4addeb7e1dae07d2a4b89" category="inline-link">Gartner</block>
  <block id="47fa981bf7641c90f0ce83a88c21234e" category="paragraph">L'intelligenza artificiale conversazionale, resa possibile dall'elaborazione del linguaggio naturale (NLP), è il ramo dell'intelligenza artificiale che aiuta i computer a comunicare con gli esseri umani.  L'NLP è diffuso in ogni settore verticale e in molti casi d'uso, dagli assistenti intelligenti e chatbot alla ricerca Google e al testo predittivo.  Secondo un<block ref="be3a50ddc5683c6936ee69409b86e212" category="inline-link-rx"></block> Si prevede che entro il 2022 il 70% delle persone interagirà quotidianamente con piattaforme di intelligenza artificiale conversazionale.  Per una conversazione di alta qualità tra un essere umano e una macchina, le risposte devono essere rapide, intelligenti e naturali.</block>
  <block id="9cac4209da8ee0481a45fa299b66e587" category="paragraph">I clienti necessitano di una grande quantità di dati per elaborare e addestrare i loro modelli NLP e di riconoscimento automatico del parlato (ASR).  Devono inoltre spostare i dati attraverso l'edge, il core e il cloud e hanno bisogno della potenza necessaria per eseguire inferenze in millisecondi per stabilire una comunicazione naturale con gli esseri umani.  NetApp AI e Apache Spark rappresentano una combinazione ideale per elaborazione, archiviazione, elaborazione dati, addestramento di modelli, messa a punto e distribuzione.</block>
  <block id="6ecf226f4b849e3111584c1eebd25f3c" category="paragraph">L'analisi del sentimento è un campo di studio della PNL in cui vengono estratti sentimenti positivi, negativi o neutri da un testo.  L'analisi del sentiment ha una varietà di casi d'uso, dalla determinazione delle prestazioni dei dipendenti del centro di supporto nelle conversazioni con i chiamanti alla fornitura di risposte automatizzate appropriate tramite chatbot.  È stato utilizzato anche per prevedere il prezzo delle azioni di un'azienda in base alle interazioni tra i rappresentanti dell'azienda e il pubblico durante le conference call trimestrali sui risultati.  Inoltre, l'analisi del sentiment può essere utilizzata per determinare l'opinione di un cliente sui prodotti, sui servizi o sul supporto forniti dal marchio.</block>
  <block id="635dbe8a61ae76776533cf731db5ca3d" category="inline-link">Spark NLP</block>
  <block id="511405f2428e9a6a71530b7f2cdcbc21" category="inline-link">John Snow Labs</block>
  <block id="351594930581e8fa82cf694de7562fd2" category="inline-link">sentimento delle notizie finanziarie</block>
  <block id="8f1fadc17d848b3be53c2009f5f9070a" category="inline-link">FinBERT</block>
  <block id="c1856f13b6ce4dd1f710cf08138e0c51" category="paragraph">Abbiamo usato il<block ref="0f17ea1334fb20ed83c3ab03268616d7" category="inline-link-rx"></block> biblioteca da<block ref="22825786ea861b373c2a5fdda9f62d81" category="inline-link-rx"></block> per caricare pipeline pre-addestrate e modelli di rappresentazioni di encoder bidirezionali da trasformatori (BERT) inclusi<block ref="1a3a0057856cc0bfa7cb2c9343eb2415" category="inline-link-rx"></block> E<block ref="ac723dc3fc44f63057a74e935ae9db52" category="inline-link-rx"></block> , eseguendo la tokenizzazione, il riconoscimento di entità denominate, l'addestramento del modello, l'adattamento e l'analisi del sentiment su larga scala.  Spark NLP è l'unica libreria NLP open source in produzione che offre trasformatori all'avanguardia come BERT, ALBERT, ELECTRA, XLNet, DistilBERT, RoBERTa, DeBERTa, XLM-RoBERTa, Longformer, ELMO, Universal Sentence Encoder, Google T5, MarianMT e GPT2.  La libreria funziona non solo in Python e R, ma anche nell'ecosistema JVM (Java, Scala e Kotlin) su larga scala, estendendo Apache Spark in modo nativo.</block>
  <block id="e353dbe42c8654f33588d4da0b517469" category="doc">Astratto</block>
  <block id="c9da861bd07fd9446a0e4f9108517532" category="paragraph">Questo documento descrive come spostare i dati dai sistemi di analisi dei big data e di calcolo ad alte prestazioni (HPC) in modo che possano essere utilizzati nei flussi di lavoro di intelligenza artificiale (IA).  L'intelligenza artificiale elabora in genere i dati NFS tramite esportazioni NFS.  Tuttavia, potresti avere i tuoi dati di intelligenza artificiale in una piattaforma di analisi di big data e di calcolo ad alte prestazioni (HPC).  Potrebbe trattarsi dell'Hadoop Distributed File System (HDFS), di un oggetto binario di grandi dimensioni (Blob), dello storage S3 o del General Parallel File System (GPFS) di IBM.  In questo documento descriviamo come spostare i dati da una piattaforma di analisi big data e GPFS a NFS utilizzando comandi nativi di Hadoop, NetApp In-Place Analytics Module (NIPAM) e NetApp XCP.  Questo documento analizza anche i vantaggi aziendali derivanti dallo spostamento dei dati dai big data e dall'HPC all'intelligenza artificiale.</block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">Dove trovare ulteriori informazioni</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">Per saperne di più sulle informazioni descritte nel presente documento, consultare i seguenti documenti e/o siti web:</block>
  <block id="f5ac1e3c252855373c7f660dbd89699d" category="list-text">Guida alle best practice e all'implementazione NetApp FlexGroup Volume</block>
  <block id="7d72333a4556beea0bd57e4b8a007b47" category="paragraph"><block ref="7d72333a4556beea0bd57e4b8a007b47" category="inline-link-rx"></block></block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="list-text">Documentazione del prodotto NetApp</block>
  <block id="c9617ae303d0bce89d13bebecca2ea1b" category="paragraph"><block ref="c9617ae303d0bce89d13bebecca2ea1b" category="inline-link-rx"></block></block>
  <block id="e0a1057b7f63b9621d22a28a118e4a79" category="summary">In questa sezione vengono descritti i vantaggi aziendali di questa soluzione.</block>
  <block id="7f0cbc7391fd4e971628295e6bff035a" category="doc">Vantaggi aziendali</block>
  <block id="239f77225835899839f2d1318d1cc1c4" category="paragraph">Il passaggio dei dati dall'analisi dei big data all'intelligenza artificiale offre i seguenti vantaggi:</block>
  <block id="c07548816e2d37db2db301172209009e" category="list-text">La capacità di estrarre dati da diversi file system Hadoop e GPFS in un sistema di archiviazione NFS unificato</block>
  <block id="17480f22ec6a36806354b84f9824ff80" category="list-text">Un modo automatizzato e integrato con Hadoop per trasferire dati</block>
  <block id="626dfcaeea53c1bdef78276b0f594dbf" category="list-text">Una riduzione del costo di sviluppo della libreria per lo spostamento dei dati dai file system Hadoop</block>
  <block id="8576c8e67d6540e2f677340d38ec60e9" category="list-text">Massime prestazioni tramite throughput aggregato di più interfacce di rete da un'unica fonte di dati utilizzando NIPAM</block>
  <block id="28338c61f9a9de656b504b14a75bb824" category="list-text">Metodi programmati e su richiesta per trasferire i dati</block>
  <block id="3c70d03dd35337605475e972b74654c8" category="list-text">Efficienza di archiviazione e capacità di gestione aziendale per dati NFS unificati mediante l'utilizzo del software di gestione dati ONTAP</block>
  <block id="2b602714583b0c6daac65349c0e00e16" category="list-text">Costo zero per lo spostamento dei dati con il metodo Hadoop per il trasferimento dei dati</block>
  <block id="eea7b9fa88f883b7983320cb8dd802ac" category="summary">In questa pagina vengono illustrate le sfide che un cliente potrebbe incontrare quando cerca di accedere ai dati derivanti dall'analisi dei big data per le operazioni di intelligenza artificiale.</block>
  <block id="b794cc731a2a9499d064b08a32552e78" category="paragraph">I clienti potrebbero trovarsi ad affrontare le seguenti sfide quando cercano di accedere ai dati derivanti dall'analisi dei big data per le operazioni di intelligenza artificiale:</block>
  <block id="593806557377bd8506b6705484962785" category="list-text">I dati dei clienti si trovano in un repository di data lake.  Il data lake può contenere diversi tipi di dati, come dati strutturati, non strutturati, semi-strutturati, log e dati macchina-macchina.  Tutti questi tipi di dati devono essere elaborati nei sistemi di intelligenza artificiale.</block>
  <block id="43d7d5ce8487763157eabcf01d1cf6ef" category="list-text">L'intelligenza artificiale non è compatibile con i file system Hadoop.  Una tipica architettura AI non è in grado di accedere direttamente ai dati HDFS e HCFS, che devono essere spostati in un file system (NFS) comprensibile dall'AI.</block>
  <block id="e032c722c87677b6dfba13af108c61b8" category="list-text">In genere, lo spostamento dei dati del data lake verso l'intelligenza artificiale richiede processi specializzati.  La quantità di dati nel data lake può essere molto grande.  Un cliente deve disporre di un modo efficiente, ad alta produttività e conveniente per trasferire i dati nei sistemi di intelligenza artificiale.</block>
  <block id="30bd7dc66c05e60d2ea66d09e568cb06" category="list-text">Sincronizzazione dei dati.  Se un cliente desidera sincronizzare i dati tra la piattaforma big data e l'intelligenza artificiale, a volte i dati elaborati tramite l'intelligenza artificiale possono essere utilizzati con i big data per l'elaborazione analitica.</block>
  <block id="c877e65bbe37324c3309ace4aa7745d1" category="summary">In un cluster Big Data, i dati vengono archiviati in HDFS o HCFS, come MapR-FS, Windows Azure Storage Blob, S3 o il file system di Google.  Abbiamo eseguito test con HDFS, MapR-FS e S3 come origine per copiare i dati nell'esportazione NFS NetApp ONTAP con l'aiuto di NIPAM utilizzando il comando hadoop distcp dall'origine.</block>
  <block id="d73e7d11401e9256a0dea0d1e174e1de" category="doc">Soluzione di spostamento dati</block>
  <block id="013c5604f73da0e909c46aa5d3a670f3" category="paragraph">In un cluster Big Data, i dati vengono archiviati in HDFS o HCFS, come MapR-FS, Windows Azure Storage Blob, S3 o il file system di Google.  Abbiamo eseguito test con HDFS, MapR-FS e S3 come origine per copiare i dati nell'esportazione NFS NetApp ONTAP con l'aiuto di NIPAM utilizzando<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> comando dalla sorgente.</block>
  <block id="9fabfa5fcba2e539b6d2c5eff5bb2116" category="paragraph">Il diagramma seguente illustra il tipico spostamento dei dati da un cluster Spark in esecuzione con storage HDFS a un volume NetApp ONTAP NFS in modo che NVIDIA possa elaborare le operazioni di intelligenza artificiale.</block>
  <block id="67ed14506d4065a668f7cb0136039d8b" category="paragraph"><block ref="67ed14506d4065a668f7cb0136039d8b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da6616575a7b32d3eb2fa505007a9a4a" category="paragraph">IL<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> Il comando utilizza il programma MapReduce per copiare i dati.  NIPAM funziona con MapReduce per fungere da driver per il cluster Hadoop durante la copia dei dati.  NIPAM può distribuire un carico su più interfacce di rete per una singola esportazione.  Questo processo massimizza la produttività della rete distribuendo i dati su più interfacce di rete quando si copiano i dati da HDFS o HCFS a NFS.</block>
  <block id="c2cad9f038dfeecd75697cb4bebe4c68" category="admonition">NIPAM non è supportato né certificato con MapR.</block>
  <block id="20220b4c576eeca673151438f5ee1da9" category="summary">La soluzione di spostamento dati per l'intelligenza artificiale si basa sulle esigenze dei clienti di elaborare i dati Hadoop provenienti dalle operazioni di intelligenza artificiale.  NetApp sposta i dati da HDFS a NFS utilizzando NIPAM.  In un caso d'uso, il cliente aveva bisogno di spostare i dati su NFS in sede e un altro cliente aveva bisogno di spostare i dati da Windows Azure Storage Blob a Google Cloud NetApp Volumes per elaborare i dati dalle istanze cloud GPU nel cloud.</block>
  <block id="7f10e017358079527e7045a68782eb14" category="doc">Soluzione di spostamento dati per l'intelligenza artificiale</block>
  <block id="b6392eaf0ddf0463d633e69aaeeef3ce" category="paragraph">Il diagramma seguente illustra i dettagli della soluzione di spostamento dei dati.</block>
  <block id="44c3f61c0684bc5b43b5e243a139152c" category="paragraph"><block ref="44c3f61c0684bc5b43b5e243a139152c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e01b73324e59213b14e79f9d912546bc" category="paragraph">Per creare la soluzione di spostamento dati sono necessari i seguenti passaggi:</block>
  <block id="03337d241355e58cdaa3df5a4bb980ef" category="list-text">ONTAP SAN fornisce HDFS e NAS fornisce il volume NFS tramite NIPAM al cluster del data lake di produzione.</block>
  <block id="625dd6cfdf4a097dff4340366eec8942" category="list-text">I dati del cliente sono in HDFS e NFS.  I dati NFS possono essere dati di produzione provenienti da altre applicazioni, utilizzati per analisi di big data e operazioni di intelligenza artificiale.</block>
  <block id="32477fa182341c04b6e8076232250f76" category="list-text">La tecnologia NetApp FlexClone crea un clone del volume NFS di produzione e lo distribuisce al cluster AI in locale.</block>
  <block id="4e7e9a946510d25d1b28cc93a3723e69" category="list-text">I dati da un HDFS SAN LUN vengono copiati in un volume NFS con NIPAM e<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> comando.  NIPAM utilizza la larghezza di banda di più interfacce di rete per trasferire i dati.  Questo processo riduce il tempo di copia dei dati, consentendo di trasferire una maggiore quantità di dati.</block>
  <block id="b0dd56fceeaba1e1db258d1b06d2572d" category="list-text">Entrambi i volumi NFS vengono forniti al cluster AI per le operazioni AI.</block>
  <block id="344c1652d7730f66d822b6ed5d07ff77" category="list-text">Per elaborare i dati NFS in locale con GPU nel cloud, i volumi NFS vengono replicati su NetApp Private Storage (NPS) con la tecnologia NetApp SnapMirror e montati sui provider di servizi cloud per GPU.</block>
  <block id="98105737f8ac55863a4e0763f588cab5" category="list-text">Il cliente desidera elaborare i dati nei servizi EC2/EMR, HDInsight o DataProc nelle GPU dei provider di servizi cloud.  Il data mover Hadoop sposta i dati dai servizi Hadoop ai Google Cloud NetApp Volumes con NIPAM e<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> comando.</block>
  <block id="f490cd633c8e7648911d95daf043af8f" category="list-text">I dati Google Cloud NetApp Volumes vengono forniti all'IA tramite il protocollo NFS. I dati elaborati tramite l'IA possono essere inviati in una posizione locale per l'analisi dei big data, oltre che al cluster NVIDIA tramite NIPAM, SnapMirror e NPS.</block>
  <block id="f13f02e9fbfc272070bb10c4ae60e707" category="paragraph">In questo scenario, il cliente dispone di un elevato numero di file nel sistema NAS in una posizione remota, necessari per l'elaborazione AI sul controller di archiviazione NetApp in sede.  In questo scenario, è meglio utilizzare XCP Migration Tool per migrare i dati a una velocità maggiore.</block>
  <block id="74c03e6f525ff7a5f56d15dd77d9d7ee" category="paragraph">Il cliente che utilizza un caso d'uso ibrido può utilizzare BlueXP Copy and Sync per migrare i dati locali dai dati NFS, CIFS e S3 al cloud e viceversa per l'elaborazione AI utilizzando GPU come quelle in un cluster NVIDIA .  Per la migrazione dei dati NFS su NetApp ONTAP NFS vengono utilizzati sia BlueXP Copy and Sync che XCP Migration Tool.</block>
  <block id="ae1992b408fce873deb0f11eb017ea19" category="summary">In questa convalida, abbiamo utilizzato quattro server come server NSD (Network Shared Disk) per fornire dischi fisici per GPFS.  GPFS viene creato sopra i dischi NSD per esportarli come esportazioni NFS, in modo che i client NFS possano accedervi, come mostrato nella figura seguente.  Abbiamo utilizzato XCP per copiare i dati da NFS esportato tramite GPFS a un volume NFS NetApp .</block>
  <block id="bc64aad447f072e96947f5d02f7e8134" category="doc">GPFS a NetApp ONTAP NFS</block>
  <block id="f0987b9b1ed71523f2b4be4961e35e12" category="paragraph"><block ref="f0987b9b1ed71523f2b4be4961e35e12" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86339fb1bc11f77d6e48efc42d910f0f" category="section-title">Elementi essenziali del GPFS</block>
  <block id="d859f99e3b66fbd7305cfd50ba2d4566" category="paragraph">In GPFS vengono utilizzati i seguenti tipi di nodo:</block>
  <block id="4ac5c1b5474a4920e2433b8f1610729f" category="list-text">*Nodo di amministrazione.*  Specifica un campo facoltativo contenente un nome di nodo utilizzato dai comandi di amministrazione per comunicare tra i nodi.  Ad esempio, il nodo di amministrazione<block ref="f2fde43b571e78e29f67743af45165cb" prefix=" " category="inline-code"></block> potrebbe superare un controllo di rete su tutti gli altri nodi del cluster.</block>
  <block id="6659be8d3c5ae97ae05588383a9efb5a" category="list-text">*Nodo quorum.*  Determina se un nodo è incluso nel pool di nodi da cui viene derivato il quorum.  È necessario almeno un nodo come nodo quorum.</block>
  <block id="504f43a7f6382dae9e638f1c396a1779" category="list-text">*Nodo Gestore.*  Indica se un nodo fa parte del pool di nodi da cui è possibile selezionare i gestori del file system e i gestori dei token.  È una buona idea definire più di un nodo come nodo gestore.  Il numero di nodi da designare come gestori dipende dal carico di lavoro e dal numero di licenze server GPFS di cui si dispone.  Se si eseguono grandi lavori paralleli, potrebbero essere necessari più nodi di gestione rispetto a un cluster a quattro nodi che supporta un'applicazione Web.</block>
  <block id="48b637b1e31141b7e6faae1b7c6d8be2" category="list-text">*Server NSD.*  Il server che prepara ogni disco fisico per l'utilizzo con GPFS.</block>
  <block id="8cd64755dc629d6061cef8f3bdddfe8f" category="list-text">*Nodo protocollo.*  Il nodo che condivide i dati GPFS direttamente tramite qualsiasi protocollo Secure Shell (SSH) con NFS.  Questo nodo richiede una licenza server GPFS.</block>
  <block id="d1a65ffa2a3768b3a494baba34855023" category="section-title">Elenco delle operazioni per GPFS, NFS e XCP</block>
  <block id="089009e49dc3cafdc4329d07f11c5250" category="paragraph">Questa sezione fornisce l'elenco delle operazioni che creano GPFS, esportano GPFS come esportazione NFS e trasferiscono i dati utilizzando XCP.</block>
  <block id="1d9da206467eb5273c4b522820cfddb2" category="section-title">Crea GPFS</block>
  <block id="454f38a55393f7773c6e59f13eb6fef5" category="paragraph">Per creare GPFS, completare i seguenti passaggi:</block>
  <block id="a69093440b15d387cf13aadb026e36a9" category="list-text">Scarica e installa l'accesso ai dati su scala spettrale per la versione Linux su uno dei server.</block>
  <block id="8a3d13c75e4dd8c8cffdf92d8e9dd956" category="list-text">Installare il pacchetto prerequisito (ad esempio chef) in tutti i nodi e disabilitare Security-Enhanced Linux (SELinux) in tutti i nodi.</block>
  <block id="9356dbe859ed4334d7e27c641d7dd594" category="list-text">Configurare il nodo di installazione e aggiungere il nodo di amministrazione e il nodo GPFS al file di definizione del cluster.</block>
  <block id="1bdc86658a65033989c8064812818633" category="list-text">Aggiungere il nodo gestore, il nodo quorum, i server NSD e il nodo GPFS.</block>
  <block id="d55b679ec8a82b729ae03c882f27b80e" category="list-text">Aggiungere i nodi GUI, admin e GPFS e, se necessario, aggiungere un ulteriore server GUI.</block>
  <block id="f4e47c4647a3dafebf21a5f40cfa7f9c" category="list-text">Aggiungere un altro nodo GPFS e controllare l'elenco di tutti i nodi.</block>
  <block id="303364b5437159140dc70a76a77e8aa8" category="list-text">Specificare un nome cluster, un profilo, un binario shell remoto, un binario copia file remoto e un intervallo di porte da impostare su tutti i nodi GPFS nel file di definizione del cluster.</block>
  <block id="30d14bbe638530772662c104a30d53d3" category="list-text">Visualizza le impostazioni di configurazione GPFS e aggiungi un ulteriore nodo di amministrazione.</block>
  <block id="d6daa755d449b0cec4c1c23153b9a0be" category="list-text">Disattivare la raccolta dati e caricare il pacchetto dati su IBM Support Center.</block>
  <block id="765ad728fb1bb9eb3c981693321a01ef" category="list-text">Abilitare NTP e verificare preventivamente le configurazioni prima dell'installazione.</block>
  <block id="1deb66562b5d0f8ce755a102f2731d8d" category="list-text">Configurare, creare e controllare i dischi NSD.</block>
  <block id="f54668a02541c80dd54234689ef58ad4" category="list-text">Creare il GPFS.</block>
  <block id="048c1f8a018373ca436ef1a91fe6be57" category="list-text">Montare il GPFS.</block>
  <block id="18a8260437fd56c8bdc1f994d860e490" category="list-text">Verificare e fornire le autorizzazioni richieste al GPFS.</block>
  <block id="a150a1930bbf429fc0204993b66d46cb" category="list-text">Verificare la lettura e la scrittura GPFS eseguendo il comando<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> comando.</block>
  <block id="83cd36fb568894200fe5f9cf7f7e1193" category="section-title">Esporta GPFS in NFS</block>
  <block id="e2fc86fc4827b925f5cccecdcd51d6b1" category="paragraph">Per esportare il GPFS in NFS, completare i seguenti passaggi:</block>
  <block id="af125b713cb0d82420980798e0276ea7" category="list-text">Esporta GPFS come NFS tramite<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> file.</block>
  <block id="c953ca93794388b6266ed8529319d420" category="list-text">Installare i pacchetti server NFS richiesti.</block>
  <block id="c0d11d4c7c65daa849ff313e229d632c" category="list-text">Avviare il servizio NFS.</block>
  <block id="873ad6aeda101f4e6c3a2cb8a46e84ad" category="list-text">Elenca i file nel GPFS per convalidare il client NFS.</block>
  <block id="f9b2649730ae4997f650bc4a2f8c1773" category="section-title">Configurare il client NFS</block>
  <block id="25be8238edbbbd8936c0385098957520" category="paragraph">Per configurare il client NFS, completare i seguenti passaggi:</block>
  <block id="d11e3a3b633c68e9cc37f13adcdfd95a" category="list-text">Esportare il GPFS come NFS tramite<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> file.</block>
  <block id="64aef4f16c4a9f913379e9668323ed4f" category="list-text">Avviare i servizi client NFS.</block>
  <block id="b7eb10685995437ddaa0df5b09b22fb8" category="list-text">Montare il GPFS tramite il protocollo NFS sul client NFS.</block>
  <block id="bb8a91cbc28d52ebb4edab31956c7f58" category="list-text">Convalida l'elenco dei file GPFS nella cartella montata NFS.</block>
  <block id="690b19ed08f992a8a2d6e3e872641b2e" category="list-text">Spostare i dati da GPFS esportati da NFS a NetApp NFS utilizzando XCP.</block>
  <block id="f919d4d761d618912a13cac0895236af" category="list-text">Convalidare i file GPFS sul client NFS.</block>
  <block id="0e0fdc9fc616f1d8648561d150679a8c" category="summary">Questa sezione fornisce i passaggi dettagliati necessari per configurare GPFS e spostare i dati in NFS utilizzando NetApp XCP.</block>
  <block id="2cf43976b964350d85af88e8c7c56bfc" category="doc">Passaggi dettagliati da GPFS a NFS</block>
  <block id="7f1260d8686ace0468fd1c74b243b7a1" category="section-title">Configurare GPFS</block>
  <block id="de00400b12b028274700d1385b53c26d" category="list-text">Scarica e installa Spectrum Scale Data Access per Linux su uno dei server.</block>
  <block id="61a030f51cd790deb6f1374ae7e4d88f" category="list-text">Installare il pacchetto prerequisito (inclusi chef e gli header del kernel) su tutti i nodi.</block>
  <block id="cea532f5e6d51ac7b08d9f6d71886efe" category="list-text">Disabilitare SELinux in tutti i nodi.</block>
  <block id="e116db66dcd3a8a38d53716cdd97c179" category="list-text">Configurare il nodo di installazione.</block>
  <block id="6021211d885ba9ec28a1dfcdb72b0542" category="list-text">Aggiungere il nodo admin e il nodo GPFS al file di definizione del cluster.</block>
  <block id="8b361b52f2d7d8ddca7c364e1826015d" category="list-text">Aggiungere il nodo gestore e il nodo GPFS.</block>
  <block id="d98e392ead2711bea231821e3cafe06e" category="list-text">Aggiungere il nodo quorum e il nodo GPFS.</block>
  <block id="549101fb45a9a42ca05a3b680ea6dcdc" category="list-text">Aggiungere i server NSD e il nodo GPFS.</block>
  <block id="0150b7ec1d76a294c8fce802481a2e2d" category="list-text">Aggiungere i nodi GUI, admin e GPFS.</block>
  <block id="5076e582b15cea2e7319261b9eb2dc4e" category="list-text">Aggiungi un altro server GUI.</block>
  <block id="65d8f0643532859908a7e9616439572a" category="list-text">Aggiungere un altro nodo GPFS.</block>
  <block id="8c6e090e52befa2e95e6d658661749dc" category="list-text">Verificare ed elencare tutti i nodi.</block>
  <block id="6a21679cbbcb8a64de6016e8efb6b2ea" category="list-text">Specificare un nome per il cluster nel file di definizione del cluster.</block>
  <block id="0e890aabbc215ad4497b26965a0435ad" category="list-text">Specificare il profilo.</block>
  <block id="3296b6b95878e4a01015b9d97691cd23" category="list-text">Specificare il binario della shell remota da utilizzare da GPFS; utilizzare<block ref="f8b2a03096b35c105ccb9e1687ea4d21" prefix=" " category="inline-code"></block> .</block>
  <block id="6b1edec7f7c05cc2bc9fb41ef76dc8c9" category="list-text">Specificare il binario di copia del file remoto da utilizzare da GPFS; utilizzare<block ref="795f05204859c09fe2f151b742bf82f9" prefix=" " category="inline-code"></block> .</block>
  <block id="f35c3f5ce8fa5fca13e0eb96082b73fe" category="list-text">Specificare l'intervallo di porte da impostare su tutti i nodi GPFS; utilizzare<block ref="3b552a3fb3ecdff1af07892680e6d03a" prefix=" " category="inline-code"></block> .</block>
  <block id="84807c9c164a1fd83db3680e7b5a6587" category="list-text">Visualizza le impostazioni di configurazione GPFS.</block>
  <block id="0addd886868e88c985dddc68658e5767" category="list-text">Aggiungi un nodo di amministrazione.</block>
  <block id="d2e4082ff74b3d592d15b584ec3e64a9" category="list-text">Abilita NTP.</block>
  <block id="bc5f73d061ad4090dd4180838b34fc5a" category="list-text">Verificare preventivamente le configurazioni prima dell'installazione.</block>
  <block id="7f2019dce6ead5054cb5c0d5ccac9d68" category="list-text">Configurare i dischi NSD.</block>
  <block id="bd625aeaf0eb9674912c4c51a421cdb6" category="list-text">Creare i dischi NSD.</block>
  <block id="bfc7a92fefcdbb8be49ae2f09a04c609" category="list-text">Controllare lo stato del disco NSD.</block>
  <block id="abe092e554a73bb99bd2fd85086ffdce" category="list-text">Controllare e fornire le autorizzazioni richieste al GPFS.</block>
  <block id="737cdea6c4302200061636f408685896" category="list-text">Controllare la lettura e la scrittura GPFS eseguendo il comando<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> comando.</block>
  <block id="978d4e591d532e5741bf55bbe09b8672" category="paragraph">Per esportare GPFS in NFS, completare i seguenti passaggi:</block>
  <block id="67ae9e67c637e0c39f8d92303b0a9c01" category="list-text">Elenca i file in GPFS per convalidare il client NFS.</block>
  <block id="e90c8e55eda7dc2ebdbef5659a22a517" category="section-title">Configurare il client NFS</block>
  <block id="bc2bba568f2fe74e5616fa8f5953b1bf" category="list-text">Installare i pacchetti nel client NFS.</block>
  <block id="7e4215ed068d7218ec28fe900e8feb16" category="list-text">Convalida l'elenco dei file GPFS nella cartella montata su NFS.</block>
  <block id="77086f36ad335fd9c2cc6a63c1d21d84" category="list-text">Spostare i dati dall'NFS esportato da GPFS all'NFS NetApp utilizzando XCP.</block>
  <block id="29fb90c4a1468e178582858240052f4c" category="summary">Per questa soluzione, NetApp ha convalidato la migrazione dei dati dal data lake (HDFS) e dai dati del cluster MapR a ONTAP NFS.  I dati risiedevano in MapR-FS e HDFS.  NetApp XCP ha introdotto una nuova funzionalità che migra direttamente i dati da un file system distribuito come HDFS e MapR-FS a ONTAP NFS.</block>
  <block id="d233c10a88f93c454d0e84cd34840512" category="doc">HDFS e MapR-FS su ONTAP NFS</block>
  <block id="676df8e27b06b6dd639822191d432dc2" category="paragraph">Per questa soluzione, NetApp ha convalidato la migrazione dei dati dal data lake (HDFS) e dai dati del cluster MapR a ONTAP NFS.  I dati risiedevano in MapR-FS e HDFS.  NetApp XCP ha introdotto una nuova funzionalità che migra direttamente i dati da un file system distribuito come HDFS e MapR-FS a ONTAP NFS.  XCP utilizza thread asincroni e chiamate API C HDFS per comunicare e trasferire dati da MapR-FS e HDFS.</block>
  <block id="adc95e83c5f5ce743bb6468ffdef4fc3" category="paragraph">La figura seguente mostra la migrazione dei dati dal data lake (HDFS) e MapR-FS a ONTAP NFS.  Grazie a questa nuova funzionalità, non è più necessario esportare la sorgente come condivisione NFS.</block>
  <block id="3789ec0eac19c6a55506d3fe4f2e880e" category="paragraph"><block ref="3789ec0eac19c6a55506d3fe4f2e880e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11c71088d0987243547dd8fc322c2ad" category="section-title">Perché i clienti stanno passando da HDFS e MapR-FS a NFS?</block>
  <block id="8616e2393304ffc26da9b5e853b8db33" category="paragraph">La maggior parte delle distribuzioni Hadoop, come Cloudera e Hortonworks, utilizzano HDFS, mentre le distribuzioni MapR utilizzano il proprio file system denominato Mapr-FS per archiviare i dati.  I dati HDFS e MapR-FS forniscono agli scienziati dei dati informazioni preziose che possono essere sfruttate nell'apprendimento automatico (ML) e nell'apprendimento profondo (DL).  I dati in HDFS e MapR-FS non sono condivisi, il che significa che non possono essere utilizzati da altre applicazioni.  I clienti sono alla ricerca di dati condivisi, in particolare nel settore bancario, dove i dati sensibili dei clienti vengono utilizzati da più applicazioni.  L'ultima versione di Hadoop (3.x o successiva) supporta l'origine dati NFS, a cui è possibile accedere senza software di terze parti aggiuntivo.  Con la nuova funzionalità NetApp XCP, i dati possono essere spostati direttamente da HDFS e MapR-FS a NetApp NFS per fornire accesso a più applicazioni</block>
  <block id="fa2772759fe171754d3e04460b417464" category="paragraph">Sono stati eseguiti test in Amazon Web Services (AWS) per trasferire i dati da MapR-FS a NFS per il test iniziale delle prestazioni con 12 nodi MAPR e 4 server NFS.</block>
  <block id="694e8d1f2ee056f98ee488bdc4982d73" category="cell">Quantità</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">Misurare</block>
  <block id="5d56dbd20d9ee1ab8a722ff12e331953" category="cell">CPU virtuale</block>
  <block id="4789f23283b3a61f858b641a1bef19a3" category="cell">Memoria</block>
  <block id="8c4aa541ee911e8d80451ef8cc304806" category="cell">Magazzinaggio</block>
  <block id="eec89088ee408b80387155272b113256" category="cell">Rete</block>
  <block id="e83e5674ab295a6613b60f5e12d1bfe3" category="cell">server NFS</block>
  <block id="6215b1525ff41917096b1eb923fe894f" category="cell">i3en.24xlarge</block>
  <block id="26657d5ff9020d2abefe558796b99584" category="cell">96</block>
  <block id="c45b008ff7fe72f83bb47cba575960c7" category="cell">488GiB</block>
  <block id="9f8ce2ff912e3931e4fc14876f3097f2" category="cell">8x SSD NVMe 7500</block>
  <block id="f899139df5e1059396431415e770c6dd" category="cell">100</block>
  <block id="899f7b8a7c3e28d3161a77da8f1c8e33" category="cell">Nodi MapR</block>
  <block id="6ac0fbf236c6d341a7f2c6c92933f744" category="cell">I3en.12xlarge</block>
  <block id="642e92efb79421734881b53e1e1b18b6" category="cell">48</block>
  <block id="1aa80378346dacbf8ce58aaadcefc35e" category="cell">384GiB</block>
  <block id="3ce58620106227953b9e12e2e0633095" category="cell">4x SSD NVMe 7500</block>
  <block id="c0c7c76d30bd3dcaefc96f40275bdc0a" category="cell">50</block>
  <block id="03e4c674f628169124f81fb7b98f9c92" category="paragraph">Sulla base dei test iniziali, abbiamo ottenuto una velocità di trasmissione di 20 GBps e siamo riusciti a trasferire 2 PB di dati al giorno.</block>
  <block id="fce5332d471cfbe0baf7fa83eb2d427d" category="inline-link-macro">TR-4863: TR-4863: Linee guida sulle best practice per NetApp XCP - Data Mover, migrazione file e analisi</block>
  <block id="d7b251f310540db8b677090e4068b718" category="paragraph">Per ulteriori informazioni sulla migrazione dei dati HDFS senza esportare HDFS in NFS, vedere la sezione "Fasi di distribuzione - NAS" in<block ref="8057f0a15e6751a5fa14293a5e88f017" category="inline-link-macro-rx"></block> .</block>
  <block id="5e1ee998c60aed58b6080afc9d8903a3" category="summary">Questo documento fornisce linee guida per lo spostamento dei dati di analisi dei big data e dei dati HPC verso l'intelligenza artificiale utilizzando NetApp XCP e NIPAM.  Discutiamo anche i vantaggi aziendali derivanti dal passaggio dei dati dai big data e dall'HPC all'intelligenza artificiale.</block>
  <block id="82a406843faa25e62de32fd044584709" category="doc">TR-4732: Analisi dei Big Data per l'intelligenza artificiale</block>
  <block id="439be0f3df9ab229e224aa3c8dbeca77" category="paragraph">Karthikeyan Nagalingam, NetApp</block>
  <block id="bdd40c24689e02e4043333640734a44e" category="paragraph">Questo documento descrive come trasferire i dati di analisi dei big data e i dati HPC all'intelligenza artificiale.  L'intelligenza artificiale elabora i dati NFS tramite esportazioni NFS, mentre i clienti spesso dispongono dei propri dati AI in una piattaforma di analisi big data, come HDFS, Blob o storage S3, nonché piattaforme HPC come GPFS.  Questo documento fornisce linee guida per lo spostamento dei dati di analisi dei big data e dei dati HPC verso l'intelligenza artificiale utilizzando NetApp XCP e NIPAM.  Discutiamo anche i vantaggi aziendali derivanti dal passaggio dei dati dai big data e dall'HPC all'intelligenza artificiale.</block>
  <block id="9895310afc8a3755fef2e679c38f32f8" category="section-title">Concetti e componenti</block>
  <block id="8ba5fcae463371ff85de74be48ced059" category="section-title">Archiviazione di analisi di Big Data</block>
  <block id="b5b25f8714075ee7aa7cae37cabc6e77" category="paragraph">L'analisi dei big data è il principale fornitore di storage per HDFS.  Un cliente utilizza spesso un file system compatibile con Hadoop (HCFS), come Windows Azure Blob Storage, MapR File System (MapR-FS) e S3 Object Storage.</block>
  <block id="201dde15c75147909c8154fe3e727aed" category="section-title">Sistema di file parallelo generale</block>
  <block id="510b2e746f7cab5126465c64edad8541" category="paragraph">GPFS di IBM è un file system aziendale che rappresenta un'alternativa a HDFS.  GPFS offre alle applicazioni la flessibilità di decidere la dimensione del blocco e il layout di replicazione, garantendo buone prestazioni ed efficienza.</block>
  <block id="49d7c87b66a2b688ec65b1a4fe9b5ddc" category="section-title">Modulo di analisi in loco NetApp</block>
  <block id="f1b570aebec7f92867ad62cf2fe7c50c" category="paragraph">Il modulo NetApp In-Place Analytics Module (NIPAM) funge da driver per i cluster Hadoop per l'accesso ai dati NFS.  È costituito da quattro componenti: un pool di connessioni, un NFS InputStream, una cache di gestione dei file e un NFS OutputStream. Per ulteriori informazioni, vedere <block ref="ead8bf031afc74347ebd06de968e5895" category="inline-link-rx"></block> .</block>
  <block id="0be6a753178a606f6e24a10fde5ec644" category="section-title">Copia distribuita di Hadoop</block>
  <block id="3cc73009b533164939781f9f6a4a1aa0" category="paragraph">Hadoop Distributed Copy (DistCp) è uno strumento di copia distribuita utilizzato per attività di copia inter-cluster e intra-cluster di grandi dimensioni.  Questo strumento utilizza MapReduce per la distribuzione dei dati, la gestione degli errori e la segnalazione.  Espande l'elenco di file e directory e li inserisce nelle attività di mappatura per copiare i dati dall'elenco di origine.  L'immagine seguente mostra l'operazione DistCp in HDFS e non HDFS.</block>
  <block id="513bd70b6fe800dda2548dae1bc404df" category="paragraph"><block ref="513bd70b6fe800dda2548dae1bc404df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8f54af1bdcb54a020503d81bc3b2114" category="paragraph">Hadoop DistCp sposta i dati tra i due sistemi HDFS senza utilizzare un driver aggiuntivo.  NetApp fornisce il driver per i sistemi non HDFS.  Per una destinazione NFS, NIPAM fornisce il driver per copiare i dati che Hadoop DistCp utilizza per comunicare con le destinazioni NFS durante la copia dei dati.</block>
  <block id="1215f8190533dfdf63d2224a6d88266f" category="section-title">Google Cloud NetApp Volumes</block>
  <block id="e6b6086807cb6588f15ae36a2a999e8f" category="paragraph">Google Cloud NetApp Volumes è un servizio file nativo nel cloud con prestazioni estreme.  Questo servizio aiuta i clienti ad accelerare il time-to-market aumentando e diminuendo rapidamente le risorse e utilizzando le funzionalità NetApp per migliorare la produttività e ridurre i tempi di inattività del personale.  Google Cloud NetApp Volumes è la giusta alternativa per il disaster recovery e il backup sul cloud perché riduce l'ingombro complessivo del data center e consuma meno spazio di archiviazione cloud pubblico nativo.</block>
  <block id="6efa8f47d1a76af77ce311b436e4dca9" category="section-title">NetApp XCP</block>
  <block id="a12ce47d330a9ea070b4fd322ca5f890" category="paragraph">NetApp XCP è un software client che consente la migrazione rapida e affidabile dei dati da qualsiasi dispositivo a NetApp e da NetApp a NetApp .  Questo strumento è progettato per copiare una grande quantità di dati NAS non strutturati da qualsiasi sistema NAS a un controller di archiviazione NetApp .  XCP Migration Tool utilizza un motore di streaming I/O multi-core e multicanale in grado di elaborare numerose richieste in parallelo, come la migrazione dei dati, l'elenco di file o directory e la segnalazione dello spazio.  Questo è lo strumento di migrazione dati NetApp predefinito.  È possibile utilizzare XCP per copiare dati da un cluster Hadoop e HPC allo storage NFS NetApp .  Il diagramma seguente mostra il trasferimento dati da un cluster Hadoop e HPC a un volume NetApp NFS utilizzando XCP.</block>
  <block id="31e2e6a49223ff3b99782fced8ae2f33" category="paragraph"><block ref="31e2e6a49223ff3b99782fced8ae2f33" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ccf66760432e212bf920c4b630bf24a8" category="section-title">Copia e sincronizzazione NetApp BlueXP</block>
  <block id="182c915d2a513090f731fbf85d4576bd" category="paragraph">NetApp BlueXP Copy and Sync è un software-as-a-service di replicazione dati ibrida che trasferisce e sincronizza i dati NFS, S3 e CIFS in modo fluido e sicuro tra storage locale e storage cloud.  Questo software viene utilizzato per la migrazione dei dati, l'archiviazione, la collaborazione, l'analisi e altro ancora.  Dopo il trasferimento dei dati, BlueXP Copy and Sync sincronizza continuamente i dati tra l'origine e la destinazione.  Andando avanti, trasferisce il delta.  Protegge inoltre i dati all'interno della tua rete, nel cloud o in sede.  Questo software si basa su un modello di pagamento a consumo, che fornisce una soluzione conveniente e offre funzionalità di monitoraggio e reporting per il trasferimento dei dati.</block>
  <block id="600c9e3e31c7cdf2c69044801b9ea998" category="summary">Questa sezione fornisce i passaggi dettagliati necessari per spostare i dati MapR-FS in ONTAP NFS utilizzando NetApp XCP.</block>
  <block id="6a848946dc9169e87668bb9f057c56c2" category="doc">MapR-FS a ONTAP NFS</block>
  <block id="3362be4f8dc0d043bec6bb8bf22a565b" category="list-text">Fornire tre LUN per ciascun nodo MapR e assegnare alle LUN la proprietà di tutti i nodi MapR.</block>
  <block id="a74eeec8d29cc5a609b980af2aee2fb3" category="list-text">Durante l'installazione, selezionare i LUN appena aggiunti per i dischi del cluster MapR utilizzati per MapR-FS.</block>
  <block id="87ae055df3def21f83bbbb9e287167b6" category="list-text">Installare un cluster MapR secondo la documentazione di MapR 6.1.</block>
  <block id="7549eec0595c1177d1a3b1a8c556ea8e" category="list-text">Controllare le operazioni di base di Hadoop utilizzando i comandi MapReduce come<block ref="b5a58cfcf19813db2fae678c75e004c8" prefix=" " category="inline-code"></block> .</block>
  <block id="455177bd981566b3ae1e0084e3381b11" category="list-text">Conserva i dati dei clienti in MapR-FS.  Ad esempio, abbiamo generato circa un terabyte di dati campione in MapR-FS utilizzando Teragen.</block>
  <block id="570bd2111387f5da50ad7d54e23e5fb2" category="list-text">Configurare MapR-FS come esportazione NFS.</block>
  <block id="4fe9587feb0e4de26dff3d33bbaf046e" category="list-text">Disabilitare il servizio nlockmgr su tutti i nodi MapR.</block>
  <block id="8c5d6c82648b5d5b2a4c82d33569b1c4" category="list-text">Esporta cartelle specifiche da MapR-FS su tutti i nodi MapR in<block ref="84a05a173e6cd86a4169f3dbd5897873" prefix=" " category="inline-code"></block> file.  Non esportare la cartella padre con autorizzazioni diverse quando si esportano le sottocartelle.</block>
  <block id="e78b84d9c1ff3b973293510503e86b95" category="list-text">Aggiorna il servizio NFS MapR-FS.</block>
  <block id="341009af7864703863b08f0bd1df43b5" category="list-text">Assegna un intervallo IP virtuale a un server specifico o a un set di server nel cluster MapR.  Quindi il cluster MapR assegna un IP a un server specifico per l'accesso ai dati NFS.  Gli IP consentono un'elevata disponibilità, il che significa che, se un server o una rete con un particolare IP subisce un errore, per l'accesso NFS può essere utilizzato l'IP successivo nell'intervallo di IP.</block>
  <block id="5165f49b44f610d03a79da336b53e8f2" category="admonition">Se si desidera fornire l'accesso NFS da tutti i nodi MapR, è possibile assegnare un set di IP virtuali a ciascun server e utilizzare le risorse di ciascun nodo MapR per l'accesso ai dati NFS.</block>
  <block id="c508683f7afca451e58f95b67197d51f" category="paragraph"><block ref="c508683f7afca451e58f95b67197d51f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54b9596f082ff106a71134b100eee486" category="paragraph"><block ref="54b9596f082ff106a71134b100eee486" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be91199bb393028826e953c78a526a54" category="paragraph"><block ref="be91199bb393028826e953c78a526a54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97532f358124e4f3087e522bb35f2cb8" category="list-text">Controllare gli IP virtuali assegnati a ciascun nodo MapR e utilizzarli per l'accesso ai dati NFS.</block>
  <block id="d1ed36990409b90ebe749d4e8ddab8b7" category="list-text">Montare il MapR-FS esportato tramite NFS utilizzando l'IP virtuale assegnato per verificare il funzionamento NFS.  Tuttavia, questo passaggio non è necessario per il trasferimento dati tramite NetApp XCP.</block>
  <block id="6288e9b84b4573721ff701d3bdc55fed" category="list-text">Configurare NetApp XCP per trasferire i dati dal gateway MapR-FS NFS a ONTAP NFS.</block>
  <block id="47bcc9815ee0b47ea9de7729c9c727f7" category="list-text">Configurare la posizione del catalogo per XCP.</block>
  <block id="e125588061821db7957020ded3b976f0" category="list-text">Copia il file di licenza in<block ref="0c8468e8bc6e9c8ce8e4de412fee0c10" prefix=" " category="inline-code"></block> .</block>
  <block id="76725a579a117275c078f16fdbe1fd04" category="list-text">Attiva XCP utilizzando<block ref="974d7928831087bfbec5968aec9bea85" prefix=" " category="inline-code"></block> comando.</block>
  <block id="07f3313db35fd32ada5426648ae5817d" category="list-text">Controllare la fonte per l'esportazione NFS.</block>
  <block id="7eefcefaba7483a2c7d6c71e934d0f28" category="list-text">Trasferire i dati tramite XCP da più nodi MapR da più IP di origine e più IP di destinazione (LIF ONTAP ).</block>
  <block id="c2cb3a97c34a702522aba4d19b7a1d39" category="list-text">Controllare la distribuzione del carico sul controller di accumulo.</block>
  <block id="af7ba099603ccd4070a5102166f2c998" category="summary">Sulla base di questa convalida, gli scienziati e gli ingegneri dei dati possono accedere ai dati NFS dai notebook AWS SageMaker Jupyter tramite bucket S3 da NetApp Cloud Volumes ONTAP.  Questo approccio consente un facile accesso e la condivisione degli stessi dati sia da NFS che da S3 senza la necessità di software aggiuntivo.</block>
  <block id="8053f00cf5e08f449b7cafe189c73a39" category="list-text">Classificazione del testo utilizzando SageMaker BlazingText</block>
  <block id="d6667429b7c60bcbf5e5d593e91d6cae" category="list-text">Supporto della versione ONTAP per l'archiviazione di oggetti S3</block>
  <block id="91ef54d96688b56bf968f57803df6675" category="inline-link"><block ref="91ef54d96688b56bf968f57803df6675" category="inline-link-rx"></block></block>
  <block id="53a581d907d105a589be9419e91b16fa" category="paragraph"><block ref="53a581d907d105a589be9419e91b16fa" category="inline-link-rx"></block></block>
  <block id="6e74710636e2da95cda4899adcdf891e" category="summary">I dati sono disponibili in NFS e accessibili da S3 da AWS SageMaker.</block>
  <block id="8394db253ec71ed9d59b9429983b8eb4" category="doc">Dualità dei dati per data scientist e altre applicazioni</block>
  <block id="3c438be737391744e2fed6f73c418638" category="section-title">Requisiti tecnologici</block>
  <block id="f4900d1d4a0a26325c4c9514e57c2c75" category="paragraph">Per il caso d'uso di dualità dei dati sono necessari NetApp BlueXP, NetApp Cloud Volumes ONTAP e AWS SageMaker Notebooks.</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="section-title">Requisiti software</block>
  <block id="6e6b6052efed2574e2dc05cbdc5d66d5" category="paragraph">Nella tabella seguente sono elencati i componenti software necessari per implementare il caso d'uso.</block>
  <block id="9b9477e579c3b44dd623d5a6e1ea8d78" category="cell">BlueXP</block>
  <block id="0f0b99ea2f70cd363c2c6a279f74e760" category="cell">NetApp Cloud Volumes ONTAP</block>
  <block id="dda9f6d67571441afa5cfb6b54b70873" category="cell">Quaderno AWS SageMaker</block>
  <block id="5ac7b083aa99c6ec0d7a272c37dc611d" category="section-title">Procedure di distribuzione</block>
  <block id="cc5f7f3bee6dcb16913051d6fc267977" category="paragraph">L'implementazione della soluzione di dualità dei dati comporta le seguenti attività:</block>
  <block id="6bb1f60bf0d00924a1bba54557e1feae" category="list-text">Connettore BlueXP</block>
  <block id="cf25fa6cf104cc1a67119acb6d4d364d" category="list-text">Dati per l'apprendimento automatico</block>
  <block id="59b20c2117a395af59d54a6533498e99" category="list-text">Apprendimento automatico convalidato da Jupyter Notebooks</block>
  <block id="46e0bb4f28dbf5013a68a8a69a3cf9f5" category="section-title">Connettore BlueXP</block>
  <block id="6ff27f6b5b95b177c735d22a2783e9ef" category="paragraph">Per questa convalida abbiamo utilizzato AWS.  È applicabile anche ad Azure e Google Cloud.  Per creare un connettore BlueXP in AWS, completa i seguenti passaggi:</block>
  <block id="4d7b48a5181bdd203b2ff52910c67d94" category="list-text">Abbiamo utilizzato le credenziali basate su mcarl-marketplace-subscription in BlueXP.</block>
  <block id="c0caffb5ab49caead75d39f6416ba841" category="list-text">Scegli la regione adatta al tuo ambiente (ad esempio, us-east-1 [N. Virginia]) e seleziona il metodo di autenticazione (ad esempio, Assumi ruolo o chiavi AWS).  In questa convalida utilizziamo le chiavi AWS.</block>
  <block id="86b72593a2ce2f4e46e7669ced916111" category="list-text">Fornire il nome del connettore e creare un ruolo.</block>
  <block id="71ffd00d3592df40d0db94a71ceab12d" category="list-text">Fornisci i dettagli della rete, come VPC, subnet o coppia di chiavi, a seconda che ti serva o meno un IP pubblico.</block>
  <block id="b5b37cef840fa0a17af0ef55c09a0e1f" category="list-text">Fornire i dettagli per il gruppo di sicurezza, come l'accesso HTTP, HTTPS o SSH dal tipo di origine, ad esempio ovunque e informazioni sull'intervallo IP.</block>
  <block id="45b20434e20aeebd5991cd84f2cf11c9" category="list-text">Rivedere e creare il connettore BlueXP .</block>
  <block id="92043f8a1dc0b0180854c25bcf5ff79d" category="list-text">Verificare che lo stato dell'istanza BlueXP EC2 sia in esecuzione nella console AWS e controllare l'indirizzo IP dalla scheda *Networking*.</block>
  <block id="7044ee6a43ee2152ca6d008fcb8228c3" category="list-text">Accedi all'interfaccia utente del connettore dal portale BlueXP oppure puoi utilizzare l'indirizzo IP per l'accesso dal browser.</block>
  <block id="064d933c0c02c4fe7ef1a07ad3a537d7" category="paragraph">Per creare un'istanza Cloud Volumes ONTAP in BlueXP, completare i seguenti passaggi:</block>
  <block id="35d88740e5ca53f6cabb06b3fce807b7" category="list-text">Crea un nuovo ambiente di lavoro, seleziona il provider cloud e seleziona il tipo di istanza Cloud Volumes ONTAP (ad esempio, single-CVO, HA o Amazon FSx ONTAP per ONTAP).</block>
  <block id="dcb89e397dde3dedb1a32224f0c15b78" category="list-text">Fornire dettagli quali il nome del cluster Cloud Volumes ONTAP e le credenziali.  In questa convalida, abbiamo creato un'istanza di Cloud Volumes ONTAP denominata<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block> .</block>
  <block id="9cf479af21359b2928a1b672d60577f2" category="list-text">Selezionare i servizi necessari per Cloud Volumes ONTAP.  In questa convalida, abbiamo scelto di monitorare solo, quindi abbiamo disabilitato *Data Sense &amp; Compliance* e *Backup su servizi cloud*.</block>
  <block id="cb95ef3838d59d553c71f50b1cadee27" category="list-text">Nella sezione *Posizione e connettività*, seleziona la regione AWS, la VPC, la subnet, il gruppo di sicurezza, il metodo di autenticazione SSH e una password o una coppia di chiavi.</block>
  <block id="fdd5d37c21ee01084537317345b3d78b" category="list-text">Scegli il metodo di ricarica.  Per questa convalida abbiamo utilizzato *Professional*.</block>
  <block id="00efec60d606ea6ad0bafe93bc77df92" category="list-text">È possibile scegliere un pacchetto preconfigurato, ad esempio *POC e piccoli carichi di lavoro*, *Carichi di lavoro di produzione di dati di database e applicazioni*, *DR conveniente* o *Carichi di lavoro di produzione ad altissime prestazioni*.  In questa convalida, scegliamo *Poc e piccoli carichi di lavoro*.</block>
  <block id="f22934293c2f2a761ea26fa4ae1828e1" category="list-text">Crea un volume con dimensioni specifiche, protocolli consentiti e opzioni di esportazione.  In questa convalida, abbiamo creato un volume chiamato<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block> .</block>
  <block id="f2706214c4a60177d14fb8495cbc6924" category="list-text">Scegliere un tipo di disco di profilo e un criterio di suddivisione in livelli.  In questa convalida, abbiamo disabilitato *Efficienza di archiviazione* e *SSD per uso generico – Prestazioni dinamiche*.</block>
  <block id="40d3f73a73f67ce67b286aef7a5d3ecb" category="list-text">Infine, rivedere e creare l'istanza Cloud Volumes ONTAP .  Quindi attendere 15-20 minuti affinché BlueXP crei l'ambiente di lavoro Cloud Volumes ONTAP .</block>
  <block id="a8b538b74c3f662c2248af9c6d4742db" category="list-text">Configurare i seguenti parametri per abilitare il protocollo Duality.  Il protocollo Duality (NFS/S3) è supportato da ONTAP 9.  12.1 e versioni successive.</block>
  <block id="15b53c14b58ee146309847451d1eb90a" category="list-text">In questa convalida, abbiamo creato un SVM chiamato<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block> e volume<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block> .</block>
  <block id="3514969b2381af83551c246e34b74403" category="list-text">Verificare che l'SVM supporti il protocollo per NFS e S3.  In caso contrario, modificare l'SVM per supportarli.</block>
  <block id="e41c06ffff0f8c9cadbc7f8bb37f8ae5" category="list-text">Se necessario, creare e installare un certificato CA.</block>
  <block id="0395f8062a8a7f4af05113bae8133737" category="list-text">Creare una policy sui dati di servizio.</block>
  <block id="6e16e110899749a795fe713253d850e7" category="list-text">Controllare i dettagli aggregati.</block>
  <block id="5d3f8e127103f0d5cf3de305db892b4d" category="list-text">Crea un utente e un gruppo.</block>
  <block id="efa22127bde2d3ab2e4f5b9a42d14814" category="list-text">Creare un bucket sul volume NFS.</block>
  <block id="c3fd6f44bf88d3f0eae4742edb58eafc" category="paragraph">Per creare un AWS Notebook da AWS SageMaker, completa i seguenti passaggi:</block>
  <block id="31378aab1ee6190e0b7fe33c501a5625" category="list-text">Assicurarsi che l'utente che crea l'istanza Notebook disponga di una policy IAM AmazonSageMakerFullAccess o faccia parte di un gruppo esistente che dispone dei diritti AmazonSageMakerFullAccess.  In questa convalida, l'utente fa parte di un gruppo esistente.</block>
  <block id="13c1455885d16af64f1bb96c4e48680a" category="list-text">Fornire le seguenti informazioni:</block>
  <block id="bb8101aed18120fa18dedaa994ffeea0" category="list-text">Nome dell'istanza del notebook.</block>
  <block id="6239d232142a089e53e7a13fa721237a" category="list-text">Tipo di istanza.</block>
  <block id="37056dac7373f7e1b74382036d25b69e" category="list-text">Identificatore della piattaforma.</block>
  <block id="38e2059c32c628cf89e90a6844a93800" category="list-text">Selezionare il ruolo IAM che dispone dei diritti AmazonSageMakerFullAccess.</block>
  <block id="55d7da5ede713135b1c2ebd7a615c3b4" category="list-text">Accesso root: abilita.</block>
  <block id="8f0e92e4434abc32ff62a914ae9f2ba6" category="list-text">Chiave di crittografia: seleziona Nessuna crittografia personalizzata.</block>
  <block id="8b77028d248afd826900d895636b4e98" category="list-text">Mantenere le restanti opzioni predefinite.</block>
  <block id="78456ee20793f732edfa9105bbb4e490" category="list-text">In questa convalida, i dettagli dell'istanza SageMaker sono i seguenti:</block>
  <block id="e90e797343ea3f751b0c32e808edaff8" category="inline-image-macro">Screenshot che illustra il passaggio.</block>
  <block id="e987fe9ec5699958a73a8f310b4d99e8" category="paragraph"><block ref="e987fe9ec5699958a73a8f310b4d99e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4414f1275568cfaaea91b68f1514516e" category="paragraph"><block ref="4414f1275568cfaaea91b68f1514516e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4789a9ab6472480889e111503d068623" category="list-text">Avviare AWS Notebook.</block>
  <block id="ce1d8475b6a4d461318eb3139cc54a3b" category="paragraph"><block ref="ce1d8475b6a4d461318eb3139cc54a3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbfbebd805ee7945ad38bc26f8fa9f1b" category="list-text">Apri il laboratorio Jupyter.</block>
  <block id="d81c10b932515c107a06a3737d985eaf" category="paragraph"><block ref="d81c10b932515c107a06a3737d985eaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab3269ab0de58f5611205f6ace06f3af" category="list-text">Accedi al terminale e monta il volume Cloud Volumes ONTAP .</block>
  <block id="cc0649b0871fde24c4a46e09186a36e0" category="list-text">Controllare il bucket creato sul volume Cloud Volumes ONTAP utilizzando i comandi AWS CLI.</block>
  <block id="4f31ff9815d3a8a959e7c557213068d6" category="paragraph">In questa convalida, abbiamo utilizzato un set di dati di DBpedia, un progetto comunitario basato sul crowdsourcing, per estrarre contenuti strutturati dalle informazioni create in vari progetti Wikimedia.</block>
  <block id="06d6ccf33b49ed20a34cdc26b6820253" category="list-text">Scarica i dati dalla posizione GitHub di DBpedia ed estraili.  Utilizzare lo stesso terminale utilizzato nella sezione precedente.</block>
  <block id="7f50b7f719282741fdf7ce5b8ca1f3dd" category="list-text">Copiare i dati nella posizione Cloud Volumes ONTAP e controllarli dal bucket S3 utilizzando AWS CLI.</block>
  <block id="0ecfbac978ab3f5979ec31eb5574d93e" category="list-text">Eseguire una convalida di base per assicurarsi che la funzionalità di lettura/scrittura funzioni sul bucket S3.</block>
  <block id="877169a066e14f0512d5f119945ef14d" category="section-title">Convalida l'apprendimento automatico da Jupyter Notebooks</block>
  <block id="6f73420916237ed836932ccf967d82ba" category="paragraph">La seguente convalida consente di creare, addestrare e distribuire modelli di apprendimento automatico tramite classificazione del testo utilizzando l'esempio SageMaker BlazingText riportato di seguito:</block>
  <block id="3cf03767e04159d1ec88e7fb0827b487" category="list-text">Installare i pacchetti boto3 e SageMaker.</block>
  <block id="b1282d58a4dcde0a2015d98ad33afd4c" category="paragraph">Produzione:</block>
  <block id="39017441ac701ebaef8de7116e7f71a0" category="list-text">Nel passaggio successivo, i dati<block ref="0a726fdd06082d233cd4eade40f12612" prefix="(" category="inline-code"></block> ) viene scaricato dal bucket s3<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block> a un'istanza di Jupyter Notebook utilizzata nell'apprendimento automatico.</block>
  <block id="a270350e3527fea9a36815fa5fe04ba0" category="list-text">Il codice seguente crea la mappatura dagli indici interi alle etichette di classe che vengono utilizzate per recuperare il nome effettivo della classe durante l'inferenza.</block>
  <block id="d17fa3d0aed3f8aaa5e78b447054126d" category="paragraph">L'output elenca i file e le cartelle presenti in<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block> bucket utilizzati come dati per la convalida dell'apprendimento automatico di AWS SageMaker.</block>
  <block id="0cfbf64679378e3e5367734fd2bd69aa" category="list-text">Avviare la fase di pre-elaborazione dei dati per pre-elaborare i dati di addestramento in un formato di testo tokenizzato e separato da spazi che può essere utilizzato dall'algoritmo BlazingText e dalla libreria nltk per tokenizzare le frasi di input dal dataset DBPedia.  Scarica il tokenizzatore nltk e altre librerie.  IL<block ref="6d49a792c1080aa5b33d27ec694621b6" prefix=" " category="inline-code"></block> applicato a ciascuna istanza di dati in parallelo utilizza il modulo multiprocessing Python.</block>
  <block id="d68566815a7248bae03e105c2db8853a" category="list-text">Carica il set di dati formattato e di addestramento su S3 in modo che possa essere utilizzato da SageMaker per eseguire attività di addestramento.  Quindi carica due file nel bucket e aggiungi il prefisso alla posizione utilizzando Python SDK.</block>
  <block id="e886ad36e527d85b26c492618651edad" category="list-text">Impostare una posizione di output in S3 in cui viene caricato l'artefatto del modello, in modo che gli artefatti possano essere l'output del processo di addestramento dell'algoritmo.  Crea un<block ref="6e3281884db83f9ee468a6e798b6bdfb" prefix=" " category="inline-code"></block> oggetto per avviare il lavoro di formazione.</block>
  <block id="41215e143c2b3810b37c4e4f47819077" category="list-text">Definisci SageMaker<block ref="a0b1f5f7b93af313b6e2452f52c8f3f6" prefix=" " category="inline-code"></block> con configurazioni di risorse e iperparametri per addestrare la classificazione del testo sul dataset DBPedia utilizzando la modalità supervisionata su un'istanza c4.4xlarge.</block>
  <block id="6c773c4d6e4a7dda7e00352894786bdb" category="list-text">Preparare un handshake tra i canali dati e l'algoritmo.  Per fare questo, crea il<block ref="0e021845d2c0e4ad94a91ce444c13681" prefix=" " category="inline-code"></block> oggetti dai canali dati e conservarli in un dizionario affinché l'algoritmo possa utilizzarli.</block>
  <block id="3b29bef19a742b8ab66cddf620871d31" category="list-text">Una volta terminato il lavoro, viene visualizzato il messaggio Lavoro completato.  Il modello addestrato può essere trovato nel bucket S3 che è stato impostato come<block ref="212ad7a4c11069727ffd02f333d7d8b1" prefix=" " category="inline-code"></block> nello stimatore.</block>
  <block id="6cb5683d87e53b375bd915572f960759" category="list-text">Una volta completato l'addestramento, distribuisci il modello addestrato come endpoint ospitato in tempo reale su Amazon SageMaker per effettuare previsioni.</block>
  <block id="4254a612097ca58653de7c0c39da8df2" category="list-text">Per impostazione predefinita, il modello restituisce una previsione con la probabilità più alta.  Per recuperare la parte superiore<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block> previsioni, set<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block> nel file di configurazione.</block>
  <block id="67be4f1bb90039baec0d8f73ff82a47e" category="list-text">Eliminare l'endpoint prima di chiudere il notebook.</block>
  <block id="16147684eb6910d9d73a43bb83091da4" category="summary">Gli scienziati e gli ingegneri dei dati hanno spesso bisogno di accedere ai dati archiviati nel formato NFS, ma accedere a questi dati direttamente dal protocollo S3 in AWS SageMaker può essere complicato perché AWS supporta solo l'accesso al bucket S3.  Tuttavia, NetApp ONTAP fornisce una soluzione consentendo l'accesso a doppio protocollo per NFS e S3.  Con questa soluzione, gli scienziati e gli ingegneri dei dati possono accedere ai dati NFS dai notebook AWS SageMaker tramite bucket S3 da NetApp Cloud Volumes ONTAP.  Questo approccio consente un facile accesso e la condivisione degli stessi dati sia da NFS che da S3 senza la necessità di software aggiuntivo.</block>
  <block id="e8ce8afdd7d335aed5b93d4a41ae0115" category="doc">TR-4967: Gestione dei dati nel cloud con la dualità file-oggetto NetApp e AWS SageMaker</block>
  <block id="7caace9abf76a798c629a9134d1bb259" category="summary">Un potenziale caso d'uso per l'accesso tramite doppio protocollo NFS e S3 è nei campi dell'apprendimento automatico e della scienza dei dati.  Ad esempio, un team di data scientist potrebbe lavorare a un progetto di apprendimento automatico utilizzando AWS SageMaker, che richiede l'accesso ai dati archiviati nel formato NFS.  Tuttavia, potrebbe essere necessario accedere ai dati e condividerli tramite bucket S3 per collaborare con altri membri del team o per integrarli con altre applicazioni che utilizzano S3.</block>
  <block id="ee8cf3bf54dea46135e299d79fa1c179" category="paragraph">Questa soluzione utilizza le seguenti tecnologie:</block>
  <block id="a03ea23912d3b35c875ff398aa4888af" category="list-text">*Quaderno AWS SageMaker.*  Offre funzionalità di apprendimento automatico a sviluppatori e data scientist per creare, addestrare e distribuire modelli di apprendimento automatico di alta qualità in modo efficiente.</block>
  <block id="bbe2552dc6295d353c02fd85c243f334" category="list-text">* NetApp BlueXP.*  Consente l'individuazione, la distribuzione e la gestione dello storage in locale, nonché su AWS, Azure e Google Cloud.  Fornisce protezione dei dati contro la perdita di dati, le minacce informatiche e le interruzioni non pianificate e ottimizza l'archiviazione e l'infrastruttura dei dati.</block>
  <block id="aa6fa71ab9848c5875470d36bbc2138a" category="list-text">* NetApp Cloud Volumes ONTAP.*  Fornisce volumi di archiviazione di livello aziendale con protocolli NFS, SMB/CIFS, iSCSI e S3 su AWS, Azure e Google Cloud, offrendo agli utenti maggiore flessibilità nell'accesso e nella gestione dei propri dati nel cloud.</block>
  <block id="eea496572a01ca3e5ced1dfe99a5809c" category="paragraph">NetApp Cloud Volumes ONTAP creato da BlueXP per archiviare i dati ML.</block>
  <block id="923baf107dc23ca10f968a4fdecd4f4f" category="paragraph">La figura seguente mostra i componenti tecnici della soluzione.</block>
  <block id="8afbfe3aeb9c594404d5c244cf8f6024" category="inline-image-macro">Questa figura mostra i componenti tecnici della soluzione.</block>
  <block id="d3d9ae40ce6d205245ae4b8c9649b6e2" category="paragraph"><block ref="d3d9ae40ce6d205245ae4b8c9649b6e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55c5281d80934f950192f768715495f0" category="paragraph">Utilizzando NetApp Cloud Volumes ONTAP, il team può archiviare i propri dati in un'unica posizione e renderli accessibili tramite i protocolli NFS e S3.  Gli scienziati dei dati possono accedere ai dati in formato NFS direttamente da AWS SageMaker, mentre altri membri del team o applicazioni possono accedere agli stessi dati tramite bucket S3.</block>
  <block id="f8ba1b513231e9ca54a5c3b94733c28d" category="paragraph">Questo approccio consente di accedere ai dati e di condividerli in modo semplice ed efficiente, senza la necessità di software aggiuntivo o di migrazione dei dati tra diverse soluzioni di archiviazione.  Permette inoltre un flusso di lavoro più snello e una maggiore collaborazione tra i membri del team, con conseguente sviluppo più rapido ed efficace dei modelli di apprendimento automatico.</block>
  <block id="7747c0c1913888384e25d3a99b247187" category="summary">Questo documento fornisce linee guida sulle best practice per l'utilizzo di Kafka con lo storage NetApp , inclusi test di certificazione Confluent Kafka, risultati delle prestazioni, ottimizzazione, connettori Kafka e la funzionalità di auto-ribilanciamento.</block>
  <block id="d17096a4e247d84eba8c623e8df7bb38" category="paragraph">Questo documento fornisce linee guida sulle best practice per l'utilizzo di Confluent Tiered Storage con storage NetApp , inclusi test di verifica, risultati delle prestazioni dello storage a livelli, ottimizzazione, connettori Confluent S3 e funzionalità di autobilanciamento.  Considerando le policy ILM, le prestazioni di Confluent con più test delle prestazioni per la verifica e le API S3 standard del settore, l'archiviazione di oggetti NetApp StorageGRID è la scelta ottimale per l'archiviazione a livelli di Confluent.</block>
  <block id="06bf7cdac46014ea728ea73ea94f29ed" category="list-text">Che cos'è Apache Kafka</block>
  <block id="9411b66537bb375699af4bbf90c682d3" category="inline-link"><block ref="9411b66537bb375699af4bbf90c682d3" category="inline-link-rx"></block></block>
  <block id="a2b6e6fe4a206b71df85cc00f128ef0c" category="paragraph"><block ref="a2b6e6fe4a206b71df85cc00f128ef0c" category="inline-link-rx"></block></block>
  <block id="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link"><block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="6bfac05f3cc2c0adace9c385ef708fd9" category="paragraph"><block ref="6bfac05f3cc2c0adace9c385ef708fd9" category="inline-link-rx"></block></block>
  <block id="8f74869149421fffb3c139e146a83d10" category="list-text">Dettagli dei parametri del sink S3</block>
  <block id="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link"><block ref="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link-rx"></block></block>
  <block id="26f8d9a8c1177c17a089f9a5c18628f4" category="paragraph"><block ref="26f8d9a8c1177c17a089f9a5c18628f4" category="inline-link-rx"></block></block>
  <block id="bb2bd99338b18762ef6953ad2cbfafc7" category="list-text">Apache Kafka</block>
  <block id="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link"><block ref="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link-rx"></block></block>
  <block id="c001bbfb62e45f662fe697182fa82240" category="paragraph"><block ref="c001bbfb62e45f662fe697182fa82240" category="inline-link-rx"></block></block>
  <block id="4f6236b021284cc85e87f1145d34e74b" category="list-text">Archiviazione infinita nella piattaforma Confluent</block>
  <block id="43a9697f317e04e185bacb99ee76b7fb" category="inline-link"><block ref="43a9697f317e04e185bacb99ee76b7fb" category="inline-link-rx"></block></block>
  <block id="a156036c426dcb5d87fc97e5eacdc183" category="paragraph"><block ref="a156036c426dcb5d87fc97e5eacdc183" category="inline-link-rx"></block></block>
  <block id="a53b0667612f6e25b1d426569d860cac" category="list-text">Confluent Tiered Storage: best practice e dimensionamento</block>
  <block id="a2e63818a36c6308885f4c0109e99b56" category="inline-link"><block ref="a2e63818a36c6308885f4c0109e99b56" category="inline-link-rx"></block></block>
  <block id="0c2ea24bb29ad03d1f43efe9a08c7da0" category="paragraph"><block ref="0c2ea24bb29ad03d1f43efe9a08c7da0" category="inline-link-rx"></block></block>
  <block id="ee764f7614a20c6500a54f1abc769567" category="list-text">Connettore sink Amazon S3 per Confluent Platform</block>
  <block id="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link"><block ref="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link-rx"></block></block>
  <block id="ca80d8d3004f0fce6bc195b6b43ccaeb" category="paragraph"><block ref="ca80d8d3004f0fce6bc195b6b43ccaeb" category="inline-link-rx"></block></block>
  <block id="5cbad2383ea03d52c73feba910ccb4a9" category="list-text">Dimensionamento di Kafka</block>
  <block id="7a8c563c1b96991ca597759bb447eb65" category="inline-link"><block ref="7a8c563c1b96991ca597759bb447eb65" category="inline-link-rx"></block></block>
  <block id="a2d2c0cad325abb54e33c688d54ce125" category="paragraph"><block ref="a2d2c0cad325abb54e33c688d54ce125" category="inline-link-rx"></block></block>
  <block id="989772944133ad8cd766bbdfe91cb365" category="list-text">Dimensionamento StorageGRID</block>
  <block id="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link"><block ref="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link-rx"></block></block>
  <block id="1e9dcc0360cfc46d71d6e0c3effa6379" category="paragraph"><block ref="1e9dcc0360cfc46d71d6e0c3effa6379" category="inline-link-rx"></block></block>
  <block id="5f750332aea13a67a316c81c03a35752" category="list-text">Casi d'uso di Kafka</block>
  <block id="c97a8ddb222f78361f59ac027aa08c70" category="inline-link"><block ref="c97a8ddb222f78361f59ac027aa08c70" category="inline-link-rx"></block></block>
  <block id="58f7c8dd51e4199a8f2caf79409bada1" category="paragraph"><block ref="58f7c8dd51e4199a8f2caf79409bada1" category="inline-link-rx"></block></block>
  <block id="f51439b4d8807e7a73cb24b6f11e16e2" category="list-text">Cluster Kafka autobilancianti nella piattaforma confluente 6.0</block>
  <block id="866d1bcab8bac705e171a01e8fe2e717" category="inline-link"><block ref="866d1bcab8bac705e171a01e8fe2e717" category="inline-link-rx"></block></block>
  <block id="b6251e175649ca2d0108725f99fc225f" category="paragraph"><block ref="b6251e175649ca2d0108725f99fc225f" category="inline-link-rx"></block></block>
  <block id="aa3c3c6442ddbda62fd0694691e34122" category="inline-link"><block ref="aa3c3c6442ddbda62fd0694691e34122" category="inline-link-rx"></block></block>
  <block id="f7365ec0514100387d644210374998c1" category="paragraph"><block ref="f7365ec0514100387d644210374998c1" category="inline-link-rx"></block></block>
  <block id="69fc1008ccb741113af5042f04fcbc8b" category="summary">Questo documento descrive le linee guida sulle best practice per l'utilizzo di Kafka su un controller di storage NetApp .</block>
  <block id="a29b982ab81cd1d74045ee43e3378135" category="paragraph">Karthikeyan Nagalingam, Joseph Kandatilparambil, NetApp Rankesh Kumar, Confluent</block>
  <block id="37281d123cc59a7c05b3ce30b5ea435e" category="paragraph">Apache Kafka è una piattaforma di streaming di eventi distribuita dalla comunità, in grado di gestire migliaia di miliardi di eventi al giorno.  Inizialmente concepito come una coda di messaggistica, Kafka si basa su un'astrazione di un registro di commit distribuito.  Da quando è stato creato e reso open source da LinkedIn nel 2011, Kafka si è evoluto da una coda di messaggi a una piattaforma di streaming di eventi a tutti gli effetti.  Confluent fornisce la distribuzione di Apache Kafka tramite la piattaforma Confluent.  La piattaforma Confluent integra Kafka con funzionalità aggiuntive per la comunità e commerciali, progettate per migliorare l'esperienza di streaming sia degli operatori che degli sviluppatori in produzione su larga scala.</block>
  <block id="4a967c3b711955b2fd888bf0abedb515" category="paragraph">Questo documento descrive le linee guida sulle best practice per l'utilizzo di Confluent Tiered Storage su un'offerta di storage a oggetti di NetApp, fornendo i seguenti contenuti:</block>
  <block id="2717b4b699259a5e59279aac92d526a2" category="list-text">Verifica confluente con NetApp Object Storage – NetApp StorageGRID</block>
  <block id="0939eec6a072b9deba2d6aa39249110d" category="list-text">Test delle prestazioni di archiviazione a livelli</block>
  <block id="7607a859995debe77df0676d09d8270b" category="list-text">Linee guida sulle best practice per Confluent sui sistemi di storage NetApp</block>
  <block id="59cb8890508bcaf057fd0360eb8ff783" category="section-title">Perché Confluent Tiered Storage?</block>
  <block id="7a3966946c615eb57ae930f6948a1c65" category="inline-link-macro">questo articolo di Confluent</block>
  <block id="eced8e0ff3a0cd0f66b3a8845f1e08be" category="paragraph">Confluent è diventata la piattaforma di streaming in tempo reale predefinita per molte applicazioni, in particolare per i carichi di lavoro di big data, analisi e streaming.  Tiered Storage consente agli utenti di separare l'elaborazione dall'archiviazione nella piattaforma Confluent.  Rende l'archiviazione dei dati più conveniente, consente di archiviare quantità di dati praticamente infinite e di aumentare (o diminuire) i carichi di lavoro su richiesta, semplificando inoltre le attività amministrative come il ribilanciamento dei dati e dei tenant.  I sistemi di archiviazione compatibili con S3 possono sfruttare tutte queste funzionalità per democratizzare i dati con tutti gli eventi in un unico posto, eliminando la necessità di una complessa ingegneria dei dati.  Per maggiori informazioni sul motivo per cui dovresti utilizzare l'archiviazione a livelli per Kafka, controlla<block ref="3c87b0bff8160b787f5bf29d10131d5e" category="inline-link-macro-rx"></block> .</block>
  <block id="911086e7904dbc449b09545eba850304" category="section-title">Perché NetApp StorageGRID per l'archiviazione a livelli?</block>
  <block id="ee6c2a9cd0205695027987ec8da32dfe" category="paragraph">StorageGRID è una piattaforma di archiviazione di oggetti leader del settore di NetApp.  StorageGRID è una soluzione di archiviazione basata su oggetti e definita dal software che supporta le API di oggetti standard del settore, tra cui l'API Amazon Simple Storage Service (S3).  StorageGRID archivia e gestisce dati non strutturati su larga scala per fornire un archivio di oggetti sicuro e durevole.  I contenuti vengono posizionati nel posto giusto, al momento giusto e sul livello di archiviazione corretto, ottimizzando i flussi di lavoro e riducendo i costi per i rich media distribuiti a livello globale.</block>
  <block id="5e5ef53b540f19d6746e6645de37cbb4" category="paragraph">Il principale elemento di differenziazione di StorageGRID è il suo motore di policy Information Lifecycle Management (ILM), che consente la gestione del ciclo di vita dei dati basata su policy.  Il motore delle policy può utilizzare i metadati per gestire il modo in cui i dati vengono archiviati durante il loro ciclo di vita, ottimizzando inizialmente le prestazioni e ottimizzando automaticamente i costi e la durabilità man mano che i dati invecchiano.</block>
  <block id="a7f9d3e4bde145f56bcbec81a6dc2ef3" category="section-title">Abilitazione dell'archiviazione a livelli confluenti</block>
  <block id="a5cb83c3eb7e8757a8f985f8d935e700" category="paragraph">L'idea di base dell'archiviazione a livelli è quella di separare le attività di archiviazione dei dati da quelle di elaborazione degli stessi.  Grazie a questa separazione, diventa molto più semplice per il livello di archiviazione dei dati e per il livello di elaborazione dei dati scalare in modo indipendente.</block>
  <block id="ec4d623bd1019ab2fabc3a02ae9dc70d" category="paragraph">Una soluzione di archiviazione a livelli per Confluent deve tenere conto di due fattori.  Innanzitutto, deve aggirare o evitare le proprietà comuni di coerenza e disponibilità dell'archivio oggetti, come incongruenze nelle operazioni LIST e occasionali indisponibilità degli oggetti.  In secondo luogo, deve gestire correttamente l'interazione tra l'archiviazione a livelli e il modello di replicazione e tolleranza agli errori di Kafka, inclusa la possibilità che i leader zombie continuino a suddividere gli intervalli di offset.  L'archiviazione di oggetti NetApp garantisce sia la disponibilità costante degli oggetti sia il modello HA che rende l'archiviazione obsoleta disponibile per intervalli di offset di livello.  Lo storage di oggetti NetApp garantisce una disponibilità costante degli oggetti e un modello HA per rendere lo storage obsoleto disponibile per intervalli di offset di livello.</block>
  <block id="104f1daa661d4c74d5bfd4e54946a4f4" category="paragraph">Con l'archiviazione a livelli, puoi utilizzare piattaforme ad alte prestazioni per letture e scritture a bassa latenza in prossimità della coda dei dati in streaming, e puoi anche utilizzare archivi di oggetti più economici e scalabili come NetApp StorageGRID per letture storiche ad alta velocità.  Disponiamo anche di una soluzione tecnica per Spark con il controller di archiviazione NetApp; i dettagli sono disponibili qui.  La figura seguente mostra come Kafka si inserisce in una pipeline di analisi in tempo reale.</block>
  <block id="eea5b5aaa7bc893f83efe26850f04584" category="paragraph"><block ref="eea5b5aaa7bc893f83efe26850f04584" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0977e5b84fa31f5087efbbc1dc355236" category="paragraph">La figura seguente illustra come NetApp StorageGRID si inserisce come livello di archiviazione degli oggetti di Confluent Kafka.</block>
  <block id="baa92f35a9209359bb52e9fa325d0e29" category="paragraph"><block ref="baa92f35a9209359bb52e9fa325d0e29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="35f99fa939062899487754f637210a25" category="summary">Questa sezione riguarda l'hardware e il software utilizzati per la certificazione Confluent.  Queste informazioni sono applicabili alla distribuzione di Kafka con storage NetApp .</block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="doc">Dimensionamento</block>
  <block id="faa5cf9412df3e7266db15b6f1a5070d" category="paragraph">Il dimensionamento Kafka può essere eseguito con quattro modalità di configurazione: semplice, granulare, inversa e partizioni.</block>
  <block id="1fbb1e3943c2c6c560247ac8f9289780" category="section-title">Semplice</block>
  <block id="580c6adb23970405f45409b06eb3ba39" category="paragraph">La modalità semplice è adatta ai nuovi utenti di Apache Kafka o ai casi d'uso iniziali.  Per questa modalità, è necessario specificare requisiti quali velocità effettiva in MBps, fanout di lettura, conservazione e percentuale di utilizzo delle risorse (il 60% è l'impostazione predefinita).  Si accede anche all'ambiente, ad esempio on-premise (bare-metal, VMware, Kubernetes o OpenStack) o cloud.  Sulla base di queste informazioni, il dimensionamento di un cluster Kafka fornisce il numero di server necessari per il broker, lo zookeeper, i worker di connessione Apache Kafka, il registro degli schemi, un proxy REST, ksqlDB e il centro di controllo Confluent.</block>
  <block id="ae20e37661048a8d6cd37c4dbacac985" category="paragraph">Per l'archiviazione a livelli, prendere in considerazione la modalità di configurazione granulare per il dimensionamento di un cluster Kafka.  La modalità granulare è adatta agli utenti esperti di Apache Kafka o a casi d'uso ben definiti.  Questa sezione descrive il dimensionamento per produttori, processori di flusso e consumatori.</block>
  <block id="40d2d6f5a1dfde1a3b5ba2a70377fa0f" category="section-title">Produttori</block>
  <block id="05318fa579b7e76a65531afd94250ed3" category="paragraph">Per descrivere i produttori per Apache Kafka (ad esempio un client nativo, un proxy REST o un connettore Kafka), fornire le seguenti informazioni:</block>
  <block id="91be21e4458c6c8f0d6f61c307faf194" category="list-text">*Nome.*  Scintilla.</block>
  <block id="b39a7ae16ea364375daa4f600ebed072" category="list-text">*Tipo di produttore.*  Applicazione o servizio, proxy (REST, MQTT, altro) e database esistente (RDBMS, NOSQL, altro).  Puoi anche selezionare "Non lo so".</block>
  <block id="3fd4bc385cb0a0f62ae4183f316ff707" category="list-text">*Capacità media.*  In eventi al secondo (ad esempio 1.000.000).</block>
  <block id="14ec4c2c8c9edf10c6aeefaf27f1f713" category="list-text">*Massima produttività.*  In eventi al secondo (ad esempio 4.000.000).</block>
  <block id="b4672ddde5cb9c30e0e682084a411123" category="list-text">*Dimensione media del messaggio.*  In byte, non compresso (max 1 MB; ad esempio 1000).</block>
  <block id="f56fd2104d8bf51910ee81196e8b4751" category="list-text">*Formato del messaggio.*  Le opzioni includono Avro, JSON, buffer di protocollo, binario, testo, "Non lo so" e altro.</block>
  <block id="b26274df5f3f47d18e40ee961fa8c5b5" category="list-text">*Fattore di replicazione.*  Le opzioni sono 1, 2, 3 (raccomandazione Confluent), 4, 5 o 6.</block>
  <block id="6320400b940be83033b0ce5ea91a3799" category="list-text">*Tempo di conservazione.*  Un giorno (ad esempio).  Per quanto tempo desideri che i tuoi dati vengano archiviati in Apache Kafka?  Inserire -1 con qualsiasi unità per un tempo infinito.  La calcolatrice presuppone un tempo di conservazione di 10 anni per una conservazione infinita.</block>
  <block id="eb46bfc819d70448200241a8f1efec72" category="list-text">Selezionare la casella di controllo "Abilitare l'archiviazione a livelli per ridurre il conteggio dei broker e consentire l'archiviazione infinita?"</block>
  <block id="d66063041931961a7565ee71f7a7dd67" category="list-text">Quando è abilitato l'archiviazione a livelli, i campi di conservazione controllano il set di dati archiviati localmente sul broker.  I campi di conservazione degli archivi controllano per quanto tempo i dati vengono conservati nell'archivio degli oggetti.</block>
  <block id="13bc2bec2c4039bad2d63b4ccf9611d4" category="list-text">*Conservazione in archivio.*  Un anno (ad esempio).  Per quanto tempo desideri che i tuoi dati rimangano archiviati?  Inserisci -1 con qualsiasi unità per una durata infinita.  Il calcolatore presuppone una conservazione di 10 anni per una conservazione infinita.</block>
  <block id="841d5d94c8cc645b8a35f0b58d3d5c6d" category="list-text">*Moltiplicatore di crescita.*  1 (ad esempio).  Se il valore di questo parametro si basa sulla produttività attuale, impostarlo su 1.  Per dimensionare in base alla crescita aggiuntiva, impostare questo parametro su un moltiplicatore di crescita.</block>
  <block id="5f044353fac0e72b8b68a9608cdfea2d" category="list-text">*Numero di istanze del produttore.*  10 (ad esempio).  Quante istanze del produttore saranno in esecuzione?  Questo input è necessario per incorporare il carico della CPU nel calcolo delle dimensioni.  Un valore vuoto indica che il carico della CPU non viene incorporato nel calcolo.</block>
  <block id="585e13820ff765aec3c094fbb66fb358" category="paragraph">Sulla base di questo esempio di input, il dimensionamento ha il seguente effetto sui produttori:</block>
  <block id="5504abde59477d70ee34b7c970af3ed2" category="list-text">Velocità media in byte non compressi: 1 GBps.  Velocità di trasmissione massima in byte non compressi: 4 GBps.  Velocità media in byte compressi: 400 MBps.  Velocità di trasmissione massima in byte compressi: 1,6 GBps.  Questo valore si basa su un tasso di compressione predefinito del 60% (è possibile modificarlo).</block>
  <block id="fe685c6164262035f3c0407347a3d38d" category="inline-link-macro"><block ref="fe685c6164262035f3c0407347a3d38d" category="inline-link-rx"></block></block>
  <block id="d6730cec7284a7856088b8a49563caef" category="list-text">Spazio di archiviazione hotset totale on-broker richiesto: 31.104 TB, inclusa la replica, compresso.  Spazio di archiviazione totale richiesto fuori dal broker: 378.432 TB, compresso.  Utilizzo<block ref="e132e1b42fc350f637835189d38d8bdf" category="inline-link-macro-rx"></block> per il dimensionamento StorageGRID .</block>
  <block id="65541f1c1daa682e605090dda4f5581b" category="paragraph">Gli Stream Processor devono descrivere le loro applicazioni o servizi che consumano dati da Apache Kafka e li riproducono in Apache Kafka.  Nella maggior parte dei casi sono creati in ksqlDB o Kafka Streams.</block>
  <block id="47bf3a39e68a8e88ad9fff34b58afc0a" category="list-text">*Nome.*  Streamer scintillante.</block>
  <block id="23f4b8037342e7943a6f549d7868281e" category="list-text">*Tempo di elaborazione.*  Quanto tempo impiega questo processore per elaborare un singolo messaggio?</block>
  <block id="0d4a13e2166384d926575e139fe3c68c" category="list-text">1 ms (trasformazione semplice, senza stato) [esempio], 10 ms (operazione in memoria con stato).</block>
  <block id="a1d2bac0d8ed78c0ce6bb941328bc680" category="list-text">100 ms (operazione di rete o disco con stato), 1000 ms (chiamata REST di terze parti).</block>
  <block id="8b74c5757b588cdfea993715c0ce3b58" category="list-text">Ho confrontato questo parametro e so esattamente quanto tempo ci vuole.</block>
  <block id="df8cd4e4488e4a8198132e46fc2beec9" category="list-text">*Ritenzione dell'output.*  1 giorno (esempio).  Un processore di flusso restituisce il suo output ad Apache Kafka.  Per quanto tempo desideri che questi dati di output vengano archiviati in Apache Kafka?  Inserisci -1 con qualsiasi unità per una durata infinita.</block>
  <block id="108b072da5b6fab64d55b4f1d69690d4" category="list-text">Selezionare la casella di controllo "Abilitare l'archiviazione a livelli per ridurre il conteggio dei broker e consentire l'archiviazione infinita?"</block>
  <block id="c4462b25651379530a9eea9b2b478755" category="list-text">*Conservazione in archivio.*  1 anno (ad esempio).  Per quanto tempo desideri che i tuoi dati rimangano archiviati?  Inserisci -1 con qualsiasi unità per una durata infinita.  Il calcolatore presuppone una conservazione di 10 anni per una conservazione infinita.</block>
  <block id="6507507d73f33bc3d1077b4454d9d3dd" category="list-text">*Percentuale di passaggio in uscita.*  100 (ad esempio).  Un processore di flusso restituisce il suo output ad Apache Kafka.  Quale percentuale del throughput in entrata verrà reinviata ad Apache Kafka?  Ad esempio, se la velocità in ingresso è di 20 MBps e questo valore è 10, la velocità in uscita sarà di 2 MBps.</block>
  <block id="aa35062fd231efb888b1d664e6480c1d" category="list-text">Da quali applicazioni viene letto?  Selezionare "Spark", il nome utilizzato nel dimensionamento basato sul tipo di produttore.  Sulla base dei dati sopra riportati, è possibile aspettarsi i seguenti effetti del dimensionamento sulle istanze del processore di flusso e sulle stime delle partizioni degli argomenti:</block>
  <block id="bbc0ea8f6decb55572d395615cd02a3b" category="list-text">Questa applicazione di elaborazione di flussi richiede il seguente numero di istanze.  Probabilmente anche gli argomenti in arrivo richiederanno questo numero di partizioni.  Contattare Confluent per confermare questo parametro.</block>
  <block id="0a206846c82be8eef261c4c686599582" category="list-text">1.000 per la produttività media senza moltiplicatore di crescita</block>
  <block id="b032c5d1deed2d1b75c4f8019b5155e3" category="list-text">4.000 per la massima produttività senza moltiplicatore di crescita</block>
  <block id="5cbe73cfdf68ec8b04b4506b237d8af9" category="list-text">1.000 per la produttività media con un moltiplicatore di crescita</block>
  <block id="f51843d6cdec756114fb7f153ab79f46" category="list-text">4.000 per la massima produttività con un moltiplicatore di crescita</block>
  <block id="1ebe06b1421d14bafea4a4d9a545d956" category="section-title">Consumatori</block>
  <block id="4d2351cfaa069bdffc56cd73486deacb" category="paragraph">Descrivi le tue applicazioni o i tuoi servizi che consumano dati da Apache Kafka e non li restituiscono in Apache Kafka; ad esempio, un client nativo o Kafka Connector.</block>
  <block id="21af20352468dedb23eb4b6fa7362e32" category="list-text">*Nome.*  Consumatore di scintille.</block>
  <block id="9e3b25cc5e8806da459be0a41ecfce10" category="list-text">*Tempo di elaborazione.*  Quanto tempo impiega questo consumatore a elaborare un singolo messaggio?</block>
  <block id="39ad97382609f7463897aa49624f20d4" category="list-text">1 ms (ad esempio, un'attività semplice e senza stato come la registrazione)</block>
  <block id="3d74518bdd6cfa27a42a16145872cc59" category="list-text">10 ms (scritture veloci su un datastore)</block>
  <block id="9f44c2afdbd671220f00e45494646aa6" category="list-text">100 ms (scritture lente su un datastore)</block>
  <block id="1284667da9611e925a39eee76e44e565" category="list-text">1000 ms (chiamata REST di terze parti)</block>
  <block id="fff6a4b96ed9fb45c7eab95aeb8eb684" category="list-text">Qualche altro processo di riferimento di durata nota.</block>
  <block id="6490501e3342b6bea241de7194a60bba" category="list-text">*Tipo di consumatore.*  Applicazione, proxy o sink per un datastore esistente (RDBMS, NoSQL, altro).</block>
  <block id="23a444b3f78a63619b03bea8301f4edb" category="list-text">Da quali applicazioni viene letto?  Collegare questo parametro con le dimensioni del produttore e del flusso determinate in precedenza.</block>
  <block id="2feb2ea8e1991424930eda0c7cdeb393" category="paragraph">Sulla base dei dati di cui sopra, è necessario determinare le dimensioni per le istanze dei consumatori e le stime della partizione degli argomenti.  Un'applicazione consumer richiede il seguente numero di istanze.</block>
  <block id="90e1e02e655ca52c281e9b5ac01ca245" category="list-text">2.000 per la produttività media, nessun moltiplicatore di crescita</block>
  <block id="228e2cc32e2eedd0cfaf646cb26ad562" category="list-text">8.000 per la massima produttività, nessun moltiplicatore di crescita</block>
  <block id="622c202fad5851b4699d8679ec9d3ce4" category="list-text">2.000 per la produttività media, incluso il moltiplicatore di crescita</block>
  <block id="da18372dd9e384fd5a4fd97fa6bdb872" category="list-text">8.000 per la massima produttività, incluso il moltiplicatore di crescita</block>
  <block id="5992882fb5e2f68b36cbf47d5ffc182a" category="paragraph">Probabilmente anche gli argomenti in arrivo necessitano di questo numero di partizioni.  Contattare Confluent per conferma.</block>
  <block id="152f9b32fca1ce5e9a3fc34e8c9e69c0" category="paragraph">Oltre ai requisiti per produttori, processori di streaming e consumatori, è necessario fornire i seguenti requisiti aggiuntivi:</block>
  <block id="aea71dcdb94c855eb0655cb615bdcfe2" category="list-text">*È tempo di ricostruire.*  Ad esempio, 4 ore.  Se un host broker Apache Kafka si guasta, i suoi dati vengono persi e viene predisposto un nuovo host per sostituire quello guasto, quanto velocemente deve ricostruirsi questo nuovo host?  Lasciare vuoto questo parametro se il valore è sconosciuto.</block>
  <block id="3bc49d2594090d023892da5211f6f7a4" category="list-text">*Obiettivo di utilizzo delle risorse (percentuale).*  Ad esempio, 60.  Quanto vuoi che vengano utilizzati i tuoi host durante la velocità media?  Confluent consiglia un utilizzo del 60%, a meno che non si utilizzino cluster autobilancianti Confluent, nel qual caso l'utilizzo può essere maggiore.</block>
  <block id="9fa691f61c91ce32c6fb2dcc53a9d09c" category="section-title">Descrivi il tuo ambiente</block>
  <block id="7e431f8959ae4a79bcfc6e55728ead5a" category="list-text">*In quale ambiente verrà eseguito il tuo cluster?*  Amazon Web Services, Microsoft Azure, Google Cloud Platform, bare-metal on premises, VMware on premises, OpenStack on premises o Kubernates on premises?</block>
  <block id="34946a533795a145eb4c6d66ee12e56b" category="list-text">*Dettagli dell'host.*  Numero di core: 48 (ad esempio), tipo di scheda di rete (10GbE, 40GbE, 16GbE, 1GbE o altro tipo).</block>
  <block id="a50ad1bade1c614aa4ceaa766944b0e1" category="list-text">*Volumi di archiviazione.*  Host: 12 (ad esempio).  Quanti dischi rigidi o SSD sono supportati per host?  Confluent consiglia 12 dischi rigidi per host.</block>
  <block id="bf903fced4e4e598ede3fb2a9dd5427a" category="list-text">*Capacità/volume di archiviazione (in GB).*  1000 (ad esempio).  Quanto spazio di archiviazione può contenere un singolo volume in gigabyte?  Confluent consiglia dischi da 1 TB.</block>
  <block id="85a140efdb29007799d7d5e7c16691d5" category="list-text">*Configurazione di archiviazione.*  Come vengono configurati i volumi di archiviazione?  Confluent consiglia RAID10 per sfruttare tutte le funzionalità di Confluent.  Sono supportati anche JBOD, SAN, RAID 1, RAID 0, RAID 5 e altri tipi.</block>
  <block id="237d14e07eccd0d6535cf69ee4507805" category="list-text">*Capacità di trasmissione di un singolo volume (MBps).*  125 (ad esempio).  Qual è la velocità in megabyte al secondo con cui un singolo volume di archiviazione può leggere o scrivere?  Confluent consiglia dischi rigidi standard, che in genere hanno una velocità di trasmissione di 125 MBps.</block>
  <block id="57499d42a69c4ed9f1e7994a0bad7e9f" category="list-text">*Capacità di memoria (GB).*  64 (ad esempio).</block>
  <block id="9db0153ae987c66e360fc7027c7819c8" category="paragraph">Dopo aver determinato le variabili ambientali, seleziona Dimensiona il mio cluster.  Sulla base dei parametri di esempio indicati sopra, abbiamo determinato le seguenti dimensioni per Confluent Kafka:</block>
  <block id="fc644e6661f2118a6b0733f85424f3fa" category="list-text">*Apache Kafka.*  Numero di broker: 22.  Il cluster è vincolato allo storage.  Valuta la possibilità di abilitare l'archiviazione a livelli per ridurre il numero di host e consentire uno spazio di archiviazione infinito.</block>
  <block id="689921f4781dfd392aedc0eac4116284" category="list-text">*Apache ZooKeeper.*  Conteggio: 5; Apache Kafka Connect Workers: Conteggio: 2; Schema Registry: Conteggio: 2; REST Proxy: Conteggio: 2; ksqlDB: Conteggio: 2; Confluent Control Center: Conteggio: 1.</block>
  <block id="df1673ed6a212d182bedbf3a4bdc79a7" category="paragraph">Utilizzare la modalità inversa per i team della piattaforma che non hanno in mente un caso d'uso.  Utilizzare la modalità partizioni per calcolare quante partizioni richiede un singolo argomento.  Vedere<block ref="d971ea0f6ada2eeb1a618f5145544e00" category="inline-link-rx"></block> per il dimensionamento basato sulle modalità inversa e partizioni.</block>
  <block id="16d17bd11d09e7ab044f85f158c4ee5c" category="doc">Dettagli dell'architettura della soluzione</block>
  <block id="096d10f0062b97cca959118975fa506a" category="paragraph">Questa sezione riguarda l'hardware e il software utilizzati per la verifica Confluent.  Queste informazioni sono applicabili alla distribuzione della piattaforma Confluent con storage NetApp .  La tabella seguente illustra l'architettura della soluzione testata e i componenti di base.</block>
  <block id="7e897f23ed71aef1c0a8acf1ae54e9e4" category="cell">Componenti della soluzione</block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">Dettagli</block>
  <block id="cd6b218ceb186591718799f941a99fd0" category="cell">Confluent Kafka versione 6.2</block>
  <block id="8a1732b4cde6f106471a0e6dbb186bed" category="list-text">Tre guardiani dello zoo</block>
  <block id="fde5b2c6fa48108e02c6a3587ce451b4" category="list-text">Cinque server broker</block>
  <block id="cd2e7d4aa00a79a9a92980e984ec50d7" category="list-text">Cinque server di strumenti</block>
  <block id="e9617e461b2b6597095fc0d3c26666c5" category="list-text">Una Grafana</block>
  <block id="5d96f98a638cf23ac2f3dfe513198e9a" category="list-text">Un centro di controllo</block>
  <block id="a2a44121136232f1f2dcfb5e5ce5cf22" category="cell">Linux (Ubuntu 18.04)</block>
  <block id="a0681d05c825936a4afc9d89f305934c" category="cell">Tutti i server</block>
  <block id="cc3bec1f9974aef63e75985fed9c343e" category="cell">NetApp StorageGRID per l'archiviazione a livelli</block>
  <block id="2d4f4568ad652ff08727bc044f1373cc" category="list-text">Software StorageGRID</block>
  <block id="4ebcee22d98fbad50cf1c7e108dd9541" category="list-text">1 x SG1000 (bilanciatore di carico)</block>
  <block id="a51cb0f5fd275943954c8d687912e458" category="list-text">4 x SGF6024</block>
  <block id="83cc5cf13ad44caf6aa94887d189cd3a" category="list-text">4 x 24 x 800 SSD</block>
  <block id="7ccdc7c1d04d9b48b4b016417504685b" category="list-text">Protocollo S3</block>
  <block id="e185a6ccd16ce2c64c7e948bbc46f45a" category="list-text">4 x 100 GbE (connettività di rete tra broker e istanze StorageGRID )</block>
  <block id="5ecafb7b42f662438e20bd643feb79c9" category="cell">15 server Fujitsu PRIMERGY RX2540</block>
  <block id="cdb0680ecb0e0ed91d8293e41334b379" category="cell">Ciascuno dotato di: * 2 CPU, 16 core fisici totali * Intel Xeon * 256 GB di memoria fisica * Doppia porta 100 GbE</block>
  <block id="06a768157cb89879ca041da1b730da6e" category="summary">Questo documento fornisce linee guida sulle best practice per l'utilizzo di Dremio con lo storage NetApp , inclusi test di certificazione TPCDS, ottimizzazione e dettagli sui casi d'uso dei clienti.</block>
  <block id="5539c6da3e2032488a631305f1265434" category="paragraph">In conclusione, questo rapporto tecnico ha fornito dettagli completi sulla distribuzione di q Hybrid Iceberg Lakehouse con Dremio in combinazione con varie fonti di dati dai controller di storage NetApp , tra cui ONTAP S3, NAS e StorageGRID.  Il processo di distribuzione è stato eseguito con successo e lo strumento di benchmarking TPC-DS è stato utilizzato per eseguire 99 query SQL su diverse fonti di dati.  Il rapporto ha inoltre esaminato i casi d'uso dei clienti all'interno di NetApp, dimostrando la versatilità e l'efficacia di Dremio nel soddisfare diverse esigenze aziendali.  Inoltre, è stato esaminato un caso d'uso specifico che coinvolge un cliente di vendita di ricambi auto, evidenziando l'applicazione pratica e i vantaggi derivanti dall'utilizzo di Dremio per l'analisi dei dati e le informazioni dettagliate.</block>
  <block id="682cc1e627af4457882db17515ccaf5b" category="paragraph">Nel complesso, questo documento rappresenta una risorsa preziosa per comprendere l'implementazione e l'utilizzo di Dremio con i controller di storage NetApp , evidenziandone le capacità e il potenziale per favorire l'ottimizzazione e il processo decisionale basato sui dati in vari settori.</block>
  <block id="c63354da3a3a21f3ae0083d0a275540c" category="list-text">Installazione di Zookeeper</block>
  <block id="661fab58be11f3fe0e5fd03c183c9a3b" category="paragraph"><block ref="661fab58be11f3fe0e5fd03c183c9a3b" category="inline-link-rx"></block></block>
  <block id="288e0e9ab8b8ac8737afefecf16f61fd" category="list-text">Dremio</block>
  <block id="d9f3b0f9c66b1c99f5e01fefb31f3280" category="paragraph"><block ref="d9f3b0f9c66b1c99f5e01fefb31f3280" category="inline-link-rx"></block></block>
  <block id="7d56340ec96dd44dedf67654c4b228a9" category="list-text">Configurazione di Dremio con storageGRID</block>
  <block id="d6a7c21494adf18f10c2f9b2b6da5584" category="paragraph"><block ref="d6a7c21494adf18f10c2f9b2b6da5584" category="inline-link-rx"></block></block>
  <block id="719a5826913817829f2d138a33720835" category="list-text">Caso d'uso NetApp</block>
  <block id="abd766d13b2562c1684015edb41ddc75" category="paragraph"><block ref="abd766d13b2562c1684015edb41ddc75" category="inline-link-rx"></block></block>
  <block id="108f231402daaaf5b7a58841053615dd" category="summary">Abbiamo eseguito la certificazione con la piattaforma Dremio con convalida lakehouse nello storage NetApp Object.</block>
  <block id="3cd3290a9231e38be51fc2cb3ce01572" category="doc">Procedura di distribuzione</block>
  <block id="d44c5f08c906e8f8bc746c8e4083522e" category="inline-image-macro">Figura che mostra l'architettura di Dremio con NetApp Storage Controller</block>
  <block id="5e5f3a2661fa2ba525c6c6d493b1058d" category="paragraph">In questa convalida dell'architettura di riferimento, abbiamo utilizzato una configurazione Dremio composta da un coordinatore e quattro esecutori<block ref="b76f8c360d80a001aee0571894d68ba2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="07efd46e12f0d695c6aa9e2abf057781" category="section-title">Configurazione NetApp</block>
  <block id="82c8a5cee83d98576ecd7fb9135c1b41" category="list-text">Inizializzazione del sistema di archiviazione</block>
  <block id="8028442c79907b3f88933ff5c16fac5e" category="list-text">Creazione di una macchina virtuale di archiviazione (SVM)</block>
  <block id="ff602335ea946bbb0494a8ca5aa58bf5" category="list-text">Assegnazione delle interfacce di rete logiche</block>
  <block id="c1d1275f7bc999e53ce84a9b2a48cc7f" category="list-text">Configurazione e licenza NFS, S3</block>
  <block id="bbc1adf735eb5e7f9c1e5bae1fb2aed8" category="paragraph">Per NFS (Network File System) procedere come segue: 1.  Creare un volume Flex Group per NFSv4 o NFSv3.  Nella nostra configurazione per questa convalida, abbiamo utilizzato 48 SSD, 1 SSD dedicato al volume root del controller e 47 SSD distribuiti per NFSv4]].  Verificare che il criterio di esportazione NFS per il volume Flex Group disponga di autorizzazioni di lettura/scrittura per la rete dei server Dremio.</block>
  <block id="77cf539931cef9f508e194dbd28a0bc0" category="list-text">Su tutti i server Dremio, creare una cartella e montare il volume Flex Group su questa cartella tramite un'interfaccia logica (LIF) su ciascun server Dremio.</block>
  <block id="575afa472f95d77f2af74b7f99bc9d28" category="paragraph">Per S3 (Simple Storage Service) seguire i passaggi indicati di seguito:</block>
  <block id="28863b320894e844cb1d2df9a479aa31" category="list-text">Impostare un object-store-server con HTTP abilitato e lo stato di amministrazione impostato su "attivo" utilizzando il comando "vserver object-store-server create".  Hai la possibilità di abilitare HTTPS e impostare una porta di ascolto personalizzata.</block>
  <block id="993520e0cce3e5f87179d01caa10a746" category="list-text">Creare un utente object-store-server utilizzando il comando "vserver object-store-server user create -user &lt;username&gt;".</block>
  <block id="4c7b617c418e3a5f7073d2d64ba8cb1c" category="list-text">Per ottenere la chiave di accesso e la chiave segreta, è possibile eseguire il seguente comando: "set diag; vserver object-store-server user show -user &lt;nomeutente&gt;".  Tuttavia, in futuro, queste chiavi verranno fornite durante il processo di creazione dell'utente oppure potranno essere recuperate tramite chiamate API REST.</block>
  <block id="c3d4f7a6161c482cb921db78c64d1543" category="list-text">Creare un gruppo object-store-server utilizzando l'utente creato nel passaggio 2 e concedere l'accesso.  In questo esempio abbiamo fornito "FullAccess".</block>
  <block id="f346ebaf71f9d3850361e0b732a352f5" category="list-text">Crea due bucket S3 impostandone il tipo su "S3".  Uno per la configurazione di Dremio e uno per i dati del cliente.</block>
  <block id="3c29c74ed24f85f4cf464243c6d69bc7" category="section-title">Configurazione del guardiano dello zoo</block>
  <block id="a284e9d9802d2b863fce5aa237106342" category="paragraph">Puoi utilizzare la configurazione zookeeper fornita da Dremio.  In questa convalida, abbiamo utilizzato uno zookeeper separato. Abbiamo seguito i passaggi menzionati in questo collegamento web<block ref="757110f854f50ea29baeb536bc067417" category="inline-link-rx"></block></block>
  <block id="fb6e0f74d4f2cd819e198308d0e560c8" category="section-title">Configurazione di Dremio</block>
  <block id="3e793dc4b6b41d43692a24d29150ed55" category="paragraph">Abbiamo seguito questo collegamento web per installare Dremio tramite tarball.</block>
  <block id="694299a05f621f9d6c47fbc0cdd75cdb" category="list-text">Crea un gruppo Dremio.</block>
  <block id="28b115fb542519f28216941113c7fc69" category="list-text">Crea un utente dremio.</block>
  <block id="6190c0f96190f68e7387989b98fecd3c" category="list-text">Crea directory Dremio.</block>
  <block id="b8d53340c1af1590a07a31d4782e75c8" category="list-text">Scarica il file tar da<block ref="993599c5d8336ec040e5e84c23246c65" category="inline-link-rx"></block></block>
  <block id="38152bcebb8f6d46160b6d2462ce40a0" category="list-text">Scompattare Dremio nella directory /opt/dremio.</block>
  <block id="9af78d03c81be6e6dd350c73be883f9b" category="list-text">Creare un collegamento simbolico per la cartella di configurazione.</block>
  <block id="a16cec17e87f61728dcdd563b7d8ecc7" category="list-text">Imposta la configurazione del servizio (configurazione SystemD).</block>
  <block id="44aba27523001647040cfa3dab851cbb" category="list-text">Copiare il file dell'unità per il demone dremio da /opt/dremio/share/dremio.service a /etc/systemd/system/dremio.service.</block>
  <block id="617a522470fb25e0b60757c2347779fd" category="list-text">Riavviare il sistema</block>
  <block id="b0a645a7658dbbe597c81a61d8095535" category="list-text">Abilita l'avvio di dremio all'avvio.</block>
  <block id="715ae8a49286aaa14659522218602fba" category="list-text">Configurare Dremio sul coordinatore.  Per maggiori informazioni, vedere Configurazione di Dremio</block>
  <block id="940845b76f9832cb794ce21b8053c3d9" category="list-text">Dremio.conf</block>
  <block id="e49741f6cfbc4fdc21eaf59a034e694c" category="list-text">Core-site.xml</block>
  <block id="157bf0c98c644ad5d09f3dda0843bb8d" category="list-text">La configurazione di Dremio è archiviata nell'archivio oggetti NetApp .  Nella nostra convalida, il bucket "dremioconf" risiede in un bucket S3 ontap.  L'immagine sottostante mostra alcuni dettagli delle cartelle "scratch" e "uploads" del bucket S3 "dremioconf".</block>
  <block id="dec65ddc4408a5fd22bf6eef9c5dc2c4" category="inline-image-macro">Figura che mostra dremio con storage di oggetti NetApp</block>
  <block id="3f6534c1dba4ce90c550aec7ec304146" category="paragraph"><block ref="3f6534c1dba4ce90c550aec7ec304146" category="inline-image-macro-rx" type="image"></block></block>
  <block id="536241c2f7d1f3fbe227bc001b56b949" category="list-text">Configurare Dremio sugli esecutori.  Nella nostra configurazione abbiamo 3 esecutori.</block>
  <block id="98acd539813ecdb677a633c1e8d72ba9" category="list-text">dremio.conf</block>
  <block id="19aac463221a9324b146be45c5f27561" category="list-text">Core-site.xml: uguale alla configurazione del coordinatore.</block>
  <block id="9ebe81db6df147f3eea7002c858d2821" category="admonition">NetApp consiglia StorageGRID come soluzione di archiviazione di oggetti primaria per gli ambienti Datalake e Lakehouse.  Inoltre, NetApp ONTAP viene utilizzato per la dualità file/oggetto.  Nel contesto di questo documento, abbiamo condotto dei test su ONTAP S3 in risposta alla richiesta di un cliente, e il sistema funziona correttamente come fonte di dati.</block>
  <block id="5b8d6104bd7d25e99e47f619fdfd8f81" category="section-title">Configurazione di più sorgenti</block>
  <block id="4ee12bc75bcc4f7fb3bbf527ef1d2720" category="list-text">Configurare ONTAP S3 e storageGRID come sorgente S3 in Dremio.</block>
  <block id="dbd1ae231acf755d63de74b16a8cbeb7" category="list-text">Dashboard di Dremio -&gt; set di dati -&gt; fonti -&gt; aggiungi fonte.</block>
  <block id="c102e8893995a295f2cc62063b2e0cd5" category="list-text">Nella sezione generale, aggiorna l'accesso AWS e la chiave segreta</block>
  <block id="71a7d593565f192b138481a0e8d335c4" category="list-text">Nell'opzione avanzata, abilita la modalità compatibilità e aggiorna le proprietà di connessione con i dettagli seguenti.  L'IP/nome dell'endpoint dal controller di archiviazione NetApp da ontap S3 o storageGRID.</block>
  <block id="4f594a255a564afe3df4ac263caedbb5" category="list-text">Abilita la memorizzazione nella cache locale quando possibile, percentuale massima della cache totale disponibile da utilizzare quando possibile = 100</block>
  <block id="c71df1ddac771fdc9b484b0ed6f6d9f7" category="inline-image-macro">Figura che mostra l'elenco dei file dall'archiviazione di oggetti NetApp</block>
  <block id="a4d1986a0b1a4f12d2237b0963d2e43d" category="list-text">Quindi visualizza l'elenco dei bucket dall'archiviazione di oggetti NetApp .<block ref="3774299f093c28855158f425c629b55d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c80afe9a6ef853e0d394059a332a406d" category="list-text">Visualizzazione di esempio dei dettagli del bucket storageGRID<block ref="e0f51eae5ca0e68849adc9661a7def73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18ebb902e9ccb331331d9d1b8b5e0f76" category="list-text">Configurare NAS (in particolare NFS) come sorgente in Dremio.</block>
  <block id="08a5aec8691cede64f84acb42700e07d" category="list-text">Nella sezione generale, immettere il nome e il percorso di montaggio NFS.  Assicurarsi che il percorso di montaggio NFS sia montato sulla stessa cartella su tutti i nodi del cluster Dremio.</block>
  <block id="eaa2d3817be8fb7b330c01f9605f0808" category="paragraph"><block ref="eaa2d3817be8fb7b330c01f9605f0808" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26b17225b626fb9238849fd60eabdf60" category="paragraph">+</block>
  <block id="b134468afaa618eaef2e7bfaf5f30da7" category="summary">Questo documento descrive le linee guida sulle best practice per l'utilizzo di Dremio su un controller di storage NetApp .</block>
  <block id="53bd7dac219a2662a137c6de870224d2" category="doc">La soluzione ibrida Iceberg Lakehouse di nuova generazione di NetApp e Dremio</block>
  <block id="0c74f27a6d1c41b83e5cc59468f24a0d" category="paragraph">In questo documento, analizziamo i dettagli di distribuzione di Dremio con diverse fonti di dati provenienti dai controller di storage NetApp , tra cui ONTAP S3, NAS e StorageGRID.  Durante l'implementazione, abbiamo utilizzato lo strumento di benchmarking TPC-DS per eseguire 99 query SQL su varie origini.  Il documento esamina anche i casi d'uso dei clienti all'interno di NetApp, nonché un caso d'uso che coinvolge un cliente di vendita di ricambi auto.</block>
  <block id="d4b28ab5babb078bc6498faee7c53a81" category="summary">Questa sezione riguarda l'hardware e il software utilizzati per la certificazione dremio.  Queste informazioni sono applicabili alla distribuzione di Dremio con storage NetApp .</block>
  <block id="cb2418c01859c7704da751aa5a7d2421" category="doc">Panoramica della soluzione</block>
  <block id="9953e901936889810e67ec0949c6b2fc" category="paragraph">La soluzione Hybrid Iceberg Lakehouse offre vantaggi esclusivi per affrontare le sfide che i clienti dei data lake si trovano ad affrontare.  Sfruttando la piattaforma Dremio Unified Lakehouse e le soluzioni NetApp ONTAP, StorageGRID e NetApp Cloud, le aziende possono aggiungere un valore significativo alle loro operazioni aziendali.  La soluzione non solo fornisce accesso a più fonti di dati, tra cui quelle NetApp , ma migliora anche le prestazioni analitiche complessive e aiuta le aziende a ottenere informazioni aziendali che favoriscono la crescita aziendale.</block>
  <block id="91c847ff0ec1e96ccc74039eaf1b5bf3" category="section-title">Panoramica NetApp</block>
  <block id="b630104207f28e8a0523849fe77c1e9f" category="list-text">Le offerte di NetApp, come ONTAP e StorageGRID, consentono la separazione tra storage ed elaborazione, consentendo un utilizzo ottimale delle risorse in base a requisiti specifici.  Questa flessibilità consente ai clienti di scalare in modo indipendente il proprio storage utilizzando le soluzioni di storage NetApp</block>
  <block id="bc213af00312a8c2d752b8b42715eed6" category="list-text">Sfruttando i controller di storage di NetApp, i clienti possono fornire in modo efficiente i dati al proprio database vettoriale utilizzando i protocolli NFS e S3.  Questi protocolli facilitano l'archiviazione dei dati dei clienti e gestiscono l'indice del database vettoriale, eliminando la necessità di più copie dei dati a cui si accede tramite metodi di file e oggetti.</block>
  <block id="1557c431be0fea4f212f4006eafc9a8c" category="list-text">NetApp ONTAP fornisce supporto nativo per NAS e storage di oggetti attraverso i principali provider di servizi cloud come AWS, Azure e Google Cloud.  Questa ampia compatibilità garantisce un'integrazione perfetta, consentendo la mobilità dei dati dei clienti, l'accessibilità globale, il ripristino di emergenza, la scalabilità dinamica e le prestazioni elevate.</block>
  <block id="392d70ca39f31f10bd637936769788df" category="section-title">StorageGRID</block>
  <block id="9409f64cd9405163cc619bf89c44eaf4" category="paragraph">Il nostro storageGRID, leader del settore per l'archiviazione di oggetti, offre un potente motore di policy per il posizionamento automatico dei dati, opzioni di distribuzione flessibili e una durata senza pari con codifica di cancellazione a livelli.  Ha un'architettura scalabile che supporta miliardi di oggetti e petabyte di dati in un unico namespace.  La soluzione consente l'integrazione del cloud ibrido, consentendo il tiering dei dati sulle principali piattaforme cloud.  È stato riconosciuto come leader nell'IDC Marketscape Worldwide Object-Based Vendor Assessment del 2019.</block>
  <block id="546a8027b219510c369554288fd7eff4" category="paragraph">Inoltre, storageGRID eccelle nella gestione di dati non strutturati su larga scala con archiviazione di oggetti definiti dal software, ridondanza geografica e funzionalità multi-sito.  Incorpora la gestione del ciclo di vita delle informazioni basata su policy e offre funzionalità di integrazione cloud come mirroring e ricerca.  Possiede diverse certificazioni, tra cui Common Criteria, NF203 Digital Safe Component, ISO/IEC 25051, KPMG e Cohasset Compliance Assessment.</block>
  <block id="030de30483fabd3aca42be7503592961" category="paragraph">In sintesi, NetApp storageGRID offre potenti funzionalità, scalabilità, integrazione con cloud ibrido e certificazioni di conformità per una gestione efficiente dei dati non strutturati su larga scala.</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="section-title">NetApp ONTAP</block>
  <block id="185a43d593912638c2bb37ef99444fc9" category="paragraph">NetApp ONTAP è una soluzione di storage affidabile che offre un'ampia gamma di funzionalità aziendali.  Include Snapshot, che fornisce backup istantanei coerenti con l'applicazione e a prova di manomissione.  SnapRestore consente il ripristino quasi istantaneo dei backup su richiesta, mentre SnapMirror offre funzionalità integrate di backup remoto e disaster recovery.  La soluzione integra anche Autonomous Ransomware Protection (ARP), garantendo la sicurezza dei dati con funzionalità quali la verifica multi-amministratore, la crittografia dei dati inattivi con certificazione FIPS, la crittografia dei dati in transito, l'autenticazione a più fattori (MFA) e il controllo degli accessi basato sui ruoli (RBAC).  La registrazione completa, l'audit, la gestione delle chiavi interne ed esterne, l'eliminazione sicura e la gestione sicura di più tenant migliorano ulteriormente la sicurezza e la conformità dei dati.</block>
  <block id="48af054a9eb5d217f15aab37f5fe9b91" category="paragraph">NetApp ONTAP è inoltre dotato SnapLock, che garantisce la conservazione dei dati conforme alle normative con elevati livelli di integrità, prestazioni e conservazione a un basso costo totale di proprietà.  È completamente integrato con NetApp ONTAP 9 e offre protezione contro azioni dannose, amministratori non autorizzati e ransomware.</block>
  <block id="afd4da5566327275499951d8db99e683" category="paragraph">La soluzione comprende la crittografia NSE/NVE per la crittografia in transito e dei dati a riposo, l'accesso amministrativo multifattoriale e la verifica multi-amministratore.  Active IQ fornisce analisi predittive basate sull'intelligenza artificiale e azioni correttive, mentre QoS garantisce il controllo del carico di lavoro della qualità del servizio.  L'integrazione di gestione e automazione è intuitiva tramite SysMgr/GUI/CLI/API.  FabricPool consente la suddivisione automatica dei dati e la soluzione offre efficienza attraverso la compressione, la deduplicazione e la compattazione dei dati in linea.  NetApp garantisce il raggiungimento degli obiettivi di efficienza del carico di lavoro senza alcun costo per il cliente.</block>
  <block id="327b294a4782dbbd617ca02b0227198e" category="paragraph">NetApp ONTAP supporta vari protocolli, tra cui NVMe/FC, FC, NVMe/TCP, iSCSI, NFS, SMB e S3, il che lo rende una soluzione di storage unificata.  Nel complesso, NetApp ONTAP offre ampie funzionalità aziendali, sicurezza avanzata, conformità, efficienza e versatilità per soddisfare diverse esigenze di storage.</block>
  <block id="5504df296ab63119754ecfd92e6a07d7" category="section-title">Panoramica di Dremio</block>
  <block id="46664b9047c24c224cf4898236ac4159" category="paragraph">Dremio è la piattaforma unificata Lakehouse per l'analisi self-service e l'intelligenza artificiale.  La piattaforma di analisi unificata Dremio avvicina gli utenti ai dati con flessibilità, scalabilità e prestazioni lakehouse a una frazione del costo delle soluzioni di data warehouse legacy.  Dremio consente l'analisi "shift-left" per eliminare l'integrazione dei dati e l'ETL complessi e costosi, offrendo analisi fluide su scala aziendale senza spostamento dei dati.  Dremio offre anche:</block>
  <block id="2f0acfc3dbf17a0571810cc0dedaf64f" category="list-text">Analisi self-service di facile utilizzo, abilitate tramite un livello semantico universale e un motore di query SQL altamente performante e strettamente integrato, che semplifica la connessione, la gestione e l'analisi di tutti i dati, sia nel cloud che in locale.</block>
  <block id="88be140c20067da1baf354c05223a2c6" category="list-text">Le funzionalità di gestione del lakehouse nativo di Apache Iceberg di Dremio semplificano la scoperta dei dati e automatizzano l'ottimizzazione degli stessi, offrendo analisi ad alte prestazioni con il controllo delle versioni dei dati ispirato a Git.</block>
  <block id="fe08740b7cac34b055da6ec6bfe79c3f" category="list-text">Basato su standard e codice sorgente aperti, Dremio consente alle aziende di evitare il lock-in e di rimanere orientate all'innovazione.  Le grandi aziende si affidano a Dremio perché è la piattaforma lakehouse più semplice da usare e con il miglior rapporto qualità-prezzo per tutti i carichi di lavoro.</block>
  <block id="e95806f0d7b4743b250387c094acef2b" category="section-title">Quale valore offre ai clienti la soluzione Dremio e NetApp Hybrid Iceberg Lakehouse?</block>
  <block id="81c79525dc5cb78051ffe86a4b85377f" category="list-text">*Miglioramento della gestione e dell'accessibilità dei dati*: Dremio è noto per la sua piattaforma data lakehouse che consente alle organizzazioni di interrogare i dati direttamente dai loro data lake ad alta velocità.  NetApp, d'altro canto, è un fornitore leader di servizi di dati cloud e soluzioni di archiviazione dati.  L'offerta congiunta fornisce ai clienti una soluzione completa per archiviare, gestire, accedere e analizzare i dati della loro azienda in modo efficiente ed efficiente.</block>
  <block id="4bb8954089d2a9fb6c99825861c39f62" category="list-text">*Ottimizzazione delle prestazioni*: grazie all'esperienza di NetApp nell'archiviazione dei dati e alle capacità di Dremio nell'elaborazione e nell'ottimizzazione dei dati, la partnership offre una soluzione che migliora le prestazioni delle operazioni sui dati, riduce la latenza e aumenta la velocità di acquisizione di informazioni aziendali.  Dremio ha addirittura migliorato le prestazioni dell'infrastruttura analitica IT interna di NetApp.</block>
  <block id="737f740962d700c8fb65a99e34900bc9" category="list-text">*Scalabilità*: sia Dremio che NetApp offrono una soluzione progettata per essere scalabile.  La soluzione congiunta fornisce ai clienti ambienti di archiviazione, gestione e analisi dei dati altamente scalabili.  In un ambiente Hybrid Iceberg Lakehouse, il motore di query SQL di Dremio abbinato a NetApp StorageGRID offre scalabilità, concorrenza e prestazioni di query senza pari, in grado di gestire le esigenze analitiche di qualsiasi azienda.</block>
  <block id="38eb37e9ecd9ccb05b8fda4a7890c571" category="list-text">*Sicurezza e governance dei dati*: entrambe le aziende sono fortemente attente alla sicurezza e alla governance dei dati.  Insieme, offrono solide funzionalità di sicurezza e governance dei dati, garantendo la protezione dei dati e il rispetto dei requisiti di governance dei dati.  Funzionalità quali controlli di accesso basati sui ruoli e dettagliati, auditing completo, derivazione dei dati end-to-end, gestione unificata delle identità e SSO con un ampio framework di conformità e sicurezza garantiscono che gli ambienti di dati analitici delle aziende siano sicuri e governati.</block>
  <block id="b10c860483a8763cd915a0459af4c444" category="list-text">*Efficienza dei costi*: integrando il motore data lake di Dremio con le soluzioni di storage di NetApp, i clienti possono ridurre i costi associati alla gestione e allo spostamento dei dati.  Le organizzazioni possono anche passare da ambienti data lake legacy a una soluzione lakehouse più moderna composta da NetApp e Dremio.  Questa soluzione Hybrid Iceberg Lakehouse offre prestazioni di query ad alta velocità e una concorrenza di query leader di mercato, che riduce il TCO e riduce il tempo necessario per ottenere informazioni aziendali.</block>
  <block id="55473d705d75e19b6040dbe34242319c" category="summary">Questa sezione descrive la tecnologia utilizzata in questa soluzione.</block>
  <block id="910af13beca7193218f534b5af1d8881" category="doc">Requisiti tecnologici</block>
  <block id="915f99cb757b24fafb485b82cc5fe20e" category="paragraph">Per le convalide eseguite in questo documento sono state utilizzate le configurazioni hardware e software descritte di seguito.  Queste configurazioni servono come linee guida per aiutarti a configurare il tuo ambiente. Tuttavia, tieni presente che i componenti specifici possono variare a seconda delle esigenze individuali del cliente.</block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">Requisiti hardware</block>
  <block id="3c02a379965ab0dfcd77b1c484450433" category="cell">Hardware</block>
  <block id="74cc4ae913d72260c083ab2b346121ec" category="cell">Coppia HA di array di storage NetApp AFF</block>
  <block id="e4044b704224bc11ad4a58e92f2131d7" category="list-text">A800</block>
  <block id="8020ad245e7cbc2ac49c84b7f4ace684" category="list-text">ONTAP 9.14.1</block>
  <block id="4c365c4afab33ac328254bd7c2ae19a9" category="list-text">48 SSD-NVM da 3,49 TB</block>
  <block id="fe001f20ed0495ea55b4938631878b7a" category="list-text">Due bucket S3: metadati Dremio e dati dei clienti.</block>
  <block id="637071f2d4a8f15942d2e18657010fa9" category="cell">4 x FUJITSU PRIMERGY RX2540 M4</block>
  <block id="e0c5e2628a6e691fa3fafe35f3bf20c3" category="list-text">64 CPU</block>
  <block id="319d86787ef65ef260e666cc63f6e1a3" category="list-text">CPU Intel Xeon Gold 6142 a 2,60 GHz</block>
  <block id="d6b9b9dc5caf5833c325bc02278f4817" category="list-text">256 GM di memoria fisica</block>
  <block id="81555075e106886f4be11de9599425a6" category="list-text">1 porta di rete da 100 GbE</block>
  <block id="a5fa5746370b608090b994a97b49e98b" category="cell">Networking</block>
  <block id="edcd3f3adc6d51b309e9115847fa497f" category="list-text">100 GbE</block>
  <block id="9de4526063d2d5dc8600f1abb273fb87" category="cell">* 1 x SG100, 3xSGF6024 * 3 x 24 x 7,68 TB * Due bucket S3: metadati Dremio e dati dei clienti.</block>
  <block id="500084ff15a1d3831b2b0a0cc8efb3b4" category="list-text">versione - 25.0.3-202405170357270647-d2042e1b</block>
  <block id="b5251cb924b1e27d2fa914e7b3dbd75c" category="list-text">Edizione Enterprise</block>
  <block id="cea575677c47839fde1e59dbfc9ad5bb" category="cell">In sede</block>
  <block id="fd50fb0f59921345e87394051ed99e40" category="list-text">Cluster Dremio a 5 nodi</block>
  <block id="743d1e7bf62dfc8a183c666693662dc6" category="list-text">1 coordinatore principale e 4 esecutori</block>
  <block id="cce86ec0e697036ce6aa6105904b06de" category="summary">Questa sezione illustra i dettagli del caso d'uso del cliente di Dremio con NetApp Object Storage.</block>
  <block id="fe0bd5fc290c9a203c8e8f18a2b6e647" category="doc">Casi d'uso dei clienti</block>
  <block id="46233f9bd0306ff790c810922b25e957" category="section-title">Caso d'uso di NetApp ActiveIQ</block>
  <block id="994534c401b3a0f86cd899f3b7b6ec57" category="inline-image-macro">Vecchia architettura ActiveIQ</block>
  <block id="3002c8327e7407633cb1d61c6e798c05" category="paragraph"><block ref="3002c8327e7407633cb1d61c6e798c05" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e9e9a9c8ceef33ee9b9839f01cdf06a" category="paragraph">*Sfida*: la soluzione Active IQ interna di NetApp, inizialmente progettata per supportare numerosi casi d'uso, si è evoluta in un'offerta completa sia per gli utenti interni che per i clienti.  Tuttavia, l'infrastruttura backend sottostante basata su Hadoop/MapR ha posto sfide in termini di costi e prestazioni, a causa della rapida crescita dei dati e della necessità di un accesso efficiente ai dati.  L'aumento dello storage ha comportato l'aggiunta di risorse di elaborazione non necessarie, con conseguente aumento dei costi.</block>
  <block id="66c90395e80a7e0f428abf5cf77fa1f4" category="paragraph">Inoltre, la gestione del cluster Hadoop richiedeva molto tempo e competenze specialistiche.  Problemi di gestione e prestazioni dei dati hanno complicato ulteriormente la situazione, con query che richiedevano in media 45 minuti e carenza di risorse a causa di configurazioni errate.  Per affrontare queste sfide, NetApp ha cercato un'alternativa all'ambiente Hadoop legacy esistente e ha deciso che una nuova soluzione moderna basata su Dremio avrebbe ridotto i costi, separato storage ed elaborazione, migliorato le prestazioni, semplificato la gestione dei dati, offerto controlli dettagliati e fornito funzionalità di disaster recovery.</block>
  <block id="f4327571cd8b76a68a25a1d8487a0db0" category="inline-image-macro">Nuova architettura ActiveIQ con dremio</block>
  <block id="954cc37909c75a2221a99b0c02a26f82" category="paragraph">*Soluzione*:<block ref="4a878fba67d10f0324250d8d1dafdcc5" category="inline-image-macro-rx" type="image"></block> Dremio ha consentito a NetApp di modernizzare la propria infrastruttura dati basata su Hadoop con un approccio graduale, fornendo una roadmap per l'analisi unificata.  A differenza di altri fornitori che hanno richiesto modifiche significative all'elaborazione dei dati, Dremio si è integrato perfettamente con le pipeline esistenti, risparmiando tempo e denaro durante la migrazione.  Passando a un ambiente completamente containerizzato, NetApp ha ridotto i costi di gestione, migliorato la sicurezza e aumentato la resilienza.  L'adozione da parte di Dremio di ecosistemi aperti come Apache Iceberg e Arrow ha garantito sicurezza, trasparenza ed estensibilità per il futuro.</block>
  <block id="6f323477260e85221bf9876e157b69d0" category="paragraph">In sostituzione dell'infrastruttura Hadoop/Hive, Dremio offriva funzionalità per casi d'uso secondari attraverso il livello semantico.  Mentre i meccanismi ETL e di acquisizione dati basati su Spark esistenti sono rimasti invariati, Dremio ha fornito un livello di accesso unificato per una più semplice esplorazione e scoperta dei dati senza duplicazioni.  Questo approccio ha ridotto significativamente i fattori di replicazione dei dati e ha disaccoppiato l'archiviazione e l'elaborazione.</block>
  <block id="ef3e4aef01dbcfe8475e127bc34ac240" category="paragraph">*Vantaggi*: Con Dremio, NetApp ha ottenuto notevoli riduzioni dei costi riducendo al minimo il consumo di elaborazione e i requisiti di spazio su disco nei propri ambienti dati.  Il nuovo Active IQ Data Lake è composto da 8.900 tabelle contenenti 3 petabyte di dati, rispetto agli oltre 7 petabyte della precedente infrastruttura.  La migrazione a Dremio ha comportato anche il passaggio da 33 mini-cluster e 4.000 core a 16 nodi esecutori su cluster Kubernetes.  Nonostante le significative riduzioni delle risorse di elaborazione, NetApp ha registrato notevoli miglioramenti nelle prestazioni.  Accedendo direttamente ai dati tramite Dremio, il tempo di esecuzione delle query è diminuito da 45 minuti a 2 minuti, con un conseguente risparmio del 95% sui tempi di acquisizione di informazioni per la manutenzione predittiva e l'ottimizzazione.  La migrazione ha inoltre prodotto una riduzione di oltre il 60% nei costi di elaborazione, query più veloci di oltre 20 volte e un risparmio di oltre il 30% nel costo totale di proprietà (TCO).</block>
  <block id="a0c64f41c7126c9e86274e0e58d4bc01" category="section-title">Caso d'uso del cliente nella vendita di ricambi auto.</block>
  <block id="866dec6bda5d640e2bb5d1c8de8d6f67" category="paragraph">*Sfide*: all'interno di questa azienda globale di vendita di ricambi auto, i gruppi di pianificazione e analisi finanziaria aziendale e dirigenziale non sono riusciti a ottenere una visione consolidata dei report sulle vendite e sono stati costretti a leggere i report sulle metriche di vendita delle singole linee di business e a tentare di consolidarli.  Ciò ha portato i clienti a prendere decisioni sulla base di dati risalenti ad almeno un giorno prima.  I tempi di elaborazione per ottenere nuove informazioni analitiche normalmente superano le quattro settimane.  La risoluzione dei problemi relativi alle pipeline di dati richiederebbe ancora più tempo, aggiungendo altri tre giorni o più alla già lunga tempistica.  Il lento processo di sviluppo dei report e le relative prestazioni hanno costretto la comunità degli analisti ad attendere continuamente che i dati venissero elaborati o caricati, anziché consentire loro di trovare nuove informazioni aziendali e di promuovere nuovi comportamenti aziendali.  Questi ambienti problematici erano composti da numerosi database diversi per diverse linee di business, con il risultato di creare numerosi silos di dati.  L'ambiente lento e frammentato complicava la governance dei dati, poiché gli analisti avevano troppi modi per elaborare la propria versione della verità anziché ricorrere a un'unica fonte di verità.  L'approccio è costato oltre 1,9 milioni di dollari in costi di piattaforma dati e personale.  Per mantenere la piattaforma legacy e soddisfare le richieste di dati erano necessari sette Field Technical Engineer (FTE) all'anno.  Con l'aumento delle richieste di dati, il team di data intelligence non è riuscito a ridimensionare l'ambiente legacy per soddisfare le esigenze future</block>
  <block id="9de1ea6ce232738b38a6f50397411de0" category="paragraph">*Soluzione*: archiviare e gestire in modo conveniente grandi tabelle Iceberg in NetApp Object Store.  Crea domini di dati utilizzando il livello semantico di Dremio, consentendo agli utenti aziendali di creare, cercare e condividere facilmente prodotti di dati.</block>
  <block id="859dc66fff375d140e35011f5d94d363" category="paragraph">*Vantaggi per il cliente*: • Architettura dei dati esistente migliorata e ottimizzata e riduzione del tempo per ottenere informazioni da quattro settimane a poche ore • Tempo di risoluzione dei problemi ridotto da tre giorni a poche ore • Costi di gestione e piattaforma dati ridotti di oltre $ 380.000 • (2) FTE di sforzi di Data Intelligence risparmiati all'anno</block>
  <block id="4bf80525d5b2bad7362ea2ddc1239135" category="summary">Abbiamo eseguito il test tpc-ds con cinque nodi per carichi di lavoro SQL con l'archiviazione di oggetti NetApp , come in ONTAP e storagegrid.</block>
  <block id="07c6b8ec7b7d3f9f4e97f8cab49e9952" category="doc">Panoramica della verifica della soluzione</block>
  <block id="d234b1c706880318f115c69f47d6dfa1" category="paragraph">In questa sezione abbiamo eseguito query di test SQL da più fonti per verificare la funzionalità, testare e verificare lo spillover sullo storage NetApp .</block>
  <block id="399acee44d644dcec9afa1fb807677db" category="section-title">Query SQL su Object Storage</block>
  <block id="fdbf3a00f4ffd80f1b71f818ac8c17b1" category="list-text">Imposta la memoria a 250 GB per server in dremio.env</block>
  <block id="f01e72d5763f7ff9b6212ae55fe5a618" category="list-text">Controllare la posizione di spillover (${DREMIO_HOME}"/dremiocache) nel file dremio.conf e i dettagli di archiviazione.</block>
  <block id="c1fd3f5160a9be68b59f1459ab2d43ab" category="list-text">Indicare la posizione di spillover di Dremio allo storage NFS NetApp</block>
  <block id="876f04ac63af2ea2d5f8fa3785b310ca" category="list-text">Seleziona il contesto.  Nel nostro test, abbiamo eseguito il test sui file parquet generati da TPCDS residenti in ONTAP S3.  Dashboard Dremio -&gt; SQL runner -&gt; contesto -&gt; NetAppONTAPS3-&gt;Parquet1TB</block>
  <block id="005d28008e05dae0767805243a8fb4e4" category="inline-image-macro">imposta il contesto sulla cartella parquet ontaps3</block>
  <block id="1737725edbb24ea279e1a45444de8083" category="paragraph"><block ref="1737725edbb24ea279e1a45444de8083" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d627092b3c15550dd7a319a2762deb9" category="list-text">Eseguire la query TPC-DS67 dalla dashboard di Dremio</block>
  <block id="d73e35125ec82123636d65f59cd30912" category="inline-image-macro">Esegui la query 67 che è una delle 99 query in TPC-DS</block>
  <block id="af576e90e15d8a6ff15105e65b4de6ca" category="paragraph"><block ref="af576e90e15d8a6ff15105e65b4de6ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2f6a29c6a6cbd53a7eb78e09592b591" category="list-text">Verificare che il lavoro sia in esecuzione su tutti gli esecutori.  Dashboard di Dremio -&gt; lavori -&gt; &lt;jobid&gt; -&gt; profilo raw -&gt; seleziona EXTERNAL_SORT -&gt; Nome host</block>
  <block id="cc8a9d0051ce4ea66245ee1201332dba" category="inline-image-macro">elenco dei nodi nella query Q67</block>
  <block id="de7e26680d69dfee92356b33d4b9e852" category="paragraph"><block ref="de7e26680d69dfee92356b33d4b9e852" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8ae43960f655adfac548cc72fd74e60" category="list-text">Quando si esegue la query SQL, è possibile controllare la cartella divisa per la memorizzazione dei dati nella cache nel controller di archiviazione NetApp .</block>
  <block id="a6b711eedf77bebde70bdfc6f869c41f" category="inline-image-macro">dettagli trapelati al completamento della query 67</block>
  <block id="9e9d6f8f3555c800bdfb98b69c82c2df" category="list-text">La query SQL è stata completata con spill over<block ref="d1b3ed2b7bf78249ccd584f190063118" category="inline-image-macro-rx" type="image"></block></block>
  <block id="29f8ef4d2e7065fbaf7af29841718352" category="inline-image-macro">Riepilogo del lavoro della query completata 67</block>
  <block id="af756b25baef2ba53e554daaf6f7d4b3" category="list-text">Riepilogo del completamento del lavoro.<block ref="91ffddffe841fcfba2fc7aad3683dff3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0de80fdbcc7438b84f536fcf74c03921" category="inline-image-macro">dettagli splleddata dal risultato della query</block>
  <block id="eacfb80ed9b3da589a06f11817a18a8e" category="list-text">Controllare la dimensione dei dati fuoriusciti<block ref="c25c4cfe2a16a40eeaf1652c7ba5d9f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f8d7f6ab5b07156f7006507270c9869" category="paragraph">La stessa procedura è applicabile per l'archiviazione di oggetti NAS e StorageGRID .</block>
  <block id="a64b3943d4911d301243b8ac8779ba53" category="summary">Questa sezione fornisce un riepilogo dei casi d'uso e delle soluzioni fornite da NetApp per soddisfare vari requisiti di protezione dei dati Hadoop.</block>
  <block id="ac81718eacd21c51db78a7185a5c0a96" category="paragraph">Questa sezione fornisce un riepilogo dei casi d'uso e delle soluzioni fornite da NetApp per soddisfare vari requisiti di protezione dei dati Hadoop.  Utilizzando il data fabric powered by NetApp, i clienti possono:</block>
  <block id="095ece35729c37846889cf00d16bb141" category="list-text">Ottieni la flessibilità di scegliere le giuste soluzioni di protezione dei dati sfruttando le avanzate funzionalità di gestione dei dati di NetApp e l'integrazione con i flussi di lavoro nativi di Hadoop.</block>
  <block id="925b1719b2db8532854b1de76f928f31" category="list-text">Ridurre di quasi il 70% il tempo di backup del cluster Hadoop.</block>
  <block id="7de96884f777b768ef12e40582f4d816" category="list-text">Elimina qualsiasi effetto sulle prestazioni derivante dai backup del cluster Hadoop.</block>
  <block id="d5235d7ce8947322a12272f0c6dc7e24" category="list-text">Fornisci protezione dei dati multicloud e accesso ai dati da diversi provider cloud contemporaneamente a un'unica fonte di dati analitici.</block>
  <block id="61e7eb3536cca4c51ae700159e1d247a" category="list-text">Crea copie del cluster Hadoop in modo rapido e salvaspazio utilizzando la tecnologia FlexClone .</block>
  <block id="64bb4a6337ad7b2efa8dc5d43d492edf" category="paragraph">Per saperne di più sulle informazioni descritte nel presente documento, consultare i seguenti documenti e/o siti web:</block>
  <block id="253914d41704f0f326f6595e14005170" category="list-text">Soluzioni di analisi dei Big Data NetApp</block>
  <block id="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link"><block ref="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link-rx"></block></block>
  <block id="f87d78d98a2357057eba948402e285f0" category="paragraph"><block ref="f87d78d98a2357057eba948402e285f0" category="inline-link-rx"></block></block>
  <block id="b2eb92b872fe536c4a859e695eaf280d" category="list-text">Carico di lavoro Apache Spark con NetApp Storage</block>
  <block id="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link"><block ref="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-rx"></block></block>
  <block id="3db0ab5f6c6b92b8d32d80cb1a83e214" category="paragraph"><block ref="3db0ab5f6c6b92b8d32d80cb1a83e214" category="inline-link-rx"></block></block>
  <block id="1bff250c7118efa9007019415bb2730d" category="list-text">Soluzioni di archiviazione NetApp per Apache Spark</block>
  <block id="83d445161ea1f91a19d552f783018ea5" category="inline-link"><block ref="83d445161ea1f91a19d552f783018ea5" category="inline-link-rx"></block></block>
  <block id="142c737f7563ed12b8b08b6fc8779b8c" category="paragraph"><block ref="142c737f7563ed12b8b08b6fc8779b8c" category="inline-link-rx"></block></block>
  <block id="df245018c012fa9deefc0e1d65196e46" category="list-text">Apache Hadoop su data fabric abilitato da NetApp</block>
  <block id="143ece864a38e1c8267bd8318d458955" category="inline-link"><block ref="143ece864a38e1c8267bd8318d458955" category="inline-link-rx"></block></block>
  <block id="b890b67174812331efb42656a186fa42" category="paragraph"><block ref="b890b67174812331efb42656a186fa42" category="inline-link-rx"></block></block>
  <block id="0407c27180c9b019e644e8ad4c6a9324" category="section-title">Ringraziamenti</block>
  <block id="c4f052e8512b2541f8154dd256a529d6" category="list-text">Paul Burland, rappresentante commerciale, vendite distrettuali ANZ Victoria, NetApp</block>
  <block id="5d14432aa90b3b3ebfa87b98a1844edb" category="list-text">Hoseb Dermanilian, Responsabile dello sviluppo aziendale, NetApp</block>
  <block id="929bdc02c2d9943ae8cb52786476e6c6" category="list-text">Lee Dorrier, Direttore MPSG, NetApp</block>
  <block id="a3ed56594a87e322fbcf5a6e705a4134" category="list-text">David Thiessen, Ingegnere di sistema, ANZ Victoria District SE, NetApp</block>
  <block id="f6a738f75f76f62a241636eca02cd87d" category="section-title">Cronologia delle versioni</block>
  <block id="44749712dbec183e983dcd78a7736c41" category="cell">Data</block>
  <block id="8002bc13927c65b5f265b031079ce1d4" category="cell">Cronologia delle versioni del documento</block>
  <block id="3798985ee5e15c84c4263815d5a4d0b7" category="cell">Versione 1.0</block>
  <block id="effdc6a5d743a9db1cd347a2ac8d6b80" category="cell">Gennaio 2018</block>
  <block id="dfd02aef9802f4824ead7c08b8f81f1f" category="cell">Versione iniziale</block>
  <block id="304f30474edd152dc34aef7dbb123607" category="cell">Versione 2.0</block>
  <block id="a5f3f63c2f6e1d6d4605650633b9ce8a" category="cell">Ottobre 2021</block>
  <block id="81d2cd2b484f8c425c2146303b9f1c55" category="cell">Aggiornato con il caso d'uso n. 5: accelerare il carico di lavoro analitico</block>
  <block id="46b9839969e4bc429da9cc245c756450" category="cell">Versione 3.0</block>
  <block id="fb784db76f57bc935639ba5340089d77" category="cell">Novembre 2023</block>
  <block id="11ec45d75a4ad726423d44fadee3074a" category="cell">Rimossi i dettagli NIPAM</block>
  <block id="5e524f38cae9a99f3ebbaf012df2894e" category="summary">Il data fabric basato su NetApp semplifica e integra la gestione dei dati negli ambienti cloud e on-premise per accelerare la trasformazione digitale.  Il data fabric basato su NetApp fornisce servizi e applicazioni di gestione dei dati (elementi costitutivi) coerenti e integrati per la visibilità e l'analisi dei dati, l'accesso e il controllo dei dati, nonché la protezione e la sicurezza dei dati.</block>
  <block id="3c2db15f0fee10b08496ec1701f104d8" category="doc">Data fabric basato su NetApp per l'architettura dei big data</block>
  <block id="981d357acc471e35d8d150f861ff1828" category="paragraph">Il data fabric basato su NetApp semplifica e integra la gestione dei dati negli ambienti cloud e on-premise per accelerare la trasformazione digitale.</block>
  <block id="d5a64464c1e1f9d8be4cafc8b2325fa6" category="paragraph">Il data fabric basato su NetApp fornisce servizi e applicazioni di gestione dei dati coerenti e integrati (elementi costitutivi) per la visibilità e l'analisi dei dati, l'accesso e il controllo dei dati, nonché la protezione e la sicurezza dei dati, come mostrato nella figura seguente.</block>
  <block id="42e5faac50fa6c299b9293560a7e7052" category="paragraph"><block ref="42e5faac50fa6c299b9293560a7e7052" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5083bdadc0fe82e6398670e5dcc6bff9" category="section-title">Casi d'uso comprovati dei clienti di Data Fabric</block>
  <block id="3c1223e53bc7b972a018d3e2597e0bfd" category="paragraph">Il data fabric basato su NetApp offre ai clienti i seguenti nove casi d'uso comprovati:</block>
  <block id="a6800f5cacde75e6f1cfb931a6f2dba6" category="list-text">Accelerare i carichi di lavoro di analisi</block>
  <block id="5b0fa9517345824f19ceddd9d0cd39de" category="list-text">Accelerare la trasformazione DevOps</block>
  <block id="90ed50a34505fc6883bd65c36ed8b810" category="list-text">Costruire un'infrastruttura di hosting cloud</block>
  <block id="f3933541659deec9d28aa584238f0468" category="list-text">Integrare i servizi di dati cloud</block>
  <block id="d70909396aef5247a5a1b17dd15cf43d" category="list-text">Proteggere e mettere in sicurezza i dati</block>
  <block id="7af5a6e7f241b8d284656f20880db36f" category="list-text">Ottimizzare i dati non strutturati</block>
  <block id="2c63452d476328fa43a39c00bef366f1" category="list-text">Ottieni efficienze nei data center</block>
  <block id="0f72ba4c2b371e4f9f47e7d8c61468a5" category="list-text">Fornire informazioni sui dati e controllo</block>
  <block id="0da79db0a9974fc0002f744165467752" category="list-text">Semplifica e automatizza</block>
  <block id="5d5b69e7e19270db49a42eb4e96be2ee" category="paragraph">Questo documento copre due dei nove casi d'uso (insieme alle relative soluzioni):</block>
  <block id="7adb8b5c573e74594feeb2f74e1ffc96" category="section-title">Accesso diretto NetApp NFS</block>
  <block id="c2915c2b980396a00c86766bff7195e3" category="paragraph">NetApp NFS consente ai clienti di eseguire attività di analisi di big data sui propri dati NFSv3 o NFSv4 nuovi o esistenti senza dover spostare o copiare i dati.  Impedisce la creazione di copie multiple dei dati ed elimina la necessità di sincronizzare i dati con una fonte.  Ad esempio, nel settore finanziario, lo spostamento dei dati da un luogo all'altro deve rispettare obblighi di legge, il che non è un compito facile.  In questo scenario, l'accesso diretto NFS NetApp analizza i dati finanziari dalla loro posizione originale.  Un altro vantaggio fondamentale è che l'utilizzo dell'accesso diretto NFS NetApp semplifica la protezione dei dati Hadoop mediante l'uso di comandi Hadoop nativi e consente flussi di lavoro di protezione dei dati sfruttando il ricco portafoglio di gestione dei dati di NetApp.</block>
  <block id="1e72dcaa767fcc4be580ce5e9e1b52ea" category="paragraph"><block ref="1e72dcaa767fcc4be580ce5e9e1b52ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa47c768dc0f007b4606d394be4330c3" category="paragraph">L'accesso diretto NFS NetApp offre due tipi di opzioni di distribuzione per i cluster Hadoop/Spark:</block>
  <block id="cc7514a5b2b35641026a81211ae7fe9a" category="list-text">Per impostazione predefinita, i cluster Hadoop/Spark utilizzano Hadoop Distributed File System (HDFS) per l'archiviazione dei dati e il file system predefinito.  L'accesso diretto NFS NetApp può sostituire l'HDFS predefinito con l'archiviazione NFS come file system predefinito, consentendo operazioni di analisi diretta sui dati NFS.</block>
  <block id="5a5dace50e75999dec9323da42fe5410" category="list-text">In un'altra opzione di distribuzione, l'accesso diretto NFS NetApp supporta la configurazione di NFS come storage aggiuntivo insieme a HDFS in un singolo cluster Hadoop/Spark.  In questo caso, il cliente può condividere i dati tramite esportazioni NFS e accedervi dallo stesso cluster insieme ai dati HDFS.</block>
  <block id="933871f01596456078e75585ab9480ae" category="paragraph">I principali vantaggi dell'utilizzo dell'accesso diretto NFS NetApp includono:</block>
  <block id="bc3221e251e23e5ee9782e37b0337c38" category="list-text">Analizza i dati dalla loro posizione attuale, evitando così di dover spostare i dati analitici su un'infrastruttura Hadoop come HDFS, un'attività che richiede molto tempo e prestazioni.</block>
  <block id="fe5efea0cd6733d158bfb04016f055f0" category="list-text">Riduce il numero di repliche da tre a una.</block>
  <block id="21b00f92397ca3c72f6407dd3a873e23" category="list-text">Consente agli utenti di disaccoppiare elaborazione e archiviazione per scalarli in modo indipendente.</block>
  <block id="be7e2eb6e940a1e798db3abedc75b7a8" category="list-text">Fornisce protezione dei dati aziendali sfruttando le avanzate funzionalità di gestione dei dati di ONTAP.</block>
  <block id="acc50ec5f7ffe1b08ee357afcb502a0f" category="list-text">È certificato con la piattaforma dati Hortonworks.</block>
  <block id="be5acbdc2ea462a8345ea92d4c42511c" category="list-text">Consente distribuzioni di analisi dei dati ibride.</block>
  <block id="227afbdb4ab9214131d6ca5ca3df3cd6" category="list-text">Riduce i tempi di backup sfruttando la capacità multithread dinamica.</block>
  <block id="787364630dc10cfc2657bc82f289a9fb" category="section-title">Elementi costitutivi dei big data</block>
  <block id="7698deb733ad601844c58f0102d0470c" category="paragraph">Il data fabric basato su NetApp integra servizi e applicazioni di gestione dei dati (elementi costitutivi) per l'accesso, il controllo, la protezione e la sicurezza dei dati, come mostrato nella figura seguente.</block>
  <block id="daa25861e76d8b4617b478f8cd89c0b2" category="paragraph"><block ref="daa25861e76d8b4617b478f8cd89c0b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="162f2b2249f4b8bda40b0c01043779b3" category="paragraph">Gli elementi costitutivi nella figura sopra includono:</block>
  <block id="e64f250539a531b81423d6f3f4729665" category="list-text">* Accesso diretto NetApp NFS.*  Fornisce i cluster Hadoop e Spark più recenti con accesso diretto ai volumi NetApp NFS senza requisiti aggiuntivi di software o driver.</block>
  <block id="f79865a14977797753199d8c238eade6" category="list-text">* NetApp Cloud Volumes ONTAP e Google Cloud NetApp Volumes.*  Archiviazione connessa definita dal software basata su ONTAP in esecuzione in Amazon Web Services (AWS) o Azure NetApp Files (ANF) nei servizi cloud di Microsoft Azure.</block>
  <block id="5d382bdcedb0a9c7aa214b09e129e5e7" category="list-text">* Tecnologia NetApp SnapMirror *.  Fornisce funzionalità di protezione dei dati tra istanze locali e istanze ONTAP Cloud o NPS.</block>
  <block id="e2d911047fad9851fae1d7c4e71b2fab" category="list-text">*Fornitori di servizi cloud.*  Tra questi fornitori figurano AWS, Microsoft Azure, Google Cloud e IBM Cloud.</block>
  <block id="486add91df5cb94a1fee5fccffe4f39b" category="list-text">*PaaS.*  Servizi di analisi basati su cloud come Amazon Elastic MapReduce (EMR) e Databricks in AWS, nonché Microsoft Azure HDInsight e Azure Databricks.</block>
  <block id="df343d31543826a7505d157cf243c96a" category="summary">Hadoop DistCp è uno strumento nativo utilizzato per la copia intercluster e intracluster di grandi dimensioni.  Il processo di base Hadoop DistCp è un tipico flusso di lavoro di backup che utilizza strumenti nativi di Hadoop come MapReduce per copiare i dati Hadoop da un'origine HDFS a una destinazione corrispondente.</block>
  <block id="2a377dc939cca8cab65101c1869d628d" category="doc">Protezione dei dati Hadoop e NetApp</block>
  <block id="1d766990d66db8e06b462398928288cd" category="paragraph">Hadoop DistCp è uno strumento nativo utilizzato per la copia intercluster e intracluster di grandi dimensioni.  Il processo di base di Hadoop DistCp illustrato nella figura seguente è un tipico flusso di lavoro di backup che utilizza strumenti nativi di Hadoop come MapReduce per copiare i dati Hadoop da un'origine HDFS a una destinazione corrispondente.</block>
  <block id="7cded69de10ed23fb288e8f481913718" category="paragraph">L'accesso diretto NFS NetApp consente ai clienti di impostare NFS come destinazione per lo strumento Hadoop DistCp per copiare i dati dalla sorgente HDFS in una condivisione NFS tramite MapReduce.  L'accesso diretto NFS NetApp funge da driver NFS per lo strumento DistCp.</block>
  <block id="3225c81e14f83a90295391be9d81302a" category="paragraph"><block ref="3225c81e14f83a90295391be9d81302a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cedd54d52b90b58fb9615e956db81629" category="summary">Questo documento descrive le soluzioni di dati cloud ibride che utilizzano i sistemi di storage NetApp AFF e FAS , NetApp Cloud Volumes ONTAP, NetApp Connected Storage e la tecnologia NetApp FlexClone per Spark e Hadoop.  Queste architetture di soluzioni consentono ai clienti di scegliere una soluzione di protezione dei dati adatta al loro ambiente.  NetApp ha progettato queste soluzioni basandosi sull'interazione con i clienti e sui loro casi d'uso aziendali.</block>
  <block id="71932d00608c3a9fe13a866ab35227f6" category="paragraph">Karthikeyan Nagalingam e Sathish Thyagarajan, NetApp</block>
  <block id="8b6b60ca3f35331d22d686d9c4e12871" category="paragraph">Questo documento descrive le soluzioni di dati cloud ibride che utilizzano i sistemi di storage NetApp AFF e FAS , NetApp Cloud Volumes ONTAP, NetApp Connected Storage e la tecnologia NetApp FlexClone per Spark e Hadoop.  Queste architetture di soluzioni consentono ai clienti di scegliere una soluzione di protezione dei dati adatta al loro ambiente.  NetApp ha progettato queste soluzioni basandosi sull'interazione con i clienti e sui loro casi d'uso aziendali.  Il presente documento fornisce le seguenti informazioni dettagliate:</block>
  <block id="d928ac205302ed3d60386e2a4759c6d6" category="list-text">Perché abbiamo bisogno della protezione dei dati per gli ambienti Spark e Hadoop e per le sfide dei clienti.</block>
  <block id="4444991e618ed955b12fdbcf746ad762" category="list-text">Il data fabric basato sulla visione NetApp e sui suoi componenti e servizi.</block>
  <block id="018b3e5bb8ca92450618b4f5ff9719f7" category="list-text">Come questi elementi costitutivi possono essere utilizzati per progettare flussi di lavoro flessibili per la protezione dei dati.</block>
  <block id="30b68051de2b69f7d6ab186bed865f7c" category="list-text">Pro e contro di diverse architetture basate su casi d'uso reali dei clienti.  Ogni caso d'uso fornisce i seguenti componenti:</block>
  <block id="acf055fa7efae33ce06471f448ae1267" category="list-text">Scenari dei clienti</block>
  <block id="5f5e12d29ffccf33e8cb5a30f4d2fe8c" category="list-text">Requisiti e sfide</block>
  <block id="2a9dbfa4b74c53d7304fc8b79a1874d3" category="list-text">Soluzioni</block>
  <block id="cb9825c3c7619f7000c8452d9005aa5b" category="list-text">Riepilogo delle soluzioni</block>
  <block id="40300466f60ef41f731d7fd45a1024e2" category="section-title">Perché la protezione dei dati Hadoop?</block>
  <block id="d54234515a0cb2905eb88ccb03d85491" category="paragraph">In un ambiente Hadoop e Spark, è necessario affrontare le seguenti problematiche:</block>
  <block id="9ed257b8e8a9504946fcf430ea2e12e3" category="list-text">*Errori software o umani.*  L'errore umano negli aggiornamenti software durante l'esecuzione di operazioni sui dati Hadoop può dare luogo a comportamenti errati che possono determinare risultati imprevisti dal lavoro.  In tal caso, dobbiamo proteggere i dati per evitare errori o risultati irragionevoli.  Ad esempio, a seguito di un aggiornamento software eseguito male in un'applicazione di analisi dei segnali stradali, una nuova funzionalità non riesce ad analizzare correttamente i dati dei segnali stradali in formato testo normale.  Il software analizza ancora JSON e altri formati di file non di testo, con il risultato che il sistema di analisi del controllo del traffico in tempo reale produce risultati di previsione in cui mancano punti dati.  Questa situazione può causare errori di output che potrebbero causare incidenti ai semafori.  La protezione dei dati può risolvere questo problema offrendo la possibilità di ripristinare rapidamente la versione precedente dell'applicazione funzionante.</block>
  <block id="38b145294d087c4d733df994e6a7b6c1" category="list-text">*Dimensioni e scala.*  La dimensione dei dati analitici aumenta di giorno in giorno a causa del numero sempre crescente di fonti di dati e del loro volume.  I social media, le app mobili, l'analisi dei dati e le piattaforme di cloud computing sono le principali fonti di dati nell'attuale mercato dei big data, che è in rapida crescita e pertanto i dati devono essere protetti per garantire operazioni accurate.</block>
  <block id="612be5fe1026c2566014b79f77403701" category="list-text">*Protezione dati nativa di Hadoop.*  Hadoop ha un comando nativo per proteggere i dati, ma questo comando non garantisce la coerenza dei dati durante il backup.  Supporta solo il backup a livello di directory.  Gli snapshot creati da Hadoop sono di sola lettura e non possono essere utilizzati per riutilizzare direttamente i dati di backup.</block>
  <block id="e664ca405ed3e90fecf2e085985fe24c" category="section-title">Sfide di protezione dei dati per i clienti Hadoop e Spark</block>
  <block id="c2d49a2ee903d6d86976c3618079a61d" category="paragraph">Una sfida comune per i clienti Hadoop e Spark è quella di ridurre i tempi di backup e aumentare l'affidabilità del backup senza influire negativamente sulle prestazioni del cluster di produzione durante la protezione dei dati.</block>
  <block id="8d54bea5cb89e665d1a703529f703765" category="paragraph">I clienti devono inoltre ridurre al minimo i tempi di inattività dell'RPO (Recovery Point Objective) e dell'RTO (Recovery Time Objective) e controllare i propri siti di disaster recovery on-premise e basati su cloud per una continuità aziendale ottimale.  Questo controllo deriva solitamente dalla disponibilità di strumenti di gestione a livello aziendale.</block>
  <block id="042be4d2813fd31d6b49e6eeaa1a42c3" category="paragraph">Gli ambienti Hadoop e Spark sono complessi non solo perché il volume dei dati è enorme e in crescita, ma anche perché la velocità con cui questi dati arrivano è in aumento.  Questo scenario rende difficile creare rapidamente ambienti DevTest e QA efficienti e aggiornati a partire dai dati di origine.  NetApp riconosce queste sfide e offre le soluzioni presentate in questo documento.</block>
  <block id="7d617748001976c06ae87f824ca77b2d" category="summary">In questo scenario, la piattaforma di analisi di una grande banca di servizi finanziari e di investimento è stata modernizzata utilizzando la soluzione di archiviazione NetApp NFS per ottenere un miglioramento significativo nell'analisi dei rischi di investimento e dei derivati per la sua unità aziendale di gestione patrimoniale e quantitativa.</block>
  <block id="0158648474e8dffab94ca58af2257b92" category="doc">Caso d'uso 5: accelerare i carichi di lavoro analitici</block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="section-title">Scenario</block>
  <block id="f3274c43bc916b05ebe766167f47a1ad" category="paragraph">Nell'ambiente esistente del cliente, l'infrastruttura Hadoop utilizzata per la piattaforma di analisi sfruttava l'archiviazione interna dei server Hadoop.  A causa della natura proprietaria dell'ambiente JBOD, molti clienti interni all'organizzazione non sono stati in grado di sfruttare il loro modello quantitativo Monte Carlo, una simulazione che si basa su campioni ricorrenti di dati in tempo reale.  La scarsa capacità di comprendere gli effetti dell'incertezza sui movimenti del mercato stava giocando un ruolo sfavorevole per la business unit di gestione patrimoniale quantitativa.</block>
  <block id="788ab145281501314f18747a0ab1eaea" category="paragraph">L'unità aziendale quantitativa della banca desiderava un metodo di previsione efficiente per ottenere previsioni accurate e tempestive.  Per fare ciò, il team ha riconosciuto la necessità di modernizzare l'infrastruttura, ridurre i tempi di attesa I/O esistenti e migliorare le prestazioni delle applicazioni analitiche come Hadoop e Spark per simulare in modo efficiente i modelli di investimento, misurare i potenziali guadagni e analizzare i rischi.</block>
  <block id="49b21ad0d38942f635877e7bbc5d7a1e" category="section-title">Soluzione</block>
  <block id="43b3ece7a28edcf11ee066112179b834" category="paragraph">Il cliente aveva JBOD per la sua soluzione Spark esistente.  NetApp ONTAP, NetApp StorageGRID e MinIO Gateway to NFS sono stati quindi sfruttati per ridurre i tempi di attesa I/O per il gruppo finanziario quantitativo della banca che esegue simulazioni e analisi sui modelli di investimento che valutano potenziali guadagni e rischi.  Questa immagine mostra la soluzione Spark con storage NetApp .</block>
  <block id="d9e962022f714fc5ed8bccce82c920ac" category="paragraph"><block ref="d9e962022f714fc5ed8bccce82c920ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3a052314babbb25c995c7b6b2b18d04" category="paragraph">Come mostrato nella figura sopra, i sistemi AFF A800, A700 e StorageGRID sono stati implementati per accedere ai file parquet tramite protocolli NFS e S3 in un cluster Hadoop a sei nodi con Spark e servizi di metadati YARN e Hive per operazioni di analisi dei dati.</block>
  <block id="473d88a5512cc81d2571425bbea591d2" category="paragraph">Una soluzione di storage con collegamento diretto (DAS) nel vecchio ambiente del cliente aveva lo svantaggio di dover scalare elaborazione e storage in modo indipendente.  Grazie alla soluzione NetApp ONTAP per Spark, la divisione di analisi finanziaria della banca è riuscita a separare l'archiviazione dall'elaborazione e a distribuire le risorse infrastrutturali in modo più efficace, in base alle necessità.</block>
  <block id="fceb3129a02a41b3231baa9b6f633217" category="paragraph">Utilizzando ONTAP con NFS, le CPU del server di elaborazione sono state utilizzate quasi completamente per i processi Spark SQL e il tempo di attesa I/O è stato ridotto di quasi il 70%, garantendo quindi una maggiore potenza di elaborazione e un incremento delle prestazioni per i carichi di lavoro Spark.  Successivamente, l'aumento dell'utilizzo della CPU ha consentito al cliente di sfruttare anche le GPU, come GPUDirect, per un'ulteriore modernizzazione della piattaforma.  Inoltre, StorageGRID offre un'opzione di archiviazione a basso costo per i carichi di lavoro Spark e MinIO Gateway fornisce un accesso sicuro ai dati NFS tramite il protocollo S3.  Per i dati nel cloud, NetApp consiglia Cloud Volumes ONTAP, Azure NetApp Files e Google Cloud NetApp Volumes.</block>
  <block id="9d9b3c1914053d9ff102d01b77ab40a9" category="summary">Questo caso d'uso si basa su un cliente del settore broadcasting che ha bisogno di eseguire il backup dei dati di analisi basati su cloud nel proprio data center locale.</block>
  <block id="0abf694ae9fa8ac43b805ba39a10d143" category="doc">Caso d'uso 2: Backup e disaster recovery dal cloud all'ambiente locale</block>
  <block id="733d8d14fe9ffb98d02b33079e3d3db2" category="paragraph">Questo caso d'uso si basa su un cliente di trasmissione che ha bisogno di eseguire il backup dei dati di analisi basati su cloud nel proprio data center locale, come illustrato nella figura seguente.</block>
  <block id="56f5fb8db5f5326b20e3fe17ce11efa4" category="paragraph"><block ref="56f5fb8db5f5326b20e3fe17ce11efa4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26fea23389e404e4cb8cf9be2c100cbd" category="paragraph">In questo scenario, i dati dei sensori IoT vengono acquisiti nel cloud e analizzati utilizzando un cluster Apache Spark open source all'interno di AWS.  Il requisito è quello di eseguire il backup dei dati elaborati dal cloud in locale.</block>
  <block id="c04f16bb8233216a472d30b6c509b230" category="paragraph">I principali requisiti e sfide per questo caso d'uso includono:</block>
  <block id="bb446485afc21a80bc5f26a9131de160" category="list-text">L'abilitazione della protezione dei dati non dovrebbe avere alcun effetto sulle prestazioni del cluster Spark/Hadoop di produzione nel cloud.</block>
  <block id="dbb6231aec34eed7c53cff2d4a2d43ef" category="list-text">I dati dei sensori cloud devono essere trasferiti e protetti in locale in modo efficiente e sicuro.</block>
  <block id="848b66ad8aca524142404de79ce64c73" category="list-text">Flessibilità nel trasferire dati dal cloud all'ambiente locale in diverse condizioni, ad esempio su richiesta, istantaneamente e durante periodi di basso carico del cluster.</block>
  <block id="4d8011e28e4ef4359ca7c169e7797091" category="paragraph">Il cliente utilizza AWS Elastic Block Store (EBS) per l'archiviazione HDFS del cluster Spark per ricevere e acquisire dati da sensori remoti tramite Kafka.  Di conseguenza, l'archiviazione HDFS funge da origine per i dati di backup.</block>
  <block id="e55d60f6f17896ce9b53a0ef23e23413" category="paragraph">Per soddisfare questi requisiti, NetApp ONTAP Cloud viene distribuito in AWS e viene creata una condivisione NFS che funge da destinazione di backup per il cluster Spark/Hadoop.</block>
  <block id="3c0f76e2d6fa82b2004270ec86f39aa7" category="paragraph">Dopo aver creato la condivisione NFS, copiare i dati dall'archiviazione EBS HDFS nella condivisione NFS ONTAP .  Dopo che i dati risiedono in NFS in ONTAP Cloud, la tecnologia SnapMirror può essere utilizzata per eseguire il mirroring dei dati dal cloud all'archiviazione locale, secondo necessità, in modo sicuro ed efficiente.</block>
  <block id="aecad7c5bdfba92aa6cd945a9045c37f" category="paragraph">Questa immagine mostra la soluzione di backup e disaster recovery dal cloud a quella on-premise.</block>
  <block id="6d742f93cf04e332b07c93ce2bc96163" category="paragraph"><block ref="6d742f93cf04e332b07c93ce2bc96163" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dca3067f5c6c2fa6b32ef683fcab56f" category="summary">In questo scenario, il cliente dispone di un ampio repository Hadoop in sede e desidera eseguirne il backup per scopi di disaster recovery.  Tuttavia, l'attuale soluzione di backup del cliente è costosa e presenta una finestra di backup lunga, superiore alle 24 ore.</block>
  <block id="817ac2975197bd6c376a7918a798981f" category="doc">Caso d'uso 1: backup dei dati Hadoop</block>
  <block id="7ffe71c29f8ea391bbd80c1e8441af9a" category="list-text">Compatibilità con le versioni precedenti del software:</block>
  <block id="d96828d85e8cc053407a391bee52257f" category="list-text">La soluzione di backup alternativa proposta dovrebbe essere compatibile con le attuali versioni software in esecuzione utilizzate nel cluster Hadoop di produzione.</block>
  <block id="dd5bb530e532c011487ffc3a69e56f57" category="list-text">Per rispettare gli SLA assunti, la soluzione alternativa proposta dovrebbe garantire RPO e RTO molto bassi.</block>
  <block id="4783ab1f0401dc9c24cc9afa6dc5823e" category="list-text">Il backup creato dalla soluzione di backup NetApp può essere utilizzato nel cluster Hadoop creato localmente nel data center, nonché nel cluster Hadoop in esecuzione nella posizione di disaster recovery nel sito remoto.</block>
  <block id="1dbc869d2df036d4d6e732e9c680ab6b" category="list-text">La soluzione proposta deve essere conveniente.</block>
  <block id="7405e6ba4b630f11b88a7976325a95e4" category="list-text">La soluzione proposta deve ridurre l'impatto sulle prestazioni dei processi di analisi in produzione attualmente in esecuzione durante i tempi di backup.</block>
  <block id="265e759e2a3b4c55776e0de53887b3b4" category="section-title">Soluzione di backup esistente del clientex</block>
  <block id="f350f804f84a5bf788cd78cd4aae7eab" category="paragraph">La figura seguente mostra la soluzione di backup nativa originale di Hadoop.</block>
  <block id="f9efb12aa8582a65d79ac1fcd7574665" category="paragraph"><block ref="f9efb12aa8582a65d79ac1fcd7574665" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b8e496c38192b97fdfa6cae2ba2bb4" category="paragraph">I dati di produzione sono protetti su nastro tramite il cluster di backup intermedio:</block>
  <block id="d07ca391addc59b7408fb88541552b43" category="list-text">I dati HDFS1 vengono copiati in HDFS2 eseguendo il comando<block ref="56eafdf3e9748260b9403493314dc20d" prefix=" " category="inline-code"></block> comando.</block>
  <block id="2c4cadbb7f122d1d0cd988a11681248a" category="list-text">Il cluster di backup funge da gateway NFS e i dati vengono copiati manualmente su nastro tramite Linux<block ref="9c95319bf274672d6eae7eb97c3dfda5" prefix=" " category="inline-code"></block> comando tramite la libreria a nastro.</block>
  <block id="b73035943c8623cbdb7bd67992201012" category="paragraph">I vantaggi della soluzione di backup nativa Hadoop originale includono:</block>
  <block id="5bdb90a1352ca42ab8dde5b9ab7ffac3" category="list-text">La soluzione si basa sui comandi nativi di Hadoop, evitando all'utente di dover apprendere nuove procedure.</block>
  <block id="f581d1b5f93adda1865bad95e215a7b9" category="list-text">La soluzione sfrutta l'architettura e l'hardware standard del settore.</block>
  <block id="ddd131647a4d5e1b5bcb983ec8872ff9" category="paragraph">Gli svantaggi della soluzione di backup nativa Hadoop originale includono:</block>
  <block id="2cd5e9eae715f3bb0475ed032bf56190" category="list-text">La finestra temporale di backup è lunga e supera le 24 ore, rendendo vulnerabili i dati di produzione.</block>
  <block id="b22d500a5624a2c57ec5bda86aa57011" category="list-text">Notevole degrado delle prestazioni del cluster durante i tempi di backup.</block>
  <block id="69bfe7f4231b0c1d65247d0abfc89cb3" category="list-text">La copia su nastro è un processo manuale.</block>
  <block id="6ef8e4ec49425ac5ded9c6cc599c17d2" category="list-text">La soluzione di backup è costosa in termini di hardware richiesto e di ore di lavoro umano necessarie per i processi manuali.</block>
  <block id="1b4d2bf420e7f05ecb82ecf2197ab810" category="section-title">Soluzioni di backup</block>
  <block id="6d977e36854ae6439cbc4fe8e0c1b227" category="paragraph">Sulla base di queste sfide e requisiti, e tenendo in considerazione il sistema di backup esistente, sono state suggerite tre possibili soluzioni di backup.  Le seguenti sottosezioni descrivono ciascuna di queste tre diverse soluzioni di backup, denominate dalla soluzione A alla soluzione C.</block>
  <block id="c5a6c012dc14dc7f9d2fa0df0ccb0cdf" category="section-title">Soluzione A</block>
  <block id="bc98837ed486c01d428d23d0c3a83d6a" category="paragraph">Nella soluzione A, il cluster Hadoop di backup invia i backup secondari ai sistemi di archiviazione NFS NetApp , eliminando il requisito del nastro, come mostrato nella figura seguente.</block>
  <block id="c7446a7fd101a1f229e62b8dfc3f2627" category="paragraph"><block ref="c7446a7fd101a1f229e62b8dfc3f2627" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2813f022c034c63ad3d6efeeb503eb70" category="paragraph">I compiti dettagliati per la soluzione A includono:</block>
  <block id="0406c5ca05cfb5f7a0c02971c3962460" category="list-text">Il cluster Hadoop di produzione contiene i dati analitici del cliente nell'HDFS che necessitano di protezione.</block>
  <block id="feb7749ff700168c127dfbd8376b35f7" category="list-text">Il cluster Hadoop di backup con HDFS funge da posizione intermedia per i dati.  Just a bunch of disks (JBOD) fornisce lo storage per HDFS sia nei cluster Hadoop di produzione che di backup.</block>
  <block id="b3f54540429c806b8cf0080fd78b34bc" category="list-text">Proteggere i dati di produzione Hadoop dal cluster di produzione HDFS al cluster di backup HDFS eseguendo il<block ref="900bb9daf20a55f63530a23a8ff21d21" prefix=" " category="inline-code"></block> comando.</block>
  <block id="2de4833848a0b94bd672bdf9bc60d4aa" category="admonition">Lo snapshot Hadoop viene utilizzato per proteggere i dati dalla produzione al cluster Hadoop di backup.</block>
  <block id="79ef8fc2c565c69b33f5918c3a0bdd9a" category="list-text">Il controller di archiviazione NetApp ONTAP fornisce un volume esportato NFS, che viene fornito al cluster Hadoop di backup.</block>
  <block id="1b449b0ea4a324dc81f41259db2c13e9" category="list-text">Eseguendo il<block ref="e23fdb1dae75e2830274d92fdf2535ed" prefix=" " category="inline-code"></block> comando che sfrutta MapReduce e più mapper, i dati analitici vengono protetti dal cluster Hadoop di backup su NFS.</block>
  <block id="738997de22c6371f563f69e1bb57b6e5" category="paragraph">Dopo che i dati sono stati archiviati in NFS sul sistema di archiviazione NetApp , le tecnologie NetApp Snapshot, SnapRestore e FlexClone vengono utilizzate per eseguire il backup, il ripristino e la duplicazione dei dati Hadoop secondo necessità.</block>
  <block id="0bd252182290e872b264ad65d369637f" category="admonition">I dati Hadoop possono essere protetti sia nel cloud che in posizioni di disaster recovery utilizzando la tecnologia SnapMirror .</block>
  <block id="4a1b9aaeaa6487c6df7072326cf3798e" category="paragraph">I vantaggi della soluzione A includono:</block>
  <block id="0843e6a882cae98851adbefb52d05827" category="list-text">I dati di produzione Hadoop sono protetti dal cluster di backup.</block>
  <block id="522d0cf303cbf1b16ea5cc33480ce02f" category="list-text">I dati HDFS sono protetti tramite NFS, consentendo la protezione verso posizioni cloud e di disaster recovery.</block>
  <block id="298d20d1ae9110668e52c07776f62948" category="list-text">Migliora le prestazioni trasferendo le operazioni di backup al cluster di backup.</block>
  <block id="4c10451e9e5bf987bc3ab16a9fce3966" category="list-text">Elimina le operazioni manuali sul nastro</block>
  <block id="0ff20f264e79e773549ded37f50f4b3b" category="list-text">Consente funzioni di gestione aziendale tramite strumenti NetApp .</block>
  <block id="4c84f95e2dad9b5385151a736e89f0c3" category="list-text">Richiede modifiche minime all'ambiente esistente.</block>
  <block id="66f3b3a8c99e03a363a88a58fabe03cc" category="list-text">È una soluzione conveniente.</block>
  <block id="4e941dea7920913a2c3a6d2a11a0936f" category="paragraph">Lo svantaggio di questa soluzione è che richiede un cluster di backup e mapper aggiuntivi per migliorare le prestazioni.</block>
  <block id="0628ac302dce6afb9d95a6b8ebd0d013" category="paragraph">Il cliente ha recentemente implementato la soluzione A per la sua semplicità, il costo e le prestazioni complessive.</block>
  <block id="7a3ba8b554aec9832f399bff2ba17c74" category="paragraph">In questa soluzione è possibile utilizzare dischi SAN di ONTAP al posto di JBOD.  Questa opzione scarica il carico di archiviazione del cluster di backup su ONTAP; tuttavia, lo svantaggio è che sono necessari switch fabric SAN.</block>
  <block id="501a1b4ce382e8e2da0089aded30d11e" category="section-title">Soluzione B</block>
  <block id="099eafc2208317136c2902383d7b0755" category="paragraph">La soluzione B aggiunge un volume NFS al cluster Hadoop di produzione, eliminando la necessità del cluster Hadoop di backup, come mostrato nella figura seguente.</block>
  <block id="5b70fb212e3f22443316e06668fb7eaf" category="paragraph"><block ref="5b70fb212e3f22443316e06668fb7eaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ca30c628556726e2038c5df9689fd91" category="paragraph">I compiti dettagliati per la soluzione B includono:</block>
  <block id="e493f6dc701d2253466d5705af2e5bb1" category="list-text">Il controller di archiviazione NetApp ONTAP esegue l'esportazione NFS nel cluster Hadoop di produzione.</block>
  <block id="b8c0e409f361575b0a2787968f3e6737" category="paragraph">Il nativo di Hadoop<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> Il comando protegge i dati Hadoop dal cluster di produzione HDFS a NFS.</block>
  <block id="665cfb3949b836c368d9be47d34bcbba" category="list-text">Dopo che i dati sono stati archiviati in NFS sul sistema di archiviazione NetApp , le tecnologie Snapshot, SnapRestore e FlexClone vengono utilizzate per eseguire il backup, il ripristino e la duplicazione dei dati Hadoop secondo necessità.</block>
  <block id="4f1aeb2a94e89562b7bef27c368ed9cc" category="paragraph">I vantaggi della soluzione B includono:</block>
  <block id="748dc25f775dc78e1da24328f753d1e1" category="list-text">Il cluster di produzione è leggermente modificato per la soluzione di backup, il che semplifica l'implementazione e riduce i costi aggiuntivi dell'infrastruttura.</block>
  <block id="a565a40a6656693466a7da18be6d44ca" category="list-text">Non è necessario un cluster di backup per l'operazione di backup.</block>
  <block id="fa6ae9dfac02b933ef93450603114fce" category="list-text">I dati di produzione HDFS sono protetti durante la conversione in dati NFS.</block>
  <block id="cf7952142a1253af6b9394a3f01408b3" category="list-text">La soluzione consente funzioni di gestione aziendale tramite gli strumenti NetApp .</block>
  <block id="f4ffcfc00594c5a445a43499130eb8d3" category="paragraph">Lo svantaggio di questa soluzione è che viene implementata nel cluster di produzione, il che può aggiungere ulteriori attività amministrative nel cluster di produzione.</block>
  <block id="0a3b8c5fab2a32545423ade2927b1185" category="section-title">Soluzione C</block>
  <block id="6c176725a15c1c609d24387ddf6600da" category="paragraph">Nella soluzione C, i volumi SAN NetApp vengono forniti direttamente al cluster di produzione Hadoop per l'archiviazione HDFS, come mostrato nella figura seguente.</block>
  <block id="016077aafc394500fb21c4f233724258" category="paragraph"><block ref="016077aafc394500fb21c4f233724258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0d09b63c2b939de22a3b5d0f4cb3c87" category="paragraph">I passaggi dettagliati per la soluzione C includono:</block>
  <block id="35edf0b5a2042b4561d4d499298010e6" category="list-text">Lo storage NetApp ONTAP SAN è predisposto nel cluster Hadoop di produzione per l'archiviazione dei dati HDFS.</block>
  <block id="3b694951a08990d1243da1dd36e6cd07" category="list-text">Per eseguire il backup dei dati HDFS dal cluster Hadoop di produzione vengono utilizzate le tecnologie NetApp Snapshot e SnapMirror .</block>
  <block id="c32b4eb407751e515d7d037629b66dfb" category="list-text">Non vi è alcun effetto sulle prestazioni di produzione per il cluster Hadoop/Spark durante il processo di backup della copia snapshot perché il backup avviene a livello di archiviazione.</block>
  <block id="ef54974b65426daa87a86290447ed9a6" category="admonition">La tecnologia snapshot fornisce backup che vengono completati in pochi secondi, indipendentemente dalle dimensioni dei dati.</block>
  <block id="f499d7fd731eb2bb1efe6c4069efcb47" category="paragraph">I vantaggi della soluzione C includono:</block>
  <block id="abe0be0b8deb695793caa75a1dcfc4b3" category="list-text">È possibile creare un backup efficiente in termini di spazio utilizzando la tecnologia Snapshot.</block>
  <block id="2c755351ada495582a6d9015943de077" category="summary">In questo caso d'uso, l'esigenza del cliente è quella di creare rapidamente ed efficientemente nuovi cluster Hadoop/Spark basati su un cluster Hadoop esistente contenente una grande quantità di dati analitici per scopi di DevTest e reporting nello stesso data center e in sedi remote.</block>
  <block id="acb2dd720b2161405c8cb1ca6035618b" category="doc">Caso d'uso 3: abilitazione di DevTest sui dati Hadoop esistenti</block>
  <block id="4e19c1aafa6d3711ae619f7e1621a61e" category="paragraph">In questo scenario, vengono creati più cluster Spark/Hadoop da un'ampia implementazione di data lake Hadoop in sede e in sedi di disaster recovery.</block>
  <block id="5768edca640abf2b08dd5ba0e593dcc7" category="list-text">Crea più cluster Hadoop per DevTest, QA o qualsiasi altro scopo che richieda l'accesso agli stessi dati di produzione.  La sfida in questo caso è quella di clonare un cluster Hadoop molto grande più volte, istantaneamente e in modo molto efficiente in termini di spazio.</block>
  <block id="529c78f9988d342b33707ecaae7d2576" category="list-text">Sincronizzare i dati Hadoop con i team DevTest e di reporting per l'efficienza operativa.</block>
  <block id="07178cfd87815398d5079e55c257f96c" category="list-text">Distribuisci i dati Hadoop utilizzando le stesse credenziali tra i cluster di produzione e quelli nuovi.</block>
  <block id="b26eaa756d7ec14dcec5c25d7d9ad6b6" category="list-text">Utilizzare criteri pianificati per creare in modo efficiente cluster QA senza influire sul cluster di produzione.</block>
  <block id="6442ec446d11bbd47497299e0ffceed5" category="paragraph">Per rispondere ai requisiti appena descritti viene utilizzata la tecnologia FlexClone .  La tecnologia FlexClone è la copia in lettura/scrittura di una copia Snapshot.  Legge i dati dalla copia Snapshot padre e consuma spazio aggiuntivo solo per i blocchi nuovi/modificati.  È veloce e salvaspazio.</block>
  <block id="51a22383ed7ac5a70a455d81a9bad789" category="paragraph">Innanzitutto, è stata creata una copia Snapshot del cluster esistente utilizzando un gruppo di coerenza NetApp .</block>
  <block id="ff0e15997f709c232408a5055738df05" category="paragraph">Copie snapshot all'interno di NetApp System Manager o nel prompt di amministrazione dello storage.  Le copie Snapshot del gruppo di coerenza sono copie Snapshot del gruppo di coerenza con l'applicazione e il volume FlexClone viene creato in base alle copie Snapshot del gruppo di coerenza.  Vale la pena ricordare che un volume FlexClone eredita la politica di esportazione NFS del volume padre.  Dopo aver creato la copia Snapshot, è necessario installare un nuovo cluster Hadoop per scopi di DevTest e reporting, come mostrato nella figura seguente.  Il volume NFS clonato dal nuovo cluster Hadoop accede ai dati NFS.</block>
  <block id="6ee7e035a9c46bb26ee76c40aa671148" category="paragraph">Questa immagine mostra il cluster Hadoop per DevTest.</block>
  <block id="abc9a1c20fcf276389f79d3093665e5c" category="paragraph"><block ref="abc9a1c20fcf276389f79d3093665e5c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa7dcae8e4f7d8ecc191c3ce8547a53a" category="summary">Questo caso d'uso è rilevante per un partner di servizi cloud incaricato di fornire connettività multicloud per i dati di analisi dei big data dei clienti.</block>
  <block id="2268700ee8bd2216d594273e566b0cc9" category="doc">Caso d'uso 4: Protezione dei dati e connettività multicloud</block>
  <block id="3cec8f6cf1ce867e7f73dd5132b7fbf3" category="paragraph">In questo scenario, i dati IoT ricevuti in AWS da diverse fonti vengono archiviati in una posizione centrale in NPS.  Lo storage NPS è connesso ai cluster Spark/Hadoop situati in AWS e Azure, consentendo l'esecuzione di applicazioni di analisi di big data in più cloud che accedono agli stessi dati.</block>
  <block id="bed6436414550585ccb4ac4c67a449a3" category="list-text">I clienti desiderano eseguire attività di analisi sugli stessi dati utilizzando più cloud.</block>
  <block id="6af3e1f448b2a56e9bd0fbbd43b31bc8" category="list-text">I dati devono essere ricevuti da diverse fonti, ad esempio in locale e nel cloud, tramite diversi sensori e hub.</block>
  <block id="e3c7f1ced05166adfc90c26337389e3e" category="list-text">La soluzione deve essere efficiente e conveniente.</block>
  <block id="b320f1b1ab6d0a21e40ee3d444669645" category="list-text">La sfida principale è quella di creare una soluzione efficiente e conveniente che fornisca servizi di analisi ibridi tra ambienti on-premise e cloud diversi.</block>
  <block id="0d4b3cfa555ff36cd92fb4e36fb69fbf" category="paragraph">Questa immagine illustra la soluzione di protezione dei dati e connettività multicloud.</block>
  <block id="5308dad4844e43fdad02844ec50752c0" category="paragraph"><block ref="5308dad4844e43fdad02844ec50752c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ea48e5206de42785842cb864377766c" category="paragraph">Come mostrato nella figura sopra, i dati provenienti dai sensori vengono trasmessi in streaming e acquisiti nel cluster AWS Spark tramite Kafka.  I dati vengono archiviati in una condivisione NFS residente in NPS, che si trova all'esterno del provider cloud all'interno di un data center Equinix.  Poiché NetApp NPS è connesso ad Amazon AWS e Microsoft Azure rispettivamente tramite connessioni Direct Connect ed Express Route, i clienti possono accedere ai dati NFS dai cluster di analisi di Amazon e AWS.  Questo approccio risolve il problema dell'analisi cloud su più hyperscaler.</block>
  <block id="4089db0b43263b1f59a9c2db909edf6e" category="paragraph">Di conseguenza, poiché sia lo storage on-premise che quello NPS eseguono il software ONTAP , SnapMirror può eseguire il mirroring dei dati NPS nel cluster on-premise, fornendo analisi cloud ibride su cloud on-premise e su più cloud.</block>
  <block id="d446808fb03b5fae4f2e518cbc7d767f" category="paragraph">Per ottenere le migliori prestazioni, NetApp consiglia in genere di utilizzare più interfacce di rete e percorsi di connessione diretta/espressi per accedere ai dati dalle istanze cloud.</block>
  <block id="f9fe6a27dc7f13d26e9416153b950597" category="summary">Questa sezione fornisce una descrizione di alto livello dei casi d'uso della protezione dei dati, che costituiscono l'obiettivo principale del presente documento.  Le sezioni rimanenti forniscono maggiori dettagli per ciascun caso d'uso, come il problema del cliente (scenario), i requisiti e le sfide, nonché le soluzioni.</block>
  <block id="6a15e1dac7cc5c330a1da84c32b3ff2e" category="doc">Panoramica dei casi d'uso della protezione dei dati Hadoop</block>
  <block id="6f2c5dcd0294b9c34430b1de4713c06d" category="paragraph">Per questo caso d'uso, il volume NFS NetApp ha aiutato un grande istituto finanziario a ridurre i tempi di backup da oltre 24 ore a poco meno di poche ore.</block>
  <block id="06b83cb579d9aaf1f26d8c4284a5a42e" category="paragraph">Utilizzando il data fabric basato su NetApp come elemento costitutivo, una grande azienda di trasmissione è riuscita a soddisfare la sua esigenza di eseguire il backup dei dati cloud nel suo data center locale, in base alle diverse modalità di trasferimento dei dati, ad esempio su richiesta, istantaneo o in base al carico del cluster Hadoop/Spark.</block>
  <block id="da17b6db6e3e50f66b5bcaee1d74f8b1" category="paragraph">Le soluzioni NetApp hanno aiutato un distributore di musica online a creare rapidamente più cluster Hadoop efficienti in termini di spazio in diverse filiali per creare report ed eseguire attività DevTest giornaliere utilizzando criteri pianificati.</block>
  <block id="90fc62f886a8c33032d4db8b79ec5814" category="paragraph">Un grande fornitore di servizi ha utilizzato il data fabric basato su NetApp per fornire ai propri clienti analisi multicloud da diverse istanze cloud.</block>
  <block id="67f07a55567ecfc26b3c7b54823a43ee" category="paragraph">Una delle più grandi banche di servizi finanziari e di investimento ha utilizzato la soluzione di storage collegata in rete NetApp per ridurre i tempi di attesa I/O e accelerare la propria piattaforma di analisi finanziaria quantitativa.</block>
  <block id="139709c8a32ed1bcce233da863c5efda" category="summary">Questa sezione presenta le lezioni apprese da questa certificazione.</block>
  <block id="eab9ac0f00ca7c338d71f9acf8885092" category="doc">Linee guida per le migliori pratiche</block>
  <block id="1bd6648fc95556a0a0fde4774f780085" category="list-text">In base alla nostra convalida, l'archiviazione di oggetti S3 è la soluzione migliore per Confluent per conservare i dati.</block>
  <block id="18f3dd1f96633e1c3f4b4473c8f63239" category="list-text">Possiamo utilizzare SAN ad alta capacità (in particolare FC) per mantenere i dati attivi del broker o il disco locale, perché, nella configurazione di archiviazione a livelli Confluent, la dimensione dei dati contenuti nella directory dei dati del broker si basa sulla dimensione del segmento e sul tempo di conservazione quando i dati vengono spostati nell'archiviazione degli oggetti.</block>
  <block id="992e82f9c5ce28bbe0068e8ff7ea8a09" category="list-text">Gli archivi di oggetti offrono prestazioni migliori quando segment.bytes è più alto; abbiamo testato 512 MB.</block>
  <block id="f165ec9e9849281afaf2162f6396907c" category="list-text">In Kafka, la lunghezza della chiave o del valore (in byte) per ogni record prodotto sull'argomento è controllata da<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block> parametro.  Per StorageGRID, le prestazioni di acquisizione e recupero degli oggetti S3 sono aumentate a valori più elevati.  Ad esempio, 512 byte hanno fornito un recupero di 5,8 GBps, 1024 byte hanno fornito un recupero s3 di 7,5 GBps e 2048 byte hanno fornito quasi 10 GBps.</block>
  <block id="92a9c9d4753636cd8ef8008380f5de9b" category="paragraph">La figura seguente presenta l'acquisizione e il recupero degli oggetti S3 in base a<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block> .</block>
  <block id="88108446d5ab5e54118010ab8c716e93" category="paragraph"><block ref="88108446d5ab5e54118010ab8c716e93" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9432e98ec213778ab349305141050c42" category="list-text">*Accordatura Kafka.*  Per migliorare le prestazioni dell'archiviazione a livelli, è possibile aumentare TierFetcherNumThreads e TierArchiverNumThreads.  Come linea guida generale, è consigliabile aumentare TierFetcherNumThreads in modo che corrisponda al numero di core fisici della CPU e aumentare TierArchiverNumThreads alla metà del numero di core della CPU.  Ad esempio, nelle proprietà del server, se si dispone di una macchina con otto core fisici, impostare confluent.tier.fetcher.num.threads = 8 e confluent.tier.archiver.num.threads = 4.</block>
  <block id="ed3ecb8a7183dd06de652f3dc38b1037" category="list-text">*Intervallo di tempo per l'eliminazione degli argomenti.*  Quando un argomento viene eliminato, l'eliminazione dei file dei segmenti di registro nell'archiviazione degli oggetti non inizia immediatamente.  Esiste invece un intervallo di tempo con un valore predefinito di 3 ore prima che i file vengano eliminati.  È possibile modificare la configurazione confluent.tier.topic.delete.check.interval.ms per cambiare il valore di questo intervallo.  Se elimini un argomento o un cluster, puoi anche eliminare manualmente gli oggetti nel rispettivo bucket.</block>
  <block id="3833b7b3d2c8a15e32f72248bab1add9" category="list-text">*ACL su argomenti interni di archiviazione a livelli.*  Una best practice consigliata per le distribuzioni on-premise è quella di abilitare un'autorizzazione ACL sugli argomenti interni utilizzati per l'archiviazione a livelli.  Impostare le regole ACL per limitare l'accesso a questi dati solo all'utente broker.  In questo modo si proteggono gli argomenti interni e si impedisce l'accesso non autorizzato ai dati di archiviazione a livelli e ai metadati.</block>
  <block id="ebcb583d4445a2a39076c7fa4627f79a" category="admonition">Sostituisci l'utente<block ref="a802c5bf62b7c5970725474468cf46f4" prefix=" " category="inline-code"></block> con il broker principale effettivo nella tua distribuzione.</block>
  <block id="0ca954cd7923be900c49b3b807caf2b6" category="paragraph">Ad esempio, il comando<block ref="bccf46e0861de44696513d6cbea91e4c" prefix=" " category="inline-code"></block> imposta gli ACL sull'argomento interno per l'archiviazione a livelli.  Attualmente esiste un solo argomento interno correlato allo storage a livelli.  L'esempio crea un ACL che fornisce l'autorizzazione Kafka principale per tutte le operazioni sull'argomento interno.</block>
  <block id="663d826f2d39c93c218bb619244537b3" category="summary">Abbiamo eseguito la certificazione con Confluent Platform con Kafka per l'archiviazione a livelli in NetApp StorageGRID.</block>
  <block id="5436c2a5438619c1dbe68551a8297494" category="doc">Verifica confluente</block>
  <block id="0c112d1616223eaa5f0484a9499d587f" category="paragraph">Abbiamo eseguito la verifica con Confluent Platform 6.2 Tiered Storage in NetApp StorageGRID.  I team NetApp e Confluent hanno lavorato insieme a questa verifica ed eseguito i casi di test richiesti per la verifica.</block>
  <block id="ba5b5ff137c16b8859e6ac90b55d071c" category="section-title">Configurazione della piattaforma Confluent</block>
  <block id="d8802fa9749bdc5ddc844a1f86c9461d" category="paragraph">Per la verifica abbiamo utilizzato la seguente configurazione.</block>
  <block id="7b5948d7f6534813c3989b6697841566" category="paragraph">Per la verifica, abbiamo utilizzato tre guardiani dello zoo, cinque broker, cinque server di esecuzione di script di test, server di strumenti denominati con 256 GB di RAM e 16 CPU.  Per l'archiviazione NetApp , abbiamo utilizzato StorageGRID con un bilanciatore di carico SG1000 con quattro SGF6024.  Lo storage e i broker erano collegati tramite connessioni 100GbE.</block>
  <block id="e9f968cb8cc147519310d7290c28f99d" category="paragraph">La figura seguente mostra la topologia di rete della configurazione utilizzata per la verifica Confluent.</block>
  <block id="275745d9c13bf80b7275e6f8633d15e4" category="paragraph"><block ref="275745d9c13bf80b7275e6f8633d15e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8a85abadadde0e32bd269b5667b6226" category="paragraph">I server degli strumenti agiscono come client applicativi che inviano richieste ai nodi Confluent.</block>
  <block id="a0b3c1e592076debe73b163734ed8e2b" category="section-title">Configurazione di archiviazione a livelli confluenti</block>
  <block id="81082f7982ae1144f7662efde7446f1f" category="paragraph">La configurazione dell'archiviazione a livelli richiede i seguenti parametri in Kafka:</block>
  <block id="c78850251892556ff1c48a03b16cf1bf" category="paragraph">Per la verifica abbiamo utilizzato StorageGRID con il protocollo HTTP, ma funziona anche HTTPS.  La chiave di accesso e la chiave segreta sono memorizzate nel nome del file fornito nel<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> parametro.</block>
  <block id="4e19f24a6f1bb774911253be7f9d487f" category="section-title">Archiviazione di oggetti NetApp - StorageGRID</block>
  <block id="2d5dff5c754356b277b47604fee26e79" category="paragraph">Abbiamo configurato la configurazione a sito singolo in StorageGRID per la verifica.</block>
  <block id="dddbd2d03db81f9c6cb7d2dc1329df76" category="paragraph"><block ref="dddbd2d03db81f9c6cb7d2dc1329df76" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829026ce89cdb29d9f59599cb2244752" category="section-title">Test di verifica</block>
  <block id="f97246b7185276a5fe91aba0dd7311ae" category="paragraph">Per la verifica abbiamo completato i seguenti cinque casi di test.  Questi test vengono eseguiti sul framework Trogdor.  I primi due erano test di funzionalità, mentre i restanti tre erano test di prestazioni.</block>
  <block id="4c5791ce7d906a384ff35dab9f635d41" category="section-title">Test di correttezza dell'archivio oggetti</block>
  <block id="a0a36b11d315565a64a50eb2a0ed8c35" category="paragraph">Questo test determina se tutte le operazioni di base (ad esempio, get/put/delete) sull'API dell'archivio oggetti funzionano bene in base alle esigenze dell'archiviazione a livelli.  Si tratta di un test di base che ogni servizio di archiviazione di oggetti dovrebbe aspettarsi di superare prima dei test successivi.  È un test assertivo che può essere superato o fallito.</block>
  <block id="7cf5be835d50b9e5b598a4363e5a1310" category="section-title">Test di correttezza della funzionalità di tiering</block>
  <block id="afca9446d059f239c7c73699ec215b35" category="paragraph">Questo test determina se la funzionalità di archiviazione a livelli end-to-end funziona bene con un test assertivo che può avere esito positivo o negativo.  Il test crea un argomento di prova che per impostazione predefinita è configurato con il tiering abilitato e una dimensione dell'hotset molto ridotta.  Produce un flusso di eventi per l'argomento di test appena creato, attende che i broker archivino i segmenti nell'archivio oggetti, quindi consuma il flusso di eventi e convalida che il flusso consumato corrisponda al flusso prodotto.  Il numero di messaggi prodotti nel flusso di eventi è configurabile, il che consente all'utente di generare un carico di lavoro sufficientemente ampio in base alle esigenze di test.  La dimensione ridotta dell'hotset garantisce che i recuperi dei consumatori al di fuori del segmento attivo vengano serviti solo dall'archivio oggetti; ciò aiuta a verificare la correttezza dell'archivio oggetti per le letture.  Abbiamo eseguito questo test con e senza un'iniezione di errore nell'archivio oggetti.  Abbiamo simulato un guasto del nodo arrestando il servizio di gestione dei servizi in uno dei nodi in StorageGRID e verificando che la funzionalità end-to-end funzioni con l'archiviazione di oggetti.</block>
  <block id="88960bc44aa73a667c97d6168a27332a" category="section-title">Benchmark di recupero dei livelli</block>
  <block id="777c3235446f781652127bde532a7d6e" category="paragraph">Questo test ha convalidato le prestazioni di lettura dell'archiviazione di oggetti a livelli e ha controllato le richieste di lettura di recupero dell'intervallo sotto carico pesante dai segmenti generati dal benchmark.  In questo benchmark, Confluent ha sviluppato client personalizzati per soddisfare le richieste di recupero dei livelli.</block>
  <block id="07b15abc12bd3f43d57ebd95fce23917" category="section-title">Benchmark del carico di lavoro produzione-consumo</block>
  <block id="82ac7c284d524e3dba7699721633a674" category="paragraph">Questo test ha generato indirettamente un carico di lavoro di scrittura sull'archivio oggetti tramite l'archiviazione dei segmenti.  Il carico di lavoro di lettura (segmenti letti) è stato generato dall'archiviazione degli oggetti quando i gruppi di consumatori hanno recuperato i segmenti.  Questo carico di lavoro è stato generato dallo script di test.  Questo test ha verificato le prestazioni di lettura e scrittura sull'archiviazione di oggetti in thread paralleli.  Abbiamo eseguito i test con e senza l'inserimento di errori nell'archivio oggetti, come abbiamo fatto per il test di correttezza della funzionalità di tiering.</block>
  <block id="fc8cd6782366e38a4c0191fff79825b0" category="section-title">Benchmark del carico di lavoro di conservazione</block>
  <block id="c51c74edfaecd19ad2258d1dd18ba5d5" category="paragraph">Questo test ha verificato le prestazioni di eliminazione di un archivio oggetti in presenza di un carico di lavoro di conservazione degli argomenti elevato.  Il carico di lavoro di conservazione è stato generato utilizzando uno script di test che produce molti messaggi in parallelo a un argomento di test.  L'argomento del test era la configurazione con un'impostazione di conservazione aggressiva basata sulle dimensioni e sul tempo, che causava la continua eliminazione del flusso di eventi dall'archivio oggetti.  I segmenti vennero poi archiviati.  Ciò ha portato a un gran numero di eliminazioni nell'archivio oggetti da parte del broker e alla raccolta delle prestazioni delle operazioni di eliminazione dell'archivio oggetti.</block>
  <block id="996099c5b9fa96634feb727528db335e" category="list-text">Che cos'è Apache Kafka?</block>
  <block id="64512a184434b7e7734cf3c0a7283f2a" category="list-text">Cos'è la rinominazione sciocca?</block>
  <block id="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link"><block ref="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link-rx"></block></block>
  <block id="0bf644a00aca415462aeb30f96e502cf" category="paragraph"><block ref="0bf644a00aca415462aeb30f96e502cf" category="inline-link-rx"></block></block>
  <block id="4a15e598cdac14bbb90bb0e4020f4a79" category="list-text">ONATP è letto per le applicazioni di streaming.</block>
  <block id="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link"><block ref="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link-rx"></block></block>
  <block id="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="paragraph"><block ref="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="inline-link-rx"></block></block>
  <block id="02aed7d7f25878a636d26b696ed151bb" category="list-text">Documentazione del prodotto NetApp</block>
  <block id="e861ab8ac55c9110672ee8b4ba3c5990" category="list-text">Che cos'è NFS?</block>
  <block id="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link"><block ref="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link-rx"></block></block>
  <block id="6b6d6a7e1bfbb25506c4af7f443a7b25" category="paragraph"><block ref="6b6d6a7e1bfbb25506c4af7f443a7b25" category="inline-link-rx"></block></block>
  <block id="9fee8c35c177577e85d941aa2c9dedc4" category="list-text">Che cos'è la riassegnazione delle partizioni di Kafka?</block>
  <block id="2363cdcf0f5fc9a387ed87b925979747" category="inline-link"><block ref="2363cdcf0f5fc9a387ed87b925979747" category="inline-link-rx"></block></block>
  <block id="12b4d09f121a118c1b63eba5f3523fa2" category="paragraph"><block ref="12b4d09f121a118c1b63eba5f3523fa2" category="inline-link-rx"></block></block>
  <block id="f06a814ac7d838a2d019219102377120" category="list-text">Che cos'è l'OpenMessaging Benchmark?</block>
  <block id="9466397f90b4d13297982537f7f1f157" category="inline-link"><block ref="9466397f90b4d13297982537f7f1f157" category="inline-link-rx"></block></block>
  <block id="f42769fbe9abef93dd4da40d8f886c4a" category="paragraph"><block ref="f42769fbe9abef93dd4da40d8f886c4a" category="inline-link-rx"></block></block>
  <block id="bcc483eab76f7252a6d3060ae223f024" category="list-text">Come si migra un broker Kafka?</block>
  <block id="7702dea2646d94249d97c22a4dcb6f96" category="inline-link"><block ref="7702dea2646d94249d97c22a4dcb6f96" category="inline-link-rx"></block></block>
  <block id="ebdd7bc6eaa2157f5f400c61c1826417" category="paragraph"><block ref="ebdd7bc6eaa2157f5f400c61c1826417" category="inline-link-rx"></block></block>
  <block id="3f7e227a8b3d0fc0cdcbf84e2bc565ac" category="list-text">Come si monitora il broker Kafka con Prometheus?</block>
  <block id="2d2cb8fe8b8d32b7fb984622e41036f1" category="paragraph"><block ref="2d2cb8fe8b8d32b7fb984622e41036f1" category="inline-link-rx"></block></block>
  <block id="c8219112931de58f84e7a14a0d24d1ce" category="list-text">Piattaforma gestita per Apache Kafka</block>
  <block id="a96e98488edf9123c2fb5281e71c6ec2" category="paragraph"><block ref="a96e98488edf9123c2fb5281e71c6ec2" category="inline-link-rx"></block></block>
  <block id="0cb1f340d12ba20e283d00e1e0823526" category="list-text">Supporto per Apache Kafka</block>
  <block id="14bb5ca8b6287991417f8f43b4d9eb0c" category="paragraph"><block ref="14bb5ca8b6287991417f8f43b4d9eb0c" category="inline-link-rx"></block></block>
  <block id="9d5591555b2fbddd314212720dc97729" category="list-text">Servizi di consulenza per Apache Kafka</block>
  <block id="583ea5ea8c7ad81fed86a1925483124c" category="paragraph"><block ref="583ea5ea8c7ad81fed86a1925483124c" category="inline-link-rx"></block></block>
  <block id="bf06620c2cdf1b79a1673e62b409eae0" category="summary">La soluzione NetApp per il problema assurdo della ridenominazione fornisce una forma di archiviazione semplice, economica e gestita centralmente per carichi di lavoro che in precedenza erano incompatibili con NFS.</block>
  <block id="5fe141c77d102adcaccfa6da33564741" category="paragraph">Questo nuovo paradigma consente ai clienti di creare cluster Kafka più gestibili, più facili da migrare e da rispecchiare ai fini del disaster recovery e della protezione dei dati.  Abbiamo anche visto che NFS offre ulteriori vantaggi, come un utilizzo ridotto della CPU e tempi di ripristino più rapidi, un'efficienza di archiviazione notevolmente migliorata e prestazioni migliori tramite NetApp ONTAP.</block>
  <block id="34ea6423c17a78bdf284132538078bac" category="summary">In questo documento vengono descritti i seguenti argomenti: il problema della ridenominazione inutile e la convalida della soluzione, la riduzione dell'utilizzo della CPU per ridurre il tempo di attesa I/O, tempi di ripristino più rapidi del broker Kafka e prestazioni nel cloud e in locale.</block>
  <block id="47e33b895b285760d0d1bcb64e42e5d0" category="doc">TR-4947: Carico di lavoro Apache Kafka con storage NetApp NFS - Validazione funzionale e prestazioni</block>
  <block id="62233ad21bd81bbbff938616c0106477" category="paragraph">Shantanu Chakole, Karthikeyan Nagalingam e Joe Scott, NetApp</block>
  <block id="8150fcf9bdcb89b4901e10f34571667e" category="paragraph">Kafka è un sistema di messaggistica distribuito di tipo publish-subscribe con una coda robusta in grado di accettare grandi quantità di dati di messaggi.  Con Kafka, le applicazioni possono scrivere e leggere dati sugli argomenti in modo molto rapido.  Grazie alla sua tolleranza agli errori e alla sua scalabilità, Kafka viene spesso utilizzato nel settore dei big data come metodo affidabile per acquisire e spostare rapidamente numerosi flussi di dati.  I casi d'uso includono l'elaborazione di flussi, il monitoraggio delle attività del sito web, la raccolta e il monitoraggio delle metriche, l'aggregazione dei log, l'analisi in tempo reale e così via.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link">Qui</block>
  <block id="e1304dc2c6d37619b73112fae0bd8411" category="paragraph">Sebbene le normali operazioni Kafka su NFS funzionino bene, il problema assurdo della ridenominazione causa l'arresto anomalo dell'applicazione durante il ridimensionamento o il ripartizionamento di un cluster Kafka in esecuzione su NFS.  Si tratta di un problema significativo perché un cluster Kafka deve essere ridimensionato o ripartizionato per scopi di bilanciamento del carico o di manutenzione.  Puoi trovare ulteriori dettagli<block ref="eff8c14b44ddf611b2ff09607d7665a2" category="inline-link-rx"></block> .</block>
  <block id="229b214236b3c346dc9f6c75d096604b" category="paragraph">Il presente documento descrive i seguenti argomenti:</block>
  <block id="995fd45f2f5174bc9a5d8029655c1b88" category="list-text">Il problema della ridenominazione sciocca e la convalida della soluzione</block>
  <block id="7c9e8a4fdb767e60565e9c4b4d95eed2" category="list-text">Riduzione dell'utilizzo della CPU per ridurre il tempo di attesa I/O</block>
  <block id="915a1ce7d578786f5aa93e503452d2b9" category="list-text">Tempi di recupero più rapidi del broker Kafka</block>
  <block id="5810e3ce10e4e8edfee5f25cae3459c1" category="list-text">Prestazioni nel cloud e on-premise</block>
  <block id="7910f734d679965fb4e725f87dcb3c61" category="section-title">Perché utilizzare l'archiviazione NFS per i carichi di lavoro Kafka?</block>
  <block id="932e5edaa1f66c6b109d045d3c7ba0bc" category="paragraph">I carichi di lavoro Kafka nelle applicazioni di produzione possono trasmettere in streaming enormi quantità di dati tra le applicazioni.  Questi dati vengono conservati e archiviati nei nodi broker Kafka nel cluster Kafka.  Kafka è noto anche per la disponibilità e il parallelismo, che ottiene suddividendo gli argomenti in partizioni e replicando poi tali partizioni in tutto il cluster.  Ciò significa che l'enorme quantità di dati che fluisce attraverso un cluster Kafka viene generalmente moltiplicata in termini di dimensioni.  NFS rende il ribilanciamento dei dati molto rapido e semplice man mano che cambia il numero di broker.  Negli ambienti di grandi dimensioni, il ribilanciamento dei dati su DAS quando cambia il numero di broker richiede molto tempo e, nella maggior parte degli ambienti Kafka, il numero di broker cambia frequentemente.</block>
  <block id="a49afd0b2827b8f1d1b83a36f75d3efc" category="paragraph">Altri vantaggi includono quanto segue:</block>
  <block id="889d2761ec65245a621931da633b8cfe" category="list-text">*Scadenza.*  NFS è un protocollo maturo, il che significa che la maggior parte degli aspetti relativi alla sua implementazione, protezione e utilizzo sono ben compresi.</block>
  <block id="c231daeb716325a2bca62a5e30431c8d" category="list-text">*Aprire.*  NFS è un protocollo aperto e il suo continuo sviluppo è documentato nelle specifiche Internet come protocollo di rete libero e aperto.</block>
  <block id="6526aeb62806bf842c7ab66949c2de0c" category="list-text">*Economico.*  NFS è una soluzione economica per la condivisione di file in rete, facile da configurare perché utilizza l'infrastruttura di rete esistente.</block>
  <block id="8c70ad2ab84f33f7d462109fc8edc329" category="list-text">*Gestione centralizzata.*  La gestione centralizzata di NFS riduce la necessità di software e spazio su disco aggiuntivi sui sistemi dei singoli utenti.</block>
  <block id="dbb4f7d4eb0147816ffd5d84e4a79e19" category="list-text">*Distribuito.*  NFS può essere utilizzato come file system distribuito, riducendo la necessità di dispositivi di archiviazione su supporti rimovibili.</block>
  <block id="37377984e38462f1628867b8e7a1e772" category="section-title">Perché NetApp per i carichi di lavoro Kafka?</block>
  <block id="300fdb82e8f9a8b6ebb6d42a92483544" category="paragraph">L'implementazione NetApp NFS è considerata uno standard di riferimento per il protocollo e viene utilizzata in innumerevoli ambienti NAS aziendali. Oltre alla credibilità, NetApp offre anche i seguenti vantaggi:</block>
  <block id="f7e7d6aebe6163c0f639238b2e1a0333" category="list-text">Affidabilità ed efficienza</block>
  <block id="735980c2ea138788423c50ba2ef7c6c5" category="list-text">Scalabilità e prestazioni</block>
  <block id="a8fbd78750bfdd72ecb8371fa5fa9648" category="list-text">Alta disponibilità (partner HA in un cluster NetApp ONTAP )</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="list-text">Protezione dei dati</block>
  <block id="e005f1a13de2a01927e39ecb29ff1a7c" category="list-text">*Ripristino di emergenza (NetApp SnapMirror).*  Il tuo sito non funziona più oppure vuoi ripartire da un sito diverso e riprendere da dove eri rimasto.</block>
  <block id="81757222cee28779fe25327e8ef3f5a2" category="list-text">Gestibilità del sistema di storage (amministrazione e gestione tramite NetApp OnCommand).</block>
  <block id="7d411cbcfa7cf122ac8423795b89a4b8" category="list-text">*Bilanciamento del carico.*  Il cluster consente di accedere a volumi diversi da LIF di dati ospitati su nodi diversi.</block>
  <block id="6c38013b179499c32ccf05a98b927de6" category="list-text">*Operazioni non distruttive.*  Gli spostamenti LIF o di volume sono trasparenti per i client NFS.</block>
  <block id="d4baa2e552beefa00e93883ed51f3ba2" category="summary">In locale, abbiamo utilizzato il controller di storage NetApp AFF A900 con ONTAP 9.12.1RC1 per convalidare le prestazioni e la scalabilità di un cluster Kafka.  Abbiamo utilizzato lo stesso banco di prova delle nostre precedenti best practice di archiviazione a livelli con ONTAP e AFF.</block>
  <block id="1e753c720a0b773dd9d69024ca734577" category="doc">Panoramica e convalida delle prestazioni con AFF A900 in locale</block>
  <block id="94391d4f56386aadb6f39e1a596f2427" category="paragraph">In locale, abbiamo utilizzato il controller di storage NetApp AFF A900 con ONTAP 9.12.1RC1 per convalidare le prestazioni e la scalabilità di un cluster Kafka.  Abbiamo utilizzato lo stesso banco di prova delle nostre precedenti best practice di archiviazione a livelli con ONTAP e AFF.</block>
  <block id="b1e7584c9874b52caeb25c3646e8f273" category="paragraph">Abbiamo utilizzato Confluent Kafka 6.2.0 per valutare l' AFF A900.  Il cluster è composto da otto nodi broker e tre nodi zookeeper.  Per i test delle prestazioni abbiamo utilizzato cinque nodi worker OMB.</block>
  <block id="7d23a6a699d760fc27aa7ce39406c010" category="paragraph"><block ref="7d23a6a699d760fc27aa7ce39406c010" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="section-title">Configurazione di archiviazione</block>
  <block id="637d24b49cc32320a5e44ea905f65d10" category="paragraph">Abbiamo utilizzato istanze NetApp FlexGroups per fornire un singolo namespace per le directory di registro, semplificando il ripristino e la configurazione.  Abbiamo utilizzato NFSv4.1 e pNFS per fornire un accesso diretto al percorso dei dati del segmento di registro.</block>
  <block id="50ff5e789ae0742f2485b5147c072643" category="section-title">Ottimizzazione del cliente</block>
  <block id="fc3a7751877b7f4e9a71c82ad3da7e44" category="paragraph">Ogni client ha montato l'istanza FlexGroup con il seguente comando.</block>
  <block id="a5b2794b174e20f0b6dd9350cba3df82" category="paragraph">Inoltre, abbiamo aumentato il<block ref="44d907b0e69e5aa31320f9e86a7ef440" prefix=" " category="inline-code"></block> dal valore predefinito<block ref="ea5d2f1c4608232e07d3aa3d998e5135" prefix=" " category="inline-code"></block> A<block ref="045117b0e0a11a242b9765e79cbf113f" prefix=" " category="inline-code"></block> .  Corrisponde al limite predefinito dello slot di sessione in ONTAP.</block>
  <block id="31305973da10c7b492918a2ad2b3deee" category="section-title">Ottimizzazione del broker Kafka</block>
  <block id="4ed38f0369b8bb562a96594ca860ab81" category="paragraph">Per massimizzare la produttività nel sistema sottoposto a test, abbiamo aumentato significativamente i parametri predefiniti per alcuni pool di thread chiave.  Consigliamo di seguire le best practice di Confluent Kafka per la maggior parte delle configurazioni.  Questa ottimizzazione è stata utilizzata per massimizzare la concorrenza di I/O in sospeso sullo storage.  Questi parametri possono essere modificati in base alle risorse di calcolo e agli attributi di archiviazione del tuo broker.</block>
  <block id="0e80721091b1e58209e2877462ebbd21" category="section-title">Metodologia di test del generatore di carico di lavoro</block>
  <block id="9707ee58e22a2478985c56025e656cad" category="paragraph">Abbiamo utilizzato le stesse configurazioni OMB utilizzate per i test cloud per la configurazione del driver Throughput e dell'argomento.</block>
  <block id="dbdfae7d08a693255815e0890397b78f" category="list-text">Un'istanza FlexGroup è stata fornita tramite Ansible su un cluster AFF .</block>
  <block id="6c2577e00543c33096c33e1b2e79742d" category="list-text">pNFS è stato abilitato ONTAP SVM.</block>
  <block id="62313ead30e5ae09df5e2329bfe44784" category="list-text">Il carico di lavoro è stato attivato con il driver Throughput utilizzando la stessa configurazione del carico di lavoro di Cloud Volumes ONTAP.  Vedi la sezione "<block ref="f628eac6c1ff8c1b0462e81ea7b2efc1" category="inline-xref-macro-rx"></block> " sotto.  Il carico di lavoro utilizzava un fattore di replicazione pari a 3, il che significa che tre copie dei segmenti di registro venivano mantenute in NFS.</block>
  <block id="823002616491cde5a10847131e46b9a6" category="list-text">Infine, abbiamo completato le misurazioni utilizzando un backlog per misurare la capacità dei consumatori di tenersi aggiornati sui messaggi più recenti.  L'OMB crea un backlog mettendo in pausa i consumatori all'inizio di una misurazione.  Ciò produce tre fasi distinte: creazione del backlog (traffico riservato ai soli produttori), svuotamento del backlog (una fase in cui i consumatori recuperano gli eventi persi in un argomento) e stato stazionario. Vedi la sezione "<block ref="67d9096f7dc6dfc3943f178b4a30cff8" category="inline-xref-macro-rx"></block> " per maggiori informazioni.</block>
  <block id="158bb82f009332b2fe16aba7bebc0c15" category="section-title">Prestazioni in stato stazionario</block>
  <block id="216824b7a5a0da585075bc35333402f6" category="paragraph">Abbiamo valutato l' AFF A900 utilizzando OpenMessaging Benchmark per fornire un confronto simile a quello tra Cloud Volumes ONTAP in AWS e DAS in AWS.  Tutti i valori delle prestazioni rappresentano la produttività del cluster Kafka a livello di produttore e consumatore.</block>
  <block id="34121e3b81b5330bbb499603af5609e6" category="paragraph">Le prestazioni in stato stazionario con Confluent Kafka e AFF A900 hanno raggiunto una velocità di trasmissione media di oltre 3,4 GBps sia per il produttore che per i consumatori.  Si tratta di oltre 3,4 milioni di messaggi nel cluster Kafka.  Visualizzando la produttività sostenuta in byte al secondo per BrokerTopicMetrics, vediamo le eccellenti prestazioni in stato stazionario e il traffico supportato dall'AFF AFF A900.</block>
  <block id="c99b1e0f8a1447330448c8c7dc3df6b6" category="inline-image-macro">Questo grafico mostra la produttività della rete Broker.</block>
  <block id="7965f443cb0aaaa8c5c51bc5dec6bed3" category="paragraph"><block ref="7965f443cb0aaaa8c5c51bc5dec6bed3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9877d3e22635e0b37f0b74ab2d832d05" category="paragraph">Ciò si allinea bene con la visione dei messaggi inviati per argomento.  Il grafico seguente fornisce una ripartizione per argomento.  Nella configurazione testata abbiamo visto quasi 900.000 messaggi per argomento, suddivisi in quattro argomenti.</block>
  <block id="a6f05b2032cdce5554a9058f33e2d728" category="paragraph"><block ref="a6f05b2032cdce5554a9058f33e2d728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc35bf5a15bb7c42ab972c7038f773f5" category="section-title">Prestazioni estreme ed esplorazione dei limiti di archiviazione</block>
  <block id="58b4fe8d21ee892b9633349960eaa7ab" category="paragraph">Per AFF, abbiamo anche effettuato test con OMB utilizzando la funzionalità backlog.  La funzionalità di backlog sospende gli abbonamenti dei consumatori mentre viene creato un backlog di eventi nel cluster Kafka.  Durante questa fase si verifica solo il traffico del produttore, che genera eventi che vengono salvati nei log.  Questa emula più fedelmente i flussi di lavoro di elaborazione batch o di analisi offline; in questi flussi di lavoro, gli abbonamenti dei consumatori vengono avviati e devono leggere i dati storici che sono già stati rimossi dalla cache del broker.</block>
  <block id="2aeeb1b752e68f3fabc8026c34af1e23" category="paragraph">Per comprendere i limiti di archiviazione sulla capacità di elaborazione del consumatore in questa configurazione, abbiamo misurato la fase solo del produttore per capire quanto traffico di scrittura poteva assorbire l'A900.  Vedi la sezione successiva "<block ref="dbf93a9130703fe2432219c42c2bf311" category="inline-xref-macro-rx"></block> " per capire come sfruttare questi dati.</block>
  <block id="feec11a45c1fd079250c6f3603d708cd" category="paragraph">Durante la parte di questa misurazione riservata al solo produttore, abbiamo riscontrato un throughput di picco elevato che ha spinto al limite le prestazioni dell'A900 (quando le altre risorse del broker non erano sature e servivano il traffico del produttore e del consumatore).</block>
  <block id="bab88ff8b10be68a7d1ab6839852ce6b" category="paragraph"><block ref="bab88ff8b10be68a7d1ab6839852ce6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f237b36d09d10702066fb620cf352dcf" category="admonition">Abbiamo aumentato la dimensione del messaggio a 16k per questa misurazione, per limitare i sovraccarichi per messaggio e massimizzare la capacità di archiviazione sui punti di montaggio NFS.</block>
  <block id="9e1dbe9319ed19b15341f3000f56398a" category="paragraph">Il cluster Confluent Kafka ha raggiunto un throughput di produzione massimo di 4,03 GBps.</block>
  <block id="3355268f822f520fe03b272691c2e428" category="paragraph">Dopo che OMB ha completato il popolamento dell'eventbacklog, il traffico dei consumatori è stato riavviato.  Durante le misurazioni con drenaggio del backlog, abbiamo osservato un throughput di picco dei consumatori di oltre 20 GBps su tutti gli argomenti.  La velocità effettiva combinata del volume NFS che memorizzava i dati del registro OMB si avvicinava a circa 30 GBps.</block>
  <block id="157a25969caf77d231e319ce70f0b637" category="section-title">Guida alle taglie</block>
  <block id="2e4bacad236b9e36d868b929042e2bad" category="inline-link">guida alle taglie</block>
  <block id="eec877a6f9c2530996fae2423259c2c6" category="paragraph">Amazon Web Services offre un<block ref="e9ae0e8f89540055129f0fae422bdb9a" category="inline-link-rx"></block> per il dimensionamento e la scalabilità dei cluster Kafka.</block>
  <block id="cc4abcaa3ba3e4f795b82759d3dcd056" category="paragraph">Questo dimensionamento fornisce una formula utile per determinare i requisiti di capacità di archiviazione per il cluster Kafka:</block>
  <block id="f2fb73fb163775775c1145d28c68ad20" category="paragraph">Per una produttività aggregata prodotta nel cluster di tcluster con un fattore di replicazione di r, la produttività ricevuta dallo storage del broker è la seguente:</block>
  <block id="0acbbdd0cc159664d8baab43c6d168bd" category="paragraph">La cosa può essere ulteriormente semplificata:</block>
  <block id="28c949d6bdead032a1410c176cbf74cb" category="paragraph">Utilizzando questa formula è possibile selezionare la piattaforma ONTAP più adatta alle proprie esigenze di livello caldo Kafka.</block>
  <block id="df3f8ed04b35156def4360bb05a77cc1" category="paragraph">La tabella seguente illustra la produttività prevista del produttore per l'A900 con diversi fattori di replicazione:</block>
  <block id="329589e3ff014cb50ee2238aecc6a867" category="cell">Fattore di replicazione</block>
  <block id="75ec49708cc8881a7762e3740e342ca3" category="cell">Produzione del produttore (GPps)</block>
  <block id="c2b3050f7fde2050bb86e4e9ef0f7567" category="cell">3 (misurato)</block>
  <block id="31053ad0506e935470ca21b43cae98cf" category="cell">3,4</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="43ff194f410f3e93a8680bef5ba51e50" category="cell">5,1</block>
  <block id="a9d9d1b0257dda96d595bd00149cccdb" category="cell">10,2</block>
  <block id="bc0316be7ba1d2f8b53c282f09f9b532" category="summary">Un cluster Kafka con il livello di archiviazione montato su NetApp NFS è stato sottoposto a benchmark per le prestazioni nel cloud AWS.  Gli esempi di benchmarking sono descritti nelle sezioni seguenti.</block>
  <block id="bf57de8e029ea3108f102be3202cff5f" category="doc">Panoramica e convalida delle prestazioni in AWS FSx ONTAP</block>
  <block id="71db594c48140b244b2b54ff2bdedb71" category="paragraph">Un cluster Kafka con il livello di archiviazione montato su NetApp NFS è stato sottoposto a benchmark per le prestazioni in AWS FSx ONTAP.  Gli esempi di benchmarking sono descritti nelle sezioni seguenti.</block>
  <block id="1c036e91476215fff31a2c45fdf276f9" category="section-title">Apache Kafka in AWS FSx ONTAP</block>
  <block id="29144a8d530212e5210d98eceae62106" category="paragraph">Network File System (NFS) è un file system di rete ampiamente utilizzato per archiviare grandi quantità di dati.  Nella maggior parte delle organizzazioni i dati vengono sempre più generati da applicazioni di streaming come Apache Kafka.  Questi carichi di lavoro richiedono scalabilità, bassa latenza e un'architettura di acquisizione dati solida con moderne capacità di archiviazione.  Per consentire analisi in tempo reale e fornire informazioni fruibili, è necessaria un'infrastruttura ben progettata e altamente performante.</block>
  <block id="3c10ee4415fe854b95a1b3d124b0f0ea" category="paragraph">Kafka è progettato per funzionare con un file system compatibile con POSIX e si affida al file system per gestire le operazioni sui file, ma quando si archiviano dati su un file system NFSv3, il client NFS del broker Kafka può interpretare le operazioni sui file in modo diverso rispetto a un file system locale come XFS o Ext4.  Un esempio comune è la rinomina NFS Silly che causava il fallimento dei broker Kafka durante l'espansione dei cluster e la riallocazione delle partizioni.  Per affrontare questa sfida, NetApp ha aggiornato il client NFS Linux open source con modifiche ora generalmente disponibili in RHEL8.7, RHEL9.1 e supportate dall'attuale versione di FSx ONTAP , ONTAP 9.12.1.</block>
  <block id="2c69958ee453c213417e415ee57b1690" category="paragraph">Amazon FSx ONTAP fornisce un file system NFS completamente gestito, scalabile e ad alte prestazioni nel cloud.  I dati Kafka su FSx ONTAP possono essere scalati per gestire grandi quantità di dati e garantire la tolleranza agli errori.  NFS fornisce una gestione centralizzata dell'archiviazione e della protezione dei dati per set di dati critici e sensibili.</block>
  <block id="542c651fdfac42519bffb9b7ebf01539" category="paragraph">Questi miglioramenti consentono ai clienti AWS di sfruttare FSx ONTAP durante l'esecuzione di carichi di lavoro Kafka sui servizi di elaborazione AWS.  Questi vantaggi sono: * Riduzione dell'utilizzo della CPU per ridurre il tempo di attesa I/O * Tempo di ripristino più rapido del broker Kafka.  * Affidabilità ed efficienza.  * Scalabilità e prestazioni.  * Disponibilità di zone multi-disponibilità.  * Protezione dei dati.</block>
  <block id="cafd94f15e4ecd146a2af6ea620cc490" category="section-title">Kafka in AWS FSx ONTAP</block>
  <block id="7e3b8d1a53f4bf4f127be8ea0fda504d" category="paragraph">Un cluster Kafka con AWS FSx ONTAP è stato sottoposto a benchmark per le prestazioni nel cloud AWS.  Questo benchmarking è descritto nelle sezioni seguenti.</block>
  <block id="029bc8dc2b20f11a166635df18b0a419" category="section-title">Configurazione architettonica</block>
  <block id="6d14883a196c6b234f62d60a400fe708" category="paragraph">La tabella seguente mostra la configurazione ambientale per un cluster Kafka che utilizza AWS FSx ONTAP.</block>
  <block id="7a785978a6b38bb45ae8786c30a1781e" category="cell">Componente della piattaforma</block>
  <block id="c704d8c873b1a8d5d0243075656aa1f5" category="cell">Configurazione dell'ambiente</block>
  <block id="f874b8bfe50ce846d8156aabe96e5a34" category="cell">Kafka 3.2.3</block>
  <block id="e2322efe17a0927e7f855686b9597301" category="list-text">3 guardiani dello zoo – t2.small</block>
  <block id="ea55ea3b374458b5777457efaf0db679" category="list-text">3 server broker – i3en.2xlarge</block>
  <block id="d521f24278937c9ada520622e97168d8" category="list-text">1 x Grafana – c5n.2xlarge</block>
  <block id="747684069b5286f0282d40e544a04812" category="list-text">4 x produttore/consumatore -- c5n.2xlarge *</block>
  <block id="29c331c65dbb1c85faa29881b295fbfc" category="cell">Sistema operativo su tutti i nodi</block>
  <block id="a0d574b61a80df70bd921b269853cc18" category="cell">RHEL8.6</block>
  <block id="9e813193a6755822d3c1628326e814e6" category="cell">Multi-AZ con throughput di 4 GB/sec e 160.000 IOPS</block>
  <block id="8eb6827eb8f798501ab14f58155a9982" category="section-title">Configurazione NetApp FSx ONTAP</block>
  <block id="eb1e12842ba64aa1b662a4e95a406d45" category="list-text">Per i nostri test iniziali, abbiamo creato un file system FSx ONTAP con 2 TB di capacità e 40.000 IOPS per una velocità di elaborazione di 2 GB/sec.</block>
  <block id="7ce8d5b94f98d9eb7023e64b4f92f5fd" category="paragraph">Nel nostro esempio, stiamo distribuendo FSx ONTAP tramite AWS CLI.  Sarà necessario personalizzare ulteriormente il comando nel proprio ambiente, a seconda delle necessità.  FSx ONTAP può inoltre essere distribuito e gestito tramite la console AWS per un'esperienza di distribuzione più semplice e ottimizzata, con meno input dalla riga di comando.</block>
  <block id="81656db36243146de24c60a68b7b395c" category="paragraph">Documentazione In FSx ONTAP, il massimo IOPS raggiungibile per un file system con throughput di 2 GB/sec nella nostra regione di test (US-East-1) è di 80.000 IOPS.  Il numero massimo totale di IOPS per un file system FSx ONTAP è di 160.000 IOPS, il che richiede un throughput di 4 GB/sec per essere raggiunto, come verrà illustrato più avanti in questo documento.</block>
  <block id="3c50ca3005ca0da0071db25317a45f47" category="paragraph">Per ulteriori informazioni sulle specifiche delle prestazioni di FSx ONTAP , non esitate a consultare la documentazione di AWS FSx ONTAP qui:<block ref="f270bb91d9718c264ef59ceaf9562990" category="inline-link-rx"></block> .</block>
  <block id="ac3f15100beedf3665df00f75c6a126e" category="paragraph">La sintassi dettagliata della riga di comando per FSx "create-file-system" è disponibile qui:<block ref="6dfaa72a4db79e3cd69acb6bd09e3928" category="inline-link-rx"></block></block>
  <block id="4510c1fa7d54bc22137fc99fdee7ec14" category="paragraph">Ad esempio, è possibile specificare una chiave KMS specifica anziché la chiave master AWS FSx predefinita utilizzata quando non viene specificata alcuna chiave KMS.</block>
  <block id="b2d4bc4b14215051ed2eea3eff254d84" category="list-text">Durante la creazione del file system FSx ONTAP , attendi che lo stato "LifeCycle" cambi in "AVAILABLE" nel tuo ritorno JSON dopo aver descritto il tuo file system come segue:</block>
  <block id="fcd00639267fd24b3c25a30b3abcd5b0" category="list-text">Convalidare le credenziali effettuando l'accesso a FSx ONTAP SSH con l'utente fsxadmin: Fsxadmin è l'account amministratore predefinito per i file system FSx ONTAP al momento della creazione.  La password per fsxadmin è la password configurata durante la prima creazione del file system nella console AWS o tramite AWS CLI, come abbiamo fatto nel passaggio 1.</block>
  <block id="89fd702da938a0842ce8bbbd1978c407" category="list-text">Una volta convalidate le credenziali, creare la macchina virtuale di archiviazione sul file system FSx ONTAP</block>
  <block id="52140a6ade484065f20232f9d150ea61" category="paragraph">Una Storage Virtual Machine (SVM) è un file server isolato con credenziali amministrative e endpoint propri per l'amministrazione e l'accesso ai dati nei volumi FSx ONTAP e fornisce la multi-tenancy FSx ONTAP .</block>
  <block id="e05c7d2454cf3006c8871c25085ec858" category="list-text">Dopo aver configurato la macchina virtuale di archiviazione primaria, accedi tramite SSH al file system FSx ONTAP appena creato e crea volumi nella macchina virtuale di archiviazione utilizzando il comando di esempio seguente; allo stesso modo, creiamo 6 volumi per questa convalida.  In base alla nostra convalida, mantieni il costituente predefinito (8) o meno costituenti, il che fornirà prestazioni migliori a Kafka.</block>
  <block id="f82c8c9ef7e5f94bfc60abe80b30a2c1" category="list-text">Per i nostri test avremo bisogno di una capacità aggiuntiva nei nostri volumi.  Estendi le dimensioni del volume a 2 TB e montalo sul percorso di giunzione.</block>
  <block id="401223c85704727381abb64f33f1e700" category="paragraph">In FSx ONTAP, i volumi possono essere sottoposti a thin provisioning.  Nel nostro esempio, la capacità totale del volume esteso supera la capacità totale del file system, quindi dovremo estendere la capacità totale del file system per sbloccare ulteriore capacità del volume fornito, come illustreremo nel passaggio successivo.</block>
  <block id="980bf78b74033a80493ead9ead18533e" category="list-text">Successivamente, per prestazioni e capacità aggiuntive, estendiamo la capacità di throughput di FSx ONTAP da 2 GB/sec a 4 GB/sec e IOPS a 160000 e capacità a 5 TB</block>
  <block id="cfd6d8adc21dc264014c117cc1a95fda" category="paragraph">La sintassi dettagliata della riga di comando per FSx "update-file-system" è disponibile qui:<block ref="f3196344ef0cf3de8d956a0736aba68b" category="inline-link-rx"></block></block>
  <block id="d067a587144a5c3f420cd628e1e5e9ae" category="list-text">I volumi FSx ONTAP vengono montati con le opzioni nconnect e default nei broker Kafka</block>
  <block id="fe25ee0c1614b7db9e4a6cec9f2cd488" category="paragraph">L'immagine seguente mostra l'architettura finale del nostro cluster Kafka basato su FSx ONTAP :</block>
  <block id="a09d4eb20485c4e2d2f9ed81274d727a" category="inline-image-macro">Questa immagine mostra l'architettura di un cluster Kafka basato su FSx ONTAP.</block>
  <block id="f230dbbbd1d967f5675641bd1e9ff03e" category="paragraph"><block ref="f230dbbbd1d967f5675641bd1e9ff03e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a205c51d74e59d28030cda2886e41130" category="list-text">Calcolare.  Abbiamo utilizzato un cluster Kafka a tre nodi con un ensemble zookeeper a tre nodi in esecuzione su server dedicati.  Ogni broker aveva sei punti di montaggio NFS su sei volumi nell'istanza FSx ONTAP .</block>
  <block id="447931d0542671d1817df0b8bdc35ff4" category="list-text">Monitoraggio.  Abbiamo utilizzato due nodi per una combinazione Prometheus-Grafana.  Per generare i carichi di lavoro, abbiamo utilizzato un cluster separato a tre nodi in grado di produrre e consumare dati per questo cluster Kafka.</block>
  <block id="35f0ed4ee5bc59733f7cd41a36cf4721" category="list-text">Magazzinaggio.  Abbiamo utilizzato un FSx ONTAP con sei volumi da 2 TB montati.  Il volume è stato quindi esportato nel broker Kafka con un montaggio NFS. I volumi FSx ONTAP vengono montati con 16 sessioni nconnect e opzioni predefinite nei broker Kafka.</block>
  <block id="c06018aab55e4fa9ef871b34b2cf7897" category="section-title">Configurazioni di benchmarking di OpenMessage.</block>
  <block id="9300a7a969a31b3c5371c03474456ec3" category="paragraph">Abbiamo utilizzato la stessa configurazione utilizzata per NetApp Cloud Volumes ONTAP e i relativi dettagli sono disponibili qui: link:kafka-nfs-performance-overview-and-validation-in-aws.html#architectural-setup</block>
  <block id="91c26176df142d17ab999313541632c5" category="section-title">Metodologia di test</block>
  <block id="79f0e8e2c892a7ffb6c02f9be47fd6f5" category="list-text">Un cluster Kafka è stato predisposto secondo le specifiche descritte sopra utilizzando Terraform e Ansible.  Terraform viene utilizzato per creare l'infrastruttura utilizzando istanze AWS per il cluster Kafka, mentre Ansible crea il cluster Kafka su di esse.</block>
  <block id="d9a3b4ca51b8378374ab25c3f90ec2a2" category="list-text">Un carico di lavoro OMB è stato attivato con la configurazione del carico di lavoro descritta sopra e il driver Sync.</block>
  <block id="3f6a85702112dff5bcd0970b7ceb3f02" category="list-text">Un altro carico di lavoro è stato attivato con il driver Throughput con la stessa configurazione del carico di lavoro.</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">Osservazione</block>
  <block id="5f2da6c069f19294c52f39a18639f0d2" category="paragraph">Sono stati utilizzati due diversi tipi di driver per generare carichi di lavoro per confrontare le prestazioni di un'istanza Kafka in esecuzione su NFS.  La differenza tra i driver è la proprietà di svuotamento del registro.</block>
  <block id="6e3e5905f95f1d3670a864fd2b1e1855" category="paragraph">Per un fattore di replicazione Kafka 1 e FSx ONTAP:</block>
  <block id="477397883986e4a6ef0944db3f171a9a" category="list-text">Velocità di trasmissione totale generata in modo coerente dal driver Sync: ~ 3218 MBps e prestazioni di picco in ~ 3652 MBps.</block>
  <block id="526cf61e40ed54cf3e36bc48e608fe6a" category="list-text">Throughput totale generato in modo coerente dal driver Throughput: ~ 3679 MBps e prestazioni di picco in ~ 3908 MBps.</block>
  <block id="5c677e3834aab5345e650615a307b653" category="paragraph">Per Kafka con fattore di replicazione 3 e FSx ONTAP :</block>
  <block id="1d0957e5fc4340aeed631639b2076501" category="list-text">Velocità di trasmissione totale generata in modo coerente dal driver Sync: ~ 1252 MBps e prestazioni di picco in ~ 1382 MBps.</block>
  <block id="e18b6be6753e1c55e4474648e1073e75" category="list-text">Throughput totale generato in modo coerente dal driver Throughput: ~ 1218 MBps e prestazioni di picco in ~ 1328 MBps.</block>
  <block id="9e99c55380b9b536ec73cd9bdfbad865" category="paragraph">Nel fattore di replicazione Kafka 3, l'operazione di lettura e scrittura è avvenuta tre volte su FSx ONTAP. Nel fattore di replicazione Kafka 1, l'operazione di lettura e scrittura è avvenuta una volta su FSx ONTAP, quindi in entrambe le convalide siamo riusciti a raggiungere la velocità massima di 4 GB/sec.</block>
  <block id="4bb1ab47e2a029960970bd2e246f9a57" category="paragraph">Il driver Sync è in grado di generare un throughput costante poiché i log vengono scaricati sul disco all'istante, mentre il driver Throughput genera picchi di throughput poiché i log vengono salvati sul disco in blocco.</block>
  <block id="920a7d00fe9032493a9a70c1e6c8972a" category="paragraph">Questi numeri di throughput vengono generati per la configurazione AWS specificata.  Per requisiti di prestazioni più elevati, i tipi di istanza possono essere ampliati e ulteriormente ottimizzati per ottenere numeri di throughput migliori.  La produttività totale o tasso totale è la combinazione del tasso del produttore e del tasso del consumatore.</block>
  <block id="5d4902b750979a6daa75a334daf3b4dd" category="inline-image-macro">Questa immagine mostra le prestazioni di Kafka con RF1 e RF3</block>
  <block id="67731dd79a61f656bfde458fade09eb2" category="paragraph"><block ref="67731dd79a61f656bfde458fade09eb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3293059261e00d42aa4678d1677be1b1" category="paragraph">Il grafico sottostante mostra le prestazioni FSx ONTAP a 2 GB/sec e 4 GB/sec per il fattore di replicazione Kafka 3.  Il fattore di replicazione 3 esegue l'operazione di lettura e scrittura tre volte sullo storage FSx ONTAP .  La velocità totale per il driver di throughput è di 881 MB/sec, che esegue operazioni di lettura e scrittura Kafka a circa 2,64 GB/sec sul file system FSx ONTAP da 2 GB/sec, mentre la velocità totale per il driver di throughput è di 1328 MB/sec, che esegue operazioni di lettura e scrittura Kafka a circa 3,98 GB/sec.  Le prestazioni di Kafka sono lineari e scalabili in base alla velocità di elaborazione di FSx ONTAP .</block>
  <block id="a7ddac9765853f96e59270871b8a3925" category="inline-image-macro">Questa immagine mostra le prestazioni di scalabilità di 2 GB/sec e 4 GB/sec.</block>
  <block id="94043e4666620e8e09ceedcb705c7951" category="paragraph"><block ref="94043e4666620e8e09ceedcb705c7951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61f2d83a3758c796ac8892836cada117" category="paragraph">Il grafico sottostante mostra le prestazioni tra l'istanza EC2 e FSx ONTAP (fattore di replicazione Kafka: 3)</block>
  <block id="b891a78e120a481bc23346cb210b2fa2" category="inline-image-macro">Questa immagine mostra il confronto delle prestazioni di EC2 rispetto a FSx ONTAP in RF3.</block>
  <block id="59b617ab46ce09f11c02ed94c18645e4" category="paragraph"><block ref="59b617ab46ce09f11c02ed94c18645e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02b742a6a1f227191aecb81d8822d2ee" category="doc">Panoramica e convalida delle prestazioni in AWS</block>
  <block id="28e2dfa4242e2b504727dab8605d1432" category="section-title">Kafka nel cloud AWS con NetApp Cloud Volumes ONTAP (coppia ad alta disponibilità e nodo singolo)</block>
  <block id="1dc7a426b0cbf7d35c5edda73f68403d" category="paragraph">Un cluster Kafka con NetApp Cloud Volumes ONTAP (coppia HA) è stato sottoposto a benchmark per le prestazioni nel cloud AWS.  Questo benchmarking è descritto nelle sezioni seguenti.</block>
  <block id="61c964c4267b0fa60eeaa1a7ccdf706e" category="paragraph">La tabella seguente mostra la configurazione ambientale per un cluster Kafka che utilizza NAS.</block>
  <block id="4f04a8a7e04e79aafa7150a5ae2bab1b" category="cell">Istanza ONTAP di NetApp Cloud Volumes ONTAP</block>
  <block id="462fed98d4e5a4d1be4d08b1fdd3f0df" category="cell">Istanza di coppia HA – m5dn.12xLarge x 2 nodi Istanza di nodo singolo – m5dn.12xLarge x 1 nodo</block>
  <block id="29e8b4fdf26266c94b184b76858f935e" category="section-title">Configurazione ONTAP del volume del cluster NetApp</block>
  <block id="febbbf2a22b781c8cb2d828a8cbf52d6" category="list-text">Per la coppia Cloud Volumes ONTAP HA, abbiamo creato due aggregati con tre volumi su ciascun aggregato su ciascun controller di storage.  Per il singolo nodo Cloud Volumes ONTAP , creiamo sei volumi in un aggregato.</block>
  <block id="72bcc37cf8850d4e74a6305d71727956" category="inline-image-macro">Questa immagine illustra le proprietà di aggr3 e aggr22.</block>
  <block id="cc5972f21a1c1b3f25fd1c54ca580885" category="paragraph"><block ref="cc5972f21a1c1b3f25fd1c54ca580885" category="inline-image-macro-rx" type="image"></block></block>
  <block id="518fcf406a83698c4ba5d2f41cafab41" category="inline-image-macro">Questa immagine illustra le proprietà di aggr2.</block>
  <block id="7bf987d778dee1c98d1b0b2d5fb00a9c" category="paragraph"><block ref="7bf987d778dee1c98d1b0b2d5fb00a9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a6501fcefae41cda9ecf425cdc1ef15" category="list-text">Per ottenere migliori prestazioni di rete, abbiamo abilitato la rete ad alta velocità sia per la coppia HA che per il singolo nodo.</block>
  <block id="a4de9e1c332b656e2e19024cce28f939" category="inline-image-macro">Questa immagine mostra come abilitare la rete ad alta velocità.</block>
  <block id="49c32669e9d6be5a2b08ff5d8eb59127" category="paragraph"><block ref="49c32669e9d6be5a2b08ff5d8eb59127" category="inline-image-macro-rx" type="image"></block></block>
  <block id="678217b29dc6cbf917f08c79a1819f92" category="list-text">Abbiamo notato che la NVRAM ONTAP aveva più IOPS, quindi abbiamo modificato gli IOPS a 2350 per il volume root Cloud Volumes ONTAP .  Il disco del volume radice in Cloud Volumes ONTAP aveva una dimensione di 47 GB.  Il seguente comando ONTAP è per la coppia HA e lo stesso passaggio è applicabile al singolo nodo.</block>
  <block id="71ac6dbf3d671b6b9db5497aad37fc67" category="inline-image-macro">Questa immagine mostra come modificare le proprietà del volume.</block>
  <block id="044b1cecac787ba4da45dc749881f5a1" category="paragraph"><block ref="044b1cecac787ba4da45dc749881f5a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c2cacbcd5f4927358fee9d8a0b60252" category="paragraph">La figura seguente illustra l'architettura di un cluster Kafka basato su NAS.</block>
  <block id="a5f2ebf87b5aa37d2e02d041ede98e4f" category="list-text">*Calcolare.*  Abbiamo utilizzato un cluster Kafka a tre nodi con un ensemble zookeeper a tre nodi in esecuzione su server dedicati.  Ogni broker aveva due punti di montaggio NFS su un singolo volume sull'istanza Cloud Volumes ONTAP tramite un LIF dedicato.</block>
  <block id="493b3bd02a683f505d957bb27957e1b6" category="list-text">*Monitoraggio.*  Abbiamo utilizzato due nodi per una combinazione Prometheus-Grafana.  Per generare i carichi di lavoro, abbiamo utilizzato un cluster separato a tre nodi in grado di produrre e consumare dati per questo cluster Kafka.</block>
  <block id="dcb39d8372b01f5eb051372b3d943fbd" category="list-text">*Magazzinaggio.*  Abbiamo utilizzato un'istanza ONTAP di volumi Cloud HA-pair con un volume GP3 AWS-EBS da 6 TB montato sull'istanza.  Il volume è stato quindi esportato sul broker Kafka con un montaggio NFS.</block>
  <block id="78f0f1d311c4aae35de324851ecea08a" category="inline-image-macro">Questa figura illustra l'architettura di un cluster Kafka basato su NAS.</block>
  <block id="474d97e74219f2fc9511f3691ed0ae94" category="paragraph"><block ref="474d97e74219f2fc9511f3691ed0ae94" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cce0ad6ab772599285bd32c539025c1f" category="section-title">Configurazioni di benchmarking di OpenMessage</block>
  <block id="6a1fe63829e046313e1b3073459bf538" category="list-text">Per migliorare le prestazioni NFS, abbiamo bisogno di più connessioni di rete tra il server NFS e il client NFS, che possono essere create utilizzando nconnect.  Montare i volumi NFS sui nodi broker con l'opzione nconnect eseguendo il seguente comando:</block>
  <block id="a973eefced896f4a698ed64af6dc0199" category="list-text">Controllare le connessioni di rete in Cloud Volumes ONTAP.  Il seguente comando ONTAP viene utilizzato dal singolo nodo Cloud Volumes ONTAP .  Lo stesso passaggio è applicabile alla coppia Cloud Volumes ONTAP HA.</block>
  <block id="828ed34406e4dab30166070e0af1f142" category="list-text">Utilizziamo il seguente Kafka<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> in tutti i broker Kafka per la coppia Cloud Volumes ONTAP HA.  IL<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> La proprietà è diversa per ogni broker, mentre le restanti proprietà sono comuni a tutti i broker.  Per broker1, il<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> il valore è il seguente:</block>
  <block id="66ddebf2d4ab98ff8682a008dc466ce6" category="list-text">Per broker2, il<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> il valore della proprietà è il seguente:</block>
  <block id="fcfc381980a9ed554f51cbfd5b77616a" category="list-text">Per broker3, il<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> il valore della proprietà è il seguente:</block>
  <block id="00d57462d7009374713be86d6c491d89" category="list-text">Per il singolo nodo Cloud Volumes ONTAP , The Kafka<block ref="21d5034d4d99d6ca0da314367f1cccd6" prefix=" " category="inline-code"></block> è lo stesso della coppia Cloud Volumes ONTAP HA, ad eccezione di<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> proprietà.</block>
  <block id="cf168cce281f1eccdc9f9fb55c933d29" category="list-text">Per broker1, il<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> il valore è il seguente:</block>
  <block id="1692ac5191f19e15cf0e3a8af0820752" category="list-text">Per broker2, il<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> il valore è il seguente:</block>
  <block id="4b0728fa62359454465b3a26a608d83c" category="list-text">Il carico di lavoro nell'OMB è configurato con le seguenti proprietà:<block ref="9a97642a426510e31f49e0a98ed35e46" prefix=" " category="inline-code"></block> .</block>
  <block id="433b44cf3e6084d97e5162a06d481873" category="paragraph">IL<block ref="f21d26061df60c086aedb156e38f66b5" prefix=" " category="inline-code"></block> può variare a seconda del caso d'uso.  Nel nostro test delle prestazioni abbiamo utilizzato 3K.</block>
  <block id="bd9348653b0cfa7f0962b694fa058428" category="paragraph">Abbiamo utilizzato due driver diversi, Sync o Throughput, di OMB per generare il carico di lavoro sul cluster Kafka.</block>
  <block id="50e5861dab89d00bf88787e044b2c24f" category="list-text">Il file yaml utilizzato per le proprietà del driver di sincronizzazione è il seguente<block ref="46c2adf6b9dc6e5883c47b1d76feb008" prefix=" " category="inline-code"></block> :</block>
  <block id="9ae100f8fb1875133a485c355266af55" category="list-text">Il file yaml utilizzato per le proprietà del driver Throughput è il seguente<block ref="658e4b47fcd8812e9b0b2886af867717" prefix=" " category="inline-code"></block> :</block>
  <block id="a887b430cb278fa8f52827a223308324" category="list-text">Un cluster Kafka è stato predisposto secondo le specifiche descritte sopra utilizzando Terraform e Ansible.  Terraform viene utilizzato per creare l'infrastruttura utilizzando istanze AWS per il cluster Kafka, mentre Ansible crea il cluster Kafka su di esse.</block>
  <block id="59f70e2d523801f5ede7c9bb7b48cc76" category="paragraph">Per una coppia Cloud Volumes ONTAP HA:</block>
  <block id="ffb03fd768825b381d478b114716f8cf" category="list-text">Velocità totale generata in modo coerente dal driver Sync: ~1236 MBps.</block>
  <block id="84c96e7c92d1f10aac5f3600c7df9299" category="list-text">Throughput totale generato per il driver Throughput: picco ~1412 MBps.</block>
  <block id="5896e2cd1e01fb8ef69cdf280a9a38e3" category="paragraph">Per un singolo Cloud Volumes ONTAP :</block>
  <block id="d3c9dedf3eb9fce5e9a983948c3cef0e" category="list-text">Velocità totale generata in modo coerente dal driver Sync: ~ 1962 MBps.</block>
  <block id="86acf2bdaf8de60bbc77d3dc8f0e1b12" category="list-text">Throughput totale generato dal driver Throughput: picco ~1660MBps</block>
  <block id="c5616509b949bfcdee10d7e87918ec9d" category="inline-image-macro">Qui vengono presentati quattro grafici diversi.  Driver di throughput della coppia CVO-HA.  Driver di sincronizzazione coppia CVO-HA.  CVO - driver di throughput a nodo singolo.  Driver di sincronizzazione a nodo singolo CVO.</block>
  <block id="d2fc51602d60125ca82c279f8a8e03af" category="paragraph"><block ref="d2fc51602d60125ca82c279f8a8e03af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c6ad6fcb6db991d86273d33ed35d3c9" category="paragraph">Assicurarsi di controllare la velocità di archiviazione quando si esegue il benchmarking della velocità di elaborazione o del driver di sincronizzazione.</block>
  <block id="22156e4cc2df3388f0f9dfe0c178db37" category="inline-image-macro">Questo grafico mostra le prestazioni in termini di latenza, IOPS e throughput.</block>
  <block id="e34c5c483b0b104d0cc1453f3be5f6b4" category="paragraph"><block ref="e34c5c483b0b104d0cc1453f3be5f6b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc2e9a005ff6b9d50a1fca9914e8eac0" category="summary">In questa sezione viene descritto il problema della ridenominazione e le modifiche necessarie al server NFS e al client NFS per risolvere il problema.</block>
  <block id="0d5e61a5d0c056718a15d6df7037a50c" category="doc">Soluzione NetApp per un problema di rinomina stupido per carichi di lavoro da NFS a Kafka</block>
  <block id="e5ee0fc73f4f4f38e75acb2c0b2343be" category="paragraph">Kafka è stato sviluppato partendo dal presupposto che il file system sottostante sia compatibile con POSIX: ad esempio, XFS o Ext4.  Il ribilanciamento delle risorse di Kafka rimuove i file mentre l'applicazione li sta ancora utilizzando.  Un file system conforme a POSIX consente di procedere con l'annullamento del collegamento.  Tuttavia, rimuove il file solo dopo che tutti i riferimenti al file sono scomparsi.  Se il file system sottostante è collegato alla rete, il client NFS intercetta le chiamate di unlink e gestisce il flusso di lavoro.  Poiché ci sono aperture in sospeso sul file che viene scollegato, il client NFS invia una richiesta di rinomina al server NFS e, all'ultima chiusura del file scollegato, esegue un'operazione di rimozione sul file rinominato.  Questo comportamento è comunemente noto come NFS silly rename ed è orchestrato dal client NFS.</block>
  <block id="f17efbdff90d69935a8d84a6215665a5" category="paragraph">Qualsiasi broker Kafka che utilizzi l'archiviazione da un server NFSv3 riscontra problemi a causa di questo comportamento.  Tuttavia, il protocollo NFSv4.x dispone di funzionalità per risolvere questo problema consentendo al server di assumersi la responsabilità dei file aperti e non collegati.  I server NFS che supportano questa funzionalità opzionale comunicano la capacità di proprietà al client NFS al momento dell'apertura del file.  Il client NFS interrompe quindi la gestione dell'unlink quando ci sono aperture in sospeso e consente al server di gestire il flusso.  Sebbene la specifica NFSv4 fornisca linee guida per l'implementazione, fino ad ora non esistevano implementazioni di server NFS note che supportassero questa funzionalità opzionale.</block>
  <block id="219af746424bba4643138d0820ab40b5" category="paragraph">Per risolvere il problema assurdo della ridenominazione, sono necessarie le seguenti modifiche al server NFS e al client NFS:</block>
  <block id="36efd47a4ba95b58e3b2a0f2ed7420ad" category="list-text">*Modifiche al client NFS (Linux).*  Al momento dell'apertura del file, il server NFS risponde con un flag, indicando la capacità di gestire lo scollegamento dei file aperti.  Le modifiche apportate al lato client NFS consentono al server NFS di gestire la disconnessione in presenza del flag.  NetApp ha aggiornato il client NFS Linux open source con queste modifiche.  Il client NFS aggiornato è ora generalmente disponibile in RHEL8.7 e RHEL9.1.</block>
  <block id="f400588f268c9f90112ff6290a81575a" category="list-text">*Modifiche al server NFS.*  Il server NFS tiene traccia delle aperture.  La disconnessione di un file aperto esistente è ora gestita dal server in modo da corrispondere alla semantica POSIX.  Quando l'ultimo file aperto viene chiuso, il server NFS avvia la rimozione effettiva del file, evitando così il noioso processo di rinomina.  Il server NFS ONTAP ha implementato questa funzionalità nella sua ultima versione, ONTAP 9.12.1.</block>
  <block id="21a87b96dd7bfc9863d6bca5fc12f005" category="paragraph">Grazie alle modifiche sopra descritte al client e al server NFS, Kafka può sfruttare in tutta sicurezza tutti i vantaggi dell'archiviazione NFS collegata alla rete.</block>
  <block id="8a1762b0db0285b0ca6661669e3a9aec" category="summary">Per la convalida funzionale, abbiamo dimostrato che un cluster Kafka con un mount NFSv3 per l'archiviazione non riesce a eseguire operazioni Kafka come la ridistribuzione delle partizioni, mentre un altro cluster montato su NFSv4 con la correzione può eseguire le stesse operazioni senza interruzioni.</block>
  <block id="2b1635c7ae2a72d0b26454157a03e197" category="doc">Validazione funzionale - Correzione stupida del cambio di nome</block>
  <block id="a8ead7a6a54d47ea0a38e64908ab321f" category="section-title">Impostazione di convalida</block>
  <block id="e087dbbdc5792f1e574cdf41c135d858" category="paragraph">L'installazione viene eseguita su AWS.  Nella tabella seguente sono riportati i diversi componenti della piattaforma e la configurazione ambientale utilizzati per la convalida.</block>
  <block id="cccdd75af54f32ac7f570bbcca39f516" category="cell">Piattaforma Confluent versione 7.2.1</block>
  <block id="185b9d1a84206af090c5f70ac68f24ad" category="list-text">3 guardiani dello zoo – t3.xlarge</block>
  <block id="6677060ff0c6c4620e427121a576713c" category="list-text">4 x server broker – r3.xlarge</block>
  <block id="61e62294effd3d2046982e7d5a22b824" category="list-text">1 x Grafana – t3.xlarge</block>
  <block id="1e2657a43dca2051e4684eb73c2a856c" category="list-text">1 x centro di controllo – t3.xlarge</block>
  <block id="2dcca349e332f9e312cebc29485dadf0" category="list-text">3 x Produttore/consumatore</block>
  <block id="00ecb59dfdd1b1378b38c6b7bf8e91dc" category="cell">RHEL8.7 o successivo</block>
  <block id="d09d15c71c68b596f76c57a87a19e0e5" category="cell">Istanza a nodo singolo – M5.2xLarge</block>
  <block id="3ba4ec8d167c12be652d6829ce6e51d8" category="paragraph">La figura seguente mostra la configurazione architettonica di questa soluzione.</block>
  <block id="b3c6c8984f5671892932b2a7eacc5bf4" category="inline-image-macro">Questa immagine mostra la topologia AWS contenente una VPC contenente tre subnet private con rispettivamente uno sciame di produttori, il cluster Kafka e un'istanza CVO.</block>
  <block id="2046377162498de9fec810aafa41c2b3" category="paragraph"><block ref="2046377162498de9fec810aafa41c2b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d580bb4c55b441a712ec6c9dc12d38b" category="section-title">Flusso architettonico</block>
  <block id="82c8c0c94e152cc00496c6c5a1fa76b0" category="list-text">*Calcolare.*  Abbiamo utilizzato un cluster Kafka a quattro nodi con un ensemble zookeeper a tre nodi in esecuzione su server dedicati.</block>
  <block id="e236bd14d5d59a952978645a606dd7f9" category="list-text">*Monitoraggio.*  Abbiamo utilizzato due nodi per una combinazione Prometheus-Grafana.</block>
  <block id="c375f003dbf6b1accc45fd3811ce2b82" category="list-text">*Carico di lavoro.*  Per generare carichi di lavoro, abbiamo utilizzato un cluster separato a tre nodi in grado di produrre e consumare da questo cluster Kafka.</block>
  <block id="ada284cbb65ff7bad5814ecb0c6ecb2f" category="list-text">*Magazzinaggio.*  Abbiamo utilizzato un'istanza ONTAP NetApp Cloud Volumes a nodo singolo con due volumi GP2 AWS-EBS da 500 GB collegati all'istanza.  Questi volumi sono stati quindi esposti al cluster Kafka come singoli volumi NFSv4.1 tramite un LIF.</block>
  <block id="e86dc7584f98dc172fd46661ef8b935a" category="paragraph">Per tutti i server sono state scelte le proprietà predefinite di Kafka.  Lo stesso è stato fatto per lo sciame dei guardiani dello zoo.</block>
  <block id="c31fea06105fe5260bb879284c6181e0" category="list-text">Aggiornamento<block ref="9733772c7c0780d4ef7a6a8d6a9dbd7d" prefix=" " category="inline-code"></block> al volume di Kafka, come segue:</block>
  <block id="5ca41832794ba1f8118f718465d6ffe4" category="list-text">Sono stati creati due cluster Kafka simili con la seguente differenza:</block>
  <block id="fc1a46a26a283c18443e516b58cb0a58" category="list-text">*Gruppo 1.*  Il server backend NFS v4.1 che esegue ONTAP versione 9.12.1 pronto per la produzione era ospitato da un'istanza NetApp CVO.  Sui broker sono stati installati RHEL 8.7/RHEL 9.1.</block>
  <block id="183a9a6c4f97a876554696844cf5cd19" category="list-text">*Gruppo 2.*  Il server NFS backend era un server Linux NFSv3 generico creato manualmente.</block>
  <block id="8dac413f2b3b7fdfc73d642ae6e79a33" category="list-text">È stato creato un argomento dimostrativo su entrambi i cluster Kafka.</block>
  <block id="dc30a10b7f3dac3bcce7b54e12502e89" category="paragraph">Gruppo 1:</block>
  <block id="0cdb385ae4a7f7449cf10919962c71c8" category="inline-image-macro">Questa schermata mostra l'argomento demo creato sul Cluster 1.</block>
  <block id="23e2fb3a3a7caf11826a6ddc3650812b" category="paragraph"><block ref="23e2fb3a3a7caf11826a6ddc3650812b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83655cf6beab33b344c9ae17bec532d0" category="paragraph">Gruppo 2:</block>
  <block id="772ab3218dd37dea5c304575fe358498" category="inline-image-macro">Questa schermata mostra l'argomento demo creato sul Cluster 2.</block>
  <block id="2d82e26036412c43987356c7c8ca8fb3" category="paragraph"><block ref="2d82e26036412c43987356c7c8ca8fb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb392c27040a7eb25cfeb1d96323917e" category="list-text">I dati sono stati caricati in questi argomenti appena creati per entrambi i cluster.  Ciò è stato fatto utilizzando il toolkit producer-perf-test incluso nel pacchetto Kafka predefinito:</block>
  <block id="bd5bb4c79c0fd5aea6e14277bbd9c5fe" category="list-text">È stato eseguito un controllo dello stato di salute per broker-1 per ciascuno dei cluster utilizzando telnet:</block>
  <block id="ec97e8f78ae99ff145018ede90a47c77" category="list-text">telnet<block ref="da440d4c50d5bbb0ffa4021d6db8332c" prefix=" " category="inline-code"></block></block>
  <block id="a93dad1338160e3b828529ad6a585d13" category="list-text">telnet<block ref="2a3da46f5894b7e15be0ea3be46975cc" prefix=" " category="inline-code"></block></block>
  <block id="a7892fb38856d45eb1f6cd89d3118830" category="paragraph">Nella schermata successiva viene mostrato un controllo dello stato di salute riuscito per i broker su entrambi i cluster:</block>
  <block id="855ba5b1fb4b822400c8e412d08df6e4" category="inline-image-macro">Questa schermata mostra la lettura di un controllo di integrità riuscito su entrambi i broker.</block>
  <block id="abe3c89cfc6f09b3a5f31df9bcf7ac04" category="paragraph"><block ref="abe3c89cfc6f09b3a5f31df9bcf7ac04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a63ad47b1692dcaccf39fb2a5c42e393" category="list-text">Per innescare la condizione di errore che causa l'arresto anomalo dei cluster Kafka che utilizzano volumi di archiviazione NFSv3, abbiamo avviato il processo di riassegnazione delle partizioni su entrambi i cluster.  La riassegnazione della partizione è stata eseguita utilizzando<block ref="5cbd65bd2e4824bbb4876b792e513e10" prefix=" " category="inline-code"></block> .  Il processo dettagliato è il seguente:</block>
  <block id="9ea6b7d5de4fbe3c468699ad3c8bb6ef" category="list-text">Per riassegnare le partizioni per un argomento in un cluster Kafka, abbiamo generato la configurazione di riassegnazione proposta in formato JSON (questa operazione è stata eseguita per entrambi i cluster).</block>
  <block id="c4c8306a70b22c96715a3f79fe60eca9" category="list-text">Il JSON di riassegnazione generato è stato quindi salvato in<block ref="d773b1c180323b61e54dc5acaa6fb66f" prefix=" " category="inline-code"></block> .</block>
  <block id="05e65fb821eccc3b4cb26cc7285d75f8" category="list-text">Il processo di riassegnazione della partizione effettiva è stato attivato dal seguente comando:</block>
  <block id="83c299e30316ef5659e9b3bbd34b40ad" category="list-text">Dopo alcuni minuti, una volta completata la riassegnazione, un altro controllo dello stato di salute dei broker ha mostrato che il cluster che utilizzava volumi di storage NFSv3 aveva riscontrato un problema di ridenominazione e si era bloccato, mentre il Cluster 1 che utilizzava volumi di storage NetApp ONTAP NFSv4.1 con la correzione ha continuato a funzionare senza interruzioni.</block>
  <block id="197bc98012d3a74f45e086c86b7237bc" category="inline-image-macro">Questa schermata mostra l'output di un broker in crash.</block>
  <block id="3a51f6a0340d9026c9fc6619a6584b83" category="paragraph"><block ref="3a51f6a0340d9026c9fc6619a6584b83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7796cd6b11de5af34093097d2db9b94f" category="list-text">Cluster1-Broker-1 è attivo.</block>
  <block id="fef78f6445fec5a3c0d0cb2008e6c34e" category="list-text">Cluster2-broker-1 è morto.</block>
  <block id="e413a6c934b14b11c478c905d8c0489b" category="list-text">Dopo aver controllato le directory del registro di Kafka, è risultato chiaro che il Cluster 1 che utilizzava volumi di storage NetApp ONTAP NFSv4.1 con la correzione aveva un'assegnazione di partizioni pulita, mentre il Cluster 2 che utilizzava storage NFSv3 generico non aveva un'assegnazione di partizioni pulita a causa di stupidi problemi di ridenominazione, che hanno causato l'arresto anomalo.  L'immagine seguente mostra il ribilanciamento delle partizioni del Cluster 2, che ha causato un problema di ridenominazione nello storage NFSv3.</block>
  <block id="1c2cca9f5ca8cce4b11ebdc970e4a78c" category="inline-image-macro">Questa schermata mostra l'output del registro per l'arresto anomalo del Cluster 2.</block>
  <block id="587e107619187efb07b3bd05f8bcf7f9" category="paragraph"><block ref="587e107619187efb07b3bd05f8bcf7f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43fea21bb45bdea6ebc007efbf3c0053" category="paragraph">L'immagine seguente mostra un ribilanciamento pulito della partizione del Cluster 1 utilizzando lo storage NetApp NFSv4.1.</block>
  <block id="1ac73d9186e013f2157d22422bc044ff" category="inline-image-macro">Questa schermata mostra l'output del registro per un'assegnazione di partizione pulita riuscita per il Cluster 1 mentre</block>
  <block id="f3d0f09c5b4a3c2f532881572a744b6c" category="paragraph"><block ref="f3d0f09c5b4a3c2f532881572a744b6c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8eac57fa6403d9c896c24cb94767e954" category="summary">Ora che esiste una soluzione per il problema di ridenominazione nello storage NFS con Kafka, puoi creare distribuzioni robuste che sfruttano lo storage NetApp ONTAP per il tuo carico di lavoro Kafka.  Ciò non solo riduce significativamente i costi operativi, ma apporta anche i seguenti vantaggi ai cluster Kafka.</block>
  <block id="76827cff700415303c6b7420a1869192" category="doc">Perché NetApp NFS per i carichi di lavoro Kafka?</block>
  <block id="984b2b530f32710e640393a80677e426" category="paragraph">Ora che esiste una soluzione per il problema di ridenominazione nello storage NFS con Kafka, puoi creare distribuzioni robuste che sfruttano lo storage NetApp ONTAP per il tuo carico di lavoro Kafka.  Ciò non solo riduce significativamente i costi operativi, ma apporta anche i seguenti vantaggi ai cluster Kafka:</block>
  <block id="2dbec01439aed1c5b5fbe8a521623f2d" category="list-text">*Utilizzo ridotto della CPU sui broker Kafka.*  L'utilizzo di storage NetApp ONTAP disaggregato separa le operazioni di I/O del disco dal broker, riducendo così l'ingombro della CPU.</block>
  <block id="24c6011da569f3cc3fede5c4eafff91e" category="list-text">*Tempi di recupero del broker più rapidi.*  Poiché lo storage disaggregato NetApp ONTAP è condiviso tra i nodi broker Kafka, una nuova istanza di elaborazione può sostituire un broker non funzionante in qualsiasi momento e in una frazione del tempo rispetto alle distribuzioni Kafka convenzionali, senza dover ricostruire i dati.</block>
  <block id="04615fed33ad7a5a209c685460f2c557" category="list-text">*Efficienza di archiviazione.* Poiché il livello di storage dell'applicazione è ora fornito tramite NetApp ONTAP, i clienti possono usufruire di tutti i vantaggi dell'efficienza di storage offerti da ONTAP, come la compressione dei dati in linea, la deduplicazione e la compattazione.</block>
  <block id="c7444ea1ca211e0d3dd1b89c4f792d00" category="paragraph">Questi vantaggi sono stati testati e convalidati in casi di prova che analizzeremo in dettaglio in questa sezione.</block>
  <block id="454cd026e1a6a7761ee25bf6682aeb2b" category="section-title">Utilizzo ridotto della CPU sul broker Kafka</block>
  <block id="70c59ac3ed6ee89fe977676b2dba2f05" category="paragraph">Abbiamo scoperto che l'utilizzo complessivo della CPU è inferiore rispetto alla controparte DAS quando abbiamo eseguito carichi di lavoro simili su due cluster Kafka separati, identici nelle specifiche tecniche ma diversi nelle tecnologie di archiviazione.  Non solo l'utilizzo complessivo della CPU è inferiore quando il cluster Kafka utilizza l'archiviazione ONTAP , ma l'aumento dell'utilizzo della CPU ha mostrato un gradiente più graduale rispetto a un cluster Kafka basato su DAS.</block>
  <block id="c9d177e7e6018d464567bf6a8f9773e7" category="paragraph">La tabella seguente mostra la configurazione ambientale utilizzata per dimostrare un utilizzo ridotto della CPU.</block>
  <block id="5ed4a4dbe122b39d7103642bff11de54" category="cell">Strumento di benchmarking di Kafka 3.2.3: OpenMessaging</block>
  <block id="3cb61b8b67329a8a20d9128458cf6633" category="list-text">4 x Produttore/Consumatore -- c5n.2xlarge</block>
  <block id="d34010cfee0f2a6d774e450acd135088" category="cell">RHEL 8.7 o successivo</block>
  <block id="bce5fbe7fa89f635a887c6af2f95a9be" category="cell">Istanza a nodo singolo – M5.2xLarge</block>
  <block id="a27bb92a9fdd5b8b4c084b824b810232" category="section-title">Strumento di benchmarking</block>
  <block id="d483516be45a355eab4c7f9b129540c9" category="inline-link">OpenMessaging</block>
  <block id="0a48e066bcee681066419fb01ccd9f16" category="paragraph">Lo strumento di benchmarking utilizzato in questo caso di prova è il<block ref="3990ab384d3299fd4c655b02444eb5d6" category="inline-link-rx"></block> struttura.  OpenMessaging è indipendente dal fornitore e dal linguaggio; fornisce linee guida di settore per finanza, e-commerce, IoT e big data e aiuta a sviluppare applicazioni di messaggistica e streaming su sistemi e piattaforme eterogenei.  La figura seguente illustra l'interazione dei client OpenMessaging con un cluster Kafka.</block>
  <block id="ac6d62ee86368b8c24366434f9b5d5a1" category="inline-image-macro">Questa immagine illustra l'interazione dei client OpenMessaging con un cluster Kafka.</block>
  <block id="9cb3e560e852dc92918678c092a4105e" category="paragraph"><block ref="9cb3e560e852dc92918678c092a4105e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6250495e61aa2eb3c47f71d21f58c6f8" category="list-text">*Calcolare.*  Abbiamo utilizzato un cluster Kafka a tre nodi con un ensemble zookeeper a tre nodi in esecuzione su server dedicati.  Ogni broker aveva due punti di montaggio NFSv4.1 su un singolo volume sull'istanza NetApp CVO tramite un LIF dedicato.</block>
  <block id="f91ee5c5359f2260d72c50f2c8009925" category="list-text">*Monitoraggio.*  Abbiamo utilizzato due nodi per una combinazione Prometheus-Grafana.  Per generare carichi di lavoro, disponiamo di un cluster separato a tre nodi che può produrre e consumare da questo cluster Kafka.</block>
  <block id="e2b1493c4214be739b2c9349a2c481ef" category="list-text">*Magazzinaggio.*  Abbiamo utilizzato un'istanza ONTAP NetApp Cloud Volumes a nodo singolo con sei volumi GP2 AWS-EBS da 250 GB montati sull'istanza.  Questi volumi sono stati quindi esposti al cluster Kafka come sei volumi NFSv4.1 tramite LIF dedicati.</block>
  <block id="ede634748bd4515e69245593cfc4478c" category="list-text">*Configurazione.*  I due elementi configurabili in questo caso di test erano i broker Kafka e i carichi di lavoro OpenMessaging.</block>
  <block id="b053d1656e3b9dcaa2b4834fbdc4fb86" category="list-text">*Configurazione del broker.*  Per i broker Kafka sono state selezionate le seguenti specifiche.  Abbiamo utilizzato un fattore di replicazione pari a 3 per tutte le misurazioni, come evidenziato di seguito.</block>
  <block id="d5ee20b40da2061d10bff33a6f13467a" category="inline-image-macro">Questa immagine illustra le specifiche selezionate per i broker Kafka.</block>
  <block id="41b835894ba02ffb1ba3f3fdae71877c" category="paragraph"><block ref="41b835894ba02ffb1ba3f3fdae71877c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82f54619faeaa86063f362102c160601" category="list-text">*Configurazione del carico di lavoro del benchmark OpenMessaging (OMB).*  Sono state fornite le seguenti specifiche.  Abbiamo specificato un tasso di produzione target, evidenziato di seguito.</block>
  <block id="da43f96a4bfe17af8039df6b15f4f6da" category="inline-image-macro">Questa immagine illustra le specifiche selezionate per la configurazione del carico di lavoro del benchmark OpenMessaging.</block>
  <block id="41106ec7ad546fdd6a08b370c8093ab9" category="paragraph"><block ref="41106ec7ad546fdd6a08b370c8093ab9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6067cc387407f4d8dc9d623c770cfd" category="list-text">Sono stati creati due cluster simili, ciascuno con il proprio set di swarm di cluster di benchmarking.</block>
  <block id="c85bb905404dda665035e21b11ab1a58" category="list-text">*Gruppo 1.*  Cluster Kafka basato su NFS.</block>
  <block id="9ed0b3eccef17299a0119b0f28568e78" category="list-text">*Gruppo 2.*  Cluster Kafka basato su DAS.</block>
  <block id="a38c46362b3feb9b3bb5f53b1957d50f" category="list-text">Utilizzando un comando OpenMessaging, sono stati attivati carichi di lavoro simili su ciascun cluster.</block>
  <block id="c18ed3feb8720fe4fc76d90a9fa6a6e3" category="list-text">La configurazione della velocità di produzione è stata aumentata in quattro iterazioni e l'utilizzo della CPU è stato registrato con Grafana.  Il tasso di produzione è stato fissato ai seguenti livelli:</block>
  <block id="04207e7bb62b9b5d14bdb603f74e683c" category="list-text">10.000</block>
  <block id="e19784a5420512b2876c7b24680652b5" category="list-text">40.000</block>
  <block id="e57650a6c15f273334d41da58fa72111" category="list-text">80.000</block>
  <block id="ee70718f6a92d6c1b099a6942f594963" category="list-text">100.000</block>
  <block id="524fdb84d137ea63c19f5efab343f82b" category="paragraph">L'utilizzo dello storage NFS NetApp con Kafka offre due vantaggi principali:</block>
  <block id="612e27ad9fd383437f1445cf80d554b1" category="list-text">*È possibile ridurre l'utilizzo della CPU di quasi un terzo.*  L'utilizzo complessivo della CPU con carichi di lavoro simili è risultato inferiore per NFS rispetto agli SSD DAS; i risparmi vanno dal 5% per tassi di produzione inferiori al 32% per tassi di produzione superiori.</block>
  <block id="bc31b9852409e970a3a4659fef4b4f93" category="list-text">*Una riduzione tripla dell'utilizzo della CPU a velocità di produzione più elevate.*  Come previsto, si è registrato un aumento dell'utilizzo della CPU con l'aumento dei tassi di produzione.  Tuttavia, l'utilizzo della CPU sui broker Kafka che utilizzano DAS è aumentato dal 31% per il tasso di produzione più basso al 70% per il tasso di produzione più alto, con un incremento del 39%.  Tuttavia, con un backend di archiviazione NFS, l'utilizzo della CPU è aumentato dal 26% al 38%, con un incremento del 12%.</block>
  <block id="6299b9c8f7a14a0a0ca7407cbb9a187a" category="inline-image-macro">Questo grafico illustra il comportamento di un cluster basato su DAS.</block>
  <block id="9630ee6aa29406a977bc5179849d2639" category="paragraph"><block ref="9630ee6aa29406a977bc5179849d2639" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60e393621d29424b529201d4bc48e3b4" category="inline-image-macro">Questo grafico illustra il comportamento di un cluster basato su NFS.</block>
  <block id="74336896d4b61e55ed364028f046f35b" category="paragraph"><block ref="74336896d4b61e55ed364028f046f35b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03d4293a3bcf73010216e2f0399fd571" category="paragraph">Inoltre, a 100.000 messaggi, DAS mostra un utilizzo della CPU maggiore rispetto a un cluster NFS.</block>
  <block id="a0e6052c526d2d343fa217b609c943a6" category="inline-image-macro">Questo grafico illustra il comportamento di un cluster basato su DAS con 100.000 messaggi.</block>
  <block id="73c360518d32a693e133ab63604b2ab4" category="paragraph"><block ref="73c360518d32a693e133ab63604b2ab4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9d76c4aeb68cf4d7ef9bf3ce121bdd2" category="inline-image-macro">Questo grafico illustra il comportamento di un cluster basato su NFS con 100.000 messaggi.</block>
  <block id="be31c668debc31c9573036c63b1b4f49" category="paragraph"><block ref="be31c668debc31c9573036c63b1b4f49" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60a5caa55d79e52e0af298cf19b5c73d" category="section-title">Recupero più rapido del broker</block>
  <block id="bc0ed21388f4042414a88362de068e14" category="paragraph">Abbiamo scoperto che i broker Kafka ripristinano più velocemente quando utilizzano lo storage NetApp NFS condiviso.  Quando un broker si blocca in un cluster Kafka, può essere sostituito da un broker funzionante con lo stesso ID broker.  Dopo aver eseguito questo caso di test, abbiamo scoperto che, nel caso di un cluster Kafka basato su DAS, il cluster ricostruisce i dati su un broker funzionante appena aggiunto, il che richiede molto tempo.  Nel caso di un cluster Kafka basato su NetApp NFS, il broker sostitutivo continua a leggere i dati dalla directory di registro precedente e ripristina molto più rapidamente.</block>
  <block id="687972ccb765e5204fa2220ba3dff130" category="list-text">4 x produttore/consumatore -- c5n.2xlarge</block>
  <block id="31638173210d76d464e93c8f3f53711c" category="list-text">1 x nodo Kafka di backup – i3en.2xlarge</block>
  <block id="5d27021addda02398c54d28a4ceee767" category="cell">RHEL8.7 o successivo</block>
  <block id="477284b661c88fdd810eb7273729b5ed" category="paragraph"><block ref="477284b661c88fdd810eb7273729b5ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64898c42d1ced91d44ff2e383b066de3" category="list-text">*Calcolare.*  Un cluster Kafka a tre nodi con un ensemble zookeeper a tre nodi in esecuzione su server dedicati.  Ogni broker ha due punti di montaggio NFS su un singolo volume sull'istanza NetApp CVO tramite un LIF dedicato.</block>
  <block id="06e870f499bc90bbe828323be8625621" category="list-text">*Monitoraggio.*  Due nodi per una combinazione Prometheus-Grafana.  Per generare carichi di lavoro, utilizziamo un cluster separato a tre nodi in grado di produrre e consumare dati per questo cluster Kafka.</block>
  <block id="1a5c8241b05feb71d0733c2cc2f073c2" category="list-text">*Magazzinaggio.*  Un'istanza ONTAP NetApp Cloud Volumes a nodo singolo con sei volumi GP2 AWS-EBS da 250 GB montati sull'istanza.  Questi volumi vengono quindi esposti al cluster Kafka come sei volumi NFS tramite LIF dedicati.</block>
  <block id="7a4e5e874bf6fcf8217de7f8f0af5acb" category="list-text">*Configurazione del broker.*  L'unico elemento configurabile in questo caso di test sono i broker Kafka.  Per i broker Kafka sono state selezionate le seguenti specifiche.  IL<block ref="2aa7cd054835892b354c130576c17b61" prefix=" " category="inline-code"></block> è impostato su un valore elevato perché determina la velocità con cui un nodo specifico viene rimosso dall'elenco ISR.  Quando si passa da nodi danneggiati a nodi sani, non si desidera che l'ID del broker venga escluso dall'elenco ISR.</block>
  <block id="d6068b616491b51ff179d0138965bba4" category="inline-image-macro">Questa immagine mostra le specifiche scelte per i broker Kafka.</block>
  <block id="ce565ed35fddb2c8191f4b8496e98245" category="paragraph"><block ref="ce565ed35fddb2c8191f4b8496e98245" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7f6ea5961f5640ce4fa828022abc91c1" category="list-text">Sono stati creati due cluster simili:</block>
  <block id="71754d8c640cd0a117a3c82af0bd3646" category="list-text">Un cluster confluente basato su EC2.</block>
  <block id="c4b4e0617e4a38a83a00fc9bd8083465" category="list-text">Un cluster confluente basato su NetApp NFS.</block>
  <block id="fbbf8c78f6f01371b1caa7b79bfa91b9" category="list-text">È stato creato un nodo Kafka di standby con una configurazione identica ai nodi del cluster Kafka originale.</block>
  <block id="b2d04ce59538c1ba125aa91697b3854f" category="list-text">Su ciascuno dei cluster è stato creato un argomento di esempio e sono stati popolati circa 110 GB di dati su ciascun broker.</block>
  <block id="25bb70a763a5456f70f68d98646ecbd6" category="list-text">*Cluster basato su EC2.*  Una directory di dati del broker Kafka è mappata su<block ref="8463a3643fa4431218a88d6e1e85f064" prefix=" " category="inline-code"></block> (Nella figura seguente, Broker-1 del cluster1 [terminale sinistro]).</block>
  <block id="bbec1799f53d01620bdd78881b0f0310" category="list-text">* Cluster basato su NetApp NFS.*  Una directory di dati del broker Kafka è montata sul punto NFS<block ref="ecabd55f704fe0f0dcc41be6e7e7ab83" prefix=" " category="inline-code"></block> (Nella figura seguente, Broker-1 del cluster2 [terminale destro]).</block>
  <block id="86f85a2a5eed8a784f9a06a8fe205c9a" category="inline-image-macro">Questa immagine mostra due schermate del terminale.</block>
  <block id="3a534dc7ed1f2e8444c4b278dd70aa7e" category="paragraph"><block ref="3a534dc7ed1f2e8444c4b278dd70aa7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02296aafa9e3a6424418dd97a673e931" category="list-text">In ciascuno dei cluster, Broker-1 è stato terminato per attivare un processo di ripristino del broker non riuscito.</block>
  <block id="fe4c3f604a59eb786f64f0fc5a7cfa01" category="list-text">Dopo la chiusura del broker, l'indirizzo IP del broker è stato assegnato come IP secondario al broker standby.  Ciò era necessario perché un broker in un cluster Kafka viene identificato da quanto segue:</block>
  <block id="597bfb23e3e10c354a661882e4728565" category="list-text">*Indirizzo IP.*  Assegnato riassegnando l'IP del broker non riuscito al broker standby.</block>
  <block id="d86a6ec6cd64cd7365ad5d46f7c32d85" category="list-text">*ID broker.*  Questo è stato configurato nel broker standby<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> .</block>
  <block id="c71af5d75ff28fc80b8aa2c6c6832c39" category="list-text">Dopo l'assegnazione dell'IP, il servizio Kafka è stato avviato sul broker standby.</block>
  <block id="e6f0e1804a85ff41f08342fa0cd0e8c5" category="list-text">Dopo un po', sono stati estratti i log del server per verificare il tempo impiegato per creare i dati sul nodo sostitutivo nel cluster.</block>
  <block id="b4e6de827ba8af76c3d7cf0e11dee63e" category="paragraph">Il recupero del broker Kafka è stato quasi nove volte più rapido.  È stato riscontrato che il tempo impiegato per ripristinare un nodo broker non riuscito è significativamente più rapido quando si utilizza l'archiviazione condivisa NetApp NFS rispetto all'utilizzo di SSD DAS in un cluster Kafka.  Per 1 TB di dati di argomento, il tempo di ripristino per un cluster basato su DAS è stato di 48 minuti, rispetto a meno di 5 minuti per un cluster Kafka basato su NetApp-NFS.</block>
  <block id="fcd5351f741ba27a03aeaa4aff141fde" category="paragraph">Abbiamo osservato che il cluster basato su EC2 ha impiegato 10 minuti per ricostruire i 110 GB di dati sul nuovo nodo broker, mentre il cluster basato su NFS ha completato il ripristino in 3 minuti.  Abbiamo anche osservato nei log che gli offset dei consumatori per le partizioni per EC2 erano 0, mentre, sul cluster NFS, gli offset dei consumatori venivano prelevati dal broker precedente.</block>
  <block id="01a0d5c558a836a74adf3dc3fe1de25d" category="section-title">Cluster basato su DAS</block>
  <block id="542ac5d9dd4769eb5fb4a8a7da3aa594" category="list-text">Il nodo di backup è stato avviato alle 08:55:53,730.</block>
  <block id="b5f0acf8be0dd329b7dae7c96c9b3dc8" category="inline-image-macro">Questa immagine mostra l'output del registro per un cluster basato su DAS.</block>
  <block id="91569a3f4fee956cd801e625cc8eb34f" category="paragraph"><block ref="91569a3f4fee956cd801e625cc8eb34f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d48d1996a0b89fc5aa313e48f1c2c149" category="list-text">Il processo di ricostruzione dei dati è terminato alle 09:05:24,860.  L'elaborazione di 110 GB di dati ha richiesto circa 10 minuti.</block>
  <block id="d598dda290e226574121bf65a66222c1" category="paragraph"><block ref="d598dda290e226574121bf65a66222c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d10d1e0d7dc7546ca2ee585553c90f24" category="section-title">Cluster basato su NFS</block>
  <block id="e163d6812be40c2618b43cc9d2ed21a1" category="list-text">Il nodo di backup è stato avviato alle 09:39:17,213.  Di seguito è evidenziata la voce di registro iniziale.</block>
  <block id="1af763f7fe72be73a16f6a9010023e1f" category="inline-image-macro">Questa immagine mostra l'output del registro per un cluster basato su NFS.</block>
  <block id="bbb8038819966fa92b04b31dfe935e66" category="paragraph"><block ref="bbb8038819966fa92b04b31dfe935e66" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459f0a82f7fc8505de6db94698f5e9c8" category="list-text">Il processo di ricostruzione dei dati è terminato alle 09:42:29,115.  L'elaborazione di 110 GB di dati ha richiesto circa 3 minuti.</block>
  <block id="bb69fdfb2a75f135682b3880999f8c2e" category="paragraph"><block ref="bb69fdfb2a75f135682b3880999f8c2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="24c9b21a2ca87ae467a56b044593521b" category="paragraph">Il test è stato ripetuto per broker contenenti circa 1 TB di dati, impiegando circa 48 minuti per il DAS e 3 minuti per l'NFS.  I risultati sono rappresentati nel grafico seguente.</block>
  <block id="6994918ac91afbe69dd9a20ab257afa1" category="inline-image-macro">Questo grafico mostra il tempo impiegato per il ripristino del broker in base alla quantità di dati caricati sul broker per un cluster basato su DAS o su NFS.</block>
  <block id="fcc7c3e745c4c2ba0f4fe48c8d589122" category="paragraph"><block ref="fcc7c3e745c4c2ba0f4fe48c8d589122" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd18465573ec21a6218982055981f6b1" category="section-title">Efficienza di archiviazione</block>
  <block id="f94ef2603834178da773ec5ccd97683b" category="paragraph">Poiché il livello di archiviazione del cluster Kafka è stato fornito tramite NetApp ONTAP, abbiamo ottenuto tutte le funzionalità di efficienza di archiviazione di ONTAP.  Questa soluzione è stata testata generando una quantità significativa di dati su un cluster Kafka con storage NFS fornito su Cloud Volumes ONTAP.  Abbiamo potuto constatare che si è verificata una significativa riduzione dello spazio grazie alle funzionalità ONTAP .</block>
  <block id="d1030267f4090d953bd3cabbb565b51b" category="cell">Istanza a nodo singolo – M5.2xLarge</block>
  <block id="717373873e977ccdc16d9a371e92b55b" category="list-text">*Calcolare.*  Abbiamo utilizzato un cluster Kafka a tre nodi con un ensemble zookeeper a tre nodi in esecuzione su server dedicati.  Ogni broker aveva due punti di montaggio NFS su un singolo volume sull'istanza NetApp CVO tramite un LIF dedicato.</block>
  <block id="cce21f164c30f5ce10f914c4542e252f" category="list-text">*Magazzinaggio.*  Abbiamo utilizzato un'istanza NetApp Cloud Volumes ONTAP a nodo singolo con sei volumi GP2 AWS-EBS da 250 GB montati sull'istanza.  Questi volumi sono stati quindi esposti al cluster Kafka come sei volumi NFS tramite LIF dedicati.</block>
  <block id="68f29d01fbebb4ad998127522e13950b" category="list-text">*Configurazione.*  Gli elementi configurabili in questo caso di prova erano i broker Kafka.</block>
  <block id="8e44bdd37fc66a06e9780582642d0c37" category="paragraph">La compressione è stata disattivata dal produttore, consentendogli così di generare un rendimento elevato.  L'efficienza dell'archiviazione era invece gestita dal livello di elaborazione.</block>
  <block id="7da10cbdbba2e826cd4954054b5c1843" category="list-text">È stato predisposto un cluster Kafka con le specifiche sopra menzionate.</block>
  <block id="e857c1394ce43b04a9548d5a3dec0ee5" category="list-text">Sul cluster sono stati prodotti circa 350 GB di dati utilizzando lo strumento OpenMessaging Benchmarking.</block>
  <block id="efc4a3d9bfed3a9a80b0caea9016ca6c" category="list-text">Una volta completato il carico di lavoro, le statistiche sull'efficienza dell'archiviazione sono state raccolte utilizzando ONTAP System Manager e la CLI.</block>
  <block id="9c9850d81b369454a9610d48c5bfe8a0" category="paragraph">Per i dati generati utilizzando lo strumento OMB, abbiamo riscontrato un risparmio di spazio di circa il 33% con un rapporto di efficienza di archiviazione di 1,70:1.  Come si può vedere nelle figure seguenti, lo spazio logico utilizzato dai dati prodotti era di 420,3 GB e lo spazio fisico utilizzato per contenere i dati era di 281,7 GB.</block>
  <block id="f11c8594ca77ceb3e0ab124768dd061d" category="inline-image-macro">Questa immagine illustra il risparmio di spazio in VMDISK.</block>
  <block id="565d9cbc0c15374b9bdebe62dd5efe32" category="paragraph"><block ref="565d9cbc0c15374b9bdebe62dd5efe32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3afbd9828e011526955ca93b48b57524" category="inline-image-macro">Schermata</block>
  <block id="50abdfc5295b4aedbb53a46e0bd7512b" category="paragraph"><block ref="50abdfc5295b4aedbb53a46e0bd7512b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6c6f7c15f1d0324567be0828cb855f7" category="paragraph"><block ref="c6c6f7c15f1d0324567be0828cb855f7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9fee86e220b694a9ca26cb5d3943276" category="summary">Questo documento descrive i benchmark delle prestazioni per la piattaforma Confluent su NetApp ONTAP utilizzando un kit di benchmarking per l'archiviazione a livelli.</block>
  <block id="5514e652e396365ccb56f1b2b5371569" category="doc">TR-4941: Confluent con i controller di storage NetApp ONTAP</block>
  <block id="1e0e02def11263577d232ee8ce69c727" category="paragraph">Karthikeyan Nagalingam, Joe Scott, NetApp Rankesh Kumar, Confluent</block>
  <block id="30f774bc5050b82b9a42fe5d8f4bc99f" category="paragraph">Per rendere la piattaforma Confluent più scalabile ed elastica, deve essere in grado di scalare e bilanciare i carichi di lavoro molto rapidamente.  L'archiviazione a livelli semplifica la gestione di enormi volumi di dati in Confluent, riducendone l'onere operativo.</block>
  <block id="981ac9f1443bdd13b0920d6ca1ee4eb3" category="paragraph">L'idea fondamentale è quella di separare l'archiviazione dei dati dall'elaborazione dei dati, il che rende molto più semplice scalare ciascuna attività in modo indipendente.</block>
  <block id="44f523cee834fac14fc6966d940c5e92" category="paragraph">Dotato di innovazioni all'avanguardia nel settore, il software di gestione dati NetApp ONTAP offre a Confluent numerosi vantaggi, ovunque si trovino i dati.</block>
  <block id="7e936a7640e03dad09e0b76d68277d56" category="summary">Abbiamo eseguito il test di archiviazione a livelli con tre o quattro nodi per carichi di lavoro di produzione e consumo con la configurazione NetApp StorageGRID .</block>
  <block id="3c2fe55c24192bbec6d6d3aede570213" category="doc">Test delle prestazioni con scalabilità</block>
  <block id="7d962aad50ee059cfbd23de23ab5a916" category="paragraph">Abbiamo eseguito il test di archiviazione a livelli con tre o quattro nodi per i carichi di lavoro dei produttori e dei consumatori con la configurazione NetApp StorageGRID .  Secondo i nostri test, il tempo di completamento e i risultati delle prestazioni sono stati direttamente proporzionali al numero di nodi StorageGRID .  La configurazione StorageGRID richiedeva un minimo di tre nodi.</block>
  <block id="4e6097966a711c7acf606365a2925b64" category="list-text">Il tempo necessario per completare le operazioni di produzione e consumo è diminuito linearmente all'aumentare del numero di nodi di stoccaggio.</block>
  <block id="5393f806598ea16510805a4ab3b20623" category="paragraph"><block ref="5393f806598ea16510805a4ab3b20623" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d098e780afaaad433dd6982bbc5af988" category="list-text">Le prestazioni dell'operazione di recupero s3 sono aumentate in modo lineare in base al numero di nodi StorageGRID .  StorageGRID supporta fino a 200 nodi StorgeGRID.</block>
  <block id="d73d827635c7a6fcfa52120cc6f3b96d" category="paragraph"><block ref="d73d827635c7a6fcfa52120cc6f3b96d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43f0735f931622d61f6837a0eb61f87e" category="summary">Questo test si basa sulla funzionalità di autobilanciamento dei cluster, che automatizza il ribilanciamento in base alle modifiche della topologia del cluster o al carico non uniforme.</block>
  <block id="565b2f1bfcd6857afba2efa000b83759" category="doc">Cluster autobilancianti confluenti</block>
  <block id="d3975bd93d0a2c24b382774d34b5a963" category="paragraph">Se hai già gestito un cluster Kafka, probabilmente conosci le sfide che comporta la riassegnazione manuale delle partizioni a diversi broker per garantire che il carico di lavoro sia bilanciato nel cluster.  Per le organizzazioni con grandi distribuzioni Kafka, riorganizzare grandi quantità di dati può essere scoraggiante, noioso e rischioso, soprattutto se le applicazioni mission-critical vengono sviluppate sul cluster.  Tuttavia, anche per i casi d'uso più piccoli di Kafka, il processo richiede molto tempo ed è soggetto a errori umani.</block>
  <block id="3c404a9102e2cb3ac7b75fa7ff7a2cb2" category="paragraph">Nel nostro laboratorio abbiamo testato la funzionalità di autobilanciamento dei cluster Confluent, che automatizza il ribilanciamento in base alle modifiche della topologia del cluster o al carico non uniforme.  Il test di ribilanciamento Confluent aiuta a misurare il tempo necessario per aggiungere un nuovo broker quando un errore del nodo o il nodo di ridimensionamento richiedono il ribilanciamento dei dati tra i broker.  Nelle configurazioni Kafka classiche, la quantità di dati da ribilanciare aumenta con la crescita del cluster, ma nell'archiviazione a livelli il ribilanciamento è limitato a una piccola quantità di dati.  In base alla nostra convalida, il ribilanciamento nell'archiviazione a livelli richiede secondi o minuti in un'architettura Kafka classica e cresce in modo lineare con la crescita del cluster.</block>
  <block id="829c663686b68c76ea97bd7a23d534b6" category="paragraph">Nei cluster autobilancianti, i ribilanciamenti delle partizioni sono completamente automatizzati per ottimizzare la produttività di Kafka, accelerare il ridimensionamento del broker e ridurre l'onere operativo legato all'esecuzione di un cluster di grandi dimensioni.  A regime, i cluster autobilancianti monitorano la distorsione dei dati tra i broker e riassegnano continuamente le partizioni per ottimizzare le prestazioni del cluster.  Quando si aumenta o diminuisce la scalabilità della piattaforma, i cluster autobilancianti riconoscono automaticamente la presenza di nuovi broker o la rimozione di vecchi broker e attivano una successiva riassegnazione delle partizioni.  Ciò consente di aggiungere e dismettere facilmente i broker, rendendo i cluster Kafka sostanzialmente più elastici.  Questi vantaggi si ottengono senza bisogno di alcun intervento manuale, calcoli complessi o il rischio di errore umano che solitamente comportano le riassegnazioni delle partizioni.  Di conseguenza, i ribilanciamenti dei dati vengono completati in molto meno tempo e puoi concentrarti su progetti di streaming di eventi di valore più elevato anziché dover supervisionare costantemente i tuoi cluster.</block>
  <block id="bc15ae13f16a39532174d0aec78a6432" category="summary">In questa configurazione, ti mostriamo come leggere e scrivere argomenti nell'archiviazione di oggetti da Kafka direttamente utilizzando il connettore sink Kafka s3.  Per questo test abbiamo utilizzato un cluster Confluent autonomo, ma questa configurazione è applicabile anche a un cluster distribuito.</block>
  <block id="8b7e627b574df4c4813de77ed2896ad8" category="doc">Connettore confluente s3</block>
  <block id="524b95dc71b518ce734757656cf9594c" category="paragraph">Il connettore Amazon S3 Sink esporta i dati dagli argomenti Apache Kafka agli oggetti S3 nei formati Avro, JSON o Bytes.  Il connettore sink Amazon S3 interroga periodicamente i dati da Kafka e a sua volta li carica su S3.  Un partizionatore viene utilizzato per suddividere i dati di ogni partizione Kafka in blocchi.  Ogni blocco di dati è rappresentato come un oggetto S3.  Il nome della chiave codifica l'argomento, la partizione Kafka e l'offset iniziale di questo blocco di dati.</block>
  <block id="b5829317a86f448ffca89934abe420d3" category="list-text">Scarica Confluent Kafka dal sito web di Confluent.</block>
  <block id="99eec7bbd3416776cb76d9d8f52bfddc" category="list-text">Decomprimi il pacchetto in una cartella sul tuo server.</block>
  <block id="2d025d1c11796b49f323ce393e802635" category="list-text">Esporta due variabili.</block>
  <block id="e238a3352503bcd61be91778a307f02e" category="list-text">Per una configurazione Confluent Kafka autonoma, il cluster crea una cartella radice temporanea in<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block> Crea inoltre Zookeeper, Kafka, un registro di schemi, connect, un server ksql e cartelle del centro di controllo e copia i rispettivi file di configurazione da<block ref="5f8dd6e4b96ae5c78585ed0293d4338d" prefix=" " category="inline-code"></block> .  Vedere il seguente esempio:</block>
  <block id="ed529b17b192b6bcfa1fb220aa0f37e4" category="list-text">Configura Zookeeper.  Se si utilizzano i parametri predefiniti non è necessario apportare alcuna modifica.</block>
  <block id="ad2d4e5ed593359b5d1fe13997541e6f" category="paragraph">Nella configurazione di cui sopra, abbiamo aggiornato il<block ref="2f11dbffae155119df4dc4d60229477e" prefix=" " category="inline-code"></block> proprietà.  Di default, per la selezione del leader Kafka sono necessari tre Zookeeper.</block>
  <block id="b7eb15647b54e1bfd5b79f04012f19ce" category="list-text">Abbiamo creato un file myid in<block ref="417022983f4126687b04c2a16a36183c" prefix=" " category="inline-code"></block> con un ID univoco:</block>
  <block id="78f7f3d70d7fc386cde6a61b7d08bc07" category="paragraph">Abbiamo utilizzato l'ultimo numero di indirizzi IP per il file myid.  Abbiamo utilizzato valori predefiniti per le configurazioni Kafka, connect, control-center, Kafka, Kafka-rest, ksql-server e schema-registry.</block>
  <block id="5ad6084775d1229b3edcbda0f353315c" category="list-text">Avviare i servizi Kafka.</block>
  <block id="67228b3b71aba311ab74c0946efe35e8" category="paragraph">Per ogni configurazione è presente una cartella di registro, utile per risolvere i problemi.  In alcuni casi, l'avvio dei servizi richiede più tempo.  Assicurarsi che tutti i servizi siano attivi e funzionanti.</block>
  <block id="65272a6acb72513d0bfa2bdd8b0c6d1b" category="list-text">Installa Kafka Connect utilizzando<block ref="dcd3bd9446852f6dec3cf416e98154dc" prefix=" " category="inline-code"></block> .</block>
  <block id="4bdaf464a75dbea14d9240c6722a822a" category="paragraph">È anche possibile installare una versione specifica utilizzando<block ref="edb107f75d4831212ad61dd615bc468f" prefix=" " category="inline-code"></block> .</block>
  <block id="004220cf4b170d47a455040fde149eaf" category="list-text">Per impostazione predefinita,<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block> è installato in<block ref="6ae652b878f3c54eeaed9d623a1a8c82" prefix=" " category="inline-code"></block> .</block>
  <block id="fe4b44765b8ad323e0d6a2e6b7325246" category="list-text">Aggiorna il percorso del plug-in con il nuovo<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block> .</block>
  <block id="331885900730ee061e0f6b4f55e62ece" category="list-text">Arrestare i servizi Confluent e riavviarli.</block>
  <block id="7fe69cf1bb033725fdeb56839e70fe4e" category="list-text">Configurare l'ID di accesso e la chiave segreta in<block ref="40f203cedcd08f7589920d1a469a96d9" prefix=" " category="inline-code"></block> file.</block>
  <block id="fac7d16b475df7919931f2de707a4a45" category="list-text">Verificare che il bucket sia raggiungibile.</block>
  <block id="369f5700a42f83495e179b9e947587fb" category="list-text">Configurare il file delle proprietà s3-sink per la configurazione s3 e bucket.</block>
  <block id="3d3c898205223806be88ccecb8f0598c" category="list-text">Importa alcuni record nel bucket s3.</block>
  <block id="50b781543cad31f75eed99b8efb20e79" category="list-text">Caricare il connettore s3-sink.</block>
  <block id="6e773b2ab9703d3433d0ebfb5a45a3a1" category="list-text">Controllare lo stato del sink s3.</block>
  <block id="b533fadf7b5ac18085d65eb6814528cf" category="list-text">Controllare il registro per assicurarsi che s3-sink sia pronto ad accettare argomenti.</block>
  <block id="613093505fc60a58e7893af8aee3b7b8" category="list-text">Consulta gli argomenti in Kafka.</block>
  <block id="38f7472ee233ba1cc1a7d724a0ca6542" category="list-text">Controllare gli oggetti nel bucket s3.</block>
  <block id="09fa6729fb808be555e2da157c07e47e" category="list-text">Per verificare il contenuto, copia ciascun file da S3 al tuo file system locale eseguendo il seguente comando:</block>
  <block id="e8eeb400cc1af7c80b7561572c879a12" category="inline-link">Archivi Apache</block>
  <block id="7d059565bbab6abb5da76e3abcfe6f90" category="list-text">Per stampare i record, utilizzare avro-tools-1.11.0.1.jar (disponibile nel<block ref="55ee52f435d2dbbc99b651e203ff837e" category="inline-link-rx"></block> ).</block>
  <block id="331c0d2ba7a09b3ae7f6fac4652625da" category="summary">Questa pagina descrive le best practice per migliorare le prestazioni di questa soluzione.</block>
  <block id="69cefd131c612b28f058caddd20f5cac" category="doc">Linee guida sulle migliori pratiche di prestazione</block>
  <block id="21414169b395738292b2ac2fd8ca50a9" category="list-text">Per ONTAP, quando possibile, utilizzare una dimensione GET &gt;=1 MB.</block>
  <block id="ce2e9b8aaceb2d2993c90188d874af95" category="list-text">In aumento<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> E<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> In<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> sui nodi broker consente di trasferire un'attività di tiering aumentata al livello S3.  Questi risultati sono con<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> E<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> impostato su 32.</block>
  <block id="1a48e01d01924d18e32943982eb6d924" category="list-text">I bucket S3 dovrebbero avere come target otto componenti per aggregato di membri.</block>
  <block id="b5a9dc3c7ec54467d103e00eaa0efb21" category="list-text">I collegamenti Ethernet che gestiscono il traffico S3 dovrebbero utilizzare, ove possibile, un MTU di 9k sia sullo storage che sul client.</block>
  <block id="4ea8220421596c898f8150bfebdf4ccb" category="summary">Questo test di verifica ha raggiunto 31,74 GBps di throughput di tiering su Confluent con un controller di storage NetApp ONTAP .</block>
  <block id="93a10982e8e304323ad8af9a9387d775" category="paragraph">Questo test di verifica ha raggiunto 31,74 GBps di throughput di tiering su Confluent con NetApp ONTAP Storage Controller.</block>
  <block id="0f2f674cce6910ae97ee7ecc7bd9de18" category="list-text">Che cos'è Confluent?</block>
  <block id="e6deab0ab2821160c056af4c7766624c" category="inline-link"><block ref="e6deab0ab2821160c056af4c7766624c" category="inline-link-rx"></block></block>
  <block id="ce3026317a00b57c81627bd64a1b3311" category="paragraph"><block ref="ce3026317a00b57c81627bd64a1b3311" category="inline-link-rx"></block></block>
  <block id="58a229be829dc9196abdaff6a4a26864" category="list-text">S3 nelle migliori pratiche ONTAP</block>
  <block id="f47b79954bb4ad3165d7f99db02fe933" category="inline-link"><block ref="f47b79954bb4ad3165d7f99db02fe933" category="inline-link-rx"></block></block>
  <block id="e98b34b649783312d3b317c7441a20a5" category="paragraph"><block ref="e98b34b649783312d3b317c7441a20a5" category="inline-link-rx"></block></block>
  <block id="3075344c29b864c90ae1411c1db26e87" category="list-text">Gestione dell'archiviazione degli oggetti S3</block>
  <block id="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link"><block ref="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link-rx"></block></block>
  <block id="8a93310a8dd4b405a8711f82adeb3c23" category="paragraph"><block ref="8a93310a8dd4b405a8711f82adeb3c23" category="inline-link-rx"></block></block>
  <block id="614eb548d72efbb3690b5c131745db1b" category="summary">Questa pagina descrive la convalida delle prestazioni di Confluent all'interno dei parametri di questa soluzione.</block>
  <block id="28052d386826afbb88768d0629570b19" category="doc">Validazione delle prestazioni confluenti</block>
  <block id="3ec7b1ca1aaf25c9bbca707f1ca8e466" category="paragraph">Abbiamo eseguito la verifica con Confluent Platform per l'archiviazione a livelli su NetApp ONTAP.  I team NetApp e Confluent hanno lavorato insieme a questa verifica ed eseguito i casi di test richiesti.</block>
  <block id="1f567e45477749710cbc14cf6b10afc4" category="section-title">Configurazione confluente</block>
  <block id="99b45ae42dbbf816c910ba27197525dc" category="paragraph">Per la configurazione abbiamo utilizzato tre guardiani dello zoo, cinque broker e cinque server di prova con 256 GB di RAM e 16 CPU.  Per lo storage NetApp , abbiamo utilizzato ONTAP con una coppia AFF A900 HA.  Lo storage e i broker erano collegati tramite connessioni 100GbE.</block>
  <block id="77727c2ca2ac5beb0de2853929b43367" category="paragraph">La figura seguente mostra la topologia di rete della configurazione utilizzata per la verifica dell'archiviazione a livelli.</block>
  <block id="57e8d3257fec5774d2e8d38588771a69" category="inline-image-macro">Questo grafico mostra la topologia di rete della configurazione utilizzata per la verifica dell'archiviazione a livelli.</block>
  <block id="b460294b1898fd26dfbb545338caacee" category="paragraph"><block ref="b460294b1898fd26dfbb545338caacee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d9b75f4efe285b9777255f14c81323b" category="paragraph">I server degli strumenti agiscono come client applicativi che inviano o ricevono eventi da o verso i nodi Confluent.</block>
  <block id="1068af448bd05a968329fd2341036bfb" category="paragraph">Abbiamo utilizzato i seguenti parametri di prova:</block>
  <block id="3bfb3f2755d25ed45d39dad8b3ed3008" category="paragraph">Per la verifica abbiamo utilizzato ONTAP con il protocollo HTTP, ma ha funzionato anche HTTPS.  La chiave di accesso e la chiave segreta sono memorizzate nel nome del file fornito nel<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> parametro.</block>
  <block id="86d7ae5e1e87e4958b4fafcbca603956" category="section-title">Controller di archiviazione NetApp – ONTAP</block>
  <block id="b915ce35d395a0d68a794b87705f95fa" category="paragraph">Abbiamo configurato una singola coppia HA in ONTAP per la verifica.</block>
  <block id="b9d2b35b3cfffa153fd4ed3401cb9dd9" category="inline-image-macro">Questo grafico illustra come l'ambiente è stato configurato come una singola coppia HA per la verifica.</block>
  <block id="267b459a69088e0dc82f7fe972205f92" category="paragraph"><block ref="267b459a69088e0dc82f7fe972205f92" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7069b530e46a91698a16159b7d083019" category="section-title">Risultati della verifica</block>
  <block id="3af1efc909fae49a716fe2d22ba24290" category="paragraph">Per la verifica abbiamo completato i seguenti cinque casi di test.  I primi due erano test di funzionalità, mentre i restanti tre erano test di prestazioni.</block>
  <block id="09da8339466c8b6111e4f310f1b78cb5" category="paragraph">Questo test esegue operazioni di base come get, put ed delete sull'archivio oggetti utilizzato per l'archiviazione a livelli tramite chiamate API.</block>
  <block id="622ce818e2b8228cee071a827a43e1b2" category="paragraph">Questo test verifica la funzionalità end-to-end dell'archiviazione degli oggetti.  Crea un argomento, produce un flusso di eventi per l'argomento appena creato, attende che i broker archivino i segmenti nell'archivio oggetti, consuma il flusso di eventi e convalida la corrispondenza del flusso consumato con il flusso prodotto.  Abbiamo eseguito questo test con e senza un'iniezione di errore nell'archivio oggetti.  Abbiamo simulato un guasto del nodo arrestando il servizio di gestione dei servizi in uno dei nodi in ONTAP e convalidando che la funzionalità end-to-end funzioni con l'archiviazione degli oggetti.</block>
  <block id="2712a580ff4c3586c7ba3534b78aad18" category="section-title">Generatore di carico di lavoro di produzione-consumo</block>
  <block id="0c22172129c2d0d58a5685fa1094fca0" category="paragraph">Questo test genera indirettamente un carico di lavoro di scrittura sull'archivio oggetti tramite l'archiviazione dei segmenti.  Il carico di lavoro di lettura (segmenti letti) è stato generato dall'archiviazione degli oggetti quando i gruppi di consumatori hanno recuperato i segmenti.  Questo carico di lavoro è stato generato da uno script TOCC.  Questo test ha verificato le prestazioni di lettura e scrittura sull'archiviazione di oggetti in thread paralleli.  Abbiamo eseguito i test con e senza l'iniezione di errori nell'archivio oggetti, come abbiamo fatto per il test di correttezza della funzionalità di tiering.</block>
  <block id="2a7273e52c0214e6f0b27bf1e870960e" category="section-title">Generatore di carichi di lavoro di conservazione</block>
  <block id="48771387cb6a84889bc1db951598f78c" category="paragraph">Questo test ha verificato le prestazioni di eliminazione di un archivio di oggetti in presenza di un carico di lavoro di conservazione degli argomenti elevato.  Il carico di lavoro di conservazione è stato generato utilizzando uno script TOCC che produce molti messaggi in parallelo a un argomento di prova.  L'argomento del test era la configurazione con un'impostazione di conservazione aggressiva basata sulle dimensioni e sul tempo, che causava la continua eliminazione del flusso di eventi dall'archivio oggetti.  I segmenti vennero poi archiviati.  Ciò ha portato a numerose eliminazioni nell'archivio oggetti da parte del broker e alla raccolta delle prestazioni delle operazioni di eliminazione dell'archivio oggetti.</block>
  <block id="a03d0d99a3287875dda3d19daa736d0c" category="inline-link">Confluente</block>
  <block id="047fb529cf71ef63efe04d4185302684" category="paragraph">Per i dettagli di verifica, vedere il<block ref="86830f666762f920df1dddf1c71e6509" category="inline-link-rx"></block> sito web.</block>
  <block id="dbb940c31f0b7d7563745993661f70d4" category="summary">Abbiamo eseguito test di storage a livelli con cinque o otto nodi broker durante un carico di lavoro di produzione-consumo con un controller di storage NetApp con coppia AFF A900 HA.  Secondo i nostri test, il tempo di completamento e i risultati delle prestazioni sono aumentati con il numero di nodi broker, fino a quando l'utilizzo delle risorse AFF A900 ha raggiunto il cento per cento.  La configurazione del controller di archiviazione ONTAP richiedeva almeno una coppia HA.</block>
  <block id="91e1cb9730965860cb465802520e6a45" category="doc">Test delle prestazioni con generatore di carico di lavoro di produzione-consumo</block>
  <block id="b15c40872cdd0b1e0a152907f2194e69" category="paragraph">Le prestazioni dell'operazione di recupero S3 sono aumentate in modo lineare in base al numero di nodi broker Confluent.  Il controller di archiviazione ONTAP supporta fino a 12 coppie HA in una singola distribuzione.</block>
  <block id="ec043d5e2714e1035038cbeb1aa3cba8" category="paragraph">Il grafico seguente mostra il traffico combinato di livelli S3 con cinque o otto nodi broker.  Abbiamo massimizzato le prestazioni della singola coppia HA AFF A900 .</block>
  <block id="ffff2891cfdd07445c4e1e5261739c68" category="inline-image-macro">Questo grafico di dati mostra il traffico combinato di livelli S3 con cinque o otto nodi broker.</block>
  <block id="d1912fadda4ef80cc1a01c7f3f919602" category="paragraph"><block ref="d1912fadda4ef80cc1a01c7f3f919602" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1efe906cedfd00618bda4d39b41a52fd" category="paragraph">Il grafico seguente mostra la velocità di trasmissione di Kafka a circa 31,74 GBps.</block>
  <block id="e7aff80741661a5eb60f57649077f9c5" category="inline-image-macro">Questo grafico dei dati mostra la velocità di trasmissione di Kafka a circa 31,74 GBps.</block>
  <block id="a9504735d0b0cbb3b424919bb1328a7d" category="paragraph"><block ref="a9504735d0b0cbb3b424919bb1328a7d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6821411dfc3b7f483da21b37082dfc" category="paragraph">Abbiamo anche osservato una produttività simile nel controller di archiviazione ONTAP<block ref="d40e53103e181690f77a04eadc8aa6cc" prefix=" " category="inline-code"></block> rapporto.</block>
  <block id="b0c400a1c1ac5de2cbdc877645b349a0" category="summary">Questa sezione riguarda l'hardware e il software utilizzati per la verifica delle prestazioni nella distribuzione di Confluent Platform con NetApp ONTAP per l'archiviazione a livelli.  La tabella seguente illustra l'architettura della soluzione e i componenti di base.</block>
  <block id="5197b1c9433e86b5ed33786625f77786" category="paragraph">Confluent e il controller di storage NetApp AFF A900 con tecnologia ONTAP sono sistemi distribuiti progettati per flussi di dati.  Entrambi sono scalabili orizzontalmente, tolleranti agli errori e garantiscono prestazioni eccellenti sotto carico.  Si completano a vicenda nello streaming di dati distribuiti e nell'elaborazione di flussi con costi di archiviazione inferiori, grazie a tecnologie di riduzione dei dati che riducono al minimo l'ingombro dei dati.  Il controller di archiviazione AFF A900 garantisce prestazioni eccellenti, consentendo al contempo di separare le risorse di elaborazione e di archiviazione dati.  Ciò semplifica l'amministrazione del sistema e consente di scalare le risorse in modo indipendente.</block>
  <block id="8ebef54f33ae0fdc7c4dcb83539b6eac" category="inline-image-macro">Immagine che illustra la panoramica della soluzione.</block>
  <block id="c7c06ecce0e6f1e46fab6853d4d45058" category="paragraph"><block ref="c7c06ecce0e6f1e46fab6853d4d45058" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f75094292f4afb812bc29237348d9948" category="cell">Piattaforma Confluent versione 6.2</block>
  <block id="5cc4fd015c7740c575d319eefacbce83" category="list-text">3 guardiani dello zoo</block>
  <block id="8f6a506566bd03a47cafb69561bafe0f" category="list-text">8 server broker</block>
  <block id="aa76981d988c82fc8b387682968887e6" category="list-text">5 x server di strumenti</block>
  <block id="b56d58a9a181bae1fa65f36407ea002c" category="list-text">1 x Grafana</block>
  <block id="4af3adf9207f6f8d2d6d9edda08f0638" category="list-text">1 x centro di controllo</block>
  <block id="de4d788671df5cf79fda01236d8fc9a6" category="cell">NetApp ONTAP per bucket caldi</block>
  <block id="37e0c77638b1388d83b997c8dffdb6d3" category="list-text">1 coppia AFF A900 ad alta disponibilità (HA)</block>
  <block id="2e1c9b5ce764f890af0aebf38f1a500a" category="list-text">100GbE</block>
  <block id="983e16c42b860c2511053f17d60918c8" category="list-text">2 CPU; 16 core fisici totali</block>
  <block id="ce4750dd79017960eed95bd3b2677eb4" category="list-text">Intel Xeon</block>
  <block id="01dcc4e221fc9ff7472c5102b082eaf4" category="list-text">256 GB di memoria fisica</block>
  <block id="433304c312dd41f05955324749c0a47f" category="list-text">Doppia porta 100GbE</block>
  <block id="b7d338a537a3a1d0186080c4c4ba47eb" category="summary">Questa pagina descrive la tecnologia utilizzata in questa soluzione.</block>
  <block id="a1f13b9a0674cc0beb81e208dfb68d05" category="doc">Panoramica della tecnologia</block>
  <block id="7f1512274139985d5f21a72e13808522" category="section-title">Controller di archiviazione NetApp ONTAP</block>
  <block id="b691cb82ce5ecb3d94f82b73ef3c2219" category="paragraph">NetApp ONTAP è un sistema operativo di storage di livello aziendale ad alte prestazioni.</block>
  <block id="f8b80927eb906c831742041c4c139be1" category="paragraph">NetApp ONTAP 9.8 introduce il supporto per le API Amazon Simple Storage Service (S3).  ONTAP supporta un sottoinsieme di azioni API S3 di Amazon Web Services (AWS) e consente di rappresentare i dati come oggetti nei sistemi basati su ONTAP tra provider cloud (AWS, Azure e GCP) e in locale.</block>
  <block id="9496ba5a97ab04d734dc449f86646ffe" category="paragraph">Il software NetApp StorageGRID è la soluzione di punta NetApp per l'archiviazione di oggetti.  ONTAP integra StorageGRID fornendo un punto di acquisizione e pre-elaborazione sull'edge, espandendo il data fabric basato su NetApp per i dati degli oggetti e aumentando il valore del portafoglio di prodotti NetApp .</block>
  <block id="d6e8f345bdd21d285f35171c2da8cd3a" category="paragraph">L'accesso a un bucket S3 viene fornito tramite applicazioni client e utenti autorizzati.  Il diagramma seguente mostra l'applicazione che accede a un bucket S3.</block>
  <block id="a38dfb3b286ff4854c6f5d67ebc15e13" category="inline-image-macro">Questa grafica mostra l'applicazione che accede a un bucket S3.</block>
  <block id="185bab9f8946071e86896c051a520617" category="paragraph"><block ref="185bab9f8946071e86896c051a520617" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5088428c842a8d5e45f2e6597af4138" category="section-title">Casi d'uso principali</block>
  <block id="5c2f4a513e63ae351e5dc0b7412a43c2" category="paragraph">Lo scopo principale del supporto delle API S3 è quello di fornire l'accesso agli oggetti su ONTAP.  L'architettura di archiviazione unificata ONTAP ora supporta file (NFS e SMB), blocchi (FC e iSCSI) e oggetti (S3).</block>
  <block id="1af2e65957e458000d1181bb9eba2517" category="section-title">Applicazioni S3 native</block>
  <block id="c0889d6b193afe7d0069e3d99bc5f310" category="paragraph">Un numero crescente di applicazioni è in grado di sfruttare il supporto ONTAP per l'accesso agli oggetti tramite S3.  Sebbene sia adatto a carichi di lavoro di archiviazione ad alta capacità, la necessità di prestazioni elevate nelle applicazioni S3 native sta crescendo rapidamente e include:</block>
  <block id="a768caa988605a2846599cf7e2d0c26a" category="list-text">Analisi</block>
  <block id="9d0996a44c6d51cf223e833dceecb286" category="list-text">Intelligenza artificiale</block>
  <block id="1669cbc398e4228e7e05d6b2e030cbe7" category="list-text">Acquisizione edge-to-core</block>
  <block id="bd1a4166acf45c62946d7592a64ad52d" category="paragraph">I clienti possono ora utilizzare strumenti di gestibilità familiari come ONTAP System Manager per fornire rapidamente storage di oggetti ad alte prestazioni per lo sviluppo e le operazioni in ONTAP, sfruttando al contempo l'efficienza e la sicurezza dello storage ONTAP .</block>
  <block id="50472ac5cace1b7798b3f92db5c3049e" category="section-title">Endpoint FabricPool</block>
  <block id="5050f2389b47df5462550d8e11451e9d" category="paragraph">A partire da ONTAP 9.8, FabricPool supporta la suddivisione in livelli in bucket in ONTAP, consentendo la suddivisione in livelli da ONTAP a ONTAP .  Si tratta di un'opzione eccellente per i clienti che desiderano riutilizzare l'infrastruttura FAS esistente come endpoint di archiviazione di oggetti.</block>
  <block id="10beb552e5ed01d5c890a260a1d6af16" category="paragraph">FabricPool supporta il tiering su ONTAP in due modi:</block>
  <block id="1e53159984d41f5ea848cdf412430a06" category="list-text">*Suddivisione in livelli dei cluster locali.*  I dati inattivi vengono suddivisi in livelli in un bucket situato sul cluster locale mediante i LIF del cluster.</block>
  <block id="08be0ca0511f2294cbbaf9d92327996b" category="list-text">*Suddivisione in livelli del cluster remoto.*  I dati inattivi vengono suddivisi in livelli in un bucket situato su un cluster remoto in modo simile a un livello cloud FabricPool tradizionale, utilizzando LIF IC sul client FabricPool e LIF dati sull'archivio oggetti ONTAP .</block>
  <block id="bda29d8d2c5de29e5ec15858a0f72c79" category="paragraph">ONTAP S3 è la soluzione ideale se si desiderano funzionalità S3 su cluster esistenti senza hardware e gestione aggiuntivi.  Per le distribuzioni superiori a 300 TB, il software NetApp StorageGRID continua a essere la soluzione NetApp di punta per l'archiviazione di oggetti.  Non è richiesta una licenza FabricPool quando si utilizza ONTAP o StorageGRID come livello cloud.</block>
  <block id="5a7adb78ef640711a870d82123f00775" category="section-title">NetApp ONTAP per storage a livelli Confluent</block>
  <block id="9a5bc88300f877a695de175398887e0e" category="paragraph">Ogni data center deve garantire il funzionamento delle applicazioni aziendali critiche e la disponibilità e la sicurezza dei dati importanti.  Il nuovo sistema NetApp AFF A900 è basato sul software ONTAP Enterprise Edition e su un design ad alta resilienza.  Il nostro nuovo sistema di archiviazione NVMe ultraveloce elimina le interruzioni delle operazioni mission-critical, riduce al minimo l'ottimizzazione delle prestazioni e protegge i tuoi dati dagli attacchi ransomware.</block>
  <block id="42dfa85904e1fd1b7fb41d4278c38047" category="paragraph">Dall'implementazione iniziale al ridimensionamento del cluster Confluent, il tuo ambiente richiede un rapido adattamento ai cambiamenti che non interrompono le tue applicazioni aziendali critiche.  La gestione dei dati aziendali, la qualità del servizio (QoS) e le prestazioni ONTAP consentono di pianificare e adattare il tutto al proprio ambiente.</block>
  <block id="36509bd95b243830a012c72c8a2d5844" category="paragraph">L'utilizzo congiunto NetApp ONTAP e Confluent Tiered Storage semplifica la gestione dei cluster Apache Kafka sfruttando ONTAP come destinazione di storage scalabile e consente il ridimensionamento indipendente delle risorse di elaborazione e storage per Confluent.</block>
  <block id="e09818a7d7d98185cdb0309cf3aca8f5" category="paragraph">Un server ONTAP S3 è basato sulle funzionalità di storage scalabili di ONTAP.  Il ridimensionamento del cluster ONTAP può essere eseguito senza problemi estendendo i bucket S3 per utilizzare i nodi appena aggiunti al cluster ONTAP .</block>
  <block id="1ccfe00aee80492f09968d6b208801d5" category="section-title">Gestione semplice con ONTAP System Manager</block>
  <block id="4fdad8328864e9de2db5338bb25291fc" category="paragraph">ONTAP System Manager è un'interfaccia grafica basata su browser che consente di configurare, gestire e monitorare il controller di archiviazione ONTAP in sedi distribuite a livello globale da un unico pannello di controllo.</block>
  <block id="c99eb67a4e6cbe9ba119a72c95161fab" category="inline-image-macro">Questa immagine mostra l'area di lavoro di ONTAP System Manager.</block>
  <block id="db8cf11125f7909f889c4894d1b8c042" category="paragraph"><block ref="db8cf11125f7909f889c4894d1b8c042" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783157c9c38b4e88d7eefffe21cd97d3" category="paragraph">È possibile configurare e gestire ONTAP S3 con System Manager e ONTAP CLI.  Quando si abilita S3 e si creano bucket tramite System Manager, ONTAP fornisce impostazioni predefinite basate sulle best practice per una configurazione semplificata.  Se si configura il server S3 e i bucket dalla CLI, è comunque possibile gestirli con System Manager, se lo si desidera, o viceversa.</block>
  <block id="d1623a9fec2de2642847391236e62e9b" category="paragraph">Quando si crea un bucket S3 tramite System Manager, ONTAP configura un livello di servizio di prestazioni predefinito, ovvero il più alto disponibile sul sistema.  Ad esempio, su un sistema AFF , l'impostazione predefinita sarebbe Estremo.  I livelli di servizio delle prestazioni sono gruppi di policy QoS adattive predefinite.  Invece di uno dei livelli di servizio predefiniti, è possibile specificare un gruppo di policy QoS personalizzato o nessun gruppo di policy.</block>
  <block id="bbcb9e2700fba39c3b7b7fd438155100" category="paragraph">I gruppi di policy QoS adattive predefiniti includono quanto segue:</block>
  <block id="f1ec0b0c482a42bad395f01e7f2b6c1d" category="list-text">*Estremo.*  Utilizzato per applicazioni che richiedono la latenza più bassa e le prestazioni più elevate.</block>
  <block id="06e90efc82fff7e3090ba9ff1a3bd2a3" category="list-text">*Prestazione.*  Utilizzato per applicazioni con esigenze di prestazioni e latenza modeste.</block>
  <block id="7aa0f5702784b1be0a3c5ed9e6f3df8e" category="list-text">*Valore.*  Utilizzato per applicazioni in cui la produttività e la capacità sono più importanti della latenza.</block>
  <block id="113d20f8cc4d864cdfea1b0f611cbb0a" category="list-text">*Costume.*  Specificare una policy QoS personalizzata o nessuna policy QoS.</block>
  <block id="42cc32e2c7857ba980019c70438e92ed" category="paragraph">Se si seleziona *Utilizza per la suddivisione in livelli*, non vengono selezionati livelli di servizio delle prestazioni e il sistema tenta di selezionare supporti a basso costo con prestazioni ottimali per i dati suddivisi in livelli.</block>
  <block id="5cc287af927b81043d030fc6a1ece879" category="paragraph">ONTAP tenta di fornire questo bucket sui livelli locali che dispongono dei dischi più appropriati, soddisfacendo il livello di servizio scelto.  Tuttavia, se è necessario specificare quali dischi includere nel bucket, valutare la possibilità di configurare l'archiviazione di oggetti S3 dalla CLI specificando i livelli locali (aggregati).  Se si configura il server S3 dalla CLI, è comunque possibile gestirlo con System Manager, se lo si desidera.</block>
  <block id="74869eb3dfe4756dab5491da2a3de2ad" category="paragraph">Se si desidera poter specificare quali aggregati vengono utilizzati per i bucket, è possibile farlo solo tramite la CLI.</block>
  <block id="0c0e3a803cf68a8772ebf58a68b20124" category="paragraph">Confluent Platform è una piattaforma di streaming dati completa che consente di accedere, archiviare e gestire facilmente i dati come flussi continui e in tempo reale.  Sviluppato dai creatori originali di Apache Kafka, Confluent amplia i vantaggi di Kafka con funzionalità di livello aziendale, eliminando al contempo l'onere della gestione o del monitoraggio di Kafka.  Oggi, oltre l'80% delle aziende Fortune 100 si avvale della tecnologia di streaming dei dati e la maggior parte utilizza Confluent.</block>
  <block id="3bcbf4072ba1e23a48434530e19a485d" category="section-title">Perché Confluent?</block>
  <block id="0fcb60f8560b74a641f556dbf96faf91" category="paragraph">Integrando dati storici e in tempo reale in un'unica fonte centrale di verità, Confluent semplifica la creazione di una categoria completamente nuova di applicazioni moderne basate sugli eventi, l'acquisizione di una pipeline di dati universale e lo sblocco di nuovi potenti casi d'uso con piena scalabilità, prestazioni e affidabilità.</block>
  <block id="f781b7a8a0d145997db9cf8449512bb8" category="section-title">A cosa serve Confluent?</block>
  <block id="d3c11d67f567698de4c90210b84c554d" category="paragraph">Confluent Platform ti consente di concentrarti su come ricavare valore aziendale dai tuoi dati anziché preoccuparti dei meccanismi sottostanti, ad esempio come i dati vengono trasportati o integrati tra sistemi diversi.  Nello specifico, Confluent Platform semplifica la connessione delle fonti di dati a Kafka, la creazione di applicazioni di streaming, nonché la protezione, il monitoraggio e la gestione dell'infrastruttura Kafka.  Oggi, la piattaforma Confluent viene utilizzata per un'ampia gamma di casi d'uso in numerosi settori, dai servizi finanziari, alla vendita al dettaglio omnicanale, alle auto autonome, al rilevamento delle frodi, ai microservizi e all'IoT.</block>
  <block id="870b2318ccfd123ac0f7e9ef1396d49d" category="paragraph">La figura seguente mostra i componenti della piattaforma Confluent.</block>
  <block id="9d880468cb22c04bd894fc612814dbab" category="inline-image-macro">Questo grafico mostra i componenti della piattaforma Confluent.</block>
  <block id="e21a51ac4ed645780def5d56f85ac9a8" category="paragraph"><block ref="e21a51ac4ed645780def5d56f85ac9a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05fafb4336e843d4634bd9ac122177c8" category="section-title">Panoramica della tecnologia di streaming di eventi Confluent</block>
  <block id="51be25b0145a0beca811de24a62b5cb4" category="inline-link">Kafka</block>
  <block id="0139d991fe55319f2e19e039da969fcf" category="paragraph">Il cuore della piattaforma Confluent è<block ref="66a1a9ec54e6ef0a1c109ad94b972ac9" category="inline-link-rx"></block> , la piattaforma di streaming distribuita open source più popolare.  Le principali funzionalità di Kafka includono quanto segue:</block>
  <block id="f630f472aeeab8697846e0f1f2f730aa" category="list-text">Pubblica e abbonati a flussi di record.</block>
  <block id="176fc2b349b906f6eb7a8f49c7ce9780" category="list-text">Memorizzare flussi di record in modo tollerante agli errori.</block>
  <block id="6026e29e86fd0ddcb6cba3908f85691f" category="list-text">Elaborare flussi di record.</block>
  <block id="f7ec60663c6d3ee6fd5abe343b34f2b4" category="paragraph">Confluent Platform include anche Schema Registry, REST Proxy, un totale di oltre 100 connettori Kafka predefiniti e ksqlDB.</block>
  <block id="82ff0b3d0476bb8ca2283ff06c017658" category="section-title">Panoramica delle funzionalità aziendali della piattaforma Confluent</block>
  <block id="ed2c640e88db15d474de830703c8783b" category="list-text">*Centro di controllo confluente.*  Un sistema basato sull'interfaccia utente per la gestione e il monitoraggio di Kafka.  Consente di gestire facilmente Kafka Connect e di creare, modificare e gestire connessioni ad altri sistemi.</block>
  <block id="da2f1a857a79ec960671ee4c735cc96e" category="list-text">*Confluent per Kubernetes.*  Confluent per Kubernetes è un operatore Kubernetes.  Gli operatori Kubernetes estendono le capacità di orchestrazione di Kubernetes fornendo funzionalità e requisiti esclusivi per una specifica applicazione della piattaforma.  Per Confluent Platform, ciò include una notevole semplificazione del processo di distribuzione di Kafka su Kubernetes e l'automazione delle tipiche attività del ciclo di vita dell'infrastruttura.</block>
  <block id="d63f46631d40c1c76b1a1a46445584aa" category="list-text">*Connettori Kafka Connect.*  I connettori utilizzano l'API Kafka Connect per connettere Kafka ad altri sistemi, quali database, archivi chiave-valore, indici di ricerca e file system.  Confluent Hub dispone di connettori scaricabili per le fonti e i sink di dati più diffusi, comprese versioni completamente testate e supportate di questi connettori con Confluent Platform.  Maggiori dettagli possono essere trovati<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block> .</block>
  <block id="9103a2961d6b4c593517d3d641763e5c" category="list-text">*Cluster autobilancianti.*  Fornisce bilanciamento automatico del carico, rilevamento degli errori e auto-riparazione.  Fornisce inoltre supporto per l'aggiunta o la disattivazione di broker in base alle necessità, senza necessità di ottimizzazione manuale.</block>
  <block id="776a13408286748f8c985c409604e8b6" category="list-text">*Collegamento di cluster confluenti.*  Collega direttamente i cluster tra loro e rispecchia gli argomenti da un cluster all'altro tramite un ponte di collegamento.  Il collegamento dei cluster semplifica la configurazione di distribuzioni multi-datacenter, multi-cluster e cloud ibride.</block>
  <block id="c1712fa040f6accce664a82ba6d58b94" category="list-text">*Bilanciatore automatico dei dati Confluent.*  Monitora il cluster per quanto riguarda il numero di broker, la dimensione delle partizioni, il numero di partizioni e il numero di leader all'interno del cluster.  Consente di spostare i dati per creare un carico di lavoro uniforme nel cluster, limitando al contempo il traffico di ribilanciamento per ridurre al minimo l'effetto sui carichi di lavoro di produzione durante il ribilanciamento.</block>
  <block id="0f97179e1bb10c15685ca78b035b4956" category="list-text">*Replicatore confluente.*  Rende più semplice che mai la gestione di più cluster Kafka in più data center.</block>
  <block id="a409602cf12dbcb436352a95146b6407" category="list-text">*Archiviazione a livelli.*  Offre opzioni per archiviare grandi volumi di dati Kafka utilizzando il tuo provider cloud preferito, riducendo così i costi e gli oneri operativi.  Grazie all'archiviazione a livelli, puoi conservare i dati su un archivio oggetti conveniente e utilizzare broker di scalabilità solo quando hai bisogno di più risorse di elaborazione.</block>
  <block id="ce61411f1780c30f58dd5aed90a77ad3" category="list-text">*Client JMS confluente.*  Confluent Platform include un client compatibile con JMS per Kafka.  Questo client Kafka implementa l'API standard JMS 1.1, utilizzando i broker Kafka come backend.  Questa funzionalità è utile se si dispone di applicazioni legacy che utilizzano JMS e si desidera sostituire il broker di messaggi JMS esistente con Kafka.</block>
  <block id="b38f5ff9be3975e499ba273a01035420" category="list-text">*Proxy MQTT confluente.*  Fornisce un modo per pubblicare dati direttamente su Kafka da dispositivi e gateway MQTT senza la necessità di un broker MQTT intermedio.</block>
  <block id="ab05a802c02076dd0f0b419529e71ccd" category="list-text">*Plugin di sicurezza Confluent.*  I plugin di sicurezza Confluent vengono utilizzati per aggiungere funzionalità di sicurezza a vari strumenti e prodotti della piattaforma Confluent.  Attualmente è disponibile un plugin per il proxy REST Confluent che aiuta ad autenticare le richieste in arrivo e a propagare il principal autenticato alle richieste a Kafka.  Ciò consente ai client proxy REST Confluent di utilizzare le funzionalità di sicurezza multitenant del broker Kafka.</block>
  <block id="55cf1a0f0fce69fd543500e5761dd26d" category="section-title">NetApp StorageGRID</block>
  <block id="d82d42ad0a2161d02e1d8ce74ffcf0ab" category="paragraph">NetApp StorageGRID è una piattaforma di storage di oggetti conveniente e ad alte prestazioni.  Utilizzando l'archiviazione a livelli, la maggior parte dei dati su Confluent Kafka, archiviati nell'archiviazione locale o nell'archiviazione SAN del broker, vengono scaricati nell'archivio oggetti remoto.  Questa configurazione comporta notevoli miglioramenti operativi riducendo i tempi e i costi per ribilanciare, espandere o ridurre i cluster o sostituire un broker guasto.  L'archiviazione di oggetti svolge un ruolo importante nella gestione dei dati che risiedono nel livello di archiviazione di oggetti, motivo per cui è importante scegliere l'archiviazione di oggetti giusta.</block>
  <block id="3fa5e29e13fc3b3448ca388750ef38f0" category="paragraph">StorageGRID offre una gestione intelligente dei dati globali basata su policy, utilizzando un'architettura grid distribuita basata su nodi.  Semplifica la gestione di petabyte di dati non strutturati e miliardi di oggetti attraverso il suo onnipresente spazio dei nomi degli oggetti globali combinato con sofisticate funzionalità di gestione dei dati.  L'accesso agli oggetti con una sola chiamata si estende su più siti e semplifica le architetture ad alta disponibilità, garantendo al contempo un accesso continuo agli oggetti, indipendentemente dalle interruzioni del sito o dell'infrastruttura.</block>
  <block id="30f28784f61df7a2f8e7069cefea91eb" category="paragraph">La multitenancy consente di gestire in modo sicuro più applicazioni cloud e dati aziendali non strutturati all'interno della stessa griglia, aumentando il ROI e i casi d'uso di NetApp StorageGRID.  È possibile creare più livelli di servizio con policy del ciclo di vita degli oggetti basate sui metadati, ottimizzando la durabilità, la protezione, le prestazioni e la località in più aree geografiche.  Gli utenti possono adattare le policy di gestione dei dati e monitorare e applicare limiti di traffico per riallinearsi al panorama dei dati senza interruzioni, man mano che le loro esigenze cambiano in ambienti IT in continua evoluzione.</block>
  <block id="dc10add739549f11a9f3d6ac44bf7fcc" category="section-title">Gestione semplice con Grid Manager</block>
  <block id="494ed2651e6b5b87a49cfe7ab40d5253" category="paragraph">StorageGRID Grid Manager è un'interfaccia grafica basata su browser che consente di configurare, gestire e monitorare il sistema StorageGRID in sedi distribuite a livello globale da un unico pannello di controllo.</block>
  <block id="772a64d9b71789d3f7910c440c370541" category="paragraph"><block ref="772a64d9b71789d3f7910c440c370541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3784ac64ff307aaceedbc4045a0d047c" category="paragraph">Con l'interfaccia di StorageGRID Grid Manager è possibile eseguire le seguenti attività:</block>
  <block id="57d56613e28a4b5b4e9f351d17e228f7" category="list-text">Gestisci repository di oggetti quali immagini, video e record distribuiti a livello globale, su scala petabyte.</block>
  <block id="5865c6ada208cf4e21f121f0d367b25a" category="list-text">Monitorare i nodi e i servizi della griglia per garantire la disponibilità degli oggetti.</block>
  <block id="e21286be18c417a3042cb53e1dd1e8da" category="list-text">Gestire il posizionamento dei dati degli oggetti nel tempo utilizzando le regole di gestione del ciclo di vita delle informazioni (ILM).  Queste regole stabiliscono cosa accade ai dati di un oggetto dopo che sono stati acquisiti, come vengono protetti dalla perdita, dove vengono archiviati i dati dell'oggetto e per quanto tempo.</block>
  <block id="5c578eee23496659cea7dda27021c318" category="list-text">Monitorare le transazioni, le prestazioni e le operazioni all'interno del sistema.</block>
  <block id="c91fcac1d7192250f9c73d72ad06e051" category="section-title">Politiche di gestione del ciclo di vita delle informazioni</block>
  <block id="0550f1f7df7311673165b9915b4d10b2" category="paragraph">StorageGRID dispone di policy di gestione dei dati flessibili che includono la conservazione di copie replicate degli oggetti e l'utilizzo di schemi EC (erasure coding) come 2+1 e 4+2 (tra gli altri) per archiviare gli oggetti, a seconda dei requisiti specifici di prestazioni e protezione dei dati.  Poiché i carichi di lavoro e i requisiti cambiano nel tempo, è normale che anche le policy ILM debbano cambiare nel tempo.  La modifica delle policy ILM è una funzionalità fondamentale che consente ai clienti StorageGRID di adattarsi in modo rapido e semplice al loro ambiente in continua evoluzione.</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">Prestazione</block>
  <block id="356760a65d5411f2c9f8647f90e50978" category="inline-link-macro">SG5712, SG5760, SG6060 o SGF6024</block>
  <block id="2ec930774314e7709987603c82825f4b" category="paragraph">StorageGRID aumenta le prestazioni aggiungendo più nodi di storage, che possono essere VM, bare metal o appliance appositamente realizzate come<block ref="585d6d5337b82c3c73a6c04b53fcdd23" category="inline-link-macro-rx"></block> .  Nei nostri test abbiamo superato i requisiti di prestazioni chiave di Apache Kafka con una griglia di tre nodi di dimensioni minime utilizzando l'appliance SGF6024.  Man mano che i clienti ampliano il loro cluster Kafka con broker aggiuntivi, possono aggiungere più nodi di archiviazione per aumentare prestazioni e capacità.</block>
  <block id="3eee81ca69cbbee2bec24db63e4dea0d" category="section-title">Configurazione del bilanciatore del carico e degli endpoint</block>
  <block id="5b42fd120a40ecd7cc8ac5cdedde8ceb" category="paragraph">I nodi amministrativi in StorageGRID forniscono l'interfaccia utente (UI) di Grid Manager e l'endpoint API REST per visualizzare, configurare e gestire il sistema StorageGRID , nonché registri di controllo per monitorare l'attività del sistema.  Per fornire un endpoint S3 ad alta disponibilità per l'archiviazione a livelli Confluent Kafka, abbiamo implementato il bilanciatore del carico StorageGRID , che viene eseguito come servizio sui nodi di amministrazione e sui nodi gateway.  Inoltre, il bilanciatore del carico gestisce anche il traffico locale e comunica con il GSLB (Global Server Load Balancing) per facilitare il ripristino in caso di emergenza.</block>
  <block id="95ae2f11a98975eca88411c818226d25" category="paragraph">Per migliorare ulteriormente la configurazione degli endpoint, StorageGRID fornisce criteri di classificazione del traffico integrati nel nodo di amministrazione, consente di monitorare il traffico del carico di lavoro e applica vari limiti di qualità del servizio (QoS) ai carichi di lavoro.  I criteri di classificazione del traffico vengono applicati agli endpoint del servizio StorageGRID Load Balancer per i nodi gateway e i nodi amministrativi.  Queste politiche possono aiutare a modellare e monitorare il traffico.</block>
  <block id="dca5165744ce2dbf5825f022349ee941" category="section-title">Classificazione del traffico in StorageGRID</block>
  <block id="588db6e460515c5268204303c93a770b" category="paragraph">StorageGRID ha funzionalità QoS integrate.  Le policy di classificazione del traffico possono aiutare a monitorare diversi tipi di traffico S3 provenienti da un'applicazione client.  È quindi possibile creare e applicare policy per limitare questo traffico in base alla larghezza di banda in entrata/uscita, al numero di richieste di lettura/scrittura simultanee o alla velocità delle richieste di lettura/scrittura.</block>
  <block id="75dab812558989436263375877a82fb6" category="paragraph">Apache Kafka è un framework di implementazione di un bus software che utilizza l'elaborazione di flussi, scritto in Java e Scala.  Il suo scopo è fornire una piattaforma unificata, ad alta produttività e bassa latenza per la gestione di feed di dati in tempo reale.  Kafka può connettersi a un sistema esterno per l'esportazione e l'importazione di dati tramite Kafka Connect e fornisce Kafka streams, una libreria di elaborazione di flussi Java.  Kafka utilizza un protocollo binario basato su TCP, ottimizzato per l'efficienza e basato su un'astrazione di "set di messaggi" che raggruppa naturalmente i messaggi per ridurre il sovraccarico del roundtrip di rete.  Ciò consente operazioni sequenziali su disco più grandi, pacchetti di rete più grandi e blocchi di memoria contigui, consentendo così a Kafka di trasformare un flusso continuo di scritture di messaggi casuali in scritture lineari.  La figura seguente illustra il flusso di dati di base di Apache Kafka.</block>
  <block id="3c061e9fbf92872063da256279195fbb" category="paragraph"><block ref="3c061e9fbf92872063da256279195fbb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c50889322e9d7d913a4218be06b94d9d" category="paragraph">Kafka memorizza messaggi chiave-valore provenienti da un numero arbitrario di processi chiamati produttori.  I dati possono essere suddivisi in diverse partizioni all'interno di argomenti diversi.  All'interno di una partizione, i messaggi vengono ordinati rigorosamente in base ai loro offset (la posizione di un messaggio all'interno di una partizione) e indicizzati e archiviati insieme a un timestamp.  Altri processi chiamati consumatori possono leggere i messaggi dalle partizioni.  Per l'elaborazione dei flussi, Kafka offre l'API Streams che consente di scrivere applicazioni Java che utilizzano dati da Kafka e scrivono i risultati in Kafka.  Apache Kafka funziona anche con sistemi di elaborazione di flussi esterni come Apache Apex, Apache Flink, Apache Spark, Apache Storm e Apache NiFi.</block>
  <block id="0f13dfad626acfc5a84f5c6d8127cb93" category="paragraph">Kafka viene eseguito su un cluster di uno o più server (chiamati broker) e le partizioni di tutti gli argomenti sono distribuite tra i nodi del cluster.  Inoltre, le partizioni vengono replicate su più broker.  Questa architettura consente a Kafka di distribuire flussi massivi di messaggi in modalità fault-tolerant e gli ha permesso di sostituire alcuni dei sistemi di messaggistica convenzionali come Java Message Service (JMS), Advanced Message Queuing Protocol (AMQP) e così via.  A partire dalla versione 0.11.0.0, Kafka offre scritture transazionali, che forniscono l'elaborazione di flussi esattamente una volta utilizzando l'API Streams.</block>
  <block id="a05ab89a0e70d8932f92ff5626b80205" category="paragraph">Kafka supporta due tipi di argomenti: regolari e compattati.  Gli argomenti regolari possono essere configurati con un limite di tempo di conservazione o di spazio.  Se sono presenti record più vecchi del tempo di conservazione specificato o se viene superato il limite di spazio per una partizione, Kafka può eliminare i vecchi dati per liberare spazio di archiviazione.  Per impostazione predefinita, gli argomenti sono configurati con un tempo di conservazione di 7 giorni, ma è anche possibile archiviare i dati a tempo indeterminato.  Per gli argomenti compattati, i record non scadono in base a limiti di tempo o di spazio.  Kafka, invece, tratta i messaggi successivi come aggiornamenti di messaggi più vecchi con la stessa chiave e garantisce di non eliminare mai l'ultimo messaggio per chiave.  Gli utenti possono eliminare completamente i messaggi scrivendo un cosiddetto messaggio tombstone con il valore null per una chiave specifica.</block>
  <block id="67510baee28b6897f23f317ea0eec6cd" category="paragraph">Ci sono cinque API principali in Kafka:</block>
  <block id="43437be1fd3e6788160e377194164ab4" category="list-text">*API del produttore.*  Consente a un'applicazione di pubblicare flussi di record.</block>
  <block id="d4814db3c767fa7cb8ef858faeb32012" category="list-text">*API per i consumatori.*  Consente a un'applicazione di iscriversi ad argomenti ed elaborare flussi di record.</block>
  <block id="8e4e76f717f8e282710dbe0549551bbc" category="list-text">*API del connettore.*  Esegue le API riutilizzabili del produttore e del consumatore che possono collegare gli argomenti alle applicazioni esistenti.</block>
  <block id="32a74767220f0fd870d75199524522d5" category="list-text">*API Stream.*  Questa API converte i flussi di input in output e produce il risultato.</block>
  <block id="4bb47a81bc800e1fb57bdde2d0945599" category="list-text">*API di amministrazione.*  Utilizzato per gestire argomenti Kafka, broker e altri oggetti Kafka.</block>
  <block id="610121f784783393f66b6624cf93dafb" category="paragraph">Le API consumer e producer si basano sul protocollo di messaggistica Kafka e offrono un'implementazione di riferimento per i client consumer e producer Kafka in Java.  Il protocollo di messaggistica sottostante è un protocollo binario che gli sviluppatori possono utilizzare per scrivere i propri client consumer o producer in qualsiasi linguaggio di programmazione.  Ciò sblocca Kafka dall'ecosistema Java Virtual Machine (JVM).  Un elenco dei client non Java disponibili è disponibile nel wiki di Apache Kafka.</block>
  <block id="3b85a5b4b78ed5de8ac5389862ce3d3f" category="section-title">Casi d'uso di Apache Kafka</block>
  <block id="21f595a264810e4537696c1280efad57" category="paragraph">Apache Kafka è particolarmente diffuso per la messaggistica, il monitoraggio delle attività sui siti web, le metriche, l'aggregazione dei log, l'elaborazione dei flussi, l'event sourcing e la registrazione degli commit.</block>
  <block id="60f50b920903b4049f776062aa5e6cdc" category="list-text">Kafka ha migliorato la produttività, ha integrato il partizionamento, la replica e la tolleranza agli errori, il che lo rende una buona soluzione per applicazioni di elaborazione dei messaggi su larga scala.</block>
  <block id="0ae69072c472e595412163a07084932c" category="list-text">Kafka può ricostruire le attività di un utente (visualizzazioni di pagina, ricerche) in una pipeline di monitoraggio come un insieme di feed di pubblicazione-sottoscrizione in tempo reale.</block>
  <block id="6d9673a2fe148c529c3b2051cfe93896" category="list-text">Kafka viene spesso utilizzato per i dati di monitoraggio operativo.  Ciò comporta l'aggregazione di statistiche provenienti da applicazioni distribuite per produrre feed centralizzati di dati operativi.</block>
  <block id="8b8951c427cfdc3f095bb9d556dce00e" category="list-text">Molte persone utilizzano Kafka come sostituto di una soluzione di aggregazione dei log.  L'aggregazione dei log in genere raccoglie i file di log fisici dai server e li colloca in un luogo centrale (ad esempio, un file server o HDFS) per l'elaborazione.  Kafka astrae i dettagli dei file e fornisce un'astrazione più pulita dei dati di log o di eventi come flusso di messaggi.  Ciò consente un'elaborazione a bassa latenza e un supporto più semplice per più fonti di dati e un consumo di dati distribuito.</block>
  <block id="e9b95314420c3704f19bfa0e922f51d1" category="list-text">Molti utenti di Kafka elaborano i dati in pipeline di elaborazione costituite da più fasi, in cui i dati di input grezzi vengono utilizzati dagli argomenti di Kafka e quindi aggregati, arricchiti o altrimenti trasformati in nuovi argomenti per un ulteriore utilizzo o un'elaborazione successiva.  Ad esempio, una pipeline di elaborazione per consigliare articoli di notizie potrebbe analizzare il contenuto degli articoli dai feed RSS e pubblicarlo in un argomento "articoli".  Un'ulteriore elaborazione potrebbe normalizzare o deduplicare questo contenuto e pubblicare il contenuto dell'articolo ripulito in un nuovo argomento; una fase di elaborazione finale potrebbe tentare di consigliare questo contenuto agli utenti.  Tali pipeline di elaborazione creano grafici di flussi di dati in tempo reale basati sui singoli argomenti.</block>
  <block id="f2bf506d0e67708783f1bc5c0b518527" category="list-text">L'event souring è uno stile di progettazione delle applicazioni in cui le modifiche di stato vengono registrate come una sequenza di record ordinata nel tempo.  Il supporto di Kafka per dati di log memorizzati di grandi dimensioni lo rende un backend eccellente per un'applicazione creata in questo stile.</block>
  <block id="6a4fef92874e37e1418ff91ed4fda9cd" category="list-text">Kafka può fungere da una sorta di registro di commit esterno per un sistema distribuito.  Il registro aiuta a replicare i dati tra i nodi e funge da meccanismo di risincronizzazione per i nodi non riusciti per ripristinare i propri dati.  La funzionalità di compattazione dei log in Kafka aiuta a supportare questo caso d'uso.</block>
  <block id="ca010f92402f8d9066224231329f1128" category="paragraph">Confluent Platform è una piattaforma pronta per le aziende che completa Kafka con funzionalità avanzate progettate per accelerare lo sviluppo e la connettività delle applicazioni, abilitare le trasformazioni tramite l'elaborazione in streaming, semplificare le operazioni aziendali su larga scala e soddisfare rigorosi requisiti architettonici.  Sviluppato dai creatori originali di Apache Kafka, Confluent amplia i vantaggi di Kafka con funzionalità di livello aziendale, eliminando al contempo l'onere della gestione o del monitoraggio di Kafka.  Oggi, oltre l'80% delle aziende Fortune 100 si avvale della tecnologia di streaming dei dati e la maggior parte di queste utilizza Confluent.</block>
  <block id="6b41836f6be8bfff401751859b6f5561" category="paragraph">Confluent Platform ti consente di concentrarti su come ricavare valore aziendale dai tuoi dati anziché preoccuparti dei meccanismi sottostanti, ad esempio come i dati vengono trasportati o integrati tra sistemi diversi.  Nello specifico, Confluent Platform semplifica la connessione delle fonti di dati a Kafka, la creazione di applicazioni di streaming, nonché la protezione, il monitoraggio e la gestione dell'infrastruttura Kafka.  Oggi, Confluent Platform viene utilizzata per un'ampia gamma di casi d'uso in numerosi settori, dai servizi finanziari, alla vendita al dettaglio omnicanale e alle auto autonome, fino al rilevamento delle frodi, ai microservizi e all'IoT.</block>
  <block id="774f9746d58ac38abf733a92e4720365" category="paragraph">La figura seguente mostra i componenti della piattaforma Confluent Kafka.</block>
  <block id="4f93c36b7d83350cef38a27356c0d5c9" category="paragraph"><block ref="4f93c36b7d83350cef38a27356c0d5c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95577831087dbd899deb60b296f64a9c" category="section-title">Panoramica della tecnologia di streaming degli eventi di Confluent</block>
  <block id="f6d3df755e538ab85e1dffe4e2ef9966" category="paragraph">Il cuore della piattaforma Confluent è<block ref="67718c59f00d7d04e4868dff5b37db2b" category="inline-link-rx"></block> , la piattaforma di streaming distribuita open source più popolare.  Le principali capacità di Kafka sono le seguenti:</block>
  <block id="8da3f3354457b244e53f1423a77e8944" category="section-title">Panoramica delle funzionalità aziendali della piattaforma Confluent</block>
  <block id="c7d070206c9b11b02bee9b591736971c" category="list-text">*Centro di controllo confluente.*  Un sistema basato su GUI per la gestione e il monitoraggio di Kafka.  Consente di gestire facilmente Kafka Connect e di creare, modificare e gestire connessioni ad altri sistemi.</block>
  <block id="5488a6660d4f7d32995b983624c2e915" category="list-text">*Connettori confluenti con Kafka.*  I connettori utilizzano l'API Kafka Connect per connettere Kafka ad altri sistemi, quali database, archivi chiave-valore, indici di ricerca e file system.  Confluent Hub dispone di connettori scaricabili per le fonti e i sink di dati più diffusi, comprese versioni completamente testate e supportate di questi connettori con Confluent Platform.  Maggiori dettagli possono essere trovati<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block> .</block>
  <block id="b47dc18271c0f29d64ce1f45f12a053c" category="list-text">*Cluster autobilancianti.*  Fornisce bilanciamento automatico del carico, rilevamento degli errori e auto-riparazione.  Fornisce supporto per l'aggiunta o la disattivazione di broker in base alle necessità, senza necessità di ottimizzazione manuale.</block>
  <block id="1e5c2c1a7b1c3f9809e2b97438773325" category="list-text">*Bilanciatore automatico dei dati Confluent.*  Monitora il cluster per quanto riguarda il numero di broker, la dimensione delle partizioni, il numero di partizioni e il numero di leader all'interno del cluster.  Consente di spostare i dati per creare un carico di lavoro uniforme nel cluster, limitando al contempo il traffico di ribilanciamento per ridurre al minimo l'effetto sui carichi di lavoro di produzione durante il ribilanciamento.</block>
  <block id="e2e44d09263d2131a3697ad71cadb51b" category="doc">NVA-1157-DEPLOY: carico di lavoro Apache Spark con soluzione di storage NetApp</block>
  <block id="ddf79baf38c476a90774aad122f73cb5" category="paragraph">NVA-1157-DEPLOY descrive la convalida delle prestazioni e delle funzionalità di Apache Spark SQL sui sistemi di archiviazione NetApp NFS AFF .  Esamina la configurazione, l'architettura e i test delle prestazioni in base a vari scenari, nonché i consigli per l'utilizzo di Spark con il software di gestione dati NetApp ONTAP .  Vengono inoltre analizzati i risultati dei test basati su un gruppo di dischi (JBOD) rispetto al controller di storage NetApp AFF A800 .</block>
  <block id="39234cd00ad225afa457b33c5b2c5957" category="paragraph"><block ref="39234cd00ad225afa457b33c5b2c5957" category="inline-link-macro-rx"></block></block>
  <block id="6a67053961e2b9d7e16bf757a5bea347" category="doc">Analisi dei dati moderna: diverse soluzioni per diverse strategie di analisi</block>
  <block id="139dc952e7e6df2bb7d8000f47a42232" category="paragraph">Questo white paper descrive le strategie delle soluzioni di analisi dei dati moderne NetApp .  Include dettagli sui risultati aziendali, le sfide dei clienti, le tendenze tecnologiche, l'architettura legacy della concorrenza, i flussi di lavoro moderni, i casi d'uso, i settori, il cloud, i partner tecnologici, i data mover, NetApp Active IQ Digital Advisor (noto anche come Digital Advisor), NetApp DataOps Toolkit, da Hadoop a Spark, lo storage definito dal software con NetApp Trident Protect, i container, la gestione dei dati aziendali, l'archiviazione e la suddivisione in livelli per raggiungere gli obiettivi di intelligenza artificiale e analisi e come NetApp e i clienti insieme stanno modernizzando la loro architettura dati.</block>
  <block id="9a13b1875b1cf906383834093477aa0b" category="paragraph"><block ref="9a13b1875b1cf906383834093477aa0b" category="inline-link-macro-rx"></block></block>
  <block id="b5062caa115b4047ecd2ef0d7177923b" category="paragraph">In questo TR sono stati utilizzati i seguenti riferimenti:</block>
  <block id="7a5b516d0c7b523466aabf4d65c5920e" category="list-text">Architettura e componenti di Apache Spark</block>
  <block id="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link"><block ref="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link-rx"></block></block>
  <block id="e37c2ea27f7286c4bd6a5fda415b8de8" category="paragraph"><block ref="e37c2ea27f7286c4bd6a5fda415b8de8" category="inline-link-rx"></block></block>
  <block id="63e2d6091a94e7952a98f50aab0149ce" category="list-text">Casi d'uso di Apache Spark</block>
  <block id="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link"><block ref="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link-rx"></block></block>
  <block id="7bc4162d3088ec5f539bb8bccd911d30" category="paragraph"><block ref="7bc4162d3088ec5f539bb8bccd911d30" category="inline-link-rx"></block></block>
  <block id="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link"><block ref="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link-rx"></block></block>
  <block id="4f2faa20c7d825b4d0501e1086305aac" category="paragraph"><block ref="4f2faa20c7d825b4d0501e1086305aac" category="inline-link-rx"></block></block>
  <block id="221c3eff38f8ab54d359694f9da63c6e" category="list-text">BERT</block>
  <block id="94f39b7b282094c13473d8b26a45d1f1" category="inline-link"><block ref="94f39b7b282094c13473d8b26a45d1f1" category="inline-link-rx"></block></block>
  <block id="aff4ff24147d7c4a2645c7781e081f7f" category="paragraph"><block ref="aff4ff24147d7c4a2645c7781e081f7f" category="inline-link-rx"></block></block>
  <block id="b507f78e88e67a8302f19d731bc75b06" category="list-text">Rete profonda e incrociata per le previsioni sui clic sugli annunci</block>
  <block id="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link"><block ref="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link-rx"></block></block>
  <block id="ae454d032cd3c53237c03ee439566905" category="paragraph"><block ref="ae454d032cd3c53237c03ee439566905" category="inline-link-rx"></block></block>
  <block id="54452390cac5f65f3bcec580ba079531" category="list-text">FlexGroup</block>
  <block id="63e6562f5c9bc7c86f115b960762e586" category="paragraph"><block ref="63e6562f5c9bc7c86f115b960762e586" category="inline-link-rx"></block></block>
  <block id="becd6832ca6f3b6680d480b5802d1435" category="list-text">Streaming ETL</block>
  <block id="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link"><block ref="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link-rx"></block></block>
  <block id="8d325f57229e685a7ad47c71dd567604" category="paragraph"><block ref="8d325f57229e685a7ad47c71dd567604" category="inline-link-rx"></block></block>
  <block id="31a31ad34b829349beab62dc154bb53c" category="list-text">Soluzioni NetApp E-Series per Hadoop</block>
  <block id="7cc9f35180bb40054e46d3046347f4fd" category="inline-link"><block ref="7cc9f35180bb40054e46d3046347f4fd" category="inline-link-rx"></block></block>
  <block id="ea07fc98557e1b8c5b675972fe1621da" category="paragraph"><block ref="ea07fc98557e1b8c5b675972fe1621da" category="inline-link-rx"></block></block>
  <block id="3f7d09efe0b4d4a65add41ac272194fd" category="list-text">Soluzioni di analisi dei dati moderni NetApp</block>
  <block id="105db1e1e5e90ed75dc22390638d6b74" category="inline-link-macro">Soluzioni di analisi dei dati</block>
  <block id="a1acc25bb8d463a22c069a9ae3d7a581" category="paragraph"><block ref="a1acc25bb8d463a22c069a9ae3d7a581" category="inline-link-macro-rx"></block></block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="list-text">SnapMirror</block>
  <block id="c932e562e101240deed6e4be0656dfd6" category="inline-link"><block ref="c932e562e101240deed6e4be0656dfd6" category="inline-link-rx"></block></block>
  <block id="750daab11890513d7529766b651ae531" category="paragraph"><block ref="750daab11890513d7529766b651ae531" category="inline-link-rx"></block></block>
  <block id="a7ac1d2e69b9bbb9a2accb2ec30a1d69" category="list-text">XCP</block>
  <block id="e7d54d48522774aa8774f3733414d084" category="inline-link"><block ref="f575d0e12f7a285daadcaf60a35e305e" category="inline-link-rx"></block></block>
  <block id="a0b810672fcf48d5064bdbf73f520d55" category="paragraph"><block ref="d41dfcb87efb2171f45941c801c9f5cc" category="inline-link-rx"></block></block>
  <block id="1ae50adfec05c416d0398e26bea5fc01" category="list-text">BlueXP Copia e Sincronizza</block>
  <block id="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link"><block ref="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link-rx"></block></block>
  <block id="b8cfbcc5c9748a8f12142a1b9aae0e67" category="paragraph"><block ref="b8cfbcc5c9748a8f12142a1b9aae0e67" category="inline-link-rx"></block></block>
  <block id="ce9b5cd96205262213c417b501e9ed55" category="list-text">Kit di strumenti DataOps</block>
  <block id="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link"><block ref="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link-rx"></block></block>
  <block id="20a0f3ab42054c3aa4add8c8901b4aa9" category="paragraph"><block ref="20a0f3ab42054c3aa4add8c8901b4aa9" category="inline-link-rx"></block></block>
  <block id="fd79b6614eaf33c0131b98cf6d33aef4" category="summary">Questa pagina descrive in modo più dettagliato i principali casi d'uso e le architetture di intelligenza artificiale, apprendimento automatico e apprendimento automatico (IA), nonché le relative applicazioni.</block>
  <block id="029e93fe56123e362c90a853d36c91c9" category="doc">Principali casi d'uso e architetture di intelligenza artificiale, apprendimento automatico e apprendimento automatico (DL)</block>
  <block id="38fe3ee7a8452539638ebb43094bf303" category="paragraph">I principali casi d'uso e la metodologia di intelligenza artificiale, apprendimento automatico e apprendimento digitale possono essere suddivisi nelle seguenti sezioni:</block>
  <block id="28ab286fd15a84ffcfa82ffe262b2d07" category="section-title">Pipeline Spark NLP e inferenza distribuita TensorFlow</block>
  <block id="b66d8859b0ca8adab0c5459ef44ed90c" category="paragraph">L'elenco seguente contiene le librerie NLP open source più diffuse, adottate dalla comunità della scienza dei dati a diversi livelli di sviluppo:</block>
  <block id="357d19386660ae0694f2fa195678b61a" category="inline-link">Kit di strumenti per il linguaggio naturale (NLTK)</block>
  <block id="b7c0dd146600af70e881dce2c233cdb9" category="list-text"><block ref="202d1986e5208977bf54b6b767767c39" category="inline-link-rx"></block> . Il kit completo per tutte le tecniche di PNL.  È stato mantenuto fin dai primi anni del 2000.</block>
  <block id="76e3c26aea345cd63928dae30c7683b8" category="inline-link">TextBlob</block>
  <block id="9733a294c2e8cbac3f50f2b1c6165ac9" category="list-text"><block ref="29dbbb204c6bb7c5433e577a001773ba" category="inline-link-rx"></block> . Un'API Python di strumenti NLP di facile utilizzo, basata su NLTK e Pattern.</block>
  <block id="b8dc45aaa0db9ddabebf51171beed13a" category="inline-link">Stanford Core NLP</block>
  <block id="e566a3c30415cf2003b1ae965e897b0c" category="list-text"><block ref="3aea58940b1efe70ecaf2254ccc89f1e" category="inline-link-rx"></block> . Servizi e pacchetti NLP in Java sviluppati dallo Stanford NLP Group.</block>
  <block id="7013def92af3dd7db98d1285170b5c5a" category="inline-link">Gensim</block>
  <block id="f669b3f1322541dcae0edc94f45435ac" category="list-text"><block ref="7b679f834cae0cff7425a8dc62e2ec2e" category="inline-link-rx"></block> . Topic Modelling for Humans è nato come una raccolta di script Python per il progetto Czech Digital Mathematics Library.</block>
  <block id="2840ef6b507856e3306a32ffe28a8886" category="inline-link">SpaCy</block>
  <block id="418cc23cee80079d8aa2ccd37169bfc0" category="list-text"><block ref="bc5121a0541ff390725a7d480b19b87f" category="inline-link-rx"></block> . Flussi di lavoro NLP industriali end-to-end con Python e Cython con accelerazione GPU per trasformatori.</block>
  <block id="e0b205fce51b69be7136044a22a371ab" category="inline-link">Testo veloce</block>
  <block id="c3ad48f357ddb1f4eb538b483e904fbe" category="list-text"><block ref="53fd0bea11d98e3b7893bc4fbf501c85" category="inline-link-rx"></block> . Una libreria NLP gratuita, leggera e open source per l'apprendimento di incorporamenti di parole e la classificazione di frasi, creata dal laboratorio AI Research (FAIR) di Facebook.</block>
  <block id="12680128425c827ef65d76f354329e97" category="inline-link">Spark ML</block>
  <block id="16cbab2d9cd08ef0822a3f68f3792982" category="paragraph">Spark NLP è una soluzione unica e unificata per tutte le attività e i requisiti NLP che consente di realizzare un software NLP scalabile, ad alte prestazioni e ad alta precisione per casi d'uso di produzione reali.  Sfrutta l'apprendimento per trasferimento e implementa gli algoritmi e i modelli più all'avanguardia nella ricerca e in tutti i settori.  A causa della mancanza di supporto completo da parte di Spark per le librerie di cui sopra, Spark NLP è stato costruito su<block ref="3b3cfa486b6d50798f20e9b1ded08f31" category="inline-link-rx"></block> per sfruttare il motore di elaborazione dati distribuito in memoria di Spark per uso generico come libreria NLP di livello aziendale per flussi di lavoro di produzione mission-critical.  I suoi annotatori utilizzano algoritmi basati su regole, apprendimento automatico e TensorFlow per potenziare le implementazioni di deep learning.  Ciò comprende attività NLP comuni, tra cui, a titolo esemplificativo ma non esaustivo, tokenizzazione, lemmatizzazione, stemming, tagging delle parti del discorso, riconoscimento di entità denominate, controllo ortografico e analisi del sentiment.</block>
  <block id="5f29df192bff436cf72d454f30a968c1" category="paragraph">BERT (Bidirectional Encoder Representations from Transformers) è una tecnica di apprendimento automatico basata sui trasformatori per l'elaborazione del linguaggio naturale.  Ha reso popolare il concetto di pre-addestramento e messa a punto.  L'architettura del trasformatore in BERT ha avuto origine dalla traduzione automatica, che modella le dipendenze a lungo termine meglio dei modelli linguistici basati sulle reti neurali ricorrenti (RNN).  Ha inoltre introdotto il task Masked Language Modelling (MLM), in cui un numero casuale del 15% di tutti i token viene mascherato e il modello li prevede, consentendo una vera bidirezionalità.</block>
  <block id="f12fa7d8a39cc8394ad5dfb1afe14bee" category="inline-link">Reuters TRC2</block>
  <block id="3795ebdf5b8232c65a11ceced659b1d5" category="inline-link">Financial PhraseBank</block>
  <block id="189f0cc22e5920c5fbe48e7f7a384fa4" category="inline-link">Spiega il documento DL</block>
  <block id="75396b8f8501a234110f5c2b41e8f2c1" category="paragraph">L'analisi del sentiment finanziario è complessa a causa del linguaggio specialistico e della mancanza di dati specifici in tale ambito.  FinBERT, un modello linguistico basato su BERT preaddestrato, è stato adattato al dominio<block ref="a21d1b93ad8a312fcc9c56c81567ecca" category="inline-link-rx"></block> , un corpus finanziario, e perfezionato con dati etichettati (<block ref="14fa31c8eadcc29b01046706cfe3add5" category="inline-link-rx"></block> ) per la classificazione del sentiment finanziario.  I ricercatori hanno estratto 4.500 frasi da articoli di giornale contenenti termini finanziari.  Successivamente, 16 esperti e studenti magistrali con formazione in finanza hanno etichettato le frasi come positive, neutre e negative.  Abbiamo creato un flusso di lavoro Spark end-to-end per analizzare il sentiment delle trascrizioni delle call sugli utili delle 10 principali società del NASDAQ dal 2016 al 2020 utilizzando FinBERT e altre due pipeline pre-addestrate,<block ref="520f5e4ba9970dad735654cb1f0d1138" category="inline-link-rx"></block> ) da Spark NLP.</block>
  <block id="026dcbbbfad27f6209a41e9dab2f3aed" category="paragraph">Il motore di apprendimento profondo alla base di Spark NLP è TensorFlow, una piattaforma end-to-end open source per l'apprendimento automatico che consente una facile creazione di modelli, una solida produzione di ML ovunque e una potente sperimentazione per la ricerca.  Pertanto, quando eseguiamo le nostre pipeline in Spark<block ref="cbfea9758df7100c6471e30d3f36d3e1" prefix=" " category="inline-code"></block> modalità, stavamo essenzialmente eseguendo TensorFlow distribuito con parallelizzazione di dati e modelli su un master e più nodi worker, nonché storage collegato alla rete montato sul cluster.</block>
  <block id="159bdf3f5d37e56033c6c1736f86b085" category="section-title">Formazione distribuita Horovod</block>
  <block id="7a2c7ce5896a9e74083af4e2048bb5a8" category="inline-link">Soluzione NetApp E-Series per Hadoop</block>
  <block id="bd3eac2bb98f840c3e8ec0d92eb9a66f" category="paragraph">La convalida principale di Hadoop per le prestazioni correlate a MapReduce viene eseguita con TeraGen, TeraSort, TeraValidate e DFSIO (lettura e scrittura).  I risultati della convalida TeraGen e TeraSort sono presentati in<block ref="c276ecb51e19896948b1464a39a504e4" category="inline-link-rx"></block> e nella sezione "Storage Tiering" per AFF.</block>
  <block id="2c41734dc7928bdea8c2eab845ad7074" category="inline-link">Hovorod su Spark</block>
  <block id="7509c08cb8b336b99de5f0cd33f545fd" category="paragraph">In base alle richieste dei clienti, riteniamo che la formazione distribuita con Spark sia uno dei casi d'uso più importanti.  In questo documento abbiamo utilizzato il<block ref="e46884ff7ae14dc4a4c2907aa0145199" category="inline-link-rx"></block> per convalidare le prestazioni di Spark con soluzioni NetApp on-premise, cloud-native e cloud ibride utilizzando i controller di archiviazione NetApp All Flash FAS (AFF), Azure NetApp Files e StorageGRID.</block>
  <block id="57b5eacba6da62ec21ea18f95421ef6b" category="paragraph">Il pacchetto Horovod su Spark fornisce un comodo wrapper attorno a Horovod che semplifica l'esecuzione di carichi di lavoro di formazione distribuiti nei cluster Spark, consentendo un ciclo di progettazione del modello rigoroso in cui l'elaborazione dei dati, la formazione del modello e la valutazione del modello vengono eseguite tutte in Spark, dove risiedono i dati di formazione e inferenza.</block>
  <block id="e556cc2b256f6dd2bbe1cdfdb528c858" category="inline-link">Vendite del negozio Kaggle Rossmann</block>
  <block id="f2280eb8ac361218b35f9fc97d4027b4" category="paragraph">Sono disponibili due API per eseguire Horovod su Spark: un'API Estimator di alto livello e un'API Run di basso livello.  Sebbene entrambi utilizzino lo stesso meccanismo di base per avviare Horovod sugli esecutori Spark, l'API Estimator astrae l'elaborazione dei dati, il ciclo di addestramento del modello, il checkpointing del modello, la raccolta delle metriche e l'addestramento distribuito.  Abbiamo utilizzato Horovod Spark Estimators, TensorFlow e Keras per una preparazione dei dati end-to-end e un flusso di lavoro di formazione distribuito basato su<block ref="d30b6f4a07a765f48b43dd15bf3bc8ea" category="inline-link-rx"></block> concorrenza.</block>
  <block id="85cbe9ee50d80a624a5aacb533195f44" category="paragraph">La sceneggiatura<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> può essere trovato nella sezione<block ref="b6cb6fe53e443d0379ed59c804a7a30d" category="inline-link-macro-rx"></block> Si compone di tre parti:</block>
  <block id="1e0ac520c0a0627793f8b0ca3703e8e1" category="list-text">La prima parte esegue vari passaggi di pre-elaborazione dei dati su un set iniziale di file CSV forniti da Kaggle e raccolti dalla community.  I dati di input vengono separati in un set di addestramento con un<block ref="13148717f8faa9037f37d28971dfc219" prefix=" " category="inline-code"></block> sottoinsieme e un set di dati di test.</block>
  <block id="80ee77d4db5b8f731e911e7c47803afa" category="list-text">La seconda parte definisce un modello Keras Deep Neural Network (DNN) con funzione di attivazione sigmoide logaritmica e un ottimizzatore Adam, ed esegue l'addestramento distribuito del modello utilizzando Horovod su Spark.</block>
  <block id="6c32e5a10a8b9f7e225e92b30c4eb494" category="list-text">La terza parte esegue una previsione sul set di dati di test utilizzando il modello migliore che riduce al minimo l'errore assoluto medio complessivo del set di convalida.  Quindi crea un file CSV di output.</block>
  <block id="091fa9121c047db1dd48c3e2ab5f3c91" category="inline-link-macro">Apprendimento automatico</block>
  <block id="4f57ef43a107778b9d34e7c8fabafb09" category="paragraph">Vedi la sezione<block ref="c54562cdac0f1ff9f8a09a53f27a34da" category="inline-link-macro-rx"></block> per vari risultati di confronto in fase di esecuzione.</block>
  <block id="840da3122eba37f84480a8dc769a8cc3" category="section-title">Apprendimento approfondito multi-worker con Keras per la previsione del CTR</block>
  <block id="d003b4f5bf1fc42082f5817cb6e961dc" category="paragraph">Grazie ai recenti progressi nelle piattaforme e nelle applicazioni di apprendimento automatico, molta attenzione è ora rivolta all'apprendimento su larga scala.  Il tasso di clic (CTR) è definito come il numero medio di clic per cento impressioni di annunci online (espresso in percentuale).  È ampiamente adottato come metrica chiave in vari settori verticali e casi d'uso, tra cui marketing digitale, vendita al dettaglio, e-commerce e fornitori di servizi.  Per maggiori dettagli sulle applicazioni di CTR e sui risultati delle prestazioni di formazione distribuita, vedere<block ref="7cd04747490b9545ba139688b057ed31" category="inline-link-macro-rx"></block> sezione.</block>
  <block id="45c832c8d01426bfb65d74b7c547ad0c" category="inline-link">Set di dati Criteo Terabyte Click Logs</block>
  <block id="be1115ec919e48805da898209ea2c15a" category="paragraph">In questo rapporto tecnico abbiamo utilizzato una variante del<block ref="1a19f40e7660b78c77663f74c89e1e7b" category="inline-link-rx"></block> (vedere TR-4904) per l'apprendimento profondo distribuito multi-worker utilizzando Keras per creare un flusso di lavoro Spark con modelli Deep e Cross Network (DCN), confrontando le sue prestazioni in termini di funzione di errore di perdita del registro con un modello di regressione logistica Spark ML di base.  DCN cattura in modo efficiente interazioni di caratteristiche efficaci di gradi limitati, apprende interazioni altamente non lineari, non richiede alcuna progettazione manuale delle caratteristiche o ricerche esaustive e ha un basso costo computazionale.</block>
  <block id="71b755d753dcdba2aeca91b65c167330" category="paragraph">I dati per i sistemi di raccomandazione su scala web sono per lo più discreti e categoriali, il che determina uno spazio di funzionalità ampio e sparso, che risulta difficile da esplorare.  Ciò ha limitato la maggior parte dei sistemi su larga scala a modelli lineari come la regressione logistica.  Tuttavia, per fare buone previsioni è fondamentale identificare le caratteristiche frequentemente predittive e allo stesso tempo esplorare le caratteristiche incrociate invisibili o rare.  I modelli lineari sono semplici, interpretabili e facili da scalare, ma hanno un potere espressivo limitato.</block>
  <block id="b5353aa08a1306ca5da9e3faacc66b15" category="paragraph">D'altro canto, è stato dimostrato che le caratteristiche incrociate sono significative nel migliorare l'espressività dei modelli.  Purtroppo, spesso è necessario un'ingegneria manuale delle funzionalità o una ricerca esaustiva per identificarle.  Generalizzare le interazioni tra caratteristiche invisibili è spesso difficile.  Utilizzando una rete neurale incrociata come DCN si evita l'ingegneria delle caratteristiche specifiche per un'attività, applicando esplicitamente l'incrocio delle caratteristiche in modo automatico.  La rete incrociata è composta da più strati, in cui il grado più elevato di interazioni è determinato in modo dimostrabile dalla profondità dello strato.  Ogni livello produce interazioni di ordine superiore basate su quelle esistenti e mantiene le interazioni dei livelli precedenti.</block>
  <block id="70725839e7d887ef6f8c815f325d4592" category="paragraph">Una rete neurale profonda (DNN) promette di catturare interazioni molto complesse tra le caratteristiche.  Tuttavia, rispetto a DCN, richiede quasi un ordine di grandezza in più di parametri, non è in grado di formare esplicitamente le caratteristiche incrociate e potrebbe non riuscire ad apprendere in modo efficiente alcuni tipi di interazioni delle caratteristiche.  La rete incrociata è efficiente in termini di memoria e facile da implementare.  L'addestramento congiunto dei componenti cross e DNN cattura in modo efficiente le interazioni delle caratteristiche predittive e garantisce prestazioni all'avanguardia sul set di dati Criteo CTR.</block>
  <block id="2c9e5f067c0c14c56aa757d792108648" category="inline-link">DeepCTR</block>
  <block id="c024a57f5a6b531b69123f5c78627fb9" category="paragraph">Un modello DCN inizia con uno strato di incorporamento e di impilamento, seguito da una rete incrociata e da una rete profonda in parallelo.  A loro volta, seguono uno strato di combinazione finale che unisce gli output delle due reti.  I dati di input possono essere un vettore con caratteristiche sparse e dense.  In Spark, le librerie contengono il tipo<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block> .  È quindi importante che gli utenti distinguano tra i due e facciano attenzione quando chiamano le rispettive funzioni e metodi.  Nei sistemi di raccomandazione su scala web come la previsione CTR, gli input sono per lo più caratteristiche categoriali, ad esempio<block ref="f296a99dd35f7e3e83183f98a62982bf" prefix=" " category="inline-code"></block> .  Tali caratteristiche sono spesso codificate come vettori one-hot, ad esempio,<block ref="05b38799fb2e84c83a72d68e1cb6ff67" prefix=" " category="inline-code"></block> .  Codifica one-hot (OHE) con<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block> è utile quando si ha a che fare con set di dati del mondo reale con vocabolari in continua evoluzione e crescita.  Abbiamo modificato gli esempi in<block ref="0be922124247f224cab64b030781eed7" category="inline-link-rx"></block> per elaborare vocabolari di grandi dimensioni, creando vettori di incorporamento nello strato di incorporamento e impilamento del nostro DCN.</block>
  <block id="565d2d07d9c220babb78adab27c2243a" category="inline-link">Set di dati sugli annunci display di Criteo</block>
  <block id="75253ebc28edb897ef33f95dd995dd58" category="paragraph">IL<block ref="8cb83117ecfa6e6678785dbda34d1999" category="inline-link-rx"></block> prevede il tasso di clic degli annunci.  Presenta 13 caratteristiche intere e 26 caratteristiche categoriali, in cui ogni categoria ha un'elevata cardinalità.  Per questo set di dati, un miglioramento di 0,001 nel logloss è praticamente significativo a causa delle grandi dimensioni dell'input.  Un piccolo miglioramento nella precisione delle previsioni per una vasta base di utenti può potenzialmente portare a un notevole aumento del fatturato di un'azienda.  Il set di dati contiene 11 GB di registri utente relativi a un periodo di 7 giorni, pari a circa 41 milioni di record.  Abbiamo usato Spark<block ref="26ef62452ce5167b94d9bf8e4552df44" prefix=" " category="inline-code"></block> per suddividere casualmente i dati per l'addestramento (80%), la convalida incrociata (10%) e il restante 10% per i test.</block>
  <block id="e871e132ed2e9c6d6213da57972adec1" category="paragraph">DCN è stato implementato su TensorFlow con Keras.  L'implementazione del processo di addestramento del modello con DCN si basa su quattro componenti principali:</block>
  <block id="18aca2eb061782e34fcc772d780e4327" category="list-text">*Elaborazione e incorporamento dei dati.*  Le caratteristiche a valore reale vengono normalizzate applicando una trasformata logaritmica.  Per le caratteristiche categoriali, incorporiamo le caratteristiche in vettori densi di dimensione 6×(cardinalità di categoria)1/4.  Concatenando tutti gli embedding si ottiene un vettore di dimensione 1026.</block>
  <block id="190befa8188b0e07126d23d7488e79e7" category="list-text">*Ottimizzazione.*  Abbiamo applicato l'ottimizzazione stocastica mini-batch con l'ottimizzatore Adam.  La dimensione del lotto è stata impostata su 512.  La normalizzazione batch è stata applicata alla rete profonda e la norma di clip del gradiente è stata impostata a 100.</block>
  <block id="023b8b252258fa415118862dec994bbf" category="list-text">*Regolarizzazione.*  Abbiamo utilizzato l'interruzione anticipata, poiché la regolarizzazione o l'abbandono della L2 non si sono rivelati efficaci.</block>
  <block id="5f7ce3c44b690052b88504fd4c0ff7bb" category="list-text">*Iperparametri.*  Riportiamo i risultati basati su una ricerca a griglia sul numero di livelli nascosti, sulla dimensione dei livelli nascosti, sul tasso di apprendimento iniziale e sul numero di livelli incrociati.  Il numero di livelli nascosti variava da 2 a 5, con dimensioni dei livelli nascosti che andavano da 32 a 1024.  Per DCN, il numero di strati incrociati era compreso tra 1 e 6.  Il tasso di apprendimento iniziale è stato regolato da 0,0001 a 0,001 con incrementi di 0,0001.  Tutti gli esperimenti sono stati applicati in anticipo, fermandosi al passo di addestramento 150.000, oltre il quale ha iniziato a verificarsi un overfitting.</block>
  <block id="a5203fd5d2ee4a156e177b2b5b5ecb45" category="inline-link">DeepFM</block>
  <block id="43d5f147547ecf24ebc038feb06a8312" category="inline-link">AutoInt</block>
  <block id="79249d5f44965bf593f3105190bac784" category="inline-link">DCN v2</block>
  <block id="edddedbe12bade5d0d47c6600aa7fc40" category="paragraph">Oltre a DCN, abbiamo testato anche altri modelli di deep learning popolari per la previsione del CTR, tra cui<block ref="256b68047e4850e72fc6a1a263d88e86" category="inline-link-rx"></block> ,<block ref="a61c3ddacc920697ed1145d7ed359d25" category="inline-link-rx"></block> , E<block ref="8b59d0e884bf752e43135b866516c089" category="inline-link-rx"></block> .</block>
  <block id="408be753ce98edae615db82036085d63" category="section-title">Architetture utilizzate per la convalida</block>
  <block id="2150013c97241fde077622292dd996b4" category="paragraph">Per questa convalida, abbiamo utilizzato quattro nodi worker e un nodo master con una coppia AFF-A800 HA.  Tutti i membri del cluster erano connessi tramite switch di rete 10GbE.</block>
  <block id="de404d7688ac5c78348bfea711a12792" category="paragraph">Per la convalida della soluzione NetApp Spark, abbiamo utilizzato tre diversi controller di storage: E5760, E5724 e AFF-A800.  I controller di archiviazione della serie E sono stati collegati a cinque nodi dati con connessioni SAS da 12 Gbps.  Il controller di archiviazione AFF HA-pair fornisce volumi NFS esportati tramite connessioni 10GbE ai nodi worker Hadoop.  I membri del cluster Hadoop erano connessi tramite connessioni 10GbE nelle soluzioni Hadoop E-Series, AFF e StorageGRID .</block>
  <block id="f3952bdea9a512245a3b2e368bdd17a4" category="inline-image-macro">Architetture utilizzate per la convalida.</block>
  <block id="dbb9fda021247ba28b40c95fcf20d529" category="paragraph"><block ref="dbb9fda021247ba28b40c95fcf20d529" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dce4db89f623baec1071c07c6784f4b1" category="summary">Un moderno data center aziendale è un cloud ibrido che collega più ambienti infrastrutturali distribuiti tramite un piano di gestione dati continuo con un modello operativo coerente, in sede e/o in più cloud pubblici.  Per sfruttare al meglio un cloud ibrido, è necessario essere in grado di spostare i dati senza problemi tra gli ambienti on-premise e multi-cloud, senza dover effettuare conversioni di dati o refactoring delle applicazioni.</block>
  <block id="e27d277adca53504bfe79d8a5e7c2084" category="doc">Soluzione cloud ibrida</block>
  <block id="9cf7905c60934870d86a546076b272e4" category="paragraph">I clienti hanno dichiarato di iniziare il loro percorso verso il cloud ibrido spostando lo storage secondario sul cloud per casi d'uso quali la protezione dei dati oppure spostando sul cloud carichi di lavoro meno critici per l'azienda, come lo sviluppo di applicazioni e DevOps.  Passano poi a carichi di lavoro più critici.  Tra i carichi di lavoro più diffusi nel cloud ibrido rientrano l'hosting di contenuti e web, lo sviluppo di applicazioni e DevOps, i database, l'analisi e le app containerizzate.  La complessità, i costi e i rischi dei progetti di intelligenza artificiale aziendali hanno storicamente ostacolato l'adozione dell'intelligenza artificiale dalla fase sperimentale a quella produttiva.</block>
  <block id="38ddba87301d0e027f020fd24b8a5ade" category="paragraph">Con una soluzione cloud ibrida NetApp , i clienti beneficiano di strumenti integrati di sicurezza, governance dei dati e conformità con un unico pannello di controllo per la gestione dei dati e dei flussi di lavoro in ambienti distribuiti, ottimizzando al contempo il costo totale di proprietà in base al loro consumo.  La figura seguente è un esempio di soluzione di un partner di servizi cloud incaricato di fornire connettività multi-cloud per i dati di analisi dei big data dei clienti.</block>
  <block id="10ebc90118ac5ab60f289bf34b75d978" category="inline-image-macro">Esempio di soluzione di un partner di servizi cloud.</block>
  <block id="f6eb8b15960b6dcbfd7e927644b45d94" category="paragraph"><block ref="f6eb8b15960b6dcbfd7e927644b45d94" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207f35bf95973770d860aeee0abe32a2" category="paragraph">In questo scenario, i dati IoT ricevuti in AWS da diverse fonti vengono archiviati in una posizione centrale in NetApp Private Storage (NPS).  Lo storage NPS è connesso ai cluster Spark o Hadoop situati in AWS e Azure, consentendo alle applicazioni di analisi dei big data di essere eseguite in più cloud e di accedere agli stessi dati.  I principali requisiti e sfide per questo caso d'uso includono quanto segue:</block>
  <block id="bf871745f8e53cd8c13aca4c2ae67522" category="list-text">I dati devono essere ricevuti da diverse fonti, ad esempio ambienti on-premise e cloud, tramite diversi sensori e hub.</block>
  <block id="cb1726ae6d68d40c3bc9861c2b26a1a0" category="list-text">La soluzione deve essere efficiente e conveniente.</block>
  <block id="6dc7db5e9c1da14f7d61e2a7f4428219" category="list-text">La sfida principale è quella di creare una soluzione efficiente e conveniente che fornisca servizi di analisi ibridi tra diversi ambienti on-premise e cloud.</block>
  <block id="cc4772ffa75dd53e0fb87df4b15528cd" category="paragraph">La nostra soluzione di protezione dei dati e connettività multicloud risolve il problema di dover disporre di applicazioni di analisi cloud su più hyperscaler.  Come mostrato nella figura sopra, i dati provenienti dai sensori vengono trasmessi in streaming e acquisiti nel cluster AWS Spark tramite Kafka.  I dati vengono archiviati in una condivisione NFS residente in NPS, che si trova all'esterno del provider cloud all'interno di un data center Equinix.</block>
  <block id="88971c24837a2734fa58ba8805336328" category="paragraph">Poiché NetApp NPS è connesso ad Amazon AWS e Microsoft Azure rispettivamente tramite connessioni Direct Connect ed Express Route, i clienti possono sfruttare il modulo In-Place Analytics per accedere ai dati dai cluster di analisi di Amazon e AWS.  Di conseguenza, poiché sia lo storage locale che quello NPS eseguono il software ONTAP ,<block ref="fcca72a796080b3a5e2b7b1394bd00ad" category="inline-link-rx"></block> può rispecchiare i dati NPS nel cluster locale, fornendo analisi cloud ibride su cloud locali e multipli.</block>
  <block id="bc35f58684dbedfb73dd7ff64a4bd5a8" category="paragraph">Per ottenere le migliori prestazioni, NetApp consiglia in genere di utilizzare più interfacce di rete e connessioni dirette o percorsi rapidi per accedere ai dati dalle istanze cloud.  Disponiamo di altre soluzioni di spostamento dati, tra cui<block ref="0adb843c17d646acd72646e9688dde2b" category="inline-link-rx"></block> E<block ref="079cab06c3947ff50532e4e825fc7b2c" category="inline-link-rx"></block> per aiutare i clienti a creare cluster Spark cloud ibridi, sicuri, convenienti e compatibili con le applicazioni.</block>
  <block id="cfb5f1c014066f18d7979fa1d35a934d" category="paragraph">I tre script Python seguenti corrispondono ai tre principali casi d'uso testati.  Il primo è<block ref="b01d528ada3b5a6e0e9094642b727562" prefix=" " category="inline-code"></block> .</block>
  <block id="d3abf6f12cafa2cc1b795b31cd547c75" category="paragraph">Il secondo copione è<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> .</block>
  <block id="6e9120b39f924b2eed528e3bcdd009ac" category="paragraph">Il terzo copione è<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block> .</block>
  <block id="90f0f970ed32524c528ba2778079d485" category="summary">NetApp dispone di tre portafogli di storage: FAS/ AFF, E-Series e Cloud Volumes ONTAP.  Abbiamo convalidato AFF e la serie E con il sistema di archiviazione ONTAP per le soluzioni Hadoop con Apache Spark.  Il data fabric basato su NetApp integra servizi e applicazioni di gestione dei dati (elementi costitutivi) per l'accesso, il controllo, la protezione e la sicurezza dei dati.</block>
  <block id="12a9f57585cd6b3b985dd451bf552845" category="doc">Panoramica delle soluzioni NetApp Spark</block>
  <block id="c7516072fbed3396e6f4c39a5f2356a6" category="paragraph">NetApp dispone di tre portafogli di storage: FAS/ AFF, E-Series e Cloud Volumes ONTAP.  Abbiamo convalidato AFF e la serie E con il sistema di archiviazione ONTAP per le soluzioni Hadoop con Apache Spark.</block>
  <block id="710b54a5dd637d8e21574c4fb3eea545" category="inline-image-macro">Il data fabric fornisce servizi e applicazioni di gestione dei dati.</block>
  <block id="6370a459d17d7eda9502b6008ad71b4a" category="paragraph"><block ref="6370a459d17d7eda9502b6008ad71b4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829a597c83ae2b02e991f062bb891ace" category="list-text">* Accesso diretto NetApp NFS.*  Fornisce i cluster Hadoop e Spark più recenti con accesso diretto ai volumi NetApp NFS senza requisiti aggiuntivi di software o driver.</block>
  <block id="d075304bce816c2722d405cac9bf4877" category="list-text">* Tecnologia NetApp SnapMirror .*  Fornisce funzionalità di protezione dei dati tra istanze locali e istanze ONTAP Cloud o NPS.</block>
  <block id="bd162abba0390e6a6e2e2581d449bf77" category="paragraph">La figura seguente illustra la soluzione Spark con storage NetApp .</block>
  <block id="0ec1ecf37e474c5f4116ab4ae95e84d9" category="inline-image-macro">Soluzione Spark con storage NetApp .</block>
  <block id="2c73cc344c9ea7b4fbe0e5179bb17d5a" category="paragraph"><block ref="2c73cc344c9ea7b4fbe0e5179bb17d5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e58a24b49fbb76272d712aaabf465bf7" category="paragraph">La soluzione ONTAP Spark utilizza il protocollo di accesso diretto NetApp NFS per analisi in loco e flussi di lavoro AI, ML e DL utilizzando l'accesso ai dati di produzione esistenti.  I dati di produzione disponibili per i nodi Hadoop vengono esportati per eseguire analisi in loco e attività di intelligenza artificiale, apprendimento automatico e apprendimento automatico (IA), nonché attività di DL.  È possibile accedere ai dati da elaborare nei nodi Hadoop con o senza accesso diretto NetApp NFS.  In Spark con la versione standalone o<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> gestore cluster, è possibile configurare un volume NFS utilizzando<block ref="806400a5eefaa4811c63e2b45a736984" prefix=" " category="inline-code"></block> .  Abbiamo convalidato tre casi d'uso con diversi set di dati.  I dettagli di queste convalide sono presentati nella sezione "Risultati dei test".  (xrif)</block>
  <block id="955ae639ea2500f38215e8263610b119" category="paragraph">La figura seguente illustra il posizionamento dello storage NetApp Apache Spark/Hadoop.</block>
  <block id="78157b6c5aece6e0b7b7ea998dce3a8a" category="inline-image-macro">Posizionamento dello storage NetApp Apache Spark/Hadoop.</block>
  <block id="8e32cf48ce4f12a61f456b3ec41a7e21" category="paragraph"><block ref="8e32cf48ce4f12a61f456b3ec41a7e21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cf3adbf38f17f8e0c86c8531fc379b7" category="paragraph">Abbiamo identificato le caratteristiche uniche della soluzione E-Series Spark, della soluzione AFF/ FAS ONTAP Spark e della soluzione StorageGRID Spark, e abbiamo eseguito convalide e test dettagliati.  Sulla base delle nostre osservazioni, NetApp consiglia la soluzione E-Series per installazioni greenfield e nuove distribuzioni scalabili e la soluzione AFF/ FAS per analisi in loco, carichi di lavoro AI, ML e DL utilizzando dati NFS esistenti e StorageGRID per AI, ML e DL e analisi dei dati moderne quando è richiesto l'archiviazione di oggetti.</block>
  <block id="675ed5324aa6eda280e015498c583161" category="inline-image-macro">Soluzioni NetApp consigliate per Spark.</block>
  <block id="32530ebcaeef5cc30a605229e26ea933" category="paragraph"><block ref="32530ebcaeef5cc30a605229e26ea933" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa7b20f32446fa30f765cd0b1ca93739" category="paragraph">Un data lake è un repository di archiviazione per grandi set di dati in formato nativo che può essere utilizzato per attività di analisi, intelligenza artificiale, apprendimento automatico e DL.  Abbiamo creato un repository di data lake per le soluzioni E-Series, AFF/ FAS e StorageGRID SG6060 Spark.  Il sistema E-Series fornisce l'accesso HDFS al cluster Hadoop Spark, mentre l'accesso ai dati di produzione esistenti avviene tramite il protocollo di accesso diretto NFS al cluster Hadoop.  Per i set di dati che risiedono nell'archiviazione di oggetti, NetApp StorageGRID fornisce accesso sicuro S3 e S3a.</block>
  <block id="881214767967db331c99550277ceb793" category="summary">Questa pagina descrive l'architettura di Splunk, comprese le definizioni chiave, le distribuzioni distribuite di Splunk, Splunk SmartStore, il flusso di dati, i requisiti hardware e software, i requisiti per siti singoli e multisito e così via.</block>
  <block id="1e6ade59f7284c0bca28eaeeeeed0a30" category="doc">Architettura Splunk</block>
  <block id="3924240363e47a4a292119abc4a993a1" category="paragraph">Questa sezione descrive l'architettura di Splunk, comprese le definizioni chiave, le distribuzioni distribuite di Splunk, Splunk SmartStore, il flusso di dati, i requisiti hardware e software, i requisiti per siti singoli e multisito e così via.</block>
  <block id="a8449bda57f23b9282f766113987bdf2" category="section-title">Definizioni chiave</block>
  <block id="56eee8e9cc278d0a414a6d5697a4675f" category="paragraph">Le due tabelle successive elencano i componenti Splunk e NetApp utilizzati nella distribuzione di Splunk.</block>
  <block id="5078bea36734bcaa4a0c1e3a0e6e4606" category="paragraph">Questa tabella elenca i componenti hardware Splunk per la configurazione distribuita di Splunk Enterprise.</block>
  <block id="5e536c35aec296fa99efa02703d1eb07" category="cell">Componente Splunk</block>
  <block id="eaeb30f9f18e0c50b178676f3eaef45f" category="cell">Compito</block>
  <block id="84f200201a8fe699d8d701c940bade8e" category="cell">Indicizzatore</block>
  <block id="a5aa1df4c3c47c407c84c66303cf0ece" category="cell">Repository per i dati di Splunk Enterprise</block>
  <block id="872c8a2437dfbfa5be0882eabc86bcd3" category="cell">Spedizioniere universale</block>
  <block id="66d25b75f626d8f6c535a4b4d25c9906" category="cell">Responsabile dell'acquisizione dei dati e dell'inoltro dei dati agli indicizzatori</block>
  <block id="c91b59f2eae5ebf309d600609f87a36f" category="cell">Testa di ricerca</block>
  <block id="5873147385b9bd833ffd9a046374c97b" category="cell">L'interfaccia utente utilizzata per cercare dati negli indicizzatori</block>
  <block id="a6230a0628a31d41191b4ef7800745ed" category="cell">Maestro del cluster</block>
  <block id="e4ae9d4eb2313305a17cde160f405a17" category="cell">Gestisce l'installazione Splunk di indicizzatori e testine di ricerca</block>
  <block id="805ac84d9852820feaf2e2b643a07efb" category="cell">Console di monitoraggio</block>
  <block id="5cf5006c1d7fdc954614a4e4185a2c62" category="cell">Strumento di monitoraggio centralizzato utilizzato nell'intera distribuzione</block>
  <block id="fdccec582408614d1e2f7428910b1c8f" category="cell">Master di licenza</block>
  <block id="7c3b9b8892864eb6fa5cb2a32b85cc93" category="cell">Il master delle licenze gestisce le licenze di Splunk Enterprise</block>
  <block id="06262b5ad14fe5851defa5b0b70c86c6" category="cell">Server di distribuzione</block>
  <block id="ebe1fa5d8a359a6db13876ab1142fa50" category="cell">Aggiorna le configurazioni e distribuisce le app al componente di elaborazione</block>
  <block id="4fabea287d13a082b71f046f9d8be91d" category="cell">Componente di archiviazione</block>
  <block id="8bf5bd6530ea430a8edac8a795165179" category="cell">NetApp AFF</block>
  <block id="b1edd0b37872fd00feb3bb2738987b41" category="cell">Storage all-flash utilizzato per gestire i dati di livello caldo.  Noto anche come archiviazione locale.</block>
  <block id="518d90155e7eb8bf96c6b7852ba519a6" category="cell">Archiviazione di oggetti S3 utilizzata per gestire i dati di livello caldo.  Utilizzato da SmartStore per spostare i dati tra il livello caldo e quello caldo.  Noto anche come archiviazione remota.</block>
  <block id="310a27e25811a8eca9b6e5edd921a267" category="paragraph">Questa tabella elenca i componenti dell'architettura di archiviazione Splunk.</block>
  <block id="40f14800d20c9cecbec85dbb2cf35592" category="cell">Componente responsabile</block>
  <block id="a5847d984bf6ac525e00b95b93be4e94" category="cell">Negozio intelligente</block>
  <block id="6b64d740ca8627e515d54827d95bc7cb" category="cell">Fornisce agli indicizzatori la possibilità di suddividere i dati dall'archiviazione locale all'archiviazione degli oggetti.</block>
  <block id="2f9304fe9b427489507405bef9a0bb9f" category="cell">Splunk</block>
  <block id="4194726ee334e1085d93e002837b73f0" category="cell">Caldo</block>
  <block id="cc42c7d2fb33f9ccc06f2e23486a9b0e" category="cell">Il punto di atterraggio in cui gli inoltratori universali inseriscono i dati appena scritti.  L'archiviazione è scrivibile e i dati sono ricercabili.  Questo livello di dati è in genere composto da SSD o HDD veloci.</block>
  <block id="253b40ae359ba25b56231803430c4873" category="cell">ONTAP</block>
  <block id="f156996831cd546988bf05451ede7b02" category="cell">Gestore della cache</block>
  <block id="52520fc1f4cef574661d086d8efcb1f8" category="cell">Gestisce la cache locale dei dati indicizzati, recupera i dati caldi dall'archivio remoto quando si verifica una ricerca ed elimina dalla cache i dati utilizzati meno frequentemente.</block>
  <block id="18297117d3d251afceed9ecbe797c849" category="cell">Caldo</block>
  <block id="810be2ef6ffed5e543f948bf5984d544" category="cell">I dati vengono trasferiti logicamente al bucket e rinominati prima dal livello caldo al livello caldo.  I dati all'interno di questo livello sono protetti e, come nel livello caldo, possono essere composti da SSD o HDD di capacità maggiore.  Sono supportati sia i backup incrementali che quelli completi utilizzando le comuni soluzioni di protezione dei dati.</block>
  <block id="7cf9c58117f9052c5d5a43b3add7f6a4" category="section-title">Distribuzioni distribuite di Splunk</block>
  <block id="11c2b5859cb0c1d37b40f8df716542e2" category="paragraph">Per supportare ambienti più grandi in cui i dati provengono da numerose macchine, è necessario elaborare grandi volumi di dati.  Se molti utenti devono effettuare ricerche nei dati, è possibile scalare la distribuzione distribuendo le istanze di Splunk Enterprise su più macchine.  Questo è noto come distribuzione distribuita.</block>
  <block id="113f0bd975880424e2c87874233b2afb" category="paragraph">In una tipica distribuzione distribuita, ogni istanza di Splunk Enterprise esegue un'attività specializzata e risiede su uno dei tre livelli di elaborazione corrispondenti alle principali funzioni di elaborazione.</block>
  <block id="ac31b29e5bbd68654aeb200e66227fb8" category="paragraph">Nella tabella seguente sono elencati i livelli di elaborazione di Splunk Enterprise.</block>
  <block id="9483f17a69bd0b52dbc44f9106718634" category="cell">Livello</block>
  <block id="2cb05e4bb7830be982f0922fed86b4cd" category="cell">Componente</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">Descrizione</block>
  <block id="7d38267cdf833b2983d3487954ebf88e" category="cell">Inserimento dati</block>
  <block id="2d361d5fe6d74b7550e0aa35d94342ec" category="cell">Spedizioniere</block>
  <block id="b2eebf5023a2a2ba3b35711069723656" category="cell">Un forwarder consuma i dati e poi li inoltra a un gruppo di indicizzatori.</block>
  <block id="521d4edc7c22d5f63bc5912ff2afa61a" category="cell">Indicizzazione</block>
  <block id="65265b43bef75c5bacc53c21e38eb8fc" category="cell">Un indicizzatore indicizza i dati in arrivo che solitamente riceve da un gruppo di inoltratori.  L'indicizzatore trasforma i dati in eventi e memorizza gli eventi in un indice.  L'indicizzatore ricerca anche i dati indicizzati in risposta alle richieste di ricerca provenienti da una testina di ricerca.</block>
  <block id="ff5b0dc94726e93d5db5cf7922183f2b" category="cell">Gestione della ricerca</block>
  <block id="d4c174b1ebc77694020097497547d218" category="cell">Una testina di ricerca funge da risorsa centrale per la ricerca.  Le teste di ricerca in un cluster sono intercambiabili e hanno accesso alle stesse ricerche, dashboard, oggetti di conoscenza e così via, da qualsiasi membro del cluster delle teste di ricerca.</block>
  <block id="86f51d8f8fa8928e0f6ddba31139676e" category="paragraph">Nella tabella seguente sono elencati i componenti importanti utilizzati in un ambiente Splunk Enterprise distribuito.</block>
  <block id="dee8af298acfc4c4bcb9fda657125917" category="cell">Responsabilità</block>
  <block id="3b656ff8459bec2d80d19d367bd71d19" category="cell">Indice del cluster master</block>
  <block id="407a3e34682f31b649e8cbd865fdf50c" category="cell">Coordina le attività e gli aggiornamenti di un cluster di indicizzatori</block>
  <block id="dad2f7ca532f008e8192d418406da758" category="cell">Gestione degli indici</block>
  <block id="85ba71585b2b8c323c8eb899fa033227" category="cell">Cluster di indice</block>
  <block id="f13c7b75bef35de7c42cc0569f76e366" category="cell">Gruppo di indicizzatori Splunk Enterprise configurati per replicare i dati tra loro</block>
  <block id="f8b32f50f478eb80dca360b13aa78e92" category="cell">Distributore della testina di ricerca</block>
  <block id="9f45bd6fe25c3f5597af0f46bfdb20db" category="cell">Gestisce la distribuzione e gli aggiornamenti al master del cluster</block>
  <block id="bc2eef462c1a0c8b778b607c304ba877" category="cell">Gestione della testa di ricerca</block>
  <block id="58f4a17edb05ffec840bf2b176bf6eca" category="cell">Cluster di testine di ricerca</block>
  <block id="70f36c7a653c3724df8921edce177b22" category="cell">Gruppo di responsabili della ricerca che funge da risorsa centrale per la ricerca</block>
  <block id="2ddcaa7e88a6ad9c095422ca4e601d85" category="cell">Bilanciatori di carico</block>
  <block id="fe613dab61d63209235cf49513b00d8a" category="cell">Utilizzato dai componenti in cluster per gestire la crescente domanda da parte di search head, indicizzatori e target S3 per distribuire il carico tra i componenti in cluster.</block>
  <block id="184f98cf6a6dd19d0815179e63be4298" category="cell">Gestione del carico per componenti raggruppati</block>
  <block id="e32d50596edede1bfe3978d8b7b5c5ac" category="paragraph">Scopri i seguenti vantaggi delle distribuzioni distribuite di Splunk Enterprise:</block>
  <block id="9431943c093a5cc181eccd505ca50f4c" category="list-text">Accedere a fonti di dati diverse o disperse</block>
  <block id="e825b2fa62f5af51541982cc503c8825" category="list-text">Fornire funzionalità per gestire le esigenze di dati per aziende di qualsiasi dimensione e complessità</block>
  <block id="c63fa16ec4ed3d9b3803c2d1e1548fe6" category="list-text">Ottieni un'elevata disponibilità e garantisci il ripristino di emergenza con la replica dei dati e la distribuzione multisito</block>
  <block id="fb289ff7f529e1f2477823c61e7d9c8f" category="section-title">Splunk SmartStore</block>
  <block id="e2475a05ae25f0e8f31932cc309db3f1" category="paragraph">SmartStore è una funzionalità di indicizzazione che consente agli archivi di oggetti remoti, come Amazon S3, di archiviare dati indicizzati.  Con l'aumento del volume di dati di un'implementazione, la domanda di storage in genere supera la domanda di risorse di elaborazione.  SmartStore consente di gestire in modo conveniente le risorse di archiviazione e di elaborazione dell'indicizzatore, ridimensionando tali risorse separatamente.</block>
  <block id="4b253fe4960ecb87fdd7a6c05a125003" category="paragraph">SmartStore introduce un livello di archiviazione remoto e un gestore della cache.  Queste funzionalità consentono ai dati di risiedere localmente sugli indicizzatori o sul livello di archiviazione remoto.  Il gestore della cache gestisce lo spostamento dei dati tra l'indicizzatore e il livello di archiviazione remoto, configurato sull'indicizzatore.</block>
  <block id="98941a2e255442c92447b445a4a6bc6e" category="paragraph">Con SmartStore puoi ridurre al minimo l'ingombro di archiviazione dell'indicizzatore e scegliere risorse di elaborazione ottimizzate per l'I/O.  La maggior parte dei dati risiede nell'archiviazione remota.  L'indicizzatore mantiene una cache locale che contiene una quantità minima di dati: hot bucket, copie di hot bucket che partecipano a ricerche attive o recenti e metadati dei bucket.</block>
  <block id="2d153b33a50f3343c2aeb68789ee8e26" category="section-title">Flusso di dati di Splunk SmartStore</block>
  <block id="3306b50d7dd22a0698c2245e7cd06bee" category="paragraph">Quando i dati provenienti da varie fonti raggiungono gli indicizzatori, vengono indicizzati e salvati localmente in un hot bucket.  L'indicizzatore replica anche i dati hot bucket sugli indicizzatori di destinazione.  Finora, il flusso di dati è identico al flusso di dati per gli indici non SmartStore.</block>
  <block id="ad1e15c21ba7587e1631977abe48ab09" category="paragraph">Quando il secchio caldo passa a quello caldo, il flusso di dati diverge.  L'indicizzatore di origine copia il bucket caldo nell'archivio oggetti remoto (livello di archiviazione remoto) lasciando la copia esistente nella sua cache, perché le ricerche tendono a essere eseguite su dati indicizzati di recente.  Tuttavia, gli indicizzatori di destinazione eliminano le proprie copie perché l'archivio remoto garantisce un'elevata disponibilità senza dover mantenere più copie locali.  La copia master del bucket ora risiede nell'archivio remoto.</block>
  <block id="3d39641a906c56e9e12b0f019f23bc1d" category="paragraph">L'immagine seguente mostra il flusso di dati di Splunk SmartStore.</block>
  <block id="d7a63eb40866a66e8bb1fc64387b113e" category="paragraph"><block ref="d7a63eb40866a66e8bb1fc64387b113e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fa16046e839496393e84b6a20e9604e" category="paragraph">Il gestore della cache sull'indicizzatore è fondamentale per il flusso di dati SmartStore.  Recupera copie dei bucket dall'archivio remoto secondo necessità per gestire le richieste di ricerca.  Inoltre, rimuove dalla cache le copie più vecchie o meno ricercate dei bucket, perché la probabilità che partecipino alle ricerche diminuisce nel tempo.</block>
  <block id="b36837abd403dcb47f93edcd619c14de" category="paragraph">Il compito del gestore della cache è ottimizzare l'uso della cache disponibile, garantendo al contempo che le ricerche abbiano accesso immediato ai bucket di cui hanno bisogno.</block>
  <block id="4b2ba4c21a026c9139cf1484818f31c0" category="paragraph">Nella tabella seguente sono elencati i componenti software necessari per implementare la soluzione.  I componenti software utilizzati in qualsiasi implementazione della soluzione potrebbero variare in base alle esigenze del cliente.</block>
  <block id="aa76f43f5e0552119cc8d5313c67296e" category="cell">Famiglia di prodotti</block>
  <block id="df644ae155e79abf54175bd15d75f363" category="cell">Nome del prodotto</block>
  <block id="892b5a336dfe285f2d5c04ccd3d6c465" category="cell">Versione del prodotto</block>
  <block id="696c660ff8d9323e55146a6dbd4e4088" category="cell">Sistema operativo</block>
  <block id="1b3e6de2b0fe97c3177ea5a4ad142554" category="cell">Archiviazione di oggetti StorageGRID</block>
  <block id="36552b079970ffb2dd1314115af76c4b" category="cell">11,6</block>
  <block id="274b68192b056e268f128ff63bfcd4a4" category="cell">n / a</block>
  <block id="aa1fc3398e84bda331b47203c1e53ad5" category="cell">CentOS</block>
  <block id="d6422a625045167156b3c0d85ca23ebf" category="cell">8,1</block>
  <block id="66985170e641a7e20698bfec3c1d889f" category="cell">CentOS 7.x</block>
  <block id="5dba46907e72d7502229329d2aafd8a2" category="cell">Splunk Enterprise</block>
  <block id="9d8d169ace12276d008f0d0b88b61261" category="cell">Splunk Enterprise con SmartStore</block>
  <block id="75809dde56e3fe2c2fb740f1b55807ac" category="cell">8.0.3</block>
  <block id="3192356dc19e9b4ec43ba340bad657ee" category="section-title">Requisiti per siti singoli e multisito</block>
  <block id="98b8bd4f9670277f1f0e59a574019582" category="paragraph">In un ambiente Splunk Enterprise (distribuzioni di medie e grandi dimensioni) in cui i dati hanno origine su più macchine e in cui molti utenti devono effettuare ricerche nei dati, è possibile scalare la distribuzione distribuendo le istanze di Splunk Enterprise su uno o più siti.</block>
  <block id="22e1b76cf9acbfd35603b013eefcb079" category="paragraph">Nella tabella seguente sono elencati i componenti utilizzati in un ambiente Splunk Enterprise distribuito.</block>
  <block id="ee5ff25e83985cc8f46c04780442d06b" category="cell">Gruppo di indicizzatori Splunk Enterprise configurati per replicare i dati reciproci</block>
  <block id="4e21e57c1860bf98fe3d0af8068f827d" category="cell">Bilanciatori di carico</block>
  <block id="03d7fbb295d0abb68bf4d3ce22d6d448" category="cell">Gestione del carico per componenti raggruppati</block>
  <block id="a0ebc1066e0250b1b42f1a66ae974836" category="paragraph">Questa figura illustra un esempio di distribuzione su un singolo sito.</block>
  <block id="d929fa57a2db2b79fca2a0c134995344" category="paragraph"><block ref="d929fa57a2db2b79fca2a0c134995344" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf99a89b389bc74dc1a403695b28d6cd" category="paragraph">Questa figura illustra un esempio di distribuzione multisito.</block>
  <block id="aa56e29281a1be8656361637c931faec" category="paragraph"><block ref="aa56e29281a1be8656361637c931faec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80d955d16c5178cc40e347dfe675a443" category="paragraph">Le tabelle seguenti elencano il numero minimo di componenti hardware necessari per implementare la soluzione.  I componenti hardware utilizzati in specifiche implementazioni della soluzione potrebbero variare in base alle esigenze del cliente.</block>
  <block id="f690a37fe0f7a5932c9eee9dc887f7c7" category="admonition">Indipendentemente dal fatto che Splunk SmartStore e StorageGRID siano stati distribuiti in un unico sito o in più siti, tutti i sistemi vengono gestiti da StorageGRID GRID Manager in un unico pannello di controllo.  Per maggiori dettagli, consultare la sezione "Gestione semplice con Grid Manager".</block>
  <block id="1605af3a62fa950fe8374a69086fdc94" category="paragraph">Questa tabella elenca l'hardware utilizzato per un singolo sito.</block>
  <block id="380dbc8d9d2c8a17f6ebb0b2c62d3e85" category="cell">Disco</block>
  <block id="b3e1f4c67ee07a73dcdaff1cf34f2640" category="cell">Capacità utilizzabile</block>
  <block id="3b0649c72650c313a357338dcdfb64ec" category="cell">Nota</block>
  <block id="1c594a38f9aafa3a439c25bc55815b40" category="cell">StorageGRID SG1000</block>
  <block id="b179d20c2d3e6e91708b69931e8fcf32" category="cell">Nodo di amministrazione e bilanciatore del carico</block>
  <block id="48f09b085e666c51e35dbe89367de826" category="cell">StorageGRID SG6060</block>
  <block id="ab570142c34522356bdf33666f6532a3" category="cell">x48, 8 TB (HDD NL-SAS)</block>
  <block id="1792805a48a4da5ef5a78aa014da1f84" category="cell">1PB</block>
  <block id="ecefe4d01bf4079d1e2833e9a7de2db7" category="cell">Archiviazione remota</block>
  <block id="9327a762e04913fc832ee2b182848716" category="paragraph">Questa tabella elenca l'hardware utilizzato per una configurazione multisito (per sito).</block>
  <block id="41cac74c281e47bb6feb1ef8db664ce4" category="cell">Nodo di amministrazione e bilanciatore del carico</block>
  <block id="aadc7d80b20e9c743c2920297937f9fd" category="section-title">Bilanciatore del carico NetApp StorageGRID : SG1000</block>
  <block id="b3f51763a6ba0ae7fe6d83095cb24299" category="paragraph">L'archiviazione di oggetti richiede l'uso di un bilanciatore del carico per presentare lo spazio dei nomi dell'archiviazione cloud.  StorageGRID supporta bilanciatori di carico di terze parti di fornitori leader come F5 e Citrix, ma molti clienti scelgono il bilanciatore StorageGRID di livello aziendale per semplicità, resilienza e prestazioni elevate.  Il bilanciatore del carico StorageGRID è disponibile come VM, container o appliance appositamente progettata.</block>
  <block id="01f9bf7333b91ead20b7d1ac12ba4bca" category="paragraph">StorageGRID SG1000 facilita l'uso di gruppi ad alta disponibilità (HA) e il bilanciamento del carico intelligente per le connessioni del percorso dati S3.  Nessun altro sistema di archiviazione di oggetti on-premise fornisce un bilanciatore del carico personalizzato.</block>
  <block id="2f1a2bc20d9d0cddf636827860bdeb21" category="paragraph">L'appliance SG1000 offre le seguenti funzionalità:</block>
  <block id="fee5222c1281869dd7c4e3e4b7225065" category="list-text">Un bilanciatore del carico e, facoltativamente, funzioni di nodo di amministrazione per un sistema StorageGRID</block>
  <block id="7ea5a035cfe0609861da7628e7dedc64" category="list-text">StorageGRID Appliance Installer per semplificare la distribuzione e la configurazione dei nodi</block>
  <block id="224d05cfece712836874ae47446c6d1b" category="list-text">Configurazione semplificata degli endpoint S3 e SSL</block>
  <block id="59bf11863992b10be7d53c81c21a0220" category="list-text">Larghezza di banda dedicata (rispetto alla condivisione di un bilanciatore di carico di terze parti con altre applicazioni)</block>
  <block id="1436fddc15afc971733cc42610be3718" category="list-text">Larghezza di banda Ethernet aggregata fino a 4 x 100 Gbps</block>
  <block id="4ff66456ad21f2aa88ad918b2a19287d" category="paragraph">L'immagine seguente mostra l'appliance SG1000 Gateway Services.</block>
  <block id="605bc0a01cfe9da48adf3da49367bbdc" category="paragraph"><block ref="605bc0a01cfe9da48adf3da49367bbdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40b11d9d6e72b8f3d6f6cd150ea6d5b3" category="paragraph">L'appliance StorageGRID SG6060 include un controller di elaborazione (SG6060) e uno scaffale per controller di archiviazione (E-Series E2860) che contiene due controller di archiviazione e 60 unità.  Questo apparecchio offre le seguenti caratteristiche:</block>
  <block id="5d61368716b8937ccfa3ae30bdeb3add" category="list-text">Scalabilità fino a 400 PB in un singolo namespace.</block>
  <block id="b08da7d555d413c82fa9476b78a3d1b4" category="list-text">Larghezza di banda Ethernet aggregata fino a 4x 25 Gbps.</block>
  <block id="3b384482ee0276a75964f52aab736cac" category="list-text">Include StorageGRID Appliance Installer per semplificare la distribuzione e la configurazione dei nodi.</block>
  <block id="3d6b68fb6989ac04a76612b7d50b5046" category="list-text">Ogni dispositivo SG6060 può avere uno o due ripiani di espansione aggiuntivi per un totale di 180 unità.</block>
  <block id="470503fbecc72cbe91b61c6e9b999cbe" category="list-text">Due controller E-Series E2800 (configurazione duplex) per fornire supporto failover del controller di archiviazione.</block>
  <block id="920a659800fa3289516e73f0b8d0cd70" category="list-text">Ripiano per unità a cinque cassetti che può contenere sessanta unità da 3,5 pollici (due unità a stato solido e 58 unità NL-SAS).</block>
  <block id="d60b006794c926c67e95ce7f49fffbed" category="paragraph">L'immagine seguente mostra l'appliance SG6060.</block>
  <block id="cf84ce9e448fb9e498568b901279526a" category="paragraph"><block ref="cf84ce9e448fb9e498568b901279526a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad24897680a673883f3a8e9467ea3271" category="section-title">Progettazione Splunk</block>
  <block id="c2d7b4acc3efe890969906f2a0be4bea" category="paragraph">Nella tabella seguente è elencata la configurazione di Splunk per un singolo sito.</block>
  <block id="95dd022b7af0f9fcfb9ed21236830169" category="cell">Nuclei</block>
  <block id="17bc10091293fdc562a6db69940ee924" category="cell">Sistema operativo</block>
  <block id="5132d0e71971db5ca9827d470220eae9" category="cell">16 core</block>
  <block id="f4e3903ba78addf6fadac4a2d7285203" category="cell">32 GB di RAM</block>
  <block id="3988099dd7392a8b60a290ca560ac95d" category="cell">CentOS 8.1</block>
  <block id="aa7f73db0dcc93a83403f1afb650efdd" category="cell">Gestisce i dati dell'utente</block>
  <block id="d3d9446802a44259755d38e6d163e820" category="cell">10</block>
  <block id="86e7f660faa5812369ca3195a6ab944a" category="cell">Il front-end dell'utente cerca i dati negli indicizzatori</block>
  <block id="eccbc87e4b5ce2fe28308fd9f2a7baf3" category="cell">3</block>
  <block id="e14f0b3b9201c717d9cae1db6969fb64" category="cell">Gestisce gli aggiornamenti per i cluster di testine di ricerca</block>
  <block id="0ac993c5a472613a0cd368ccfefd6009" category="cell">Gestisce l'installazione e gli indicizzatori di Splunk</block>
  <block id="a91966f90c29f7d9420d2fd902f4aac2" category="cell">Console di monitoraggio e master delle licenze</block>
  <block id="0cb149f6f77c10496cf7645357f9fd17" category="cell">Esegue il monitoraggio centralizzato dell'intera distribuzione Splunk e gestisce le licenze Splunk</block>
  <block id="9bc779a08fe3e6d54c4355c4ee8c4a95" category="paragraph">Le tabelle seguenti descrivono la configurazione di Splunk per configurazioni multisito.</block>
  <block id="9605b47d211de50422182b81685da619" category="paragraph">Questa tabella elenca la configurazione Splunk per una configurazione multisito (sito A).</block>
  <block id="d9de1b6846e3235226dba66773043a15" category="cell">Responsabile dell'acquisizione dei dati e dell'inoltro dei dati agli indicizzatori.</block>
  <block id="76132c1712ff61ff02378720304f6529" category="cell">Esegue il monitoraggio centralizzato dell'intera distribuzione Splunk e gestisce le licenze Splunk.</block>
  <block id="2d3db4a7f27e8f892b40be60e8c003b4" category="paragraph">Questa tabella elenca la configurazione Splunk per una configurazione multisito (sito B).</block>
  <block id="89586ffe0445b81e878d1032f66f2e12" category="summary">Splunk Enterprise è la soluzione SIEM leader di mercato che garantisce risultati concreti nei team di sicurezza, IT e DevOps.</block>
  <block id="4d39837f3e2d893412540b1652c97cbe" category="paragraph">Splunk Enterprise è la soluzione SIEM leader di mercato che garantisce risultati concreti nei team di sicurezza, IT e DevOps.  L'utilizzo di Splunk è aumentato considerevolmente nelle organizzazioni dei nostri clienti.  Pertanto, è necessario aggiungere più fonti di dati, conservando al contempo i dati per un periodo di tempo più lungo, sottoponendo così a stress l'infrastruttura Splunk.</block>
  <block id="25c2a1fd1c8874a3e0526920fe7f440d" category="paragraph">La combinazione di Splunk SmartStore e NetApp StorageGRID è progettata per fornire un'architettura scalabile che consenta alle organizzazioni di ottenere prestazioni di acquisizione migliorate con l'archiviazione di oggetti SmartStore e StorageGRID e una maggiore scalabilità per un ambiente Splunk in più aree geografiche.</block>
  <block id="fbf1f1e6f0848252d39ef48e7e18146f" category="inline-link">Risorse di documentazione di NetApp StorageGRID</block>
  <block id="a246b965362984dc941c948da019cebe" category="list-text"><block ref="a246b965362984dc941c948da019cebe" category="inline-link-rx"></block></block>
  <block id="1deabb4a384507a50ad75f7c30954fe6" category="list-text"><block ref="1deabb4a384507a50ad75f7c30954fe6" category="inline-link-rx"></block></block>
  <block id="e145cc414457b4a232fb0b63ce9f44ab" category="inline-link">Documentazione di Splunk Enterprise</block>
  <block id="04e37c317ba66f65142c3479329cc2e3" category="list-text"><block ref="04e37c317ba66f65142c3479329cc2e3" category="inline-link-rx"></block></block>
  <block id="14c366ebe94ed0bdf5d5eecad5a08411" category="inline-link">Splunk Enterprise Informazioni su SmartStore</block>
  <block id="fefd29a254418e70038ff08010d7066e" category="list-text"><block ref="fefd29a254418e70038ff08010d7066e" category="inline-link-rx"></block></block>
  <block id="b437e6537685614b8004334bad18e424" category="inline-link">Manuale di distribuzione distribuita di Splunk Enterprise</block>
  <block id="12c4d056a98e583e653fc125f9f3338d" category="list-text"><block ref="12c4d056a98e583e653fc125f9f3338d" category="inline-link-rx"></block></block>
  <block id="d043516086780b04d9c8b38186019be3" category="inline-link">Splunk Enterprise Gestione degli indicizzatori e dei cluster di indicizzatori</block>
  <block id="634ac9166526f20af850f5021155d4c5" category="list-text"><block ref="634ac9166526f20af850f5021155d4c5" category="inline-link-rx"></block></block>
  <block id="c7ebb883721f7d9264fd6ef2ae03fc71" category="summary">Questo rapporto tecnico illustra i vantaggi che NetApp offre a una soluzione Splunk SmartStore, illustrando al contempo un framework per la progettazione e il dimensionamento di Splunk SmartStore nel tuo ambiente.  Il risultato è una soluzione semplice, scalabile e resiliente che garantisce un TCO interessante.</block>
  <block id="766d1a96c4f198ecfe92484b980e9b31" category="doc">TR-4869: NetApp StorageGRID con Splunk SmartStore</block>
  <block id="fa4442e299e1aa350a002220ee278abc" category="paragraph">Splunk Enterprise è la soluzione SIEM (Security Information and Event Management) leader di mercato che garantisce risultati nei team di sicurezza, IT e DevOps.</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="section-title">Panoramica</block>
  <block id="78298f39c2d5411f080a61b3abeb845f" category="paragraph">I volumi di dati continuano a crescere a ritmi esponenziali, creando enormi opportunità per le aziende che riescono a sfruttare questa vasta risorsa.  Splunk Enterprise continua a essere adottato in una più ampia gamma di casi d'uso.  Con l'aumentare dei casi d'uso, aumenta anche la quantità di dati che Splunk Enterprise acquisisce ed elabora.  L'architettura tradizionale di Splunk Enterprise è un progetto distribuito e scalabile che garantisce un accesso e una disponibilità eccellenti dei dati.  Tuttavia, le aziende che utilizzano questa architettura devono far fronte a costi crescenti associati alla scalabilità per soddisfare il volume di dati in rapida crescita.</block>
  <block id="6a7254f4c4c618a79510973c24f6b258" category="paragraph">Splunk SmartStore con NetApp StorageGRID risolve questa sfida offrendo un nuovo modello di distribuzione in cui elaborazione e storage sono disaccoppiati.  Questa soluzione sblocca inoltre una scalabilità e un'elasticità senza pari per gli ambienti Splunk Enterprise, consentendo ai clienti di scalare su siti singoli e multipli, riducendo al contempo i costi grazie alla scalabilità indipendente di elaborazione e archiviazione e aggiungendo livelli intelligenti all'archiviazione di oggetti S3 basata su cloud a costi contenuti.</block>
  <block id="f8ff71716eed4ad221efc3e0d60beaf6" category="paragraph">La soluzione ottimizza la quantità di dati nell'archiviazione locale mantenendo al contempo le prestazioni di ricerca, consentendo di scalare elaborazione e archiviazione su richiesta.  SmartStore valuta automaticamente i modelli di accesso ai dati per determinare quali dati devono essere accessibili per analisi in tempo reale e quali dati devono risiedere nell'archiviazione di oggetti S3 a basso costo.</block>
  <block id="5c56ae45ba2fb5c42451dffdb2e64b55" category="paragraph">Questo rapporto tecnico illustra i vantaggi che NetApp offre a una soluzione Splunk SmartStore, illustrando al contempo un framework per la progettazione e il dimensionamento di Splunk SmartStore nel tuo ambiente.  Il risultato è una soluzione semplice, scalabile e resiliente che garantisce un TCO interessante.  StorageGRID fornisce un archivio di oggetti scalabile e conveniente basato sul protocollo S3/API, noto anche come archiviazione remota, che consente alle organizzazioni di scalare la propria soluzione Splunk a un costo inferiore, aumentando al contempo la resilienza.</block>
  <block id="9841b81741e6066deac80b48e24f10fd" category="admonition">Splunk SmartStore definisce l'archiviazione di oggetti come archivi remoti o livelli di archiviazione remoti.</block>
  <block id="4c1ead791cca9ec5a7b94356255ce5ef" category="section-title">Informazioni su NetApp StorageGRID</block>
  <block id="57f13ae6637bd7ac5af4d0b1c4342cf7" category="paragraph">NetApp StorageGRID è una soluzione di archiviazione di oggetti definita dal software per archivi di grandi dimensioni, repository multimediali e archivi di dati Web.  Con StorageGRID, NetApp sfrutta due decenni di esperienza nella fornitura di soluzioni di innovazione e gestione dei dati leader del settore, aiutando al contempo le organizzazioni a gestire e massimizzare il valore delle loro informazioni sia in sede che in distribuzioni cloud pubbliche, private o ibride.</block>
  <block id="6281e52aec6aad8556d89bbf44d95436" category="paragraph">StorageGRID fornisce un archivio sicuro e durevole per dati non strutturati su larga scala.  Le policy di gestione del ciclo di vita integrate e basate sui metadati ottimizzano la posizione dei dati durante tutto il loro ciclo di vita.  I contenuti vengono posizionati nel posto giusto, al momento giusto e nel livello di archiviazione giusto per ridurre i costi.  Grazie al singolo namespace è possibile accedere ai dati tramite un'unica chiamata, indipendentemente dalla posizione geografica dell'archiviazione StorageGRID .  I clienti possono distribuire e gestire più istanze StorageGRID tra data center e nell'infrastruttura cloud.</block>
  <block id="d0a72d49cbe69b32b6e889db2e1429c9" category="paragraph">Un sistema StorageGRID è composto da nodi eterogenei, ridondanti e distribuiti a livello globale, che possono essere integrati sia con applicazioni client esistenti che con quelle di nuova generazione.</block>
  <block id="a8bc435c89c3235d62a12e0fb3c5c909" category="paragraph"><block ref="a8bc435c89c3235d62a12e0fb3c5c909" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4077a77339f68c64c1e50f20961e468f" category="paragraph">IDC MarketScape ha recentemente nominato NetApp leader nell'ultimo rapporto, IDC MarketScape: Worldwide Object-Based Storage 2019 Vendor Assessment.  Con quasi 20 anni di implementazione in ambito produttivo nei settori più esigenti, StorageGRID è un leader riconosciuto nel settore dei dati non strutturati.</block>
  <block id="a2146cca70b8afc5500f690b84357813" category="paragraph">Con StorageGRID puoi ottenere quanto segue:</block>
  <block id="0d29e2d2977160f50fc59018cd24d6ee" category="list-text">Distribuisci più istanze StorageGRID per accedere ai dati da qualsiasi posizione tra i data center e il cloud tramite un singolo namespace facilmente scalabile fino a centinaia di petabyte.</block>
  <block id="770d656b5273d26168b61ba6ede38cfd" category="list-text">Offrire flessibilità per distribuire e gestire centralmente le infrastrutture.</block>
  <block id="5926e6b363cbfe237a46219c7f92fe02" category="list-text">Garantisce una durata senza pari con quindici-nove di resistenza sfruttando la codifica di cancellazione a strati (EC).</block>
  <block id="77a48d0beb74ba75ef47c32ed1115a01" category="list-text">Abilita più funzionalità multi-cloud ibride con integrazioni convalidate in Amazon S3 Glacier e Azure Blob.</block>
  <block id="ffa0a5ca524779112b69eb9e53aacf31" category="list-text">Soddisfa gli obblighi normativi e facilita la conformità tramite la conservazione dei dati a prova di manomissione, senza API proprietarie o vincoli con i fornitori.</block>
  <block id="6e9d67cdb6f2e5564ae28e0389bcc679" category="inline-link">Pagina iniziale di NetApp StorageGRID</block>
  <block id="206008935f811359069d9b35cb5c874e" category="paragraph">Per ulteriori informazioni su come StorageGRID può aiutarti a risolvere i problemi più complessi di gestione dei dati non strutturati, consulta<block ref="56ef38793a035acc851dabaa0c795287" category="inline-link-rx"></block> .</block>
  <block id="04bfb82e5f80fda36ff56ad540caaa63" category="section-title">Informazioni su Splunk Enterprise</block>
  <block id="a643f0cfa3f1b40b8f79f3609f0aa84f" category="paragraph">Splunk Enterprise è una piattaforma che trasforma i dati in azioni concrete.  I dati generati da varie fonti, come file di registro, siti Web, dispositivi, sensori e applicazioni, vengono inviati e analizzati dagli indicizzatori Splunk, consentendo di ricavare informazioni dettagliate dai dati.  Potrebbe identificare violazioni dei dati, evidenziare tendenze di clienti e prodotti, trovare opportunità per ottimizzare l'infrastruttura o creare informazioni fruibili in un'ampia gamma di casi d'uso.</block>
  <block id="6118f726dd6c9b9e82e01638e958e5c8" category="section-title">Informazioni su Splunk SmartStore</block>
  <block id="9ce6098334cce9db7edb3314ee645a2e" category="paragraph">Splunk SmartStore amplia i vantaggi dell'architettura Splunk semplificandone al contempo la scalabilità in modo economicamente vantaggioso.  La separazione delle risorse di elaborazione e di archiviazione si traduce in nodi indicizzatori ottimizzati per l'I/O con esigenze di archiviazione notevolmente ridotte, poiché memorizzano solo un sottoinsieme di dati nella cache.  Non è necessario aggiungere ulteriore capacità di elaborazione o di archiviazione quando è necessaria solo una di queste risorse, il che consente di ottenere notevoli risparmi sui costi.  È possibile utilizzare un archivio di oggetti basato su S3, conveniente e facilmente scalabile, che semplifica ulteriormente l'ambiente, riduce i costi e consente di gestire un set di dati più ampio.</block>
  <block id="fde880b7e5def5ccc70e3e98ba15b442" category="paragraph">Splunk SmartStore offre un valore significativo alle organizzazioni, tra cui:</block>
  <block id="16fc7d5921f88ca7b8070e1913a6fb74" category="list-text">Riduzione dei costi di archiviazione spostando i dati caldi su un archivio di oggetti S3 ottimizzato in termini di costi</block>
  <block id="9ce78e75b3ecebf85fe0d43f2cf80505" category="list-text">Scalabilità senza soluzione di continuità mediante disaccoppiamento di storage e calcolo</block>
  <block id="1dd6f3d1f3ac2a43dc2e69386b1b15ca" category="list-text">Semplificare la continuità aziendale sfruttando l'archiviazione cloud-native resiliente</block>
  <block id="bdcc72fc1bad1a939182ad2bde321f1e" category="summary">Questa pagina descrive le prestazioni di Splunk SmartStore su un controller NetApp StorageGRID .</block>
  <block id="b646ed758d0eaa12ba9fab12788f9ad4" category="doc">Prestazioni SmartStore a sito singolo</block>
  <block id="b72db8dc34d5e01f398d66c9de42c11f" category="paragraph">Questa sezione descrive le prestazioni di Splunk SmartStore su un controller NetApp StorageGRID .  Splunk SmartStore sposta i dati caldi su un archivio remoto, che in questo caso è l'archivio di oggetti StorageGRID nella convalida delle prestazioni.</block>
  <block id="dd1e8d1bd57ca578a4ba44e789957d0f" category="paragraph"><block ref="dd1e8d1bd57ca578a4ba44e789957d0f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32b74ac1eb4eb0530a3f976e96e3120d" category="paragraph">Abbiamo utilizzato EF600 per l'archiviazione hot/cache e StorageGRID 6060 per l'archiviazione remota.  Per la convalida delle prestazioni abbiamo utilizzato la seguente architettura.  Abbiamo utilizzato due search head, quattro heavy forwarder per inoltrare i dati agli indicizzatori, sette Splunk Event Generator (Eventgen) per generare i dati in tempo reale e 18 indicizzatori per archiviare i dati.</block>
  <block id="b127bd17913b4ab46912efd5b9a74269" category="paragraph"><block ref="b127bd17913b4ab46912efd5b9a74269" category="inline-image-macro-rx" type="image"></block></block>
  <block id="254f642527b45bc260048e30704edb39" category="section-title">Configurazione</block>
  <block id="45940e86de61b51821b0ec7959b3d551" category="paragraph">Questa tabella elenca l'hardware utilizzato per la convalida delle prestazioni di SmartStorage.</block>
  <block id="2fda610cb12c654fe037d4130498d5ae" category="cell">Spedizioniere pesante</block>
  <block id="6d53d218eec402993fef5394aef9acdf" category="cell">16 core</block>
  <block id="d3dd61dd737f0e824caf9d717bc1a59d" category="cell">SLITTA 15 SP2</block>
  <block id="6f4922f45568161a8cdf4ad2299f6d23" category="cell">18</block>
  <block id="21dd53b3176e5a03137d603514a60ece" category="cell">L'interfaccia utente cerca i dati negli indicizzatori</block>
  <block id="c247e74124395bc7279d790ac384786e" category="section-title">Convalida delle prestazioni del negozio remoto SmartStore</block>
  <block id="30cf0ca744869370aafb6cfecdd7b4c6" category="paragraph">In questa convalida delle prestazioni, abbiamo configurato la cache SmartStore nell'archiviazione locale su tutti gli indicizzatori per 10 giorni di dati.  Abbiamo abilitato il<block ref="6255199182bd8af7ba33e8a06e144dc4" prefix=" " category="inline-code"></block> (dimensione bucket da 750 MB) nel gestore cluster Splunk e ho inviato le modifiche a tutti gli indicizzatori.  Per misurare le prestazioni di caricamento, abbiamo acquisito 10 TB al giorno per 10 giorni e abbiamo trasferito tutti i bucket attivi in modalità riscaldamento contemporaneamente, catturando il picco e la velocità effettiva media per istanza e per l'intera distribuzione dalla dashboard della SmartStore Monitoring Console.</block>
  <block id="4fc95542b54fee8da424a2e0ab281aeb" category="paragraph">Questa immagine mostra i dati acquisiti in un giorno.</block>
  <block id="1c106a39adeca49606809938222599d3" category="paragraph"><block ref="1c106a39adeca49606809938222599d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b72140907b2e824ba4a35a2f01bac4e6" category="paragraph">Abbiamo eseguito il seguente comando dal cluster master (il nome dell'indice è<block ref="b6f5a7e4d9c3de59289306e2636a7438" prefix=" " category="inline-code"></block> ).  Abbiamo quindi registrato il picco e la velocità media di caricamento per istanza e per l'intera distribuzione tramite le dashboard della SmartStore Monitoring Console.</block>
  <block id="94a0389fcc3ce42eea7a3f351f5d39b5" category="admonition">Il master del cluster dispone di autenticazione senza password per tutti gli indicizzatori (rtp-idx0001…rtp-idx0018).</block>
  <block id="d27688c7ebc58e3f620120997e317180" category="paragraph">Per misurare le prestazioni di download, abbiamo rimosso tutti i dati dalla cache eseguendo due volte l'interfaccia a riga di comando evict utilizzando il seguente comando.</block>
  <block id="4faf8abcf7e17175784cdc9d58df1608" category="admonition">Abbiamo eseguito il seguente comando dal cluster master ed eseguito la ricerca dalla testina di ricerca su 10 giorni di dati dall'archivio remoto da StorageGRID.  Abbiamo quindi registrato il picco e la velocità media di caricamento per istanza e per l'intera distribuzione tramite le dashboard della SmartStore Monitoring Console.</block>
  <block id="995931f06acb79ea5ac83df17d692a1d" category="paragraph">Le configurazioni dell'indicizzatore sono state trasferite dal master del cluster SmartStore.  Il master del cluster aveva la seguente configurazione per l'indicizzatore.</block>
  <block id="514109dd07ed0bb93081e9e36291b879" category="paragraph">Abbiamo eseguito la seguente query di ricerca sulla testina di ricerca per raccogliere la matrice delle prestazioni.</block>
  <block id="71e6150ea19aef0f2e67a79bd131fca8" category="paragraph"><block ref="71e6150ea19aef0f2e67a79bd131fca8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67e03c2395d7a876b5160fefc76f9bb9" category="paragraph">Abbiamo raccolto le informazioni sulle prestazioni dal cluster master.  La prestazione massima è stata di 61,34 GBps.</block>
  <block id="c5e60940f195879f09af22af10f55027" category="paragraph"><block ref="c5e60940f195879f09af22af10f55027" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2850e7edd48f5666ab4f82242ddb37d2" category="paragraph">La prestazione media è stata di circa 29 GBps.</block>
  <block id="a8eebaef6e6889ddddfe09cfa523009c" category="paragraph"><block ref="a8eebaef6e6889ddddfe09cfa523009c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283456e93c96a11ef44a18693dd6c886" category="section-title">Prestazioni StorageGRID</block>
  <block id="f5451e9a153b2f625ec0bc944af01be5" category="inline-link">Eventgen</block>
  <block id="764a1901ab00adf1e8e26712bf39c23a" category="paragraph">Le prestazioni di SmartStore si basano sulla ricerca di modelli e stringhe specifici da grandi quantità di dati.  In questa convalida, gli eventi vengono generati utilizzando<block ref="6cec2d19baf7e588a52847e567dab457" category="inline-link-rx"></block> su uno specifico indice Splunk (eventgen-test) tramite la testina di ricerca e la richiesta viene inviata a StorageGRID per la maggior parte delle query.  L'immagine seguente mostra i risultati positivi e negativi dei dati della query.  I dati relativi agli hit provengono dal disco locale, mentre i dati relativi agli miss provengono dal controller StorageGRID .</block>
  <block id="3b8a6855a0eb4beaf2c787f34a2428d7" category="admonition">Il colore verde mostra i dati dei successi, mentre il colore arancione mostra i dati dei fallimenti.</block>
  <block id="5776938ffab0b4f2730d8923c004d57e" category="paragraph"><block ref="5776938ffab0b4f2730d8923c004d57e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6fa8244cc2900d6f36b3144c7e748ac" category="paragraph">Quando viene eseguita la query per la ricerca su StorageGRID, il tempo di recupero S3 da StorageGRID viene mostrato nell'immagine seguente.</block>
  <block id="7393ba7bdc5067b2c80450122c8a2f0d" category="paragraph"><block ref="7393ba7bdc5067b2c80450122c8a2f0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e3fd399eb98a5a8fae1dc144ff614f3" category="section-title">Utilizzo dell'hardware StorageGRID</block>
  <block id="8e8a6c088425467c00be94a9d15d015b" category="paragraph">L'istanza StorageGRID ha un bilanciatore del carico e tre controller StorageGRID .  L'utilizzo della CPU per tutti e tre i controller è compreso tra il 75% e il 100%.</block>
  <block id="69851341d968a4444c52d6c167608079" category="paragraph"><block ref="69851341d968a4444c52d6c167608079" category="inline-image-macro-rx" type="image"></block></block>
  <block id="140097f96ea2b213b6f37f9d71009a5e" category="section-title">SmartStore con controller di archiviazione NetApp : vantaggi per il cliente</block>
  <block id="7f18772207b4ab40d0e7574fc68b95b6" category="list-text">*Disaccoppiamento tra elaborazione e archiviazione.*  Splunk SmartStore separa elaborazione e archiviazione, consentendoti di scalarli in modo indipendente.</block>
  <block id="4e1a3208fe0742415bc087d082943293" category="list-text">*Dati su richiesta.*  SmartStore avvicina i dati al calcolo on-demand e fornisce elasticità di elaborazione e archiviazione ed efficienza dei costi per ottenere una conservazione dei dati più lunga su larga scala.</block>
  <block id="f3295a31a8b7a9b5d76cb1a1e7f67f28" category="list-text">*Conforme all'API AWS S3.*  SmartStore utilizza l'API AWS S3 per comunicare con Restore Storage, che è un archivio di oggetti conforme ad AWS S3 e all'API S3, come StorageGRID.</block>
  <block id="4fda7aba03882818928ff7bc3a03f0e5" category="list-text">*Riduce i requisiti e i costi di archiviazione.*  SmartStore riduce i requisiti di archiviazione per i dati obsoleti (caldi/freddi).  È necessaria una sola copia dei dati perché lo storage NetApp garantisce la protezione dei dati e gestisce guasti e alta disponibilità.</block>
  <block id="c27703d92f7f2316dfa63670f02dd6b6" category="list-text">*Guasto hardware.*  Un errore del nodo in una distribuzione SmartStore non rende i dati inaccessibili e il ripristino dell'indicizzatore in caso di errore hardware o squilibrio dei dati è molto più rapido.</block>
  <block id="ed20f2e9df3c744293f044d87722ce0f" category="list-text">Cache basata su dati e applicazioni.</block>
  <block id="f57d44dedead861d1eef7e912b9cbd86" category="list-text">Aggiungi/rimuovi indicizzatori e configura/distruggi cluster su richiesta.</block>
  <block id="98613866f09e0e2416018bef4be916d3" category="list-text">Il livello di archiviazione non è più legato all'hardware.</block>
  <block id="c1d2fce5798cdc81a1393206b0332f8a" category="summary">La soluzione consente di aggiungere risorse di elaborazione, hot storage o S3 per soddisfare la crescente domanda in termini di numero di utenti o velocità di acquisizione in distribuzioni singole e multi-sito.</block>
  <block id="4932435adc5992fde32a04e44fd251b8" category="doc">Vantaggi di questa soluzione</block>
  <block id="bf89e1232480b95d07f648df24c3695b" category="list-text">*Prestazione.*  La combinazione di Splunk SmartStore e NetApp StorageGRID garantisce una rapida migrazione dei dati tra hot bucket e warm bucket utilizzando l'archiviazione di oggetti.  StorageGRID accelera il processo di migrazione garantendo prestazioni rapide per carichi di lavoro di oggetti di grandi dimensioni.</block>
  <block id="e0be1ad556d6601e63eb8f1b6208c55e" category="list-text">*Pronto per più siti.*  L'architettura distribuita StorageGRID consente a Splunk SmartStore di estendere le distribuzioni su siti singoli e multipli tramite un unico namespace globale in cui è possibile accedere ai dati da qualsiasi sito, indipendentemente da dove si trovino.</block>
  <block id="9efd709ebdaac869f02b49e17fe9e92b" category="list-text">*Migliorata scalabilità.*  Scala le risorse di storage in modo indipendente dalle risorse di elaborazione per soddisfare le esigenze e le richieste in continua evoluzione nel tuo ambiente Splunk, garantendo così un TCO migliore.</block>
  <block id="52fb1ca9da3811c1cb86cd4347f98a64" category="list-text">*Capacità.*  Gestisci i volumi in rapida crescita nella distribuzione Splunk con StorageGRID , scalando un singolo namespace a oltre 560 PB.</block>
  <block id="ff501c8a6a8c7b1ee7a3c656b6f4055a" category="list-text">*Disponibilità dei dati.*  Ottimizza la disponibilità dei dati, le prestazioni, la distribuzione geografica, la conservazione, la protezione e i costi di archiviazione con policy basate sui metadati che possono essere adattate dinamicamente in base all'evoluzione del valore aziendale dei tuoi dati.</block>
  <block id="bf1b0e32d877d343f0b3bc9ba43cb688" category="inline-link">linee guida fornite da Splunk</block>
  <block id="3c5d06925a5d5bceedd74c82d3d38c04" category="paragraph">Aumenta le prestazioni con la cache SmartStore, un componente dell'indicizzatore che gestisce il trasferimento delle copie dei bucket tra l'archiviazione locale (hot) e quella remota (warm).  Il dimensionamento Splunk per questa soluzione si basa su<block ref="d615ab802f29a9ee4a18e420480d049f" category="inline-link-rx"></block> .  La soluzione consente di aggiungere risorse di elaborazione, hot storage o S3 per soddisfare la crescente domanda in termini di numero di utenti o velocità di acquisizione in distribuzioni singole e multi-sito.</block>
  <block id="39e4c49e9af8047395aa4031e5c5f3a9" category="summary">Questa pagina descrive i componenti utilizzati per completare questa soluzione, tra cui NetApp StorageGRID, Splunk Enterprise e Splunk SmartStore.</block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="doc">Panoramica della soluzione</block>
  <block id="5ab9d0d9b506bd4b5bf294baccd4ef0a" category="paragraph">NetApp StorageGRID è una piattaforma di storage di oggetti ad alte prestazioni e conveniente.  Offre una gestione intelligente dei dati globali basata su policy, utilizzando un'architettura a griglia distribuita basata su nodi.  Semplifica la gestione di petabyte di dati non strutturati e miliardi di oggetti attraverso il suo onnipresente spazio dei nomi degli oggetti globali combinato con sofisticate funzionalità di gestione dei dati.  L'accesso agli oggetti tramite una singola chiamata si estende su più siti e semplifica le architetture ad alta disponibilità, garantendo al contempo un accesso continuo agli oggetti indipendentemente dalle interruzioni del sito o dell'infrastruttura.</block>
  <block id="d67c579ad5ceca0ec4f8fe6a86f203cf" category="paragraph">La multitenancy consente di gestire in modo sicuro più applicazioni cloud e dati aziendali non strutturati all'interno della stessa griglia, aumentando il ROI e i casi d'uso di StorageGRID.  È possibile creare più livelli di servizio con policy del ciclo di vita degli oggetti basate sui metadati, ottimizzando la durabilità, la protezione, le prestazioni e la località in più aree geografiche.  Gli utenti possono adattare le policy e riallineare il panorama dei dati senza interruzioni man mano che cambiano le loro esigenze.</block>
  <block id="0d2b0fb2b312d872db772396e149b541" category="paragraph">SmartStore sfrutta StorageGRID come livello di archiviazione remoto e consente ai clienti di implementare più siti distribuiti geograficamente per una disponibilità e una durabilità elevate, presentate come un singolo spazio dei nomi di oggetti.  Ciò consente a Splunk SmartStore di sfruttare le elevate prestazioni, la capacità densa e la capacità di scalare StorageGRID fino a centinaia di nodi su più siti fisici utilizzando un singolo URL per interagire con gli oggetti.  Questo singolo URL consente inoltre che l'espansione, gli aggiornamenti e le riparazioni dello storage non interferiscano con le attività, anche al di fuori di un singolo sito.  L'esclusivo motore di policy di gestione dei dati StorageGRID garantisce livelli ottimizzati di prestazioni e durabilità, nonché il rispetto dei requisiti di località dei dati.</block>
  <block id="f9ed96cf2d028d3cfa9c658c6ec5ae72" category="paragraph">Splunk, leader nella raccolta e nell'analisi di dati generati dalle macchine, contribuisce a semplificare e modernizzare l'IT attraverso le sue capacità di analisi operativa.  Si estende anche ai casi d'uso di analisi aziendale, sicurezza e IoT.  Lo storage è un fattore essenziale per il successo della distribuzione del software Splunk.</block>
  <block id="1812fb837f2c63812e909b4457b0fa17" category="paragraph">I dati generati dalle macchine rappresentano la tipologia di big data in più rapida crescita.  Il formato è imprevedibile e proviene da molte fonti diverse, spesso a prezzi elevati e in grandi volumi.  Queste caratteristiche del carico di lavoro vengono spesso definite "scarico digitale".  Splunk SmartStore aiuta a dare un senso a questi dati e fornisce una suddivisione intelligente dei dati in livelli per il posizionamento ottimizzato dei dati attivi e passivi sul livello di archiviazione più conveniente.</block>
  <block id="bd069a1be23f237559be08ae79727806" category="paragraph">Splunk SmartStore è una funzionalità di indicizzazione che utilizza l'archiviazione di oggetti (chiamata anche archiviazione remota o livelli di archiviazione remota) come StorageGRID per archiviare dati caldi tramite il protocollo S3.</block>
  <block id="9e5e9e455aa469c6579c4cde82cf69fc" category="paragraph">Con l'aumento del volume di dati di un'implementazione, la domanda di spazio di archiviazione solitamente supera la domanda di risorse informatiche.  SmartStore consente di gestire in modo conveniente le risorse di elaborazione e di archiviazione dell'indicizzatore, ridimensionando separatamente elaborazione e archiviazione.</block>
  <block id="1ab3873a2fa155a27933ac3e2b4ae709" category="paragraph">SmartStore introduce un livello di archiviazione remoto, utilizzando il protocollo S3, e un gestore della cache.  Queste funzionalità consentono ai dati di risiedere localmente su indicizzatori o su archivi remoti.  Il gestore della cache, che risiede sull'indicizzatore, gestisce lo spostamento dei dati tra l'indicizzatore e il livello di archiviazione remoto.  I dati vengono archiviati in bucket (caldi e tiepidi) insieme ai metadati dei bucket.</block>
  <block id="85a6e51e1b2fd3e4be531f269e108f39" category="paragraph">Con SmartStore puoi ridurre al minimo l'ingombro di archiviazione dell'indicizzatore e scegliere risorse di elaborazione ottimizzate per l'I/O, poiché la maggior parte dei dati risiede sul livello di archiviazione remoto.  L'indicizzatore mantiene una cache locale, che rappresenta la quantità minima di dati necessaria per restituire i risultati richiesti e previsti.  La cache locale contiene bucket attivi, copie di bucket attivi che partecipano a ricerche attive o recenti e metadati dei bucket.</block>
  <block id="8cc78103debf2dcfe53620b96565dad4" category="paragraph">Splunk SmartStore con StorageGRID consente ai clienti di scalare in modo incrementale l'ambiente con storage remoto ad alte prestazioni e conveniente, garantendo al contempo un elevato grado di elasticità alla soluzione complessiva.  Ciò consente ai clienti di aggiungere qualsiasi componente (archiviazione a caldo e/o archiviazione S3 calda) in qualsiasi quantità e in qualsiasi momento, indipendentemente dal fatto che abbiano bisogno di più indicizzatori, di modificare la conservazione dei dati o di aumentare la velocità di acquisizione senza alcuna interruzione.</block>
  <block id="d919f51e7020fabd237372f4c163a60e" category="summary">StorageGRID offre un'ampia gamma di funzionalità che gli utenti possono sfruttare e personalizzare in base al loro ambiente in continua evoluzione.</block>
  <block id="0fc3cf31004e01f169ca3af4ef687576" category="doc">Funzionalità flessibili StorageGRID per Splunk SmartStore</block>
  <block id="d7ec4db6b0e9313773163a8a2404946e" category="paragraph">StorageGRID offre un'ampia gamma di funzionalità che gli utenti possono sfruttare e personalizzare in base al loro ambiente in continua evoluzione.  Dall'implementazione al ridimensionamento di Splunk SmartStore, il tuo ambiente richiede un'adozione rapida dei cambiamenti e non deve interrompere Splunk.  Le policy di gestione dati flessibili (ILM) e i classificatori del traffico (QoS) StorageGRID consentono di pianificare e adattare al proprio ambiente.</block>
  <block id="5b552d68210e15d5ed4e4d186264b453" category="paragraph">Grid Manager è l'interfaccia grafica basata su browser che consente di configurare, gestire e monitorare il sistema StorageGRID in sedi distribuite a livello globale da un unico pannello di controllo, come mostrato nell'immagine seguente.</block>
  <block id="b426e35a4f24b1452cf4688598a7429c" category="paragraph"><block ref="b426e35a4f24b1452cf4688598a7429c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52d198c85ec187eb3bbff17442a01baa" category="paragraph">Eseguire le seguenti attività con l'interfaccia di Grid Manager:</block>
  <block id="356e4420bfe7b6226984261d66ec9e0b" category="section-title">Applicazione NetApp StorageGRID per Splunk</block>
  <block id="d4503ceebebf47c506c3003f760662a2" category="paragraph">L'app NetApp StorageGRID per Splunk è un'applicazione specifica per Splunk Enterprise.  Questa app funziona insieme al componente aggiuntivo NetApp StorageGRID per Splunk.  Fornisce visibilità sullo stato StorageGRID , informazioni sull'utilizzo dell'account, dettagli di controllo della sicurezza, utilizzo e monitoraggio delle risorse e così via.</block>
  <block id="c7b8ad57a7270e26eba0ed9da1fa0b6c" category="paragraph">L'immagine seguente mostra l'app StorageGRID per Splunk.</block>
  <block id="33e8e06b4bbde24cf3f439a1bd66cf19" category="paragraph"><block ref="33e8e06b4bbde24cf3f439a1bd66cf19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7e07b036910adce42ba90efc47f818e" category="section-title">Politiche ILM</block>
  <block id="2121ccc9450b2df939a6752c3559486a" category="paragraph">StorageGRID dispone di policy di gestione dei dati flessibili che includono la conservazione di più copie degli oggetti e l'utilizzo di schemi EC (erasure coding) come 2+1 e 4+2 (e molti altri) per archiviare gli oggetti in base a requisiti specifici di prestazioni e protezione dei dati.  Poiché i carichi di lavoro e i requisiti cambiano nel tempo, è normale che anche le policy ILM debbano cambiare nel tempo.  La modifica delle policy ILM è una funzionalità fondamentale che consente ai clienti StorageGRID di adattarsi in modo rapido e semplice al loro ambiente in continua evoluzione.</block>
  <block id="3f7d13681fac5c1ca00c53ae2a27efaa" category="paragraph">StorageGRID aumenta le prestazioni aggiungendo più nodi, che possono essere VM, bare metal o appliance appositamente realizzate come SG5712, SG5760, SG6060 o SGF6024.  Nei nostri test abbiamo superato i requisiti di prestazioni chiave di SmartStore con una griglia minima a tre nodi utilizzando l'appliance SG6060.  Man mano che i clienti ampliano la propria infrastruttura Splunk con indicizzatori aggiuntivi, possono aggiungere più nodi di archiviazione per aumentare prestazioni e capacità.</block>
  <block id="8a0453356d4720c8c5a67e5e2a16b419" category="section-title">Configurazione del bilanciatore del carico e degli endpoint</block>
  <block id="08de46c3a8d44cfa799d969abfa407eb" category="paragraph">I nodi amministrativi in StorageGRID forniscono l'interfaccia utente (UI) di Grid Manager e l'endpoint API REST per visualizzare, configurare e gestire il sistema StorageGRID , nonché registri di controllo per monitorare l'attività del sistema.  Per fornire un endpoint S3 ad alta disponibilità per l'archiviazione remota Splunk SmartStore, abbiamo implementato il bilanciatore del carico StorageGRID , che viene eseguito come servizio sui nodi di amministrazione e sui nodi gateway.  Inoltre, il bilanciatore del carico gestisce anche il traffico locale e comunica con il GSLB (Global Server Load Balancing) per facilitare il ripristino in caso di emergenza.</block>
  <block id="d2134190f6b031237d4b1523c86c29a2" category="paragraph">Per migliorare ulteriormente la configurazione degli endpoint, StorageGRID fornisce criteri di classificazione del traffico integrati nel nodo di amministrazione, consente di monitorare il traffico del carico di lavoro e di applicare vari limiti di qualità del servizio (QoS) ai carichi di lavoro.  I criteri di classificazione del traffico vengono applicati agli endpoint del servizio StorageGRID Load Balancer per i nodi gateway e i nodi amministrativi.  Queste politiche possono aiutare a limitare e monitorare il traffico.</block>
  <block id="9fa345c6a2f967ec80e8b940a9d2a1c3" category="summary">Man mano che i clienti si rendono conto della potenza e della semplicità di utilizzo dell'analisi dei dati di Splunk, è naturale che vogliano indicizzare una quantità di dati sempre maggiore.  Con l'aumentare della quantità di dati, aumenta anche l'infrastruttura di elaborazione e archiviazione necessaria per gestirli.</block>
  <block id="f9a3e09b74e61e83c0352f2953dcdc87" category="doc">Tiering intelligente e risparmio sui costi</block>
  <block id="e09913e41f1a0082ec190482abfeff57" category="paragraph">Man mano che i clienti si rendono conto della potenza e della semplicità di utilizzo dell'analisi dei dati di Splunk, è naturale che vogliano indicizzare una quantità di dati sempre maggiore.  Con l'aumentare della quantità di dati, aumenta anche l'infrastruttura di elaborazione e archiviazione necessaria per gestirli.  Poiché i dati più vecchi vengono consultati meno frequentemente, impegnare la stessa quantità di risorse di elaborazione e consumare costosi archivi primari diventa sempre più inefficiente.  Per operare su larga scala, i clienti traggono vantaggio dallo spostamento dei dati "caldi" a un livello più conveniente, liberando risorse di elaborazione e di storage primario per i dati "caldi".</block>
  <block id="f7300ec91634b8cd535c45fd11ee503f" category="paragraph">Splunk SmartStore con StorageGRID offre alle organizzazioni una soluzione scalabile, performante e conveniente.  Poiché SmartStore è consapevole dei dati, valuta automaticamente i modelli di accesso ai dati per determinare quali dati devono essere accessibili per analisi in tempo reale (dati attivi) e quali dati devono risiedere in un archivio a lungo termine a basso costo (dati attivi).  SmartStore utilizza in modo dinamico e intelligente l'API AWS S3, standard del settore, inserendo i dati nello storage S3 fornito da StorageGRID.  L'architettura flessibile e scalabile di StorageGRID consente al livello di dati caldi di crescere in modo economicamente vantaggioso in base alle necessità.  L'architettura basata su nodi di StorageGRID garantisce che i requisiti di prestazioni e costi siano soddisfatti in modo ottimale.</block>
  <block id="d75fb5ef86bb0625c22c38dd2229c627" category="paragraph">L'immagine seguente illustra la suddivisione in livelli di Splunk e StorageGRID .</block>
  <block id="f710071dfe9306034297e2bbb442d8bc" category="paragraph"><block ref="f710071dfe9306034297e2bbb442d8bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6821c40fa59a17fa0f78dbb9e556be5" category="paragraph">La combinazione leader del settore di Splunk SmartStore con NetApp StorageGRID offre i vantaggi di un'architettura disaccoppiata tramite una soluzione full-stack.</block>
  <block id="404af9ebdf8554a92ea8d3dde06945b4" category="doc">TR-4623: NetApp E-Series E5700 e Splunk Enterprise</block>
  <block id="1dcb8fb2d6ad519f4a7ecd244f9c7c76" category="paragraph">Mitch Blackburn, NetApp</block>
  <block id="8c121c8c1e758ef244a52184e2d48c66" category="paragraph">TR-4623 descrive l'architettura integrata del design NetApp E-Series e Splunk.  Ottimizzato per l'equilibrio dello storage dei nodi, l'affidabilità, le prestazioni, la capacità di storage e la densità, questo progetto impiega il modello di nodo indice clusterizzato Splunk, con maggiore scalabilità e TCO inferiore.  Separare l'archiviazione dall'elaborazione consente di scalare ciascuna risorsa separatamente, risparmiando sui costi di un eccessivo provisioning dell'una o dell'altra.  Inoltre, questo documento riassume i risultati dei test sulle prestazioni ottenuti da uno strumento di simulazione degli eventi del registro macchina Splunk.</block>
  <block id="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="paragraph"><block ref="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="inline-link-macro-rx"></block></block>
  <block id="f1739b1d5d1c44e562a8500d3b80579f" category="summary">Funzionalità di intelligenza artificiale NetApp che consentono una gestione e uno spostamento dei dati senza interruzioni lungo la pipeline di intelligenza artificiale per la formazione, la riqualificazione, la messa a punto, l'inferenza e il monitoraggio di modelli di intelligenza artificiale generativa.</block>
  <block id="36cc0281ec7abcd20091f5d39b995cc4" category="doc">Intelligenza artificiale generativa e valore NetApp</block>
  <block id="6dbc3469d4924aa631238769172515d8" category="paragraph">La domanda di intelligenza artificiale (IA) generativa sta determinando cambiamenti radicali in tutti i settori, migliorando la creatività aziendale e l'innovazione dei prodotti.</block>
  <block id="40ed4c797a14998a489b495cd8c9a5e0" category="paragraph">Molte organizzazioni utilizzano l'intelligenza artificiale generativa per sviluppare nuove funzionalità di prodotto, migliorare la produttività ingegneristica e prototipare applicazioni basate sull'intelligenza artificiale che offrono risultati ed esperienze migliori per i consumatori.  L'intelligenza artificiale generativa, come i Generative Pre-trained Transformers (GPT), utilizza reti neurali per creare nuovi contenuti, tra cui testo, audio e video.  Considerata l'estrema scala e gli enormi set di dati coinvolti nei modelli linguistici di grandi dimensioni (LLM), è fondamentale progettare un'infrastruttura di intelligenza artificiale solida che sfrutti le interessanti funzionalità di archiviazione dei dati delle opzioni di distribuzione on-premise, ibride e multicloud e riduca i rischi associati alla mobilità dei dati, alla protezione dei dati e alla governance prima che le aziende possano progettare soluzioni di intelligenza artificiale.  In questo documento vengono descritte queste considerazioni e le corrispondenti funzionalità di intelligenza artificiale NetApp che consentono una gestione e uno spostamento dei dati senza interruzioni lungo la pipeline dei dati di intelligenza artificiale per l'addestramento, il riaddestramento, la messa a punto e l'inferenza dei modelli di intelligenza artificiale generativa.</block>
  <block id="a573d92b77d430af7e424879baf78e94" category="section-title">Sintesi</block>
  <block id="3fed37bedb6b36d52c0c5b3aa0089bfe" category="paragraph">Più di recente, dopo il lancio di ChatGPT, uno spin-off di GPT-3 nel novembre 2022, i nuovi strumenti di intelligenza artificiale utilizzati per generare testo, codice, immagini o persino proteine terapeutiche in risposta alle richieste degli utenti hanno acquisito notevole fama.  Ciò indica che gli utenti possono effettuare una richiesta utilizzando il linguaggio naturale e l'intelligenza artificiale interpreterà e genererà testo, come articoli di giornale o descrizioni di prodotti che riflettono la richiesta dell'utente o produrranno codice, musica, parlato, effetti visivi e risorse 3D utilizzando algoritmi addestrati su dati già esistenti.  Di conseguenza, espressioni come Diffusione stabile, Allucinazioni, Ingegneria rapida e Allineamento del valore stanno emergendo rapidamente nella progettazione dei sistemi di intelligenza artificiale.  Questi modelli di apprendimento automatico (ML) auto-supervisionati o semi-supervisionati stanno diventando ampiamente disponibili come modelli di base pre-addestrati (FM) tramite fornitori di servizi cloud e altri fornitori di aziende di intelligenza artificiale, e vengono adottati da varie aziende in tutti i settori per un'ampia gamma di attività NLP (elaborazione del linguaggio naturale) a valle.  Come affermato da società di analisi di ricerca come McKinsey: "L'impatto dell'intelligenza artificiale generativa sulla produttività potrebbe aggiungere migliaia di miliardi di dollari di valore all'economia globale".  Mentre le aziende stanno ripensando l'intelligenza artificiale come partner intellettuale degli esseri umani e i gestori di gestione stanno ampliando contemporaneamente ciò che aziende e istituzioni possono fare con l'intelligenza artificiale generativa, le opportunità di gestire enormi volumi di dati continueranno a crescere.  Questo documento presenta informazioni introduttive sull'intelligenza artificiale generativa e sui concetti di progettazione in relazione alle funzionalità NetApp che apportano valore ai clienti NetApp , sia in ambienti locali che ibridi o multicloud.</block>
  <block id="ba4c46fa4f06702b4667d0b3a6b2bdfe" category="section-title">Cos'è l'intelligenza artificiale generativa?</block>
  <block id="11703c9edbc2bf714a8c4be38891fc77" category="paragraph">L'intelligenza artificiale generativa sta cambiando il modo in cui creiamo contenuti, generiamo nuovi concetti di design ed esploriamo composizioni innovative.  Illustra framework di reti neurali come Generative Adversarial Network (GAN), Variational Autoencoders (VAE) e Generative Pre-Trained Transformers (GPT), che possono generare nuovi contenuti come testo, codice, immagini, audio, video e dati sintetici.  Modelli basati su trasformatori come Chat-GPT di OpenAI, Bard di Google, BLOOM di Hugging Face e LLaMA di Meta sono emersi come tecnologie fondamentali alla base di molti progressi nei modelli linguistici di grandi dimensioni.  Allo stesso modo, Dall-E di OpenAI, CM3leon di Meta e Imagen di Google sono esempi di modelli di diffusione testo-immagine che offrono ai clienti un livello di fotorealismo senza precedenti per creare nuove immagini complesse da zero o modificare immagini esistenti per generare immagini contestuali di alta qualità utilizzando l'aumento del set di dati e la sintesi testo-immagine che collega la semantica testuale e visiva.  Gli artisti digitali stanno iniziando ad applicare una combinazione di tecnologie di rendering come NeRF (Neural Radiance Field) con l'intelligenza artificiale generativa per convertire immagini 2D statiche in scene 3D immersive.  In generale, gli LLM sono ampiamente caratterizzati da quattro parametri: (1) Dimensione del modello (tipicamente in miliardi di parametri); (2) Dimensione del set di dati di addestramento; (3) Costo dell'addestramento e (4) Prestazioni del modello dopo l'addestramento.  Anche gli LLM rientrano principalmente in tre architetture di trasformatori.  (i) Modelli solo con encoder.  Ad esempio BERT (Google, 2018); (ii) modelli Encoder-Decoder, ad esempio BART (Meta, 2020) e (iii) modelli solo Decoder.  Ad esempio LLaMA (Meta, 2023), PaLM-E (Google, 2023).  A seconda dei requisiti aziendali, indipendentemente dall'architettura scelta dall'azienda, il numero di parametri del modello (N) e il numero di token (D) nel set di dati di addestramento determinano generalmente il costo di base dell'addestramento (pre-addestramento) o della messa a punto di un LLM.</block>
  <block id="d1ddcb04dcb447b3f05fa54e9ab492d0" category="section-title">Casi d'uso aziendali e attività NLP a valle</block>
  <block id="a4a7c510156562fb9841dd055348b753" category="paragraph">Le aziende di tutti i settori stanno scoprendo sempre più il potenziale dell'intelligenza artificiale nell'estrarre e produrre nuove forme di valore dai dati esistenti per le operazioni aziendali, le vendite, il marketing e i servizi legali.  Secondo le informazioni di mercato di IDC (International Data Corporation) sui casi d'uso e gli investimenti globali nell'intelligenza artificiale generativa, la gestione della conoscenza nello sviluppo del software e nella progettazione dei prodotti sarà quella maggiormente interessata, seguita dalla creazione di storyline per il marketing e dalla generazione di codice per gli sviluppatori.  Nel settore sanitario, le organizzazioni di ricerca clinica stanno aprendo nuove strade alla medicina.  I modelli preaddestrati come ProteinBERT incorporano annotazioni Gene Ontology (GO) per progettare rapidamente strutture proteiche per farmaci, rappresentando una pietra miliare significativa nella scoperta di farmaci, nella bioinformatica e nella biologia molecolare.  Le aziende biotecnologiche hanno avviato sperimentazioni sull'uomo per la medicina generativa scoperta dall'intelligenza artificiale, che mira a curare malattie come la fibrosi polmonare (IPF), una malattia polmonare che provoca cicatrici irreversibili nel tessuto polmonare.</block>
  <block id="8e5aaca094938e3b1a2e08f48f3db558" category="paragraph">Figura 1: Casi d'uso che guidano l'intelligenza artificiale generativa</block>
  <block id="8d04a6a1813e89b5849d40e5113b0902" category="paragraph"><block ref="8d04a6a1813e89b5849d40e5113b0902" category="inline-image-macro-rx" type="image"></block></block>
  <block id="605e4f6997ac64a7de35f4e8a02721e9" category="paragraph">L'aumento dell'adozione dell'automazione, favorito dall'intelligenza artificiale generativa, sta modificando anche l'offerta e la domanda di attività lavorative per molte professioni.  Secondo McKinsey, il mercato del lavoro statunitense (diagramma sotto) ha attraversato una rapida transizione, che potrebbe proseguire solo se si considera l'impatto dell'intelligenza artificiale.</block>
  <block id="844d4a4d01e4441540857f7a302f6239" category="paragraph">Fonte: McKinsey &amp; Company</block>
  <block id="14509aeb117a81412dfa4dc27107f735" category="inline-image-macro">Figura 2: Fonte: McKinsey &amp; Company</block>
  <block id="f86a1cf79787f9ca7a0bc2698a14baa8" category="paragraph"><block ref="1cdd0679074896d7373f66c66dc8dda4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="072f966c176c14e4a8ac1b32dff891bc" category="section-title">Il ruolo dello storage nell'intelligenza artificiale generativa</block>
  <block id="6a352eac97ff84fb6680bea0e3f1582b" category="inline-link-macro">512 MB</block>
  <block id="23f951a15f217f2ce467c5d52e3a74a2" category="paragraph">Gli LLM si basano in larga parte su apprendimento profondo, GPU e calcolo.  Tuttavia, quando il buffer della GPU si riempie, i dati devono essere scritti rapidamente nella memoria.  Mentre alcuni modelli di intelligenza artificiale sono sufficientemente piccoli da poter essere eseguiti in memoria, gli LLM richiedono IOPS elevati e un'archiviazione ad alta velocità per fornire un accesso rapido a grandi set di dati, soprattutto se si tratta di miliardi di token o milioni di immagini.  Per un tipico requisito di memoria GPU di un LLM, la memoria necessaria per addestrare un modello con 1 miliardo di parametri potrebbe arrivare fino a 80 GB a 32 bit di precisione completa.  In tal caso, LLaMA 2 di Meta, una famiglia di LLM con una scala che va da 7 miliardi a 70 miliardi di parametri, potrebbe richiedere 70x80, ovvero circa 5600 GB o 5,6 TB di RAM GPU.  Inoltre, la quantità di memoria necessaria è direttamente proporzionale al numero massimo di token che si desidera generare.  Ad esempio, se si desidera generare output fino a 512 token (circa 380 parole), è necessario<block ref="8b6a924b2b2c8b02d5e56762d0384bc1" category="inline-link-macro-rx"></block> .  Potrebbe sembrare irrilevante, ma se si vogliono produrre lotti più grandi, la cosa inizia a farsi sentire.  Ciò rende molto costoso per le organizzazioni addestrare o perfezionare gli LLM in memoria, rendendo così l'archiviazione un elemento fondamentale per l'intelligenza artificiale generativa.</block>
  <block id="b0b4b15d26d559735ca79c547ebcf9b6" category="section-title">Tre approcci principali agli LLM</block>
  <block id="29ff458fbe275b29aaf5e7dbd636eed4" category="inline-link-macro">Harvard Business Review</block>
  <block id="b026e17fa592b49ccc86f0f9b718b03b" category="paragraph">Per la maggior parte delle aziende, in base alle tendenze attuali, l'approccio all'implementazione degli LLM può essere condensato in 3 scenari di base.  Come descritto in un recente<block ref="9b642d86ef84545807d431905b86239d" category="inline-link-macro-rx"></block> articolo: (1) Formazione (pre-formazione) di un LLM da zero: costosa e richiede competenze specialistiche in AI/ML; (2) Perfezionamento di un modello di base con dati aziendali: complesso, ma fattibile; (3) Utilizzo della generazione aumentata dal recupero (RAG) per interrogare repository di documenti, API e database vettoriali che contengono dati aziendali.  Ciascuno di questi presenta dei compromessi tra impegno, velocità di iterazione, efficienza dei costi e accuratezza del modello nelle loro implementazioni, utilizzati per risolvere diversi tipi di problemi (diagramma seguente).</block>
  <block id="c35884049dd0467b68f884a60d4920ea" category="paragraph">Figura 3: Tipi di problemi</block>
  <block id="2ee3234ece3d669efe95dc1a84c67a06" category="paragraph"><block ref="2ee3234ece3d669efe95dc1a84c67a06" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff76a02d3da4ad3236fe1704ce7b2a4c" category="section-title">Modelli di fondazione</block>
  <block id="212ec66e09b7b19d2e397c5c04e8543d" category="paragraph">Un modello di base (FM), noto anche come modello di base, è un modello di intelligenza artificiale (LLM) di grandi dimensioni addestrato su grandi quantità di dati non etichettati, utilizzando l'autosupervisione su larga scala, generalmente adattato per un'ampia gamma di attività NLP a valle.  Poiché i dati di addestramento non sono etichettati dagli esseri umani, il modello emerge anziché essere codificato in modo esplicito.  Ciò significa che il modello può generare storie o una narrazione propria senza essere programmato esplicitamente per farlo.  Pertanto una caratteristica importante della FM è l'omogeneizzazione, ovvero lo stesso metodo viene utilizzato in molti domini.  Tuttavia, grazie alle tecniche di personalizzazione e di messa a punto, i FM integrati nei prodotti che compaiono oggigiorno non solo sono efficaci nella generazione di testo, nella conversione di testo in immagini e nella conversione di testo in codice, ma anche nella spiegazione di attività specifiche di un dominio o nel debug del codice.  Ad esempio, FM come Codex di OpenAI o Code Llama di Meta possono generare codice in più linguaggi di programmazione basandosi su descrizioni in linguaggio naturale di un'attività di programmazione.  Questi modelli sono competenti in oltre una dozzina di linguaggi di programmazione, tra cui Python, C#, JavaScript, Perl, Ruby e SQL.  Comprendono l'intento dell'utente e generano codice specifico che realizza l'attività desiderata, utile per lo sviluppo del software, l'ottimizzazione del codice e l'automazione delle attività di programmazione.</block>
  <block id="09505640cb74de4ed6c0043b4fd83b62" category="section-title">Ottimizzazione, specificità del dominio e riaddestramento</block>
  <block id="d70061bb0ac24d99b6a01f537dfc5836" category="inline-link-macro">Meta's Llama 2</block>
  <block id="95d06c21390dc25827c0fd489dc141e4" category="paragraph">Fonte: Microsoft Azure</block>
  <block id="56307bc010f6f11cf695a4f4a8868ec2" category="paragraph"><block ref="56307bc010f6f11cf695a4f4a8868ec2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="157d80dbb8ad88a26dfd59594b88e11c" category="section-title">Ingegneria e inferenza rapide</block>
  <block id="e48b39374db0f3e4c1479cb81f7ebd58" category="paragraph">Con "prompt engineering" si intendono i metodi efficaci per comunicare con gli LLM per eseguire le attività desiderate senza aggiornare i pesi del modello.  Per quanto l'addestramento e la messa a punto dei modelli di intelligenza artificiale siano importanti per le applicazioni NLP, altrettanto importante è l'inferenza, in cui i modelli addestrati rispondono alle richieste dell'utente.  I requisiti di sistema per l'inferenza sono generalmente molto più orientati alle prestazioni di lettura del sistema di archiviazione AI che invia i dati dagli LLM alle GPU, poiché deve essere in grado di applicare miliardi di parametri del modello archiviati per produrre la risposta migliore.</block>
  <block id="71451daa1205b079e03924f700485fb7" category="section-title">LLMOps, monitoraggio dei modelli e Vectorstores</block>
  <block id="37dc13dd8c23bd5e417bad0376cb8642" category="paragraph">Analogamente alle tradizionali operazioni di Machine Learning Ops (MLOps), anche le operazioni su modelli di linguaggio di grandi dimensioni (LLMOps) richiedono la collaborazione di data scientist e ingegneri DevOps con strumenti e best practice per la gestione degli LLM negli ambienti di produzione.  Tuttavia, il flusso di lavoro e lo stack tecnologico per gli LLM potrebbero variare in alcuni aspetti.  Ad esempio, le pipeline LLM create utilizzando framework come LangChain uniscono più chiamate API LLM a endpoint di incorporamento esterni come vectorstore o database vettoriali.  L'utilizzo di un endpoint di incorporamento e di un vectorstore per i connettori downstream (come per un database vettoriale) rappresenta uno sviluppo significativo nel modo in cui i dati vengono archiviati e accessibili.  A differenza dei tradizionali modelli ML sviluppati da zero, gli LLM spesso si basano sull'apprendimento per trasferimento, poiché questi modelli partono da modelli di apprendimento automatico (FM) che vengono perfezionati con nuovi dati per migliorare le prestazioni in un dominio più specifico.  Pertanto, è fondamentale che gli LLMOps forniscano le capacità di gestione del rischio e di monitoraggio del decadimento del modello.</block>
  <block id="e1e7449571fe3b65d3a1e689bc700cbc" category="section-title">Rischi ed etica nell'era dell'intelligenza artificiale generativa</block>
  <block id="c12a37efb07149af3ee94636c74b80c5" category="paragraph">"ChatGPT: è ingegnoso ma continua a vomitare assurdità." – MIT Tech Review.  Il problema dell'intrusione e dell'eliminazione dei rifiuti è sempre stato il problema più spinoso dell'informatica.  L'unica differenza con l'intelligenza artificiale generativa è che quest'ultima è in grado di rendere i dati estremamente credibili, il che porta a risultati imprecisi.  Gli LLM tendono a inventare fatti per adattarli alla narrazione che stanno costruendo.  Pertanto, le aziende che vedono nell'intelligenza artificiale generativa una grande opportunità per ridurre i costi con equivalenti di intelligenza artificiale devono individuare in modo efficiente i deep fake, ridurre i pregiudizi e i rischi per mantenere i sistemi onesti ed etici.  Un flusso di dati libero con una solida infrastruttura di intelligenza artificiale che supporti la mobilità dei dati, la qualità dei dati, la governance dei dati e la protezione dei dati tramite crittografia end-to-end e protezioni di intelligenza artificiale è fondamentale nella progettazione di modelli di intelligenza artificiale generativa responsabili e spiegabili.</block>
  <block id="b1c01c916bfeda43bbe010599a3756ef" category="section-title">Scenario del cliente e NetApp</block>
  <block id="d475afb6eaf5d8966136580d55f5a688" category="paragraph">Figura 3: Flusso di lavoro del modello di apprendimento automatico/linguaggio di grandi dimensioni</block>
  <block id="1d5b6314b7c490b3ba00c157c5d73c98" category="paragraph"><block ref="1d5b6314b7c490b3ba00c157c5d73c98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9dd90f4ead88ee59ec52f11bac2d164b" category="paragraph">*Stiamo facendo formazione o perfezionando?*  La questione se (a) addestrare un modello LLM da zero, perfezionare un FM pre-addestrato o utilizzare RAG per recuperare dati da repository di documenti al di fuori di un modello di base e ampliare i prompt e (b) sfruttare LLM open source (ad esempio, Llama 2) o FM proprietari (ad esempio, ChatGPT, Bard, AWS Bedrock) è una decisione strategica per le organizzazioni.  Ogni approccio presenta un compromesso tra efficienza dei costi, gravità dei dati, operazioni, accuratezza del modello e gestione degli LLM.</block>
  <block id="8c8696e5c9dd013fefe41f5a257ecba6" category="paragraph">NetApp , in quanto azienda, abbraccia l'intelligenza artificiale internamente, nella sua cultura aziendale e nel suo approccio alla progettazione e all'ingegneria dei prodotti.  Ad esempio, la protezione autonoma contro i ransomware di NetApp è realizzata utilizzando l'intelligenza artificiale e l'apprendimento automatico.  Fornisce il rilevamento precoce delle anomalie del file system per aiutare a identificare le minacce prima che incidano sulle operazioni.  In secondo luogo, NetApp utilizza l'intelligenza artificiale predittiva per le sue operazioni aziendali, come le previsioni di vendita e inventario, e chatbot per assistere i clienti nei servizi di supporto ai prodotti del call center, nelle specifiche tecniche, nella garanzia, nei manuali di assistenza e altro ancora.  In terzo luogo, NetApp apporta valore al cliente nella pipeline di dati AI e nel flusso di lavoro ML/LLM tramite prodotti e soluzioni al servizio dei clienti che creano soluzioni di AI predittiva come la previsione della domanda, l'imaging medico, l'analisi del sentiment e soluzioni di AI generativa come GAN per il rilevamento di anomalie nelle immagini industriali nel settore manifatturiero e l'antiriciclaggio e il rilevamento delle frodi nei servizi bancari e finanziari con prodotti e funzionalità NetApp come NetApp ONTAP AI, NetApp SnapMirror e NetApp FlexCache.</block>
  <block id="1e79e12b94e448f7c2f614e8ab2794ba" category="section-title">Capacità NetApp</block>
  <block id="14560cdfa11223c1b6b5ae41321de6d4" category="paragraph">Lo spostamento e la gestione dei dati nelle applicazioni di intelligenza artificiale generativa, come chatbot, generazione di codice, generazione di immagini o espressione di modelli genomici, possono estendersi all'edge, al data center privato e all'ecosistema multicloud ibrido.  Ad esempio, un bot di intelligenza artificiale in tempo reale che aiuta un passeggero ad aggiornare il suo biglietto aereo alla classe business tramite un'app per utenti finali esposta tramite API di modelli pre-addestrati come ChatGPT non può svolgere tale compito da solo, poiché le informazioni sul passeggero non sono disponibili pubblicamente su Internet.  L'API richiede l'accesso alle informazioni personali del passeggero e alle informazioni sul biglietto della compagnia aerea, che può esistere in un ecosistema ibrido o multicloud.  Uno scenario simile potrebbe applicarsi agli scienziati che condividono una molecola di farmaco e i dati dei pazienti tramite un'applicazione per l'utente finale che utilizza LLM per realizzare sperimentazioni cliniche nell'ambito della scoperta di farmaci che coinvolgono istituti di ricerca biomedica one-to-many.  I dati sensibili trasmessi ai FM o agli LLM possono includere informazioni personali identificabili (PII), informazioni finanziarie, informazioni sanitarie, dati biometrici, dati sulla posizione, dati sulle comunicazioni, comportamento online e informazioni legali.  In un evento di rendering in tempo reale, esecuzione rapida e inferenza edge, si verifica uno spostamento di dati dall'app dell'utente finale agli endpoint di archiviazione tramite modelli LLM open source o proprietari a un data center in sede o a piattaforme cloud pubbliche.  In tutti questi scenari, la mobilità e la protezione dei dati sono fondamentali per le operazioni di intelligenza artificiale che coinvolgono LLM, che si basano su grandi set di dati di formazione e sullo spostamento di tali dati.</block>
  <block id="2bf2b67b54f29152ea5e8649dd4b7327" category="paragraph">Figura 4: IA generativa - Pipeline dati LLM</block>
  <block id="206f6329180f9a8251d5f78b853663ab" category="inline-image-macro">Figura 4: Pipeline di dati AI-LLM generativi</block>
  <block id="47b42e2c6c693df656a00ec63e39dde3" category="paragraph"><block ref="47b42e2c6c693df656a00ec63e39dde3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc004144b88d4fadbbf7623c57d2c805" category="paragraph">Il portafoglio di infrastrutture di storage, dati e servizi cloud di NetApp è basato su un software di gestione dati intelligente.</block>
  <block id="7d5e80d61d854ee2e646efedf9f5e72d" category="paragraph">*Preparazione dei dati*: il primo pilastro dello stack tecnologico LLM è in gran parte invariato rispetto al vecchio stack ML tradizionale.  La pre-elaborazione dei dati nella pipeline dell'IA è necessaria per normalizzare e ripulire i dati prima dell'addestramento o della messa a punto.  Questa fase include connettori per l'acquisizione di dati ovunque si trovino, sotto forma di livello Amazon S3 o in sistemi di archiviazione locali, come un archivio file o un archivio oggetti come NetApp StorageGRID.</block>
  <block id="b63aea4b58eede8ed8da27c8b36c34dc" category="paragraph">* NetApp ONTAP* è la tecnologia fondamentale su cui si fondano le soluzioni di storage critiche di NetApp nei data center e nel cloud.  ONTAP include diverse funzionalità e capacità di gestione e protezione dei dati, tra cui la protezione automatica contro i ransomware e gli attacchi informatici, funzionalità integrate di trasporto dati e capacità di efficienza di archiviazione per una vasta gamma di architetture, da quelle on-premise, ibride, multicloud in NAS, SAN, oggetti e situazioni di archiviazione definita dal software (SDS) delle distribuzioni LLM.</block>
  <block id="77b83e7426a1ca8eea17df3ff3a421f7" category="paragraph">* NetApp ONTAP AI* per la formazione di modelli di deep learning.  NetApp ONTAP supporta NVIDIA GPU Direct Storage con l'uso di NFS su RDMA per i clienti NetApp con cluster di storage ONTAP e nodi di elaborazione NVIDIA DGX.  Offre prestazioni convenienti per leggere ed elaborare i set di dati sorgente dall'archiviazione alla memoria più volte, favorendo l'intelligence e consentendo alle organizzazioni di accedere ai LLM con formazione, messa a punto e scalabilità.</block>
  <block id="420e9d37fdcde42065e69c7f6d925ab3" category="paragraph">* NetApp FlexCache* è una funzionalità di caching remoto che semplifica la distribuzione dei file e memorizza nella cache solo i dati letti attivamente.  Ciò può essere utile per la formazione, la riqualificazione e la messa a punto LLM, offrendo valore ai clienti con requisiti aziendali quali rendering in tempo reale e inferenza LLM.</block>
  <block id="0aef0293018a6f953acd79d5d6fb52ae" category="paragraph">* NetApp SnapMirror* è una funzionalità ONTAP che replica gli snapshot dei volumi tra due sistemi ONTAP qualsiasi.  Questa funzionalità trasferisce in modo ottimale i dati dall'edge al data center locale o al cloud.  SnapMirror può essere utilizzato per spostare dati in modo sicuro ed efficiente tra cloud locali e hyperscaler, quando i clienti desiderano sviluppare intelligenza artificiale generativa in cloud con RAG contenenti dati aziendali.  Trasferisce in modo efficiente solo le modifiche, risparmiando larghezza di banda e velocizzando la replicazione, apportando così funzionalità essenziali di mobilità dei dati durante le operazioni di formazione, riqualificazione e messa a punto di FM o LLM.</block>
  <block id="67e47ad6c891ade32e226f1b046d1168" category="paragraph">* NetApp SnapLock* offre la funzionalità di disco immutabile sui sistemi di storage basati su ONTAP per il controllo delle versioni dei set di dati.  L'architettura microcore è progettata per proteggere i dati dei clienti con il motore FPolicy Zero Trust.  NetApp garantisce la disponibilità dei dati dei clienti resistendo agli attacchi DoS (denial-of-service) quando un aggressore interagisce con un LLM in un modo che richiede un consumo particolarmente elevato di risorse.</block>
  <block id="6fb00f321c345f8a92148aec8d1359f9" category="paragraph">* NetApp Cloud Data Sense* aiuta a identificare, mappare e classificare le informazioni personali presenti nei set di dati aziendali, a emanare policy, a soddisfare i requisiti di privacy in sede o nel cloud, a migliorare la sicurezza e a rispettare le normative.</block>
  <block id="8bca7c4074d7b3156f8b66e3ad7a5be8" category="paragraph">* Classificazione NetApp BlueXP*, basata su Cloud Data Sense.  I clienti possono automaticamente scansionare, analizzare, categorizzare e agire sui dati in tutto il patrimonio di dati, rilevare rischi per la sicurezza, ottimizzare l'archiviazione e accelerare le distribuzioni cloud.  Combina servizi di archiviazione e dati tramite il suo piano di controllo unificato. I clienti possono utilizzare istanze GPU per l'elaborazione e ambienti multicloud ibridi per la suddivisione in livelli di archiviazione a freddo e per archivi e backup.</block>
  <block id="528fb7334ec5453cef67bca12d29f735" category="paragraph">* Dualità file-oggetto NetApp *.  NetApp ONTAP consente l'accesso a doppio protocollo per NFS e S3.  Con questa soluzione, i clienti possono accedere ai dati NFS dai notebook Amazon AWS SageMaker tramite bucket S3 da NetApp Cloud Volumes ONTAP.  Ciò offre flessibilità ai clienti che necessitano di un facile accesso a fonti di dati eterogenee con la possibilità di condividere dati sia da NFS che da S3.  Ad esempio, per ottimizzare FM come i modelli di generazione di testo Llama 2 di Meta su SageMaker con accesso a bucket di file-oggetti.</block>
  <block id="a2e08866ca50b890089d6b77f640d7b5" category="paragraph">Il servizio * NetApp Cloud Sync* offre un modo semplice e sicuro per migrare i dati verso qualsiasi destinazione, nel cloud o in locale.  Cloud Sync trasferisce e sincronizza in modo fluido i dati tra storage locali o cloud, NAS e archivi di oggetti.</block>
  <block id="e53b3c8e83c8d94be048ce5801830a49" category="paragraph">* NetApp XCP* è un software client che consente migrazioni di dati da qualsiasi dispositivo a NetApp e da NetApp a NetApp in modo rapido e affidabile.  XCP offre inoltre la possibilità di spostare in modo efficiente grandi quantità di dati dai file system Hadoop HDFS a ONTAP NFS, S3 o StorageGRID , mentre l'analisi dei file XCP fornisce visibilità nel file system.</block>
  <block id="d0d48e5a8fe903e906882461b57dcfd3" category="paragraph">* NetApp DataOps Toolkit* è una libreria Python che semplifica per data scientist, DevOps e data engineer l'esecuzione di varie attività di gestione dei dati, come il provisioning, la clonazione o lo snapshot quasi istantaneo di un volume di dati o di un'area di lavoro JupyterLab, supportati da storage NetApp scalabile ad alte prestazioni.</block>
  <block id="97d451a12ea524d66984cc35758777b4" category="paragraph">*Sicurezza dei prodotti NetApp*.  Gli LLM potrebbero rivelare inavvertitamente dati riservati nelle loro risposte, il che rappresenta una preoccupazione per i CISO che studiano le vulnerabilità associate alle applicazioni di intelligenza artificiale che sfruttano gli LLM.  Come sottolineato da OWASP (Open Worldwide Application Security Project), problemi di sicurezza quali l'avvelenamento dei dati, la perdita di dati, il diniego di servizio e le iniezioni rapide all'interno degli LLM possono avere ripercussioni sulle aziende, in quanto potrebbero esporre i dati ad accessi non autorizzati da parte degli aggressori.  I requisiti di archiviazione dei dati dovrebbero includere controlli di integrità e snapshot immutabili per dati strutturati, semi-strutturati e non strutturati.  Per il controllo delle versioni dei set di dati vengono utilizzati NetApp Snapshots e SnapLock .  Offre un rigoroso controllo degli accessi basato sui ruoli (RBAC), nonché protocolli sicuri e crittografia standard del settore per proteggere sia i dati inattivi che quelli in transito.  Cloud Insights e Cloud Data Sense insieme offrono funzionalità che ti aiutano a identificare in modo forense la fonte della minaccia e a stabilire le priorità dei dati da ripristinare.</block>
  <block id="0364ee2a32c23b9f35e29f68c79d63e1" category="section-title">* ONTAP AI con DGX BasePOD*</block>
  <block id="c6f1dc673303b79fafb5e05f0c7a97cb" category="paragraph">L'architettura di riferimento NetApp ONTAP AI con NVIDIA DGX BasePOD è un'architettura scalabile per carichi di lavoro di machine learning (ML) e intelligenza artificiale (AI).  Per la fase di formazione critica degli LLM, i dati vengono solitamente copiati dall'archivio dati al cluster di formazione a intervalli regolari.  I server utilizzati in questa fase sfruttano le GPU per parallelizzare i calcoli, creando un'enorme richiesta di dati.  Soddisfare le esigenze di larghezza di banda I/O grezza è fondamentale per mantenere un elevato utilizzo della GPU.</block>
  <block id="9a05494b8b259619e21e3e78c47f4dc5" category="section-title">* ONTAP AI con NVIDIA AI Enterprise*</block>
  <block id="65590ec18b850984cfb8bbe6ba35fe7d" category="paragraph">NVIDIA AI Enterprise è una suite end-to-end e cloud-native di software di analisi dei dati e intelligenza artificiale, ottimizzata, certificata e supportata da NVIDIA per l'esecuzione su VMware vSphere con sistemi certificati NVIDIA.  Questo software semplifica e velocizza l'implementazione, la gestione e il ridimensionamento dei carichi di lavoro di intelligenza artificiale nel moderno ambiente cloud ibrido.  NVIDIA AI Enterprise, basato su NetApp e VMware, offre una gestione dei dati e dei carichi di lavoro di intelligenza artificiale di livello aziendale in un pacchetto semplificato e familiare.</block>
  <block id="1ad177c0b9d841f941eb7d5322dc9b52" category="section-title">*Piattaforme cloud 1P*</block>
  <block id="0e877c6cfb49f5bbdc17c6d204b4b7cb" category="paragraph">Le offerte di archiviazione cloud completamente gestite sono disponibili in modo nativo su Microsoft Azure come Azure NetApp Files (ANF), su AWS come Amazon FSx for NetApp ONTAP (FSx ONTAP) e su Google come Google Cloud NetApp Volumes (GNCV).  1P è un file system gestito ad alte prestazioni che consente ai clienti di eseguire carichi di lavoro di intelligenza artificiale ad alta disponibilità con maggiore sicurezza dei dati nei cloud pubblici, per ottimizzare LLM/FM con piattaforme ML native del cloud come AWS SageMaker, Azure-OpenAI Services e Vertex AI di Google.</block>
  <block id="64992f0c01704aa99d3bd851b7673bf7" category="section-title">Suite di soluzioni per i partner NetApp</block>
  <block id="0e3151175898c0a6687552a854a08b00" category="paragraph">Oltre ai suoi principali prodotti, tecnologie e capacità di dati, NetApp collabora a stretto contatto anche con una solida rete di partner di intelligenza artificiale per offrire valore aggiunto ai clienti.</block>
  <block id="5c682f526a6d29391ad4d45cd7c7cae9" category="paragraph">* I NVIDIA Guardrails* nei sistemi di intelligenza artificiale servono come misure di salvaguardia per garantire l'uso etico e responsabile delle tecnologie di intelligenza artificiale.  Gli sviluppatori di intelligenza artificiale possono scegliere di definire il comportamento delle applicazioni basate su LLM su argomenti specifici e impedire loro di impegnarsi in discussioni su argomenti indesiderati.  Guardrails, un toolkit open source, offre la possibilità di connettere un LLM ad altri servizi in modo semplice e sicuro, per creare sistemi conversazionali LLM affidabili e sicuri.</block>
  <block id="0b46f95333d136197f1bb757634ebae2" category="paragraph">*Domino Data Lab* fornisce strumenti versatili e di livello aziendale per la creazione e la produzione di intelligenza artificiale generativa: veloce, sicura ed economica, indipendentemente da dove ti trovi nel tuo percorso verso l'intelligenza artificiale.  Con la piattaforma Enterprise MLOps di Domino, gli scienziati dei dati possono utilizzare gli strumenti preferiti e tutti i loro dati, addestrare e distribuire modelli facilmente ovunque e gestire rischi e costi in modo efficace, il tutto da un unico centro di controllo.</block>
  <block id="20350fb42ff163b07d9d4a2636b4a555" category="paragraph">*Modzy per Edge AI*.  NetApp e Modzy hanno stretto una partnership per fornire l'intelligenza artificiale su larga scala a qualsiasi tipo di dati, tra cui immagini, audio, testo e tabelle.  Modzy è una piattaforma MLOps per la distribuzione, l'integrazione e l'esecuzione di modelli di intelligenza artificiale, che offre agli scienziati dei dati le capacità di monitoraggio dei modelli, rilevamento delle derive e spiegabilità, con una soluzione integrata per un'inferenza LLM senza interruzioni.</block>
  <block id="50841f507614d3540c25e7671dc0cdc0" category="paragraph">*Run:AI* e NetApp hanno stretto una partnership per dimostrare le capacità uniche della soluzione NetApp ONTAP AI con la piattaforma di gestione dei cluster Run:AI, al fine di semplificare l'orchestrazione dei carichi di lavoro di intelligenza artificiale.  Divide e unisce automaticamente le risorse GPU, ed è progettato per scalare le pipeline di elaborazione dati su centinaia di macchine con framework di integrazione integrati per Spark, Ray, Dask e Rapids.</block>
  <block id="7f8ef2f7d9a73eb64e35d815049ddd46" category="paragraph">L'intelligenza artificiale generativa può produrre risultati efficaci solo quando il modello viene addestrato su grandi quantità di dati di qualità.  Sebbene gli LLM abbiano raggiunto traguardi notevoli, è fondamentale riconoscerne i limiti, le sfide progettuali e i rischi associati alla mobilità e alla qualità dei dati.  Gli LLM si basano su set di dati di formazione ampi e eterogenei provenienti da fonti di dati eterogenee.  Risultati imprecisi o distorti generati dai modelli possono mettere a repentaglio sia le aziende che i consumatori.  Questi rischi possono corrispondere a vincoli per gli LLM che emergono potenzialmente dalle sfide di gestione dei dati associate alla qualità dei dati, alla sicurezza dei dati e alla mobilità dei dati.  NetApp aiuta le organizzazioni a far fronte alle complessità create dalla rapida crescita dei dati, dalla mobilità dei dati, dalla gestione multi-cloud e dall'adozione dell'intelligenza artificiale.  Su larga scala, l'infrastruttura di intelligenza artificiale e la gestione efficiente dei dati sono fondamentali per definire il successo delle applicazioni di intelligenza artificiale come l'intelligenza artificiale generativa.  È fondamentale che i clienti coprano tutti gli scenari di implementazione senza compromettere la capacità di espandersi in base alle esigenze aziendali, mantenendo al contempo il controllo sull'efficienza dei costi, sulla governance dei dati e sulle pratiche etiche di intelligenza artificiale.  NetApp lavora costantemente per aiutare i clienti a semplificare e accelerare le implementazioni dell'intelligenza artificiale.</block>
  <block id="cea78864209b835e9b37cbe0a2cb862e" category="doc">NVA-1172-DESIGN: NetApp AIPod con Lenovo per NVIDIA OVX</block>
  <block id="cd270e0e169361bb079873f1cb21e6b5" category="paragraph">Bobby Oommen, Abhinav Singh, Roney Daniel, NetApp</block>
  <block id="999a2bd7b329bd7fe4178352281b558b" category="paragraph">Questa architettura di riferimento abbina i server Lenovo ThinkSystem OVX certificati NVIDIA, basati su GPU NVIDIA L40S, alla rete NVIDIA Spectrum per fornire una soluzione infrastrutturale ottimale per ottimizzare e distribuire LLM (Large Language Model).  Lo scopo di questo documento è fornire indicazioni relative all'archiviazione per una configurazione OVX.  Questa piattaforma è adatta a vari carichi di lavoro di intelligenza artificiale generativa, tra cui RAG (Retrieval Augmented Generation), messa a punto e addestramento di modelli leggeri.</block>
  <block id="688a655aa25fa96dbcd977348cc95acc" category="inline-link-macro">NVA-1172-DESIGN: Guida alla progettazione di NetApp AIPod con Lenovo per NVIDIA OVX</block>
  <block id="07ba0b8aab1e2887d9dc0f7f9d5dad4f" category="paragraph"><block ref="07ba0b8aab1e2887d9dc0f7f9d5dad4f" category="inline-link-macro-rx"></block></block>
  <block id="82b67ae3d50932b0d818b7c3a23b3428" category="summary">NetApp AIPod con sistemi NVIDIA DGX - Architettura</block>
  <block id="92527686d5dc11342676e296e31b0b51" category="doc">NVA-1173 NetApp AIPod con sistemi NVIDIA DGX H100 - Architettura della soluzione</block>
  <block id="34fc6f8c7d10337be1b911dd98627e40" category="paragraph">Questa sezione si concentra sull'architettura per NetApp AIPod con sistemi NVIDIA DGX.</block>
  <block id="b10a3a95ab83cbad7acc457e6bc13a1b" category="section-title">NetApp AIPod con sistemi DGX</block>
  <block id="990e00b86cef2bb25d2e346df6e7adfe" category="paragraph">Questa architettura di riferimento sfrutta strutture separate per l'interconnessione dei cluster di elaborazione e l'accesso allo storage, con connettività InfiniBand (IB) da 400 Gb/s tra i nodi di elaborazione.  Il disegno seguente mostra la topologia complessiva della soluzione NetApp AIPod con sistemi DGX H100.</block>
  <block id="5d065d1080de5349462d7a342f622bf3" category="paragraph">_Topologia della soluzione NetApp AIpod_</block>
  <block id="552dcf63ade7f6a706107c5da1f5a2a6" category="paragraph"><block ref="552dcf63ade7f6a706107c5da1f5a2a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19c939070c0b6ebbb52e1e0119b15301" category="section-title">Progettazione di rete</block>
  <block id="57f55a30c80dbf621eb119c782a8b3c5" category="paragraph">In questa configurazione, il cluster di elaborazione utilizza una coppia di switch IB QM9700 da 400 Gb/s, collegati tra loro per garantire un'elevata disponibilità.  Ogni sistema DGX H100 è collegato agli switch tramite otto connessioni, con le porte con numero pari collegate a uno switch e le porte con numero dispari collegate all'altro switch.</block>
  <block id="8ee4ef799026973266981f7c555ea058" category="paragraph">Per l'accesso al sistema di storage, la gestione in banda e l'accesso client, viene utilizzata una coppia di switch Ethernet SN4600.  Gli switch sono collegati tramite collegamenti inter-switch e configurati con più VLAN per isolare i vari tipi di traffico.  Il routing L3 di base è abilitato tra VLAN specifiche per abilitare percorsi multipli tra interfacce client e di archiviazione sullo stesso switch, nonché tra switch per un'elevata disponibilità.  Per implementazioni più ampie, la rete Ethernet può essere estesa a una configurazione leaf-spine aggiungendo ulteriori coppie di switch per gli switch spine e ulteriori leaf, se necessario.</block>
  <block id="082b01f67d64181611dc998408a2b121" category="inline-link-macro">dettagli di distribuzione</block>
  <block id="41b55cdcb36636c126a5ef6c6e873a08" category="paragraph">Oltre all'interconnessione di elaborazione e alle reti Ethernet ad alta velocità, tutti i dispositivi fisici sono collegati anche a uno o più switch Ethernet SN2201 per la gestione fuori banda.  Si prega di vedere il<block ref="11e89a956fe8616ed611e595e22cdb97" category="inline-link-macro-rx"></block> pagina per maggiori informazioni sulla configurazione di rete.</block>
  <block id="9eaf2c6f65cf6ad700b387972ddc345e" category="section-title">Panoramica dell'accesso all'archiviazione per i sistemi DGX H100</block>
  <block id="b1cdc2ac23891a1bf0e697359ffeeef6" category="paragraph">Ogni sistema DGX H100 è dotato di due adattatori ConnectX-7 a doppia porta per la gestione e il traffico di archiviazione e, per questa soluzione, entrambe le porte su ciascuna scheda sono collegate allo stesso switch.  Una porta di ogni scheda viene quindi configurata in un bond LACP MLAG con una porta collegata a ogni switch e le VLAN per la gestione in banda, l'accesso client e l'accesso allo storage a livello utente sono ospitate su questo bond.</block>
  <block id="891c72a31ed1199769c3f62cab11e7b4" category="paragraph">L'altra porta su ciascuna scheda è utilizzata per la connettività ai sistemi di archiviazione AFF A90 e può essere utilizzata in diverse configurazioni a seconda dei requisiti del carico di lavoro.  Per le configurazioni che utilizzano NFS su RDMA per supportare NVIDIA Magnum IO GPUDirect Storage, le porte vengono utilizzate singolarmente con indirizzi IP in VLAN separate.  Per le distribuzioni che non richiedono RDMA, le interfacce di archiviazione possono anche essere configurate con bonding LACP per garantire elevata disponibilità e larghezza di banda aggiuntiva.  Con o senza RDMA, i client possono montare il sistema di archiviazione utilizzando NFS v4.1 pNFS e Session trunking per abilitare l'accesso parallelo a tutti i nodi di archiviazione nel cluster.  Si prega di vedere il<block ref="11e89a956fe8616ed611e595e22cdb97" category="inline-link-macro-rx"></block> pagina per maggiori informazioni sulla configurazione del client.</block>
  <block id="c95998835114a4e50f348f8c5e5686ed" category="inline-link-macro">Documentazione NVIDIA BasePOD</block>
  <block id="8660b0a825d671d8855117ae496d3af6" category="paragraph">Per maggiori dettagli sulla connettività del sistema DGX H100 fare riferimento a<block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block> .</block>
  <block id="42dc99c097c1b9b9af75ba060788e1f1" category="section-title">Progettazione del sistema di archiviazione</block>
  <block id="61b2fad5f824784462363e1b366833fa" category="paragraph">Ogni sistema di storage AFF A90 è connesso tramite sei porte da 200 GbE da ciascun controller.  Quattro porte di ciascun controller vengono utilizzate per l'accesso ai dati del carico di lavoro dai sistemi DGX e due porte di ciascun controller sono configurate come gruppo di interfacce LACP per supportare l'accesso dai server del piano di gestione per gli artefatti di gestione del cluster e le directory home degli utenti.  L'accesso ai dati dal sistema di storage avviene tramite NFS, con una macchina virtuale di storage (SVM) dedicata all'accesso al carico di lavoro dell'intelligenza artificiale e una SVM separata dedicata agli utilizzi di gestione del cluster.</block>
  <block id="6c9aef89eae0fd771909b15623e452df" category="paragraph">La SVM di gestione richiede solo un singolo LIF, ospitato sui gruppi di interfacce a 2 porte configurati su ciascun controller.  Altri volumi FlexGroup vengono forniti sulla SVM di gestione per ospitare artefatti di gestione del cluster come immagini dei nodi del cluster, dati storici di monitoraggio del sistema e directory home degli utenti finali.  Il disegno seguente mostra la configurazione logica del sistema di archiviazione.</block>
  <block id="995db3e6bdfdd81bd5e1b6a98b33e5b7" category="paragraph">_Configurazione logica del cluster di storage NetApp A90_</block>
  <block id="1e7a613d4d1ae838806eb303b8f25492" category="paragraph"><block ref="1e7a613d4d1ae838806eb303b8f25492" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6420553f17ebdab39fa9a1825d57651" category="section-title">Server del piano di gestione</block>
  <block id="e6391a8600a62f5346ec27d437d43626" category="paragraph">Questa architettura di riferimento include anche cinque server basati su CPU per l'utilizzo nel piano di gestione.  Due di questi sistemi vengono utilizzati come nodi principali per NVIDIA Base Command Manager per la distribuzione e la gestione dei cluster.  Gli altri tre sistemi vengono utilizzati per fornire servizi cluster aggiuntivi, come nodi master Kubernetes o nodi di accesso per distribuzioni che utilizzano Slurm per la pianificazione dei lavori.  Le distribuzioni che utilizzano Kubernetes possono sfruttare il driver NetApp Trident CSI per fornire provisioning automatizzato e servizi dati con storage persistente sia per i carichi di lavoro di gestione che di intelligenza artificiale sul sistema di storage AFF A900 .</block>
  <block id="108f9bbf932c304dff7d03edbf186c18" category="paragraph">Ogni server è fisicamente connesso sia agli switch IB che agli switch Ethernet per consentire la distribuzione e la gestione del cluster, ed è configurato con montaggi NFS sul sistema di archiviazione tramite la SVM di gestione per l'archiviazione degli artefatti di gestione del cluster, come descritto in precedenza.</block>
  <block id="19a97f58216292f6ce34aa1a3ad9e96e" category="summary">NetApp AIPod con sistemi NVIDIA DGX - Dove trovare ulteriori informazioni</block>
  <block id="43e1c1d93ec30f643ac7004cd6fafc47" category="doc">NVA-1173 NetApp AIPod con sistemi NVIDIA DGX - Conclusione e informazioni aggiuntive</block>
  <block id="7c3d91801a54614f755a9f2897ee42f3" category="paragraph">Questa sezione include riferimenti per informazioni aggiuntive sui sistemi NetApp AIPod con NVIDIA DGX.</block>
  <block id="bcde7144e6a13836183bd03e403987ef" category="paragraph">L'architettura DGX BasePOD è una piattaforma di apprendimento profondo di nuova generazione che richiede capacità di archiviazione e gestione dei dati altrettanto avanzate.  Combinando DGX BasePOD con i sistemi NetApp AFF , l'architettura NetApp AIPod con i sistemi DGX può essere implementata praticamente su qualsiasi scala.  In combinazione con l'integrazione cloud superiore e le funzionalità software-defined di NetApp ONTAP, AFF consente una gamma completa di pipeline di dati che abbracciano l'edge, il core e il cloud per progetti DL di successo.</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="section-title">Informazioni aggiuntive</block>
  <block id="68e34599e7058d633da08de84c55032d" category="paragraph">Per saperne di più sulle informazioni descritte nel presente documento, consultare i seguenti documenti e/o siti web:</block>
  <block id="f85150beb9ce598095b212b1de60815f" category="list-text">Software di gestione dati NetApp ONTAP — Libreria di informazioni ONTAP</block>
  <block id="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link"><block ref="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link-rx"></block></block>
  <block id="d99ede023f079413a479e349dcb54616" category="paragraph"><block ref="d99ede023f079413a479e349dcb54616" category="inline-link-rx"></block></block>
  <block id="b8667e5a766c0335e106bdd9b4ea825f" category="list-text">Sistemi di archiviazione NetApp AFF A90</block>
  <block id="8a5df1408a92dc0ef3181cd15cbc989e" category="inline-link"><block ref="8a5df1408a92dc0ef3181cd15cbc989e" category="inline-link-rx"></block></block>
  <block id="22ef65e375f266c2889509f939e1ac83" category="paragraph"><block ref="22ef65e375f266c2889509f939e1ac83" category="inline-link-rx"></block></block>
  <block id="29b91fda4bb7baae0176d0ca5870634a" category="list-text">Informazioni NetApp ONTAP RDMA-</block>
  <block id="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-macro"><block ref="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-rx"></block></block>
  <block id="c08c09703d9322a16ef4a93b82ff897e" category="paragraph"><block ref="c08c09703d9322a16ef4a93b82ff897e" category="inline-link-macro-rx"></block></block>
  <block id="e71e852dc96d4d0e2da95de923a6f8ff" category="list-text">NetApp Trident</block>
  <block id="3daf8b3b7ee9b11922ef3d82e81e3a2c" category="paragraph"><block ref="3daf8b3b7ee9b11922ef3d82e81e3a2c" category="inline-link-macro-rx"></block></block>
  <block id="4613e07c94020e7ba8189d048f9d61c1" category="list-text">Blog di NetApp GPUDirect Storage -</block>
  <block id="cf8832fa60205a911c1036fb274f649e" category="inline-link"><block ref="cf8832fa60205a911c1036fb274f649e" category="inline-link-rx"></block></block>
  <block id="0f1f9907ba0a6f040f1fa28d77e74fb8" category="paragraph"><block ref="0f1f9907ba0a6f040f1fa28d77e74fb8" category="inline-link-rx"></block></block>
  <block id="64dc43320ec1a44c390fafb5e2408f4b" category="list-text">NVIDIA DGX BasePOD</block>
  <block id="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link"><block ref="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link-rx"></block></block>
  <block id="0c2cd58ffa7f091c420ae61854a0a8db" category="paragraph"><block ref="0c2cd58ffa7f091c420ae61854a0a8db" category="inline-link-rx"></block></block>
  <block id="e3d6e4bdd7281f2c5d652f6f01825970" category="list-text">Sistemi NVIDIA DGX H100</block>
  <block id="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link"><block ref="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link-rx"></block></block>
  <block id="f4e11a54d0110771220fa05425235763" category="paragraph"><block ref="f4e11a54d0110771220fa05425235763" category="inline-link-rx"></block></block>
  <block id="d90238071267e4279a25de2c6945b227" category="list-text">NVIDIA</block>
  <block id="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link"><block ref="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link-rx"></block></block>
  <block id="a19d7568aa9c7e4c1f3bf3e831367115" category="paragraph"><block ref="a19d7568aa9c7e4c1f3bf3e831367115" category="inline-link-rx"></block></block>
  <block id="a96fecd8b3666b7b60c0bc0a24db79b2" category="list-text">Archiviazione NVIDIA Magnum IO&amp;#8482; GPUDirect&amp;#174;</block>
  <block id="74079d06fd0015403a15f89699e6bcba" category="inline-link"><block ref="74079d06fd0015403a15f89699e6bcba" category="inline-link-rx"></block></block>
  <block id="110c88150ddcbc728071b2fcd7848bd2" category="paragraph"><block ref="110c88150ddcbc728071b2fcd7848bd2" category="inline-link-rx"></block></block>
  <block id="c7bef72157cc39b6eb7c391a393a20d2" category="list-text">Comando di base NVIDIA</block>
  <block id="bbae10fb46fb1d3604fe601d556f4187" category="inline-link"><block ref="bbae10fb46fb1d3604fe601d556f4187" category="inline-link-rx"></block></block>
  <block id="936c47b696a994feb0ad33a2addb1168" category="paragraph"><block ref="936c47b696a994feb0ad33a2addb1168" category="inline-link-rx"></block></block>
  <block id="b4675c30af15f661c8112c2853f97970" category="list-text">Gestore dei comandi di base NVIDIA</block>
  <block id="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link"><block ref="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link-rx"></block></block>
  <block id="6b36fdb81918af4b96afe2ba587a8ae1" category="paragraph"><block ref="6b36fdb81918af4b96afe2ba587a8ae1" category="inline-link-rx"></block></block>
  <block id="51ab86189ca8b1d1a08ac2970d39f90c" category="list-text">NVIDIA AI Enterprise</block>
  <block id="42c9b161f86365b647172182503d9520" category="inline-link"><block ref="42c9b161f86365b647172182503d9520" category="inline-link-rx"></block></block>
  <block id="f5802e2c53799babc0ac27f6cb392604" category="paragraph"><block ref="f5802e2c53799babc0ac27f6cb392604" category="inline-link-rx"></block></block>
  <block id="9132ee4ebfc1bcccf9be22b87e818413" category="paragraph">Questo documento è frutto del lavoro dei team NetApp Solutions e ONTAP Engineering: David Arnette, Olga Kornievskaia, Dustin Fischer, Srikanth Kaligotla, Mohit Kumar e Raghuram Sudhaakar.  Gli autori desiderano inoltre ringraziare NVIDIA e il team di progettazione NVIDIA DGX BasePOD per il loro continuo supporto.</block>
  <block id="7c4d674fe3a4532c3ffe553151378a3f" category="summary">NetApp AIPod con sistemi NVIDIA DGX - Distribuzione</block>
  <block id="302db59f0ad2458d76aedcc8a6fdd7be" category="doc">NVA-1173 NetApp AIPod con sistemi NVIDIA DGX - Dettagli di distribuzione</block>
  <block id="c584dd3e1383c7899a434fb7b8e1a341" category="paragraph">Questa sezione descrive i dettagli di distribuzione utilizzati durante la convalida di questa soluzione.  Gli indirizzi IP utilizzati sono esempi e devono essere modificati in base all'ambiente di distribuzione.  Per ulteriori informazioni sui comandi specifici utilizzati nell'implementazione di questa configurazione, fare riferimento alla documentazione del prodotto appropriata.</block>
  <block id="b5f0a1ca7b5559b93159bcc11b7b99e9" category="paragraph">Il diagramma seguente mostra informazioni dettagliate sulla rete e sulla connettività per 1 sistema DGX H100 e 1 coppia HA di controller AFF A90 .  Le istruzioni per l'implementazione nelle sezioni seguenti si basano sui dettagli riportati in questo diagramma.</block>
  <block id="a1ce9904a2cc7e8a6e1267980553c732" category="paragraph">_Configurazione di rete NetApp AIpod_</block>
  <block id="c4e9bce0ddaf289da0094c0a0560c136" category="paragraph"><block ref="c4e9bce0ddaf289da0094c0a0560c136" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea12591fa7a8663c28086764fc393d35" category="paragraph">La tabella seguente mostra esempi di assegnazioni di cablaggio per un massimo di 16 sistemi DGX e 2 coppie AFF A90 HA.</block>
  <block id="4919e7d6c7a8481619e206520f937aaf" category="cell">Switch e porta</block>
  <block id="e0ac20adce6ffee48c7151b070aa5737" category="cell">Dispositivo</block>
  <block id="e85450f6454a8b84aa3dd8ab4cfe658c" category="cell">Porta del dispositivo</block>
  <block id="bdbd5451b62f5c0739cd0300b29d0db1" category="cell">porte switch1 1-16</block>
  <block id="b6bf51e15f6d9d931c3ef52dcf7c2e74" category="cell">DGX-H100-01 fino a -16</block>
  <block id="4d866d6d7dc3628895dbedb26f1bdf96" category="cell">enp170s0f0np0, slot1 porta 1</block>
  <block id="6438dabe67e09d4e0ec2e3d17d7074f9" category="cell">porte switch1 17-32</block>
  <block id="744d517d131df3b9ae1b4bdbdf70b282" category="cell">enp170s0f1np1, slot1 porta 2</block>
  <block id="2914cd4a87277c08ac1f71cafd311de5" category="cell">porte switch1 33-36</block>
  <block id="b08a34f62ae5d3df1c59356cb996a50a" category="cell">AFF-A90-01 attraverso -04</block>
  <block id="3d163afca230cdca293d07b9bce1004f" category="cell">porta e6a</block>
  <block id="09a5a99bfdac461078765cf577fa36c1" category="cell">porte switch1 37-40</block>
  <block id="67d1565f0da7861ffc787acf0cc159af" category="cell">porta e11a</block>
  <block id="d350694943ec1acbb17fb85d69fd2aa9" category="cell">porte switch1 41-44</block>
  <block id="44b26214a7c3f5ffe5ec1db0aa3e4f98" category="cell">porta e2a</block>
  <block id="9e444fba13b3dd8f65bd7deb1b742747" category="cell">porte switch1 57-64</block>
  <block id="7a744922ca20208077a50d69271d15fd" category="cell">ISL per switch2</block>
  <block id="68813ae3b3a11b5b786ffe4305c5d542" category="cell">porte 57-64</block>
  <block id="9b878f628cccd99408682b50785b3598" category="cell">porte switch2 1-16</block>
  <block id="3cdeea9afe6ab2952bd32f14b371d0c3" category="cell">enp41s0f0np0, slot 2 porta 1</block>
  <block id="6a11ad764d8b60d242c533b565b99142" category="cell">porte switch2 17-32</block>
  <block id="e26d3524de049d551125c01b1d65729e" category="cell">enp41s0f1np1, slot 2 porta 2</block>
  <block id="59ba8265a302f2fb97997075c8f27f6d" category="cell">porte switch2 33-36</block>
  <block id="9df3af84859046bac07e13013fce0466" category="cell">porta e6b</block>
  <block id="d9a9acdd71cb92eb03299a9702a84577" category="cell">switch2 porte 37-40</block>
  <block id="0b9b24c59934606f5e10f1c15b3a86cb" category="cell">porta e11b</block>
  <block id="2f4b59b7b40dec7ee6362e6017960380" category="cell">porte switch2 41-44</block>
  <block id="2c635d05e781d03137efe254ee8f86a1" category="cell">porta e2b</block>
  <block id="67a367a7d31cdd640df71104820055c4" category="cell">porte switch2 57-64</block>
  <block id="ed38d5a59568aa5dd0a40c94574cf056" category="cell">ISL per passare1</block>
  <block id="c470336f17afce51494a7db95c91de92" category="paragraph">Nella tabella seguente sono riportate le versioni software dei vari componenti utilizzati in questa convalida.</block>
  <block id="40ddf58fef213ff0d6433ef322edfe2e" category="cell">Versione del software</block>
  <block id="b1c079bf2940033fab8f8dffbf4a5ff2" category="cell">Switch NVIDIA SN4600</block>
  <block id="90db213df8a0c782abe8388881fce336" category="cell">Cumulus Linux v5.9.1</block>
  <block id="18cf8e6ece8a122dba390f844981b900" category="cell">Sistema NVIDIA DGX</block>
  <block id="cfba00e4a4b4df8f6a7ebf83cfd81c4c" category="cell">DGX OS v6.2.1 (Ubuntu 22.04 LTS)</block>
  <block id="857ecbf3846b57d505e2a1b49da67f65" category="cell">Mellanox OFED</block>
  <block id="38aa87e1c845f13e459d6a71f7049cac" category="cell">24,01</block>
  <block id="3eb4233634d4c27ee1a1ddf72619b98d" category="cell">NetApp AFF A90</block>
  <block id="6944cefb93932417ed3a50959c66a9c5" category="cell">NetApp ONTAP 9.14.1</block>
  <block id="93fb68f81a2ad999b6aae02d586c4ef4" category="section-title">Configurazione della rete di archiviazione</block>
  <block id="84814a12bbb8397e0a8f1357446c94e5" category="inline-link-macro">Documentazione NVIDIA Cumulus Linux</block>
  <block id="5d27fc003227b21f0392098a85eb18c2" category="paragraph">Questa sezione descrive i dettagli chiave per la configurazione della rete di archiviazione Ethernet.  Per informazioni sulla configurazione della rete di elaborazione InfiniBand, consultare<block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block> .  Per maggiori dettagli sulla configurazione dello switch fare riferimento a<block ref="5e4d481e02111d80d9871bbc3802a082" category="inline-link-macro-rx"></block> .</block>
  <block id="57719be20908b73e68d37637555b97d6" category="paragraph">Di seguito sono descritti i passaggi di base utilizzati per configurare gli switch SN4600.  Questo processo presuppone che il cablaggio e la configurazione di base dello switch (indirizzo IP di gestione, licenze, ecc.) siano stati completati.</block>
  <block id="e55cea47183e18fc2e2e86a5dcee8ec7" category="list-text">Configurare il legame ISL tra gli switch per abilitare l'aggregazione multi-link (MLAG) e il traffico di failover</block>
  <block id="72a998485758ede34cc727692eda3bd2" category="list-text">Questa convalida ha utilizzato 8 collegamenti per fornire una larghezza di banda più che sufficiente per la configurazione di archiviazione in fase di test</block>
  <block id="3051c0af523b2627a57ce2bf1e587655" category="list-text">Per istruzioni specifiche sull'abilitazione di MLAG, fare riferimento alla documentazione di Cumulus Linux.</block>
  <block id="8ae9a0f6054b5fb4a974e1f0d735ff8d" category="list-text">Configurare LACP MLAG per ogni coppia di porte client e porte di archiviazione su entrambi gli switch</block>
  <block id="3c81bce81a92df032d58d66eb88265b0" category="list-text">porta swp17 su ogni switch per DGX-H100-01 (enp170s0f1np1 e enp41s0f1np1), porta swp18 per DGX-H100-02, ecc. (bond1-16)</block>
  <block id="563a9dfd999aa71e1b86c22188243c2b" category="list-text">porta swp41 su ogni switch per AFF-A90-01 (e2a ed e2b), porta swp42 per AFF-A90-02, ecc. (bond17-20)</block>
  <block id="44f6b0b1ffb3c7d26ff370ef2db934bb" category="list-text">nv set interfaccia bondX membro del legame swpX</block>
  <block id="e88a9fc1fac9e835ce4f94863fa6c017" category="list-text">nv set interfaccia bondx bond mlag id X</block>
  <block id="53e5d1cb8672703c6d9c6468088afa1a" category="list-text">Aggiungere tutte le porte e i legami MLAG al dominio bridge predefinito</block>
  <block id="e196c3365de079c5ab9127511e0dd99c" category="list-text">nv set int swp1-16,33-40 dominio bridge br_default</block>
  <block id="807ec963a7ac91bb05d484cf2aedb28c" category="list-text">nv set int bond1-20 dominio bridge br_default</block>
  <block id="812bc6c1e22132212f3bd611d2be624b" category="list-text">Abilita RoCE su ogni switch</block>
  <block id="5b474542c656a524ee80214d547f357f" category="list-text">nv imposta la modalità roce senza perdita di dati</block>
  <block id="e1ddeeabdb3c578a39e7f7457c83adcb" category="list-text">Configurare le VLAN: 2 per le porte client, 2 per le porte di archiviazione, 1 per la gestione, 1 per lo switch L3 da switch a switch</block>
  <block id="e8c935d4b4d1ac2ba8e60a311d4dd3e3" category="list-text">interruttore 1-</block>
  <block id="d0dbd46c5b3822649194130f76e47a74" category="list-text">VLAN 3 per il routing da switch a switch L3 in caso di guasto della NIC del client</block>
  <block id="4d0ddcd703c2db59dd2b93a0864f348e" category="list-text">VLAN 101 per la porta di archiviazione 1 su ciascun sistema DGX (enp170s0f0np0, slot1 porta 1)</block>
  <block id="988d3fe9d9a9c24bdfaf0d1e8c04c718" category="list-text">VLAN 102 per la porta e6a e e11a su ciascun controller di archiviazione AFF A90</block>
  <block id="8534bf29bf68cf0b3a4ef8fc1c8367ef" category="list-text">VLAN 301 per la gestione tramite le interfacce MLAG per ciascun sistema DGX e controller di archiviazione</block>
  <block id="decdf257b13a488f92fa3c1f3c758e26" category="list-text">interruttore 2-</block>
  <block id="9d406d38f0c9d262294560c3ffe601e6" category="list-text">VLAN 201 per la porta di archiviazione 2 su ciascun sistema DGX (enp41s0f0np0, slot2 porta 1)</block>
  <block id="ad80d15b1164d5cda913549da61e6aa3" category="list-text">VLAN 202 per la porta e6b e e11b su ciascun controller di archiviazione AFF A90</block>
  <block id="09417c9a09b9c4ceb39f1b21b0c805ce" category="list-text">Assegnare porte fisiche a ciascuna VLAN in modo appropriato, ad esempio porte client nelle VLAN client e porte di archiviazione nelle VLAN di archiviazione</block>
  <block id="30add6fef18e27847f71d245bce4adf2" category="list-text">nv set int &lt;swpX&gt; dominio bridge br_default access &lt;id vlan&gt;</block>
  <block id="8c088863d87c4744d16775f50bd22826" category="list-text">Le porte MLAG dovrebbero rimanere porte trunk per abilitare più VLAN sulle interfacce collegate, secondo necessità.</block>
  <block id="dc7dbdf7949b0253d64542d3a6648b53" category="list-text">Configurare le interfacce virtuali dello switch (SVI) su ciascuna VLAN per fungere da gateway e abilitare il routing L3</block>
  <block id="bbc11fb8434953cf5f8a56090594c94e" category="list-text">nv set int vlan3 indirizzo IP 100.127.0.0/31</block>
  <block id="56a4338a8bbb720e395dea767276043e" category="list-text">nv set int vlan101 indirizzo IP 100.127.101.1/24</block>
  <block id="c88e27e83683371775c79ed4db025a42" category="list-text">nv set int vlan102 indirizzo IP 100.127.102.1/24</block>
  <block id="c8e18763efa8332ade09b61ec6c43e79" category="list-text">nv set int vlan3 indirizzo IP 100.127.0.1/31</block>
  <block id="d39015045c0b670844a63ea89a0558e1" category="list-text">nv set int vlan201 indirizzo IP 100.127.201.1/24</block>
  <block id="72caedfc84ea977b468f72cc81db5b0f" category="list-text">nv set int vlan202 indirizzo IP 100.127.202.1/24</block>
  <block id="4d86d7ad33785bddc3f3227d7cfe8c00" category="list-text">Creare percorsi statici</block>
  <block id="957e71bdd90bad3e445176749a6e839a" category="list-text">Le rotte statiche vengono create automaticamente per le subnet sullo stesso switch</block>
  <block id="ba77f5caf647fd0155f2edd382f4c005" category="list-text">Sono necessari percorsi statici aggiuntivi per il routing da switch a switch in caso di guasto del collegamento client</block>
  <block id="cb6543cc4fa221dc0cadbcce30a3d708" category="list-text">nv imposta il router predefinito vrf statico 100.127.128.0/17 tramite 100.127.0.1</block>
  <block id="3616a5e3448d387e297a217363fcd491" category="list-text">nv imposta il router predefinito vrf statico 100.127.0.0/17 tramite 100.127.0.0</block>
  <block id="2139fe384d5ae165545994dff01961d9" category="section-title">Configurazione del sistema di archiviazione</block>
  <block id="eb75aeb3b4b2b9734ba3e52f5483f0b2" category="inline-link-macro">Documentazione ONTAP</block>
  <block id="6c077f840844078f56944a0699577ff6" category="paragraph">In questa sezione vengono descritti i dettagli chiave per la configurazione del sistema di archiviazione A90 per questa soluzione.  Per maggiori dettagli sulla configurazione dei sistemi ONTAP fare riferimento a<block ref="c9be69f343f12523b36264fad0c62551" category="inline-link-macro-rx"></block> .  Il diagramma seguente mostra la configurazione logica del sistema di archiviazione.</block>
  <block id="a2720bc0a2d05de970087a0c7fad9311" category="paragraph">Di seguito sono descritti i passaggi di base utilizzati per configurare il sistema di archiviazione.  Questo processo presuppone che l'installazione del cluster di archiviazione di base sia stata completata.</block>
  <block id="a65ed1368170b15ddddd6ee0b2408084" category="list-text">Configurare 1 aggregato su ciascun controller con tutte le partizioni disponibili meno 1 di riserva</block>
  <block id="104afbbbf990a88bdaee0bb7222c4b8e" category="list-text">aggr create -node &lt;nodo&gt; -aggregate &lt;nodo&gt;_data01 -diskcount &lt;47&gt;</block>
  <block id="40531cd604f58d3ba347b865243c7e48" category="list-text">Configurare ifgrps su ciascun controller</block>
  <block id="f72dfa57e15677b92e70b5a144e0b5f9" category="list-text">net port ifgrp create -node &lt;nodo&gt; -ifgrp a1a -mode multimode_lacp -distr-function port</block>
  <block id="55be7178bd14f4153f1b019457ede4a9" category="list-text">net port ifgrp add-port -node &lt;nodo&gt; -ifgrp &lt;ifgrp&gt; -ports &lt;nodo&gt;:e2a,&lt;nodo&gt;:e2b</block>
  <block id="b13faeadb39006cbcc1d3c2e50344bf1" category="list-text">Configurare la porta VLAN mgmt su ifgrp su ciascun controller</block>
  <block id="e6e28ccd055fb443d6dd14a9a6eb7d1a" category="list-text">porta di rete vlan crea -nodo aff-a90-01 -porta a1a -id-vlan 31</block>
  <block id="f740c9ebcb9caacb0b5d819655c488ed" category="list-text">porta di rete vlan crea -nodo aff-a90-02 -porta a1a -id-vlan 31</block>
  <block id="5d71abf584a26ed36de342533bc6b11f" category="list-text">porta di rete vlan crea -nodo aff-a90-03 -porta a1a -id-vlan 31</block>
  <block id="21e3a0fbbbf79005355b371bbcdd44e6" category="list-text">porta di rete vlan crea -nodo aff-a90-04 -porta a1a -vlan-id 31</block>
  <block id="cd002818e71e3e15ea7d845a92b82053" category="list-text">Crea domini di trasmissione</block>
  <block id="060c8e724635c9585153496e36c5fe64" category="list-text">broadcast-domain create -broadcast-domain vlan21 -mtu 9000 -ports aff-a90-01:e6a,aff-a90-01:e11a,aff-a90-02:e6a,aff-a90-02:e11a,aff-a90-03:e6a,aff-a90-03:e11a,aff-a90-04:e6a,aff-a90-04:e11a</block>
  <block id="f0375c78fd286627e0ea2e893298127b" category="list-text">broadcast-domain create -broadcast-domain vlan22 -mtu 9000 -ports aaff-a90-01:e6b,aff-a90-01:e11b,aff-a90-02:e6b,aff-a90-02:e11b,aff-a90-03:e6b,aff-a90-03:e11b,aff-a90-04:e6b,aff-a90-04:e11b</block>
  <block id="46bd5a85171233df8aad89e1ea34eca2" category="list-text">creazione dominio broadcast -dominio broadcast vlan31 -mtu 9000 -porte aff-a90-01:a1a-31,aff-a90-02:a1a-31,aff-a90-03:a1a-31,aff-a90-04:a1a-31</block>
  <block id="623ea6b05fb05729ffd64b3aecd6e969" category="list-text">Crea SVM di gestione *</block>
  <block id="5619023db11b9124790191d573fd6c9a" category="list-text">Configurare la gestione SVM</block>
  <block id="a085de8c20c0316efb0b620d42f96f5d" category="list-text">creare LIF</block>
  <block id="f2a8aff28094374e836aba88837e4ecd" category="list-text">net int create -vserver basepod-mgmt -lif vlan31-01 -home-node aff-a90-01 -home-port a1a-31 -address 192.168.31.X -netmask 255.255.255.0</block>
  <block id="025643e2f4f3d8255f6a74703e817f10" category="list-text">creare volumi FlexGroup</block>
  <block id="ff251de7d10dfd4d224adb00c9771d80" category="list-text">vol create -vserver basepod-mgmt -volume home -size 10T -auto-provision-as flexgroup -junction-path /home</block>
  <block id="7eadd281ac9fa05f29dd10931c800b73" category="list-text">vol create -vserver basepod-mgmt -volume cm -size 10T -auto-provision-as flexgroup -junction-path /cm</block>
  <block id="4daa96de5bcd998457adea84b3b0d3f2" category="list-text">creare una politica di esportazione</block>
  <block id="0224cbf10aded53062d1c33a00ed3f00" category="list-text">regola export-policy create -vserver basepod-mgmt -policy default -client-match 192.168.31.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="d5c522a3ee4c4fb65fcbe94d031d0a08" category="list-text">Crea dati SVM *</block>
  <block id="6310e0b69ca3cd6447bec629307180b7" category="list-text">Configurare i dati SVM</block>
  <block id="8aa04063c0eff21564b4943f7c5bd0af" category="list-text">configurare SVM per il supporto RDMA</block>
  <block id="f67ee8861066661a87085502a485f642" category="list-text">vserver nfs modify -vserver basepod-data -rdma abilitato</block>
  <block id="f29cc71670e3362a894e54ea9924917c" category="list-text">creare LIF</block>
  <block id="3df4cfdffe24b83cba807ded784fb107" category="list-text">net int create -vserver basepod-data -lif c1-6a-lif1 -home-node aff-a90-01 -home-port e6a -address 100.127.102.101 -netmask 255.255.255.0</block>
  <block id="26a6d29a1530006b710e49ad940bc64a" category="list-text">net int create -vserver basepod-data -lif c1-6a-lif2 -home-node aff-a90-01 -home-port e6a -address 100.127.102.102 -netmask 255.255.255.0</block>
  <block id="985d0d4d212dc0238d9f101fee0a3418" category="list-text">net int create -vserver basepod-data -lif c1-6b-lif1 -home-node aff-a90-01 -home-port e6b -address 100.127.202.101 -netmask 255.255.255.0</block>
  <block id="07f93d0815d9e298cb8b02049c677706" category="list-text">net int create -vserver basepod-data -lif c1-6b-lif2 -home-node aff-a90-01 -home-port e6b -address 100.127.202.102 -netmask 255.255.255.0</block>
  <block id="2d977106413211171eefeeb51af2bdf7" category="list-text">net int create -vserver basepod-data -lif c1-11a-lif1 -home-node aff-a90-01 -home-port e11a -address 100.127.102.103 -netmask 255.255.255.0</block>
  <block id="10d75b950d2d9634a2804a1ed92f0df7" category="list-text">net int create -vserver basepod-data -lif c1-11a-lif2 -home-node aff-a90-01 -home-port e11a -address 100.127.102.104 -netmask 255.255.255.0</block>
  <block id="7e3ec60a178738ba9ac6680a6bf6340d" category="list-text">net int create -vserver basepod-data -lif c1-11b-lif1 -home-node aff-a90-01 -home-port e11b -address 100.127.202.103 -netmask 255.255.255.0</block>
  <block id="b14efeaf4c17d63f2e6011dc35f5722c" category="list-text">net int create -vserver basepod-data -lif c1-11b-lif2 -home-node aff-a90-01 -home-port e11b -address 100.127.202.104 -netmask 255.255.255.0</block>
  <block id="74c24c93e98c023e9fe31988005f6735" category="list-text">net int create -vserver basepod-data -lif c2-6a-lif1 -home-node aff-a90-02 -home-port e6a -address 100.127.102.105 -netmask 255.255.255.0</block>
  <block id="d00b578414c1bb9f219c72ef1262d701" category="list-text">net int create -vserver basepod-data -lif c2-6a-lif2 -home-node aff-a90-02 -home-port e6a -address 100.127.102.106 -netmask 255.255.255.0</block>
  <block id="c49b52997695ebd048410b0b8f9f19f2" category="list-text">net int create -vserver basepod-data -lif c2-6b-lif1 -home-node aff-a90-02 -home-port e6b -address 100.127.202.105 -netmask 255.255.255.0</block>
  <block id="912c10c91d670dee279852756245a063" category="list-text">net int create -vserver basepod-data -lif c2-6b-lif2 -home-node aff-a90-02 -home-port e6b -address 100.127.202.106 -netmask 255.255.255.0</block>
  <block id="031724ef6867c2ff3771e70c8520b1d0" category="list-text">net int create -vserver basepod-data -lif c2-11a-lif1 -home-node aff-a90-02 -home-port e11a -address 100.127.102.107 -netmask 255.255.255.0</block>
  <block id="8b417c98283cde9dc265541e2455e2f5" category="list-text">net int create -vserver basepod-data -lif c2-11a-lif2 -home-node aff-a90-02 -home-port e11a -address 100.127.102.108 -netmask 255.255.255.0</block>
  <block id="f129b43cd7a26c7049c4340ac4ef86e1" category="list-text">net int create -vserver basepod-data -lif c2-11b-lif1 -home-node aff-a90-02 -home-port e11b -address 100.127.202.107 -netmask 255.255.255.0</block>
  <block id="5a6d6f4dbbb1d6f8f5558b1c36f5e671" category="list-text">net int create -vserver basepod-data -lif c2-11b-lif2 -home-node aff-a90-02 -home-port e11b -address 100.127.202.108 -netmask 255.255.255.0</block>
  <block id="057f5c63653dacba830db83ad6ad78ee" category="list-text">Configurare LIF per l'accesso RDMA</block>
  <block id="ea7a0f026442b56683f1e50cb21a0d06" category="list-text">Per le distribuzioni con ONTAP 9.15.1, la configurazione RoCE QoS per le informazioni fisiche richiede comandi a livello di sistema operativo che non sono disponibili nella CLI ONTAP .  Contattare l'assistenza NetApp per ricevere assistenza nella configurazione delle porte per il supporto RoCE.  NFS su RDMA funziona senza problemi</block>
  <block id="2e94a4ea05164067f4cb6f27639c8b7a" category="list-text">A partire da ONTAP 9.16.1, le interfacce fisiche verranno automaticamente configurate con le impostazioni appropriate per il supporto RoCE end-to-end.</block>
  <block id="95f5fd496607048d9a2d17c6c6577aa2" category="list-text">net int modifica -vserver basepod-data -lif * -rdma-protocols roce</block>
  <block id="29789a25d415e0f3b5d8cef38626fadc" category="list-text">Configurare i parametri NFS sulla SVM dei dati</block>
  <block id="37013073e580c7f2ed500849958f49cd" category="list-text">modifica nfs -vserver basepod-data -v4.1 abilitato -v4.1-pnfs abilitato -v4.1-trunking abilitato -tcp-max-transfer-size 262144</block>
  <block id="8f7c2b974d2b68275b99738f2db92da7" category="list-text">Crea volumi FlexGroup</block>
  <block id="375a2038f90b0da452502ee281313fdd" category="list-text">vol create -vserver basepod-data -volume data -size 100T -auto-provision-as flexgroup -junction-path /data</block>
  <block id="48e79d83943623a53289accfc05a7108" category="list-text">Creare una politica di esportazione</block>
  <block id="f36c67518ab2b84b8b81ef59c8d30976" category="list-text">regola export-policy create -vserver basepod-data -policy default -client-match 100.127.101.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="738b25d5c96222859fa0d9f34e585e1d" category="list-text">regola export-policy create -vserver basepod-data -policy default -client-match 100.127.201.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="14f424e270715fb6e8bf7277cb075650" category="list-text">creare percorsi</block>
  <block id="086c700f168ee8ad618b80e189d3ab75" category="list-text">percorso aggiungi -vserver basepod_data -destinazione 100.127.0.0/17 -gateway 100.127.102.1 metrica 20</block>
  <block id="e6bf4bcbe9f12d429928fe014e660008" category="list-text">percorso aggiungi -vserver basepod_data -destinazione 100.127.0.0/17 -gateway 100.127.202.1 metrica 30</block>
  <block id="35dc59e7fce425d44a0f407fcd227c43" category="list-text">percorso aggiungi -vserver basepod_data -destinazione 100.127.128.0/17 -gateway 100.127.202.1 metrica 20</block>
  <block id="50a387548848ab61afe342aa18b992c7" category="list-text">percorso aggiungi -vserver basepod_data -destinazione 100.127.128.0/17 -gateway 100.127.102.1 metrica 30</block>
  <block id="dc8a99ae9ee0b79d432c8eac1124edb5" category="section-title">Configurazione DGX H100 per l'accesso allo storage RoCE</block>
  <block id="206274d0712987318a4f897f7e6ae75c" category="inline-link-macro">Documentazione BCM</block>
  <block id="0448e5984ca30c8aeeb162534801fe92" category="paragraph">Questa sezione descrive i dettagli chiave per la configurazione dei sistemi DGX H100.  Molti di questi elementi di configurazione possono essere inclusi nell'immagine del sistema operativo distribuita sui sistemi DGX o implementati da Base Command Manager al momento dell'avvio.  Sono elencati qui per riferimento, per maggiori informazioni sulla configurazione dei nodi e delle immagini software in BCM consultare<block ref="21b53d84e45529faee31545df8020d3b" category="inline-link-macro-rx"></block> .</block>
  <block id="12211cca460b22741ca0d08e3f60fb0c" category="list-text">Installa pacchetti aggiuntivi</block>
  <block id="0df162aa5e7703fc2c2a77a7d1d5a1fe" category="list-text">ipmitool</block>
  <block id="e08cb560fa0fac340ce6e958daaf5e4d" category="list-text">python3-pip</block>
  <block id="8cd5d0cdb86cde9f0dc88352811817ec" category="list-text">Installa i pacchetti Python</block>
  <block id="32760a760ea625ddb856e92f3b089802" category="list-text">paramiko</block>
  <block id="f02113237a5a5fff03e34c9eeeb46640" category="list-text">matplotlib</block>
  <block id="9b162ba267ba83b0a5f5cb6cdbe972dd" category="list-text">Riconfigurare dpkg dopo l'installazione del pacchetto</block>
  <block id="a8bc68a93f8c901b4a33e27af2f21da0" category="list-text">dpkg --configure -a</block>
  <block id="0243e3d81be4d79f622d517c103c3ae0" category="list-text">Installa MOFED</block>
  <block id="08c24ffe86544b752cd2764895595237" category="list-text">Imposta i valori mst per l'ottimizzazione delle prestazioni</block>
  <block id="d5bedef65a3750cb3c0a2b86f80a11e4" category="list-text">mstconfig -y -d &lt;aa:00.0,29:00.0&gt; imposta ADVANCED_PCI_SETTINGS=1 NUM_OF_VFS=0 MAX_ACC_OUT_READ=44</block>
  <block id="bdacbd6c214d3cc42e1d1f8305ef92c9" category="list-text">Reimpostare gli adattatori dopo aver modificato le impostazioni</block>
  <block id="9af48ffdb9436775e220fda80ded47ad" category="list-text">mlxfwreset -d &lt;aa:00.0,29:00.0&gt; -y ripristina</block>
  <block id="c7cb0d4934d36b9bb0816b3a5c49f0b1" category="list-text">Imposta MaxReadReq sui dispositivi PCI</block>
  <block id="1a252b6a7629ccb0f15527f8ca5f627c" category="list-text">setpci -s &lt;aa:00.0,29:00.0&gt; 68.W=5957</block>
  <block id="29aaf92306610006fe7ce7d8c90411ca" category="list-text">Imposta la dimensione del buffer ad anello RX e TX</block>
  <block id="3d789bdc86cf1d51f9b23d11b808ddd5" category="list-text">ethtool -G &lt;enp170s0f0np0,enp41s0f0np0&gt; rx 8192 tx 8192</block>
  <block id="a0340fb71fb195f79ce47dabe6242f8e" category="list-text">Imposta PFC e DSCP utilizzando mlnx_qos</block>
  <block id="6537005ab5e42cbee146ce9b17d892d8" category="list-text">mlnx_qos -i &lt;enp170s0f0np0,enp41s0f0np0&gt; --pfc 0,0,0,1,0,0,0,0 --trust=dscp --cable_len=3</block>
  <block id="a277efb29c974f8ae6d1925383335b05" category="list-text">Imposta ToS per il traffico RoCE sulle porte di rete</block>
  <block id="8c1e8c1481d777723e305f147f16012d" category="list-text">echo 106 &gt; /sys/class/infiniband/&lt;mlx5_7,mlx5_1&gt;/tc/1/traffic_class</block>
  <block id="05dae9ad2cfb95dc1f78bc696aa0d6a4" category="list-text">Configurare ogni scheda di rete di archiviazione con un indirizzo IP sulla subnet appropriata</block>
  <block id="fa2bddc64b24b8cd13f0be734ce934ca" category="list-text">100.127.101.0/24 per la scheda di rete di archiviazione 1</block>
  <block id="945382c87aa13867b8b36da66c8ae8fc" category="list-text">100.127.201.0/24 per la scheda di rete di archiviazione 2</block>
  <block id="ed769c091c9112ad2d1a5c89de5c0c65" category="list-text">Configurare le porte di rete in banda per il bonding LACP (enp170s0f1np1,enp41s0f1np1)</block>
  <block id="af487da74a6eeea9aa52d90c5c8cd04d" category="list-text">configurare percorsi statici per percorsi primari e secondari verso ciascuna subnet di archiviazione</block>
  <block id="593c13037333a6722527c42d1d0b156c" category="list-text">percorso aggiungi –net 100.127.0.0/17 gw 100.127.101.1 metrica 20</block>
  <block id="8656e83d4d88a713f09d848f3cc09702" category="list-text">percorso aggiungi –net 100.127.0.0/17 gw 100.127.201.1 metrica 30</block>
  <block id="85f6d08b3d54f8d8785ef6f36f7c61c3" category="list-text">percorso aggiungi –net 100.127.128.0/17 gw 100.127.201.1 metrica 20</block>
  <block id="d70120de1b67fd20affa2557aca990ef" category="list-text">percorso aggiungi –net 100.127.128.0/17 gw 100.127.101.1 metrica 30</block>
  <block id="7fc2f78e0bd34dcefec071f2a70514c2" category="list-text">Monta /volume home</block>
  <block id="9ff7402ee00f4969ccc4395a7241c47c" category="list-text">monta -o vers=3,nconnect=16,rsize=262144,wsize=262144 192.168.31.X:/home /home</block>
  <block id="152cd866abad6e43429948eb4715b973" category="list-text">Monta /volume dati</block>
  <block id="1cd39f0089800bb9511317cc53d73557" category="list-text">Le seguenti opzioni di montaggio sono state utilizzate durante il montaggio del volume di dati:</block>
  <block id="bcd39ebb3417a185678d6de2189af4b9" category="list-text">vers=4.1 # abilita pNFS per l'accesso parallelo a più nodi di archiviazione</block>
  <block id="5cd472c72f4b3a3c75cbdb77edc30528" category="list-text">proto=rdma # imposta il protocollo di trasferimento su RDMA invece del TCP predefinito</block>
  <block id="f8553c0c0cde0245d779c37090c093a7" category="list-text">max_connect=16 # abilita il trunking della sessione NFS per aggregare la larghezza di banda della porta di archiviazione</block>
  <block id="f8a3438d5712d48a22100c8109ea556e" category="list-text">write=eager # migliora le prestazioni di scrittura delle scritture bufferizzate</block>
  <block id="42fdb382646439a01d661ce9d2127a1c" category="list-text">rsize=262144,wsize=262144 # imposta la dimensione del trasferimento I/O a 256k</block>
  <block id="7f86b6f2a05fc6e5c5931f73e9af29fd" category="summary">NetApp AIPod con sistemi NVIDIA DGX - Componenti hardware</block>
  <block id="7c451f18f811f88a48907bf86377cdd8" category="doc">NVA-1173 NetApp AIPod con sistemi NVIDIA DGX - Componenti hardware</block>
  <block id="bd6e083031bf15817a67b63cc58a211c" category="paragraph">Questa sezione si concentra sui componenti hardware per NetApp AIPod con sistemi NVIDIA DGX.</block>
  <block id="68674fa5fbd6fb83969183d07d48b8cd" category="section-title">Sistemi di archiviazione NetApp AFF</block>
  <block id="3b6d33ce139758ecf9b0b83f9ecce001" category="paragraph">I sistemi di storage all'avanguardia NetApp AFF consentono ai reparti IT di soddisfare i requisiti di storage aziendale con prestazioni leader del settore, flessibilità superiore, integrazione cloud e la migliore gestione dei dati della categoria.  Progettati specificamente per flash, i sistemi AFF aiutano ad accelerare, gestire e proteggere i dati aziendali critici.</block>
  <block id="d1d40f451fb75b4e7160785e64a75da3" category="section-title">Sistemi di stoccaggio AFF A90</block>
  <block id="df7df1dd54ea101ca8a417ee258e2693" category="paragraph">NetApp AFF A90 , basato sul software di gestione dati NetApp ONTAP , offre protezione dati integrata, funzionalità anti-ransomware opzionali e le elevate prestazioni e la resilienza necessarie per supportare i carichi di lavoro aziendali più critici.  Elimina le interruzioni delle operazioni mission-critical, riduce al minimo l'ottimizzazione delle prestazioni e protegge i dati dagli attacchi ransomware.  Offre: • Prestazioni leader del settore • Sicurezza dei dati senza compromessi • Aggiornamenti semplificati e senza interruzioni</block>
  <block id="6bd43dd4b56bb5bfe362d48a0d5219e0" category="paragraph">_Sistema di archiviazione NetApp AFF A90</block>
  <block id="df3fd00dc667f05e52f1e05b8dedfd55" category="paragraph"><block ref="df3fd00dc667f05e52f1e05b8dedfd55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1863aa82dcf92831635aa05e975d399d" category="section-title">Prestazioni leader del settore</block>
  <block id="a261fc6acbe5e140d750bc3f1dd8c7a7" category="paragraph">L' AFF A90 gestisce facilmente carichi di lavoro di nuova generazione come deep learning, intelligenza artificiale e analisi ad alta velocità, nonché database aziendali tradizionali come Oracle, SAP HANA, Microsoft SQL Server e applicazioni virtualizzate.  Mantiene le applicazioni aziendali critiche in esecuzione alla massima velocità con un massimo di 2,4 milioni di IOPS per coppia HA e una latenza fino a 100 µs, e aumenta le prestazioni fino al 50% rispetto ai precedenti modelli NetApp .  Grazie a NFS su RDMA, pNFS e Session Trunking, i clienti possono raggiungere l'elevato livello di prestazioni di rete richiesto per le applicazioni di nuova generazione utilizzando l'infrastruttura di rete del data center esistente.  I clienti possono inoltre scalare e crescere con il supporto multiprotocollo unificato per SAN, NAS e storage di oggetti e garantire la massima flessibilità con un software di gestione dati ONTAP unificato e singolo, per i dati in sede o nel cloud.  Inoltre, lo stato di salute del sistema può essere ottimizzato con analisi predittive basate sull'intelligenza artificiale fornite da Active IQ e Cloud Insights.</block>
  <block id="773efff7a0bbe1582ceff936530b5ae3" category="section-title">Sicurezza dei dati senza compromessi</block>
  <block id="b867e6aa9b3e46766f55ab250eb69715" category="paragraph">I sistemi AFF A90 contengono una suite completa di software di protezione dei dati NetApp integrato e coerente con le applicazioni.  Fornisce protezione dei dati integrata e soluzioni anti-ransomware all'avanguardia per il recupero preventivo e post-attacco.  È possibile bloccare la scrittura su disco dei file dannosi e monitorare facilmente le anomalie di archiviazione per ottenere informazioni.</block>
  <block id="f6353452ddd71a9ef0e4d8578d7dc7e3" category="section-title">Aggiornamenti semplificati e non distruttivi</block>
  <block id="4015e152c676ca730da1d797ef1e9993" category="paragraph">L' AFF A90 è disponibile come aggiornamento non invasivo del telaio per i clienti A800 esistenti.  NetApp semplifica l'aggiornamento e l'eliminazione delle interruzioni nelle operazioni mission-critical grazie alle nostre funzionalità avanzate di affidabilità, disponibilità, manutenibilità e gestibilità (RASM).  Inoltre, NetApp aumenta ulteriormente l'efficienza operativa e semplifica le attività quotidiane dei team IT, poiché il software ONTAP applica automaticamente gli aggiornamenti del firmware per tutti i componenti del sistema.</block>
  <block id="13ab18b8510a80a65aefbf9a56e3b3d3" category="paragraph">Per le distribuzioni più grandi, i sistemi AFF A1K offrono le prestazioni e le capacità più elevate, mentre altri sistemi di storage NetApp , come AFF A70 e AFF C800, offrono opzioni per distribuzioni più piccole a costi inferiori.</block>
  <block id="3ebd416d1b3232ef4125025ab8f437a9" category="paragraph">NVIDIA DGX BasePOD è una soluzione integrata composta da componenti hardware e software NVIDIA , soluzioni MLOps e storage di terze parti.  Sfruttando le migliori pratiche di progettazione di sistemi scalabili con prodotti NVIDIA e soluzioni partner convalidate, i clienti possono implementare una piattaforma efficiente e gestibile per lo sviluppo dell'intelligenza artificiale.  La figura 1 evidenzia i vari componenti di NVIDIA DGX BasePOD.</block>
  <block id="76d810a9cb0440f2de2c7104493e266f" category="paragraph">_Soluzione NVIDIA DGX BasePOD_</block>
  <block id="559d10ed60e21f546209442a6aade09d" category="paragraph"><block ref="559d10ed60e21f546209442a6aade09d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a5f31a2eea3b274409614f4eb63433c" category="section-title">Sistemi NVIDIA DGX H100</block>
  <block id="2cdfa62855978fa129d36e4602f41e0b" category="paragraph">Il sistema NVIDIA DGX H100 è un concentrato di intelligenza artificiale accelerato dalle prestazioni rivoluzionarie della GPU NVIDIA H100 Tensor Core.</block>
  <block id="4a8da04b1b7a51ad2e9c77e221e0d9d9" category="paragraph">_Sistema NVIDIA DGX H100_</block>
  <block id="b9ab32cd1976da02bb3c074578d491c3" category="paragraph"><block ref="b9ab32cd1976da02bb3c074578d491c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93b775e18b65e433d85d83ad863c1797" category="paragraph">Le specifiche principali del sistema DGX H100 sono: • Otto GPU NVIDIA H100.  • 80 GB di memoria GPU per GPU, per un totale di 640 GB.  • Quattro chip NVIDIA NVSwitch.  • Doppi processori Intel Xeon Platinum 8480 a 56 core con supporto PCIe 5.0.  • 2 TB di memoria di sistema DDR5.  • Quattro porte OSFP che servono otto adattatori NVIDIA ConnectX-7 (InfiniBand/Ethernet) a porta singola e due adattatori NVIDIA ConnectX-7 (InfiniBand/Ethernet) a doppia porta.  • Due unità M.2 NVMe da 1,92 TB per DGX OS, otto unità U.2 NVMe da 3,84 TB per archiviazione/cache.  • Potenza massima 10,2 kW.  Di seguito sono illustrate le porte posteriori del vassoio CPU DGX H100.  Quattro delle porte OSFP servono otto adattatori ConnectX-7 per la struttura di elaborazione InfiniBand.  Ogni coppia di adattatori ConnectX-7 a doppia porta fornisce percorsi paralleli verso le strutture di archiviazione e gestione.  La porta fuori banda viene utilizzata per l'accesso BMC .</block>
  <block id="1811b955f76e78d806cc9f89eca9365d" category="paragraph">_Pannello posteriore NVIDIA DGX H100_</block>
  <block id="7d94d25261d22723cf1dcbc550472562" category="paragraph"><block ref="7d94d25261d22723cf1dcbc550472562" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e64325a640583a5afbe8ce27e88608e" category="section-title">Switch NVIDIA Quantum-2 QM9700</block>
  <block id="96e834f144fffd019191dee8b2e3fa9e" category="paragraph">_Switch NVIDIA Quantum-2 QM9700 InfiniBand_</block>
  <block id="02e6cd41035da9c303b4223fcb954c57" category="paragraph"><block ref="02e6cd41035da9c303b4223fcb954c57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58e83b10341e2ec3a48b164715b6ba34" category="paragraph">Gli switch NVIDIA Quantum-2 QM9700 con connettività InfiniBand da 400 Gb/s alimentano la struttura di elaborazione nelle configurazioni NVIDIA Quantum-2 InfiniBand BasePOD.  Per la struttura di elaborazione InfiniBand vengono utilizzati gli adattatori a porta singola ConnectX-7.  Ogni sistema NVIDIA DGX è dotato di doppie connessioni per ogni switch QM9700, fornendo più percorsi ad alta larghezza di banda e bassa latenza tra i sistemi.</block>
  <block id="88f086b3f05858ad120601108f0821a7" category="section-title">Switch NVIDIA Spectrum-3 SN4600</block>
  <block id="69dc0a65b1f9cc56bf9d1b38913e279e" category="paragraph">_Switch NVIDIA Spectrum-3 SN4600_</block>
  <block id="a5317e31cdc481b4371010e9f47b541d" category="paragraph"><block ref="a5317e31cdc481b4371010e9f47b541d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df2b71117642b0bdbf87a4e9d643c47e" category="paragraph">Gli switch NVIDIA Spectrum-3 SN4600 offrono 128 porte totali (64 per switch) per fornire connettività ridondante per la gestione in-band del DGX BasePOD.  Lo switch NVIDIA SN4600 può fornire velocità comprese tra 1 GbE e 200 GbE.  Per gli apparecchi di archiviazione collegati tramite Ethernet vengono utilizzati anche gli switch NVIDIA SN4600.  Le porte sugli adattatori ConnectX-7 a doppia porta NVIDIA DGX vengono utilizzate sia per la gestione in banda che per la connettività di archiviazione.</block>
  <block id="9bc83d36ebb307eef9521860d72d6a83" category="section-title">Switch NVIDIA Spectrum SN2201</block>
  <block id="0a58d2e4f07c9b74c7b9f0f643df366e" category="paragraph">_Switch NVIDIA Spectrum SN2201_</block>
  <block id="63573ea3854985f600f8cc8c44aa5bea" category="paragraph"><block ref="63573ea3854985f600f8cc8c44aa5bea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6714f3120a26d6eb7222fbbd52715a6c" category="paragraph">Gli switch NVIDIA Spectrum SN2201 offrono 48 porte per garantire la connettività per la gestione fuori banda.  La gestione fuori banda fornisce una connettività di gestione consolidata per tutti i componenti in DGX BasePOD.</block>
  <block id="82e5da407cc33e26189f053503aa2bf6" category="section-title">Adattatore NVIDIA ConnectX-7</block>
  <block id="74baf984365e15a6f92345e68021621a" category="paragraph">_Adattatore NVIDIA ConnectX-7_</block>
  <block id="062446821e85b6d2c053705d69b2c037" category="paragraph"><block ref="062446821e85b6d2c053705d69b2c037" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1f31835004684d86091e359c9a240e92" category="paragraph">L'adattatore NVIDIA ConnectX-7 può fornire una velocità di trasmissione di 25/50/100/200/400 G.  I sistemi NVIDIA DGX utilizzano sia gli adattatori ConnectX-7 a porta singola che doppia per garantire flessibilità nelle distribuzioni DGX BasePOD con InfiniBand ed Ethernet da 400 Gb/s.</block>
  <block id="9f68b039fbd3ecc8729ee9a4be7903ea" category="summary">NetApp AIPod con NVIDIA DGX Systems è un'architettura di riferimento pronta per le aziende basata su NVIDIA BasePOD per Deep Learning e Intelligenza Artificiale che utilizza i sistemi di storage NetApp ONTAP AFF e i sistemi di rete e DGX NVIDIA .</block>
  <block id="9b07efa8439fb4859742ace8bb15c070" category="doc">NVA-1173 NetApp AIPod con sistemi NVIDIA DGX - Introduzione</block>
  <block id="03a5dba0ba7f06a853319a59ab10f1db" category="inline-image-macro">200,200, Errore: Immagine grafica mancante</block>
  <block id="540456658a35dff79ec59aa1338d398e" category="paragraph"><block ref="540456658a35dff79ec59aa1338d398e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="217432d0ec5a422d97fdd8082983c438" category="paragraph">Ingegneria delle soluzioni NetApp</block>
  <block id="617f17b8f2c8c0557ec9f79c918464eb" category="paragraph">L' AIPod NetApp con sistemi NVIDIA DGX e sistemi di storage NetApp connessi al cloud semplifica le distribuzioni dell'infrastruttura per carichi di lavoro di apprendimento automatico (ML) e intelligenza artificiale (AI), eliminando la complessità di progettazione e le congetture.  Basandosi sul design NVIDIA DGX BasePOD per offrire prestazioni di elaborazione eccezionali per carichi di lavoro di nuova generazione, AIPod con sistemi NVIDIA DGX aggiunge sistemi di storage NetApp AFF che consentono ai clienti di iniziare in piccolo e crescere senza interruzioni, gestendo in modo intelligente i dati dall'edge al core, al cloud e viceversa.  NetApp AIPod fa parte del più ampio portafoglio di soluzioni AI NetApp , illustrato nella figura seguente.</block>
  <block id="194ff09c8e869017b4ffe91887dde829" category="paragraph">_Portafoglio di soluzioni AI NetApp_</block>
  <block id="629225e0ba0d0325f35ee6fcfd7ebf4e" category="paragraph"><block ref="629225e0ba0d0325f35ee6fcfd7ebf4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff9a398ccda9f0fc1e44521cf40ca977" category="paragraph">Questo documento descrive i componenti chiave dell'architettura di riferimento AIPod , le informazioni sulla connettività e sulla configurazione del sistema, i risultati dei test di convalida e le indicazioni per il dimensionamento della soluzione.  Questo documento è destinato agli ingegneri delle soluzioni NetApp e dei partner e ai decisori strategici dei clienti interessati a implementare un'infrastruttura ad alte prestazioni per carichi di lavoro di ML/DL e analisi.</block>
  <block id="77f2324c2483df30f029d522599f882e" category="summary">NetApp AIPod con sistemi NVIDIA DGX - Componenti software</block>
  <block id="751547b5efb176a435e672a4015bb7e9" category="doc">NVA-1173 NetApp AIPod con sistemi NVIDIA DGX - Componenti software</block>
  <block id="c3d68fb38e0db372152f5a3a84fed148" category="paragraph">Questa sezione si concentra sui componenti software di NetApp AIPod con sistemi NVIDIA DGX.</block>
  <block id="5475410ded0787143601d2206a245532" category="section-title">Software NVIDIA</block>
  <block id="96a0475a5e6d02d46b5b8d7f1327a530" category="paragraph">NVIDIA Base Command è alla base di ogni DGX BasePOD, consentendo alle organizzazioni di sfruttare il meglio dell'innovazione software NVIDIA .  Le aziende possono sfruttare appieno il potenziale del loro investimento con una piattaforma collaudata che include orchestrazione e gestione dei cluster di livello aziendale, librerie che accelerano l'infrastruttura di elaborazione, storage e rete e un sistema operativo (SO) ottimizzato per i carichi di lavoro di intelligenza artificiale.</block>
  <block id="f30878d7bf93bf61a8d0a25e397a8583" category="paragraph">_Soluzione NVIDIA BaseCommand_</block>
  <block id="26997aefe36f4fb8a168ede0ec7189e1" category="paragraph"><block ref="26997aefe36f4fb8a168ede0ec7189e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9052758d35faeab8995feefc50d729ed" category="section-title">Cloud GPU NVIDIA (NGC)</block>
  <block id="5cbbb9592d14a268aacbc5ecd838a166" category="paragraph">NVIDIA NGC fornisce software per soddisfare le esigenze di data scientist, sviluppatori e ricercatori con diversi livelli di competenza in materia di intelligenza artificiale.  Il software ospitato su NGC viene sottoposto a scansioni su un set aggregato di vulnerabilità ed esposizioni comuni (CVE), chiavi crittografiche e private.  È testato e progettato per essere scalabile su più GPU e, in molti casi, su più nodi, garantendo agli utenti di massimizzare il loro investimento nei sistemi DGX.</block>
  <block id="d19c3b09db45ed579ed1aa2895637b7d" category="paragraph">_Cloud GPU NVIDIA_</block>
  <block id="c46997ba8e7fdf0cb96f12b451129203" category="paragraph"><block ref="c46997ba8e7fdf0cb96f12b451129203" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b4d69ee10ecec0ac3d21aba6691dc53" category="paragraph">NVIDIA AI Enterprise è la piattaforma software end-to-end che rende l'intelligenza artificiale generativa accessibile a tutte le aziende, offrendo il runtime più rapido ed efficiente per i modelli di base dell'intelligenza artificiale generativa ottimizzati per l'esecuzione sulla piattaforma NVIDIA DGX.  Grazie a sicurezza, stabilità e gestibilità di livello produttivo, semplifica lo sviluppo di soluzioni di intelligenza artificiale generativa.  NVIDIA AI Enterprise è incluso in DGX BasePOD per consentire agli sviluppatori aziendali di accedere a modelli pre-addestrati, framework ottimizzati, microservizi, librerie accelerate e supporto aziendale.</block>
  <block id="9aeccfb63defa46cb78ffa3611d362c6" category="section-title">Software NetApp</block>
  <block id="f45c2aa2e74e3412ee9883eb28b7549e" category="paragraph">ONTAP 9, l'ultima generazione di software di gestione dello storage di NetApp, consente alle aziende di modernizzare l'infrastruttura e passare a un data center pronto per il cloud.  Sfruttando le funzionalità di gestione dei dati leader del settore, ONTAP consente la gestione e la protezione dei dati con un unico set di strumenti, indipendentemente da dove risiedano.  È inoltre possibile spostare liberamente i dati ovunque siano necessari: edge, core o cloud.  ONTAP 9 include numerose funzionalità che semplificano la gestione dei dati, accelerano e proteggono i dati critici e abilitano le funzionalità infrastrutturali di nuova generazione nelle architetture cloud ibride.</block>
  <block id="28e23b5888c04e1859e75c594c6cec26" category="section-title">Accelerare e proteggere i dati</block>
  <block id="d9cd75773d759d63134b34db3490eab3" category="paragraph">ONTAP garantisce livelli superiori di prestazioni e protezione dei dati ed estende queste capacità nei seguenti modi:</block>
  <block id="7c282a19ff405710e49738f9d0a03a85" category="list-text">Prestazioni e latenza più bassa.  ONTAP offre la massima produttività possibile con la latenza più bassa possibile, incluso il supporto per NVIDIA GPUDirect Storage (GDS) tramite NFS su RDMA, NFS parallelo (pNFS) e trunking di sessione NFS.</block>
  <block id="b2d0aaf645ff5747fbe1e0aec0cf528c" category="list-text">Protezione dei dati.  ONTAP offre funzionalità integrate di protezione dei dati e la garanzia anti-ransomware più forte del settore, con gestione comune su tutte le piattaforme.</block>
  <block id="892dd840b39835d7da795bbd29f99987" category="list-text">Crittografia del volume NetApp (NVE).  ONTAP offre la crittografia nativa a livello di volume con supporto sia per la gestione delle chiavi integrate che per quella esterna.</block>
  <block id="651928f77d87184265ec1be1ab0b8aff" category="list-text">Multitenancy di archiviazione e autenticazione a più fattori.  ONTAP consente la condivisione delle risorse infrastrutturali con i massimi livelli di sicurezza.</block>
  <block id="f1586460cef11d0abaaf5270f37f18d7" category="section-title">Semplificare la gestione dei dati</block>
  <block id="47b2e74e56111387efd2ff8314d1154c" category="paragraph">La gestione dei dati è fondamentale per le operazioni IT aziendali e per gli scienziati dei dati, in modo che vengano utilizzate risorse appropriate per le applicazioni di intelligenza artificiale e per la formazione di set di dati di intelligenza artificiale/apprendimento automatico.  Le seguenti informazioni aggiuntive sulle tecnologie NetApp esulano dall'ambito di questa convalida, ma potrebbero essere rilevanti a seconda della distribuzione.</block>
  <block id="31c0318dee8b7049a328f752c457824f" category="paragraph">Il software di gestione dati ONTAP include le seguenti funzionalità per semplificare e snellire le operazioni e ridurre i costi operativi totali:</block>
  <block id="621721e0b0144695aabce4090fa40eed" category="list-text">Gli snapshot e i cloni consentono la collaborazione, la sperimentazione parallela e una governance dei dati migliorata per i flussi di lavoro ML/DL.</block>
  <block id="b1932ff070760d4f32c0a3701982558d" category="list-text">SnapMirror consente lo spostamento fluido dei dati in ambienti cloud ibridi e multi-sito, fornendo i dati dove e quando sono necessari.</block>
  <block id="258ce6748736436345d3a4ade7bfcd47" category="list-text">Compattazione dei dati in linea e deduplicazione estesa.  La compattazione dei dati riduce lo spazio sprecato all'interno dei blocchi di archiviazione, mentre la deduplicazione aumenta significativamente la capacità effettiva.  Ciò vale sia per i dati archiviati localmente sia per i dati archiviati a livelli nel cloud.</block>
  <block id="e0243dd3e4c9bff6b7a18cab1c1e37c8" category="list-text">Qualità del servizio minima, massima e adattiva (AQoS).  I controlli granulari della qualità del servizio (QoS) aiutano a mantenere i livelli di prestazioni per le applicazioni critiche in ambienti altamente condivisi.</block>
  <block id="74959a361bdb223dafbb94226dd84e3e" category="list-text">NetApp FlexGroups consente la distribuzione dei dati su tutti i nodi del cluster di storage, garantendo un'enorme capacità e prestazioni più elevate per set di dati estremamente grandi.</block>
  <block id="c3528a5e48bbe189e76cf8d737aa5961" category="inline-link">TR-4598: Buone pratiche FabricPool</block>
  <block id="adc171e1d8b6a0bed3a98762139c9875" category="list-text">NetApp FabricPool.  Fornisce la suddivisione automatica dei dati inattivi in opzioni di archiviazione cloud pubbliche e private, tra cui Amazon Web Services (AWS), Azure e la soluzione di archiviazione NetApp StorageGRID .  Per ulteriori informazioni su FabricPool, vedere<block ref="234c921b7066bc1bdd676ae1a510e5c5" category="inline-link-rx"></block> .</block>
  <block id="eec4aeb85db42cd9055b9aba24052c7e" category="list-text">NetApp FlexCache.  Fornisce funzionalità di memorizzazione nella cache di volumi remoti che semplificano la distribuzione dei file, riducono la latenza WAN e abbassano i costi della larghezza di banda WAN.  FlexCache consente lo sviluppo di prodotti distribuiti su più sedi, nonché l'accesso accelerato ai set di dati aziendali da postazioni remote.</block>
  <block id="685f280ead44650493627d9ac47818e1" category="section-title">Infrastruttura a prova di futuro</block>
  <block id="836ed833c0dea3b588f04d16ca3f850d" category="paragraph">ONTAP aiuta a soddisfare le esigenze aziendali più esigenti e in continua evoluzione grazie alle seguenti funzionalità:</block>
  <block id="483e92f76323d9d7b2d7f2ec6d4c0590" category="list-text">Scalabilità fluida e operazioni senza interruzioni.  ONTAP supporta l'aggiunta online di capacità ai controller esistenti e ai cluster scalabili.  I clienti possono effettuare l'aggiornamento alle tecnologie più recenti, come NVMe e FC da 32 Gb, senza costose migrazioni di dati o interruzioni.</block>
  <block id="96cf8f94fadb527d958ae5373082d6d7" category="list-text">Connessione cloud.  ONTAP è il software di gestione dello storage più connesso al cloud, con opzioni per lo storage definito dal software (ONTAP Select) e istanze cloud-native (Google Cloud NetApp Volumes) in tutti i cloud pubblici.</block>
  <block id="2a7e7bc180cc3d059089e02f091bac27" category="list-text">Integrazione con applicazioni emergenti.  ONTAP offre servizi dati di livello aziendale per piattaforme e applicazioni di nuova generazione, come veicoli autonomi, città intelligenti e Industria 4.0, utilizzando la stessa infrastruttura che supporta le app aziendali esistenti.</block>
  <block id="2c7194a99a4f7de8ffbf3ba400a92df8" category="paragraph">NetApp DataOps Toolkit è uno strumento basato su Python che semplifica la gestione degli spazi di lavoro di sviluppo/formazione e dei server di inferenza supportati da storage NetApp ad alte prestazioni e scalabile.  DataOps Toolkit può funzionare come utility autonoma ed è ancora più efficace negli ambienti Kubernetes che sfruttano NetApp Trident per automatizzare le operazioni di archiviazione.  Le principali funzionalità includono:</block>
  <block id="f9e55f3095ff79acd2c7f6315222ba4a" category="list-text">Fornisci rapidamente nuovi spazi di lavoro JupyterLab ad alta capacità supportati da storage NetApp scalabile e ad alte prestazioni.</block>
  <block id="a9e4b1a2cc4b445907d2b986ab2f3515" category="list-text">Fornisci rapidamente nuove istanze di NVIDIA Triton Inference Server supportate da storage NetApp di classe enterprise.</block>
  <block id="44ce48cceac53b351ab54ca5685fcf55" category="list-text">Clonazione quasi istantanea di spazi di lavoro JupyterLab ad alta capacità per consentire la sperimentazione o l'iterazione rapida.</block>
  <block id="b47bad7e2a479b14e613be5ba1af90a0" category="list-text">Snapshot quasi istantanei di spazi di lavoro JupyterLab ad alta capacità per backup e/o tracciabilità/baselining.</block>
  <block id="afe9b022bbe49ebc232dc11679a61bb4" category="list-text">Provisioning, clonazione e snapshot quasi istantanei di volumi di dati ad alta capacità e ad alte prestazioni.</block>
  <block id="b242f57e51b5f507797a088899c22df7" category="paragraph">Trident è un orchestratore di storage open source completamente supportato per container e distribuzioni Kubernetes, tra cui Anthos. Trident funziona con l'intero portfolio di storage NetApp , incluso NetApp ONTAP, e supporta anche connessioni NFS, NVMe/TCP e iSCSI. Trident accelera il flusso di lavoro DevOps consentendo agli utenti finali di effettuare il provisioning e gestire lo storage dai propri sistemi di storage NetApp senza richiedere l'intervento di un amministratore dello storage.</block>
  <block id="1efc1a71dad2451e243efa783d9aaba0" category="summary">NetApp AIPod con sistemi NVIDIA DGX - Guida alla convalida e al dimensionamento della soluzione</block>
  <block id="1baf67b0ad3fef1cc60370bda6ebc7f9" category="doc">NVA-1173 NetApp AIPod con sistemi NVIDIA DGX - Guida alla convalida e al dimensionamento della soluzione</block>
  <block id="d2fb9fca0fa09d949a54ae42e337c891" category="paragraph">Questa sezione si concentra sulla convalida della soluzione e sulle linee guida per il dimensionamento dei sistemi NetApp AIPod con NVIDIA DGX.</block>
  <block id="773a9689ba6682deeabffa6746d64105" category="section-title">Validazione della soluzione</block>
  <block id="364bed9cbf28e51b3a87b1cece482054" category="paragraph">La configurazione di archiviazione in questa soluzione è stata convalidata utilizzando una serie di carichi di lavoro sintetici utilizzando lo strumento open source FIO.  Questi test includono modelli di I/O di lettura e scrittura pensati per simulare il carico di lavoro di archiviazione generato dai sistemi DGX che eseguono attività di formazione di deep learning.  La configurazione di archiviazione è stata convalidata utilizzando un cluster di server CPU a 2 socket che eseguono contemporaneamente i carichi di lavoro FIO per simulare un cluster di sistemi DGX.  Ogni client è stato configurato con la stessa configurazione di rete descritta in precedenza, con l'aggiunta dei seguenti dettagli.</block>
  <block id="5c553fedff3f40a2af76bb0c410b404f" category="paragraph">Per questa convalida sono state utilizzate le seguenti opzioni di montaggio:</block>
  <block id="cb8472643b1176f8340370ce5a0b204d" category="cell">versione=4.1</block>
  <block id="893b3a13ba8b6b5a60094306461bc370" category="cell">abilita pNFS per l'accesso parallelo a più nodi di archiviazione</block>
  <block id="1df213ce94ed5cdef706c9350768f0c2" category="cell">proto=rdma</block>
  <block id="42cc89ba8e1299f3640ad771a94abfaa" category="cell">imposta il protocollo di trasferimento su RDMA invece del TCP predefinito</block>
  <block id="9b7b56ffe75ec2daff44ba8923725d27" category="cell">porta=20049</block>
  <block id="52c223170500f2f347a266328f0c4216" category="cell">specificare la porta corretta per il servizio RDMA NFS</block>
  <block id="5b75616cf8bcd004a7fb0c78bcf4cb1e" category="cell">max_connect=16</block>
  <block id="82264615e17e10dec975d19de56f7e01" category="cell">consente il trunking della sessione NFS per aggregare la larghezza di banda della porta di archiviazione</block>
  <block id="b0b79785aa490d51befbe60046fe59a6" category="cell">scrivere=impaziente</block>
  <block id="27d6ebb9c804f9228e43f1362d2ad502" category="cell">migliora le prestazioni di scrittura delle scritture bufferizzate</block>
  <block id="df2285a23b7de4affb43985a03a9b955" category="cell">rsize=262144,wsize=262144</block>
  <block id="226cf9c18b16f30e1381d76500dcd2c3" category="cell">imposta la dimensione del trasferimento I/O a 256k</block>
  <block id="1275e87e965ab2e83ee1a3d508393bb1" category="paragraph">Inoltre, i client sono stati configurati con un valore NFS max_session_slots pari a 1024.  Poiché la soluzione è stata testata utilizzando NFS su RDMA, le porte delle reti di archiviazione sono state configurate con un collegamento attivo/passivo.  Per questa convalida sono stati utilizzati i seguenti parametri di legame:</block>
  <block id="dc2f1400a2999b58888391b52366d42d" category="cell">modalità=backup attivo</block>
  <block id="ceafe9fbea6d2853c0ef101fde263114" category="cell">imposta il legame in modalità attiva/passiva</block>
  <block id="0772e25cb688aaddbfcafe9a95042ae0" category="cell">primary=&lt;nome interfaccia&gt;</block>
  <block id="126d68b093e92a0eeafa0ea632b5dee2" category="cell">le interfacce primarie per tutti i client sono state distribuite sugli switch</block>
  <block id="cbfd831ae9cd4bbc2c5955b278fc1464" category="cell">mii-monitor-intervallo=100</block>
  <block id="ef530a18c3e08c2e1454d98413c8995a" category="cell">specifica un intervallo di monitoraggio di 100 ms</block>
  <block id="4a7a0a399fdd09cc77725d4bca22c5d2" category="cell">fail-over-mac-policy=attivo</block>
  <block id="1cddea1ebc0f8a54ddb9d1b5d3701199" category="cell">specifica che l'indirizzo MAC del collegamento attivo è il MAC del legame.  Ciò è necessario per il corretto funzionamento dell'RDMA sull'interfaccia collegata.</block>
  <block id="13e766ae456cff38288a10e042da1460" category="paragraph">Il sistema di archiviazione è stato configurato come descritto con due coppie A900 HA (4 controller) con due ripiani per dischi NS224 da 24 unità disco NVMe da 1,9 TB collegate a ciascuna coppia HA.  Come indicato nella sezione dedicata all'architettura, la capacità di archiviazione di tutti i controller è stata combinata utilizzando un volume FlexGroup e i dati di tutti i client sono stati distribuiti tra tutti i controller del cluster.</block>
  <block id="4534545218c3df22ad30ec5ab0466128" category="section-title">Guida al dimensionamento del sistema di archiviazione</block>
  <block id="e58e8ec46be51c65fb6895529b19620c" category="paragraph">NetApp ha completato con successo la certificazione DGX BasePOD e le due coppie A90 HA testate possono supportare facilmente un cluster di sedici sistemi DGX H100.  Per distribuzioni più grandi con requisiti di prestazioni di storage più elevati, è possibile aggiungere sistemi AFF aggiuntivi al cluster NetApp ONTAP fino a 12 coppie HA (24 nodi) in un singolo cluster.  Utilizzando la tecnologia FlexGroup descritta in questa soluzione, un cluster da 24 nodi può fornire oltre 79 PB e fino a 552 GBps di throughput in un singolo namespace.  Altri sistemi di storage NetApp , come AFF A400, A250 e C800, offrono prestazioni inferiori e/o opzioni di capacità più elevate per implementazioni più piccole a costi inferiori.  Poiché ONTAP 9 supporta cluster a modello misto, i clienti possono iniziare con un ingombro iniziale più piccolo e aggiungere al cluster sistemi di storage più grandi o più numerosi man mano che aumentano i requisiti di capacità e prestazioni.  La tabella seguente mostra una stima approssimativa del numero di GPU A100 e H100 supportate su ciascun modello AFF .</block>
  <block id="d151e6348ab5291d10caeda2db802b75" category="paragraph">_Guida al dimensionamento del sistema di storage NetApp_</block>
  <block id="c61d72d95f504983715ce76fcfdfb864" category="paragraph"><block ref="c61d72d95f504983715ce76fcfdfb864" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28e8b3e83af233fe7085ba954fc6fd36" category="doc">BeeGFS su NetApp con storage E-Series</block>
  <block id="e8afe31a21b6aae9717484d865743dae" category="paragraph">BeeGFS su NetApp con storage E-Series è una soluzione integrata e collaudata con un'infrastruttura HPC semplice, affidabile, scalabile e conveniente, in grado di tenere il passo con i carichi di lavoro più estremi.</block>
  <block id="d18d454d6ae7128c6b49bf41c9ea2cf4" category="paragraph"><block ref="d18d454d6ae7128c6b49bf41c9ea2cf4" category="inline-link-macro-rx"></block></block>
  <block id="fcf432f7f886df6aeafb1dec9357085d" category="doc">NVA-1150-DEPLOY: Guida alla distribuzione dei sistemi Quantum StorNext con NetApp E-Series</block>
  <block id="806008ac96286a2e08058ba3a3daa601" category="paragraph">Ryan Rodine, NetApp</block>
  <block id="25dbf1b5193ae9eff63687c18c19e6f5" category="paragraph">Questo documento fornisce dettagli su come distribuire una soluzione di file system parallelo StorNext con i sistemi di storage NetApp E-Series.  Questa soluzione copre l'array all-flash NetApp EF280, l'array all-flash NVMe NetApp EF300, l'array all-flash NVMe NetApp EF600 e il sistema ibrido NetApp E5760.  Offre una caratterizzazione delle prestazioni basata sul benchmarking Frametest, uno strumento ampiamente utilizzato per i test nel settore dei media e dell'intrattenimento.</block>
  <block id="a06fe4c2db4f7b09c705e4e8dafb5627" category="paragraph"><block ref="a06fe4c2db4f7b09c705e4e8dafb5627" category="inline-link-macro-rx"></block></block>
  <block id="96f5c57f6fea73d6692c5f8c2703e9b9" category="doc">NVA-1150-DESIGN: Guida alla progettazione dei sistemi Quantum StorNext con NetApp E-Series</block>
  <block id="5ee668b979e736471a8d46609abdc49b" category="paragraph">Questo documento fornisce dettagli su come progettare una soluzione di file system parallelo StorNext con i sistemi di storage NetApp E-Series.  Questa soluzione copre l'array all-flash NetApp EF280, l'array all-flash NVMe NetApp EF300, l'array all-flash NVMe EF600 e il sistema ibrido NetApp E5760.  Offre una caratterizzazione delle prestazioni basata sul benchmarking Frametest, uno strumento ampiamente utilizzato per i test nel settore dei media e dell'intrattenimento.</block>
  <block id="4f8b12df588cb1e82eb6d578f26c6c62" category="paragraph"><block ref="4f8b12df588cb1e82eb6d578f26c6c62" category="inline-link-macro-rx"></block></block>
  <block id="bf6adc497a862180909278cf6ed029f1" category="doc">TR-4859: Distribuzione di IBM Spectrum Scale con storage NetApp E-Series - Installazione e convalida</block>
  <block id="7d8a7f37eb34080960253271b824ab2f" category="paragraph">Chris Seirer, NetApp</block>
  <block id="06bd55c4b576fd1f13eb5e25a1415bba" category="paragraph">TR-4859 descrive il processo di distribuzione di una soluzione completa di file system parallelo basata sullo stack software Spectrum Scale di IBM.  TR-4859 è progettato per fornire dettagli su come installare Spectrum Scale, convalidare l'infrastruttura e gestire la configurazione.</block>
  <block id="6a51aeb3b4e11ee4436f8ad323e23c5a" category="paragraph"><block ref="6a51aeb3b4e11ee4436f8ad323e23c5a" category="inline-link-macro-rx"></block></block>
  <block id="3026654be6be955b54735554371ee5a0" category="summary">Questa architettura verificata da NetApp descrive la progettazione di NVIDIA DGX SuperPOD con i componenti di base NetApp BeeGFS.  Questa soluzione è una piattaforma di data center full-stack convalidata su un cluster di accettazione dedicato presso NVIDIA.</block>
  <block id="85505186d8e84ecff8e7e71596423747" category="doc">NVIDIA DGX SuperPOD con NetApp - Guida alla progettazione</block>
  <block id="49ba6c0ee9149acc4bdb6fac5165b7b0" category="paragraph">Questa architettura verificata da NetApp descrive la progettazione di NVIDIA DGX SuperPOD con i componenti di base NetApp BeeGFS.  Questa soluzione è una piattaforma di data center full-stack convalidata su un cluster di accettazione dedicato presso NVIDIA.</block>
  <block id="adb0b7d6a9d5c0af32d1c6fe9a103229" category="inline-image-macro">200.200</block>
  <block id="0a8dfa4d72d5f9b29ce5ac529286b37f" category="paragraph"><block ref="0a8dfa4d72d5f9b29ce5ac529286b37f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a7225e9429ab905378b45f3aa288040" category="paragraph">Amine Bennani, Christian Whiteside, David Arnette e Sathish Thyagarajan, NetApp</block>
  <block id="7919e821dc18f3e88c0201e01bf6a240" category="section-title">Sintesi</block>
  <block id="d83b5adf97fe549e1dc83bb95e6f2cdf" category="paragraph">Nell'attuale panorama tecnologico in rapida evoluzione, l'intelligenza artificiale sta rivoluzionando le esperienze dei consumatori e stimolando l'innovazione in tutti i settori.  Tuttavia, presenta anche sfide significative per i reparti IT, che sono sotto pressione per implementare soluzioni di calcolo ad alte prestazioni (HPC) in grado di gestire le intense richieste dei carichi di lavoro dell'intelligenza artificiale.  Mentre le organizzazioni si affrettano a sfruttare la potenza dell'intelligenza artificiale, cresce l'urgenza di una soluzione che sia facile da implementare, scalare e gestire.</block>
  <block id="2e93342ec6458064edd50d209383c787" category="paragraph">NVIDIA DGX SuperPOD è una piattaforma infrastrutturale AI per data center, fornita come soluzione chiavi in mano per l'IT, per supportare i carichi di lavoro AI più complessi a cui devono far fronte le aziende odierne.  Alla base di qualsiasi modello di deep learning (DL) accurato ci sono grandi volumi di dati, che richiedono una soluzione di archiviazione ad alta capacità in grado di gestire e rigestire in modo efficiente questi dati.  La soluzione NetApp BeeGFS, composta da array di storage NetApp EF600 con file system parallelo BeeGFS, consente a NVIDIA DGX SuperPOD di sfruttare appieno le sue potenzialità.  La soluzione NetApp BeeGFS è stata convalidata da NVIDIA per integrarsi e scalare con l'architettura SuperPOD.  Il risultato è una distribuzione e una gestione semplificate dei data center basati sull'intelligenza artificiale, offrendo al contempo una scalabilità praticamente illimitata in termini di prestazioni e capacità.</block>
  <block id="77e585eeb67a682a6445c0154fd9a028" category="paragraph">La soluzione NetApp BeeGFS, basata sui sistemi di storage NetApp EF600 NVMe ad alte prestazioni e sul file system parallelo scalabile BeeGFS, offre una base di storage solida ed efficiente per carichi di lavoro di intelligenza artificiale impegnativi.  La sua architettura a disco condiviso garantisce un'elevata disponibilità, mantenendo prestazioni e accessibilità costanti, anche di fronte a sfide di sistema.  Questa soluzione fornisce un'architettura scalabile e flessibile che può essere personalizzata per soddisfare diverse esigenze di archiviazione.  I clienti possono espandere facilmente le prestazioni e la capacità di archiviazione integrando ulteriori blocchi di archiviazione per gestire anche i carichi di lavoro più impegnativi.</block>
  <block id="1ad3f73d04f7a3d0b225d62bf707c034" category="list-text">NVIDIA DGX SuperPOD sfrutta i sistemi DGX H100 e H200 con un archivio condiviso validato collegato esternamente:</block>
  <block id="8dc89fa0c821b38b2ab07d3f5dd4385f" category="list-text">Ogni unità scalabile (SU) DGX SuperPOD è composta da 32 sistemi DGX ed è in grado di raggiungere prestazioni di intelligenza artificiale pari a 640 petaFLOPS con precisione FP8.  NetApp consiglia di dimensionare la soluzione di storage NetApp BeeGFS con almeno 2 blocchi di base per una singola configurazione DGX SuperPOD.</block>
  <block id="0aa799745475dedefbc0785863494b75" category="paragraph">_Una visione d'insieme della soluzione_</block>
  <block id="0e06b8493198d6e7d8d53d9201ddd9bc" category="inline-image-macro">Figura che mostra una panoramica di alto livello della soluzione NetApp BeeGFS con un NVIDIA DGX SuperPOD.</block>
  <block id="6bfc1196652f29c394bdbe8e2807a4a0" category="paragraph"><block ref="6bfc1196652f29c394bdbe8e2807a4a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="949e06b94ff43763386683593267b5d3" category="list-text">I blocchi di costruzione NetApp BeeGFS sono costituiti da due array NetApp EF600 e due server x86:</block>
  <block id="53a59094fc8cf61c8ceb5488c68798f9" category="list-text">Grazie agli array all-flash NetApp EF600 alla base di NVIDIA DGX SuperPOD, i clienti ottengono una base di storage affidabile supportata da un uptime di sei 9.</block>
  <block id="23830778b135794055062035d895d122" category="list-text">Il livello del file system tra i sistemi NetApp EF600 e NVIDIA DGX è il file system parallelo BeeGFS.  BeeGFS è stato creato dal Fraunhofer Center for High-Performance Computing in Germania per risolvere i problemi dei file system paralleli legacy.  Il risultato è un file system con un'architettura moderna e user space, ora sviluppato e distribuito da ThinkParQ e utilizzato da molti ambienti di supercalcolo.</block>
  <block id="d6dbc9a4d449d8584f1bc7766a233055" category="list-text">Il supporto NetApp per BeeGFS allinea l'eccellente organizzazione di supporto di NetApp alle esigenze dei clienti in termini di prestazioni e tempi di attività.  I clienti hanno accesso a risorse di supporto di livello superiore, accesso anticipato alle versioni di BeeGFS e accesso a funzionalità aziendali selezionate di BeeGFS, come l'applicazione delle quote e l'alta disponibilità (HA).</block>
  <block id="06723075d010c851032e77543613704f" category="list-text">La combinazione di NVIDIA SuperPOD SU e dei componenti di base NetApp BeeGFS fornisce una soluzione di intelligenza artificiale agile in cui l'elaborazione o l'archiviazione sono scalabili in modo semplice e fluido.</block>
  <block id="e0d00c6a1325f01dc14822163a1d43fe" category="paragraph">_Blocco di costruzione NetApp BeeGFS_</block>
  <block id="f2ccf42799ed738590ee8a95c9a2e5c9" category="inline-image-macro">Figura che mostra un singolo blocco di costruzione NetApp BeeGFS.</block>
  <block id="9390da63574f67fe268b45392cf0ec3e" category="paragraph"><block ref="9390da63574f67fe268b45392cf0ec3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df07b47923825d5392c14e80cea2d72a" category="section-title">Riepilogo del caso d'uso</block>
  <block id="976894dcc596e37094668684315ccac4" category="paragraph">Questa soluzione si applica ai seguenti casi d'uso:</block>
  <block id="30e31e5dc6388c3434cea1711261b743" category="list-text">Intelligenza artificiale (IA), tra cui apprendimento automatico (ML), apprendimento profondo (DL), elaborazione del linguaggio naturale (NLP), comprensione del linguaggio naturale (NLU) e IA generativa (GenAI).</block>
  <block id="c21f50752fbbe8f54e46848c0f9ce70a" category="list-text">Formazione AI su media e larga scala</block>
  <block id="137c3bef49af695737b7c23000204b5c" category="list-text">Modelli di visione artificiale, parlato, audio e linguaggio</block>
  <block id="15ed9179636b107f0a88e83f782e6cec" category="list-text">HPC, comprese le applicazioni accelerate dall'interfaccia di passaggio dei messaggi (MPI) e altre tecniche di elaborazione distribuita</block>
  <block id="90b7289b464ec4d544bf5a9eacbaf7f0" category="list-text">Carichi di lavoro applicativi caratterizzati da quanto segue:</block>
  <block id="c9ccfce7935790c9fd0d9ccf98da5177" category="list-text">Lettura o scrittura di file più grandi di 1 GB</block>
  <block id="680e47afa4860ce2ac4a078a0d466121" category="list-text">Lettura o scrittura sullo stesso file da parte di più client (decine, centinaia e migliaia)</block>
  <block id="af7aa0607b7f1d728a529edd21a52763" category="list-text">Set di dati multiterabyte o multipetabyte</block>
  <block id="efc155766b6000aefdf459d6ff3ecd75" category="list-text">Ambienti che necessitano di un singolo namespace di archiviazione ottimizzabile per un mix di file di grandi e piccole dimensioni</block>
  <block id="dcbd8f687e2ef904380c2b6c942c989e" category="paragraph">Questa sezione illustra i requisiti tecnologici per la soluzione NVIDIA DGX SuperPOD con NetApp .</block>
  <block id="b95d6ba22cd7d0fb6a3c655d4c24d180" category="inline-link">Architettura di riferimento NVIDIA DGX H100 SuperPOD</block>
  <block id="02399dc2f4ffe6e6772456736a8522d7" category="inline-link">NVA-1164-DESIGN: BeeGFS su NetApp NVA Design</block>
  <block id="5425be0e2232456057166446265f9a88" category="paragraph">Nella tabella 1 sottostante sono elencati i componenti hardware necessari per implementare la soluzione per una singola SU.  Il dimensionamento della soluzione inizia con 32 sistemi NVIDIA DGX H100 e due o tre blocchi di costruzione NetApp BeeGFS.  Un singolo blocco di costruzione NetApp BeeGFS è costituito da due array NetApp EF600 e due server x86.  I clienti possono aggiungere ulteriori componenti man mano che aumentano le dimensioni dell'implementazione.  Per maggiori informazioni, vedere il<block ref="55ded0354bf42e7e117b50dda2359a8a" category="inline-link-rx"></block> E<block ref="de7b61948f391c0bb69985cc0357d2a5" category="inline-link-rx"></block> .</block>
  <block id="5aa595c84818428979f9fa2d99bb6f83" category="cell">NVIDIA DGX H100 o H200</block>
  <block id="6364d3f0f495b6ab9dcf8d3b5c6e0b01" category="cell">32</block>
  <block id="eef6c1a81c81a43f02e2b7749d260ef5" category="cell">Switch NVIDIA Quantum QM9700</block>
  <block id="34a2c495ed1b62db3e0fffd75420aca5" category="cell">8 fogli, 4 spine</block>
  <block id="be3accc5713b4d53186215779c2deeed" category="cell">Blocchi di costruzione NetApp BeeGFS</block>
  <block id="0dbcb15fd014d19061fb2910f0a1ab0e" category="paragraph">Nella tabella 2 sottostante sono elencati i componenti software necessari per implementare la soluzione.  I componenti software utilizzati in una particolare implementazione della soluzione potrebbero variare in base alle esigenze del cliente.</block>
  <block id="b9e807b01f3ef86c9dfed350c8c3d49f" category="cell">Stack software NVIDIA DGX</block>
  <block id="32ac4a04c126e4e450b2f93ae6cfd3a7" category="cell">Sistema di file parallelo ThinkParQ BeeGFS</block>
  <block id="dc140913e754c7554bc598a02951fa66" category="section-title">Verifica della soluzione</block>
  <block id="f95f7879d178879af0b5a728259ce9a3" category="inline-link">NVIDIA DGX SuperPOD: architettura di riferimento NetApp EF600 e BeeGFS</block>
  <block id="24e45924f52e38078756fd5fb1d83668" category="paragraph">NVIDIA DGX SuperPOD con NetApp è stato convalidato su un cluster di accettazione dedicato presso NVIDIA utilizzando i blocchi di costruzione NetApp BeeGFS.  I criteri di accettazione si basavano su una serie di test applicativi, prestazionali e di stress eseguiti da NVIDIA. Per maggiori informazioni, vedere il<block ref="2ffc6657f5234f1aed913433d4ce09f3" category="inline-link-rx"></block> .</block>
  <block id="b7f81445ff8908f0aa2a3356e8231f05" category="paragraph">NetApp e NVIDIA collaborano da lungo tempo per offrire al mercato un portafoglio di soluzioni di intelligenza artificiale.  NVIDIA DGX SuperPOD con l'array all-flash NetApp EF600 è una soluzione collaudata e convalidata che i clienti possono implementare con sicurezza.  Questa architettura completamente integrata e chiavi in mano elimina i rischi derivanti dall'implementazione e consente a chiunque di vincere la corsa alla leadership dell'intelligenza artificiale.</block>
  <block id="dcd86a18e8aa77675f1b2f792cb6ba5c" category="inline-link-macro">Architettura di riferimento NVIDIA DGX SuperPOD</block>
  <block id="98d56828382118fe5dcd8ef673b93afb" category="list-text"><block ref="98d56828382118fe5dcd8ef673b93afb" category="inline-link-macro-rx"></block></block>
  <block id="4fafe9ef5c2efce123913e9ac744f4d6" category="inline-link-macro">Guida di riferimento alla progettazione del data center NVIDIA DGX SuperPOD</block>
  <block id="473bfb82bbec433a8f08fa15c67e0c08" category="list-text"><block ref="473bfb82bbec433a8f08fa15c67e0c08" category="inline-link-macro-rx"></block></block>
  <block id="6f698ddb1773933b8e41b2ed16297ce7" category="inline-link-macro">NVIDIA DGX SuperPOD: NetApp EF600 e BeeGFS</block>
  <block id="a552f45479fc3484a4356ed78090fa76" category="list-text"><block ref="7f25f2868948e2fffc54c32cf9c33644" category="inline-link-macro-rx"></block></block>
  <block id="58415f353579ec62f4e5d8047761a3cc" category="summary">L'automazione basata sull'intelligenza artificiale e l'edge computing rappresentano un approccio leader per aiutare le aziende a realizzare la trasformazione digitale e massimizzare l'efficienza operativa e la sicurezza.  Grazie all'edge computing, i dati vengono elaborati molto più velocemente perché non devono viaggiare da e verso un data center.  Di conseguenza, i costi associati all'invio e alla ricezione dei dati ai data center o al cloud risultano ridotti.</block>
  <block id="7d7c5045abef00692470c8d5ed1aeebd" category="paragraph">L'automazione basata sull'intelligenza artificiale e l'edge computing rappresentano un approccio leader per aiutare le aziende a realizzare la trasformazione digitale e massimizzare l'efficienza operativa e la sicurezza.  Grazie all'edge computing, i dati vengono elaborati molto più velocemente perché non devono viaggiare da e verso un data center.  Di conseguenza, i costi associati all'invio e alla ricezione dei dati ai data center o al cloud risultano ridotti.  Una latenza inferiore e una maggiore velocità possono rivelarsi vantaggiose quando le aziende devono prendere decisioni quasi in tempo reale utilizzando modelli di inferenza AI implementati all'edge.</block>
  <block id="691e8c5d8b13259848ef2e5515d14ca9" category="paragraph">I sistemi di storage NetApp garantiscono prestazioni uguali o migliori rispetto allo storage SSD locale e offrono i seguenti vantaggi a data scientist, data engineer, sviluppatori di intelligenza artificiale/apprendimento automatico e responsabili delle decisioni aziendali o IT:</block>
  <block id="59ceee4c2b9743d6e9aae43f1e9ee547" category="list-text">Condivisione semplice dei dati tra sistemi di intelligenza artificiale, analisi e altri sistemi aziendali critici.  Questa condivisione dei dati riduce il sovraccarico dell'infrastruttura, migliora le prestazioni e semplifica la gestione dei dati in tutta l'azienda.</block>
  <block id="b9f30f0e1030c74a0db7ca1a1e82a22f" category="list-text">Elaborazione e archiviazione scalabili in modo indipendente per ridurre al minimo i costi e migliorare l'utilizzo delle risorse.</block>
  <block id="40454c2a63608aacf0433b6a47f388f4" category="list-text">Flussi di lavoro di sviluppo e distribuzione semplificati mediante copie Snapshot e cloni integrati per spazi di lavoro utente istantanei e salvaspazio, controllo delle versioni integrato e distribuzione automatizzata.</block>
  <block id="0543f71645ff9108a860d92965cc1383" category="list-text">Protezione dei dati di livello aziendale per il disaster recovery e la continuità aziendale.  La soluzione NetApp e Lenovo presentata in questo documento è un'architettura flessibile e scalabile, ideale per implementazioni di inferenza AI di livello aziendale in ambito edge.</block>
  <block id="84ffd62e595c9d0122e136c3b255f4df" category="section-title">Ringraziamenti</block>
  <block id="68c8080de8c25b2c95e86546db2c34f4" category="list-text">JJ  Falkanger, Direttore senior, Soluzioni HPC e IA, Lenovo</block>
  <block id="a1be3af64bad65325413de79cbdd38ec" category="list-text">Dave Arnette, ingegnere tecnico di marketing, NetApp</block>
  <block id="ab7eb4cf2e6900db95523411e2e2d968" category="list-text">Joey Parnell, responsabile tecnico delle soluzioni di intelligenza artificiale della serie E, NetApp</block>
  <block id="7506341ffff969b3db4120a09a3cd873" category="list-text">Cody Harryman, ingegnere QA, NetApp</block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">Per saperne di più sulle informazioni descritte nel presente documento, fare riferimento ai seguenti documenti e/o siti web:</block>
  <block id="16d9e623379df2a050a5042b643bf4fc" category="list-text">Pagina del prodotto degli array NetApp AFF A-Series</block>
  <block id="2eea2276b1fb61cd770f311f77c0f440" category="inline-link"><block ref="2eea2276b1fb61cd770f311f77c0f440" category="inline-link-rx"></block></block>
  <block id="3ac5561d8de2087fdd9ac49ace880bff" category="paragraph"><block ref="3ac5561d8de2087fdd9ac49ace880bff" category="inline-link-rx"></block></block>
  <block id="ac2e4973250b614c4ffed16837be9bda" category="list-text">Software di gestione dati NetApp ONTAP: libreria di informazioni ONTAP 9</block>
  <block id="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link"><block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="paragraph"><block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="5dbac8b4dac620b04fd11b54388ac506" category="list-text">TR-4727: Introduzione alla serie EF NetApp</block>
  <block id="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link"><block ref="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link-rx"></block></block>
  <block id="5e60359f54f57375f6417990b408bc8d" category="paragraph"><block ref="5e60359f54f57375f6417990b408bc8d" category="inline-link-rx"></block></block>
  <block id="bf8eb67f3476640d74487d7395b166a8" category="list-text">Scheda tecnica del software NetApp E-Series SANtricity</block>
  <block id="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link"><block ref="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link-rx"></block></block>
  <block id="62cabab367af4d0d4f74456d673e91e7" category="paragraph"><block ref="62cabab367af4d0d4f74456d673e91e7" category="inline-link-rx"></block></block>
  <block id="f11b61c13d771c4795415471f8362f8c" category="list-text">NetApp Persistent Storage per container: NetApp Trident</block>
  <block id="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link"><block ref="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link-rx"></block></block>
  <block id="e582bd0f584c041fb70164ea1502666b" category="paragraph"><block ref="e582bd0f584c041fb70164ea1502666b" category="inline-link-rx"></block></block>
  <block id="6bd5e585bc974f029ff9c7cc8a2b68dd" category="list-text">MLPerf</block>
  <block id="856500f909a4984692886f9549398b67" category="inline-link"><block ref="856500f909a4984692886f9549398b67" category="inline-link-rx"></block></block>
  <block id="fe6e33e3be237f2a488d04432ad4b35f" category="list-text"><block ref="fe6e33e3be237f2a488d04432ad4b35f" category="inline-link-rx"></block></block>
  <block id="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link"><block ref="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link-rx"></block></block>
  <block id="3de4b3f21621e41c0738a82d4e694114" category="list-text"><block ref="3de4b3f21621e41c0738a82d4e694114" category="inline-link-rx"></block></block>
  <block id="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link"><block ref="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link-rx"></block></block>
  <block id="25b3dca46bdabc4612ba4ba5dac0f9db" category="list-text"><block ref="25b3dca46bdabc4612ba4ba5dac0f9db" category="inline-link-rx"></block></block>
  <block id="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link"><block ref="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link-rx"></block></block>
  <block id="fdad8301fde8271edff994d643d18865" category="paragraph"><block ref="fdad8301fde8271edff994d643d18865" category="inline-link-rx"></block></block>
  <block id="7749687216549469e9a78db087fbb44b" category="list-text">Benchmark di TensorFlow</block>
  <block id="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link"><block ref="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link-rx"></block></block>
  <block id="be1b7087c9993d320070b1e676c832f9" category="paragraph"><block ref="be1b7087c9993d320070b1e676c832f9" category="inline-link-rx"></block></block>
  <block id="13f9a963bd60406520ccdc128d44b54a" category="list-text">Server edge Lenovo ThinkSystem SE350</block>
  <block id="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link"><block ref="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link-rx"></block></block>
  <block id="b1a88588a48ee9492506277f8561b392" category="paragraph"><block ref="b1a88588a48ee9492506277f8561b392" category="inline-link-rx"></block></block>
  <block id="f9732caa47051768fc11729f5535891b" category="list-text">Array di archiviazione flash unificato Lenovo ThinkSystem DM5100F</block>
  <block id="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link"><block ref="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link-rx"></block></block>
  <block id="a4113bc79b3920d11274d7bf9cfafe10" category="paragraph"><block ref="a4113bc79b3920d11274d7bf9cfafe10" category="inline-link-rx"></block></block>
  <block id="207e9f2f3c6b5a3e8c9228ceadc806b2" category="summary">Questa sezione descrive le configurazioni testate, l'infrastruttura di rete, il server SE350 e i dettagli del provisioning dello storage.</block>
  <block id="32d798df7254f6703ed2262024e0e174" category="doc">Configurazione di prova</block>
  <block id="a55faacbe457d923ebd296421a71b898" category="paragraph">La figura seguente mostra la configurazione del test.  Abbiamo utilizzato il sistema di storage NetApp AFF C190 e due server Lenovo ThinkSystem SE350 (ciascuno con un acceleratore NVIDIA T4).  Questi componenti sono collegati tramite uno switch di rete 10GbE.  L'archiviazione di rete contiene set di dati di convalida/test e modelli preaddestrati.  I server forniscono capacità di calcolo e l'accesso all'archiviazione avviene tramite protocollo NFS.</block>
  <block id="d8c97013f1e301478b23530ad6ed1ef6" category="paragraph">Questa sezione descrive le configurazioni testate, l'infrastruttura di rete, il server SE350 e i dettagli del provisioning dello storage.  Nella tabella seguente sono elencati i componenti di base per l'architettura della soluzione.</block>
  <block id="d552f08a6baeb9bee58f2ca6ff5090d2" category="cell">Server Lenovo ThinkSystem</block>
  <block id="fe8ab8cb391be4f8cf88a9b64c3ce3cd" category="list-text">2 server SE350, ciascuno con una scheda GPU NVIDIA T4</block>
  <block id="acd4671bd4d78c7fc0ac8cbc66a01483" category="list-text">Ogni server contiene una CPU Intel Xeon D-2123IT con quattro core fisici che funzionano a 2,20 GHz e 128 GB di RAM</block>
  <block id="d7d02fd9ab069a2d95dee248370100f9" category="cell">Sistema di storage NetApp AFF entry-level (coppia HA)</block>
  <block id="1d680806b37a387e8d84b0c21be4d816" category="list-text">Software NetApp ONTAP 9</block>
  <block id="0c1dcc458c4dd96728e0b0998cba7305" category="list-text">24 SSD da 960 GB</block>
  <block id="a2a817ee9a8e05389f7b11bd8ce4bbdb" category="list-text">protocollo NFS</block>
  <block id="d8e87bd5878266cd4137e82d919799eb" category="list-text">Un gruppo di interfacce per controller, con quattro indirizzi IP logici per i punti di montaggio</block>
  <block id="e2921b0ff5efef521f662303c467e27f" category="paragraph"><block ref="e2921b0ff5efef521f662303c467e27f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208eac927f1261c6e6eaa3135a529cf3" category="paragraph">Nella tabella seguente è elencata la configurazione di archiviazione: AFF C190 con 2RU, 24 slot per unità.</block>
  <block id="9bbf373797bf7cf7ba62c80023682e25" category="cell">Controllore</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">Aggregato</block>
  <block id="e9db3004828d9514fafc57881dfbdbd2" category="cell">Volume FlexGroup</block>
  <block id="2e0fb97d51b96b1635dcc3ca51f74fee" category="cell">Dimensione aggregata</block>
  <block id="b94c9ec583603e13b5c32d83199c7376" category="cell">Dimensione del volume</block>
  <block id="53a35f8b51acc9748a3e172a76f542a7" category="cell">Punto di montaggio del sistema operativo</block>
  <block id="6a1ab89ed912a96429c83ff1ba0f48d0" category="cell">Controller1</block>
  <block id="4d80d82716f0b771738e7fad121e059a" category="cell">Aggr1</block>
  <block id="e39298390e27007517a0cb199728188a" category="cell">/netapplenovo_AI_fg</block>
  <block id="4923ec171d721fba1d4547deefc98e8c" category="cell">8.42TiB</block>
  <block id="f13cb116755b4e8fa1af1b201025f377" category="cell">15 TB</block>
  <block id="3fe74875837b518b23813988af1e39d9" category="cell">/netapp_lenovo_fg</block>
  <block id="3877384a92be771d61972d07648b799f" category="cell">Controller2</block>
  <block id="f3913037ef38679d334aa0cf30e2b6fd" category="cell">Aggr2</block>
  <block id="6b02e3a677be18a8be3641bb43e8b220" category="paragraph">La cartella /netappLenovo_AI_fg contiene i set di dati utilizzati per la convalida del modello.</block>
  <block id="e4239f67d8e47773c69a7cb4be34d949" category="paragraph">La figura seguente mostra la configurazione del test.  Abbiamo utilizzato il sistema di storage NetApp EF280 e due server Lenovo ThinkSystem SE350 (ciascuno con un acceleratore NVIDIA T4).  Questi componenti sono collegati tramite uno switch di rete 10GbE.  L'archiviazione di rete contiene set di dati di convalida/test e modelli preaddestrati.  I server forniscono capacità di calcolo e l'accesso all'archiviazione avviene tramite protocollo NFS.</block>
  <block id="efb90877bc42cc445eb6e1b59c0e1b16" category="paragraph">Nella tabella seguente è elencata la configurazione di archiviazione per EF280.</block>
  <block id="0951a6690e5dc87411346792c9f941c7" category="cell">Gruppo di volumi</block>
  <block id="bd7a9717d29c5ddcab1bc175eda1e298" category="cell">Volume</block>
  <block id="6c88d21af6046f64871457b825dcf1c8" category="cell">Dimensione DDP</block>
  <block id="59b02558285aa326c0e9018324ed0c4f" category="cell">Metodo di connessione</block>
  <block id="db320b0194c895c7ac56fedae7928e63" category="cell">DDP1</block>
  <block id="fc452c26db3c4aa6f6213b9c5d9e3abc" category="cell">Volume 1</block>
  <block id="fe066d0b9d36398d5f525d6ac7f8e8c5" category="cell">16 TB</block>
  <block id="e0d2b052ec3dbd102ff7a7f2b356ea41" category="cell">SE350-1 a iSCSI LUN 0</block>
  <block id="ef0e038a9f9b0db74b504d5521e7a0fc" category="cell">Volume 2</block>
  <block id="5b846730a13fc5ea0a76a6b7b9a69d5a" category="cell">SE350-2 a iSCSI LUN 1</block>
  <block id="7192b14affaba8b38680e0cd3749622e" category="paragraph"><block ref="7192b14affaba8b38680e0cd3749622e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00760d3595ff19f6db2da5213b1fdd58" category="summary">Questo documento descrive un'architettura di elaborazione e storage per implementare l'inferenza dell'intelligenza artificiale (IA) basata su GPU sui controller di storage NetApp e sui server Lenovo ThinkSystem in un ambiente edge che soddisfa gli scenari applicativi emergenti.</block>
  <block id="09f4ae28e2596e14a7568f3e12a77834" category="doc">TR-4886: Inferenza AI all'Edge - NetApp con Lenovo ThinkSystem - Progettazione della soluzione</block>
  <block id="6671938f046112e34e990cb75cc642dd" category="paragraph">Sathish Thyagarajan, NetApp Miroslav Hodak, Lenovo</block>
  <block id="290612199861c31d1036b185b4e69b75" category="section-title">Riepilogo</block>
  <block id="ee0e2e290e4e02a3860382ef2cc42ca0" category="paragraph">Diversi scenari applicativi emergenti, come i sistemi avanzati di assistenza alla guida (ADAS), l'Industria 4.0, le città intelligenti e l'Internet delle cose (IoT), richiedono l'elaborazione di flussi di dati continui con una latenza prossima allo zero.  Questo documento descrive un'architettura di elaborazione e storage per implementare l'inferenza dell'intelligenza artificiale (AI) basata su GPU sui controller di storage NetApp e sui server Lenovo ThinkSystem in un ambiente edge che soddisfa questi requisiti.  Questo documento fornisce anche dati sulle prestazioni per il benchmark standard del settore MLPerf Inference, valutando varie attività di inferenza su server edge dotati di GPU NVIDIA T4.  Esaminiamo le prestazioni di scenari di inferenza offline, a flusso singolo e multi-flusso e dimostriamo che l'architettura con un sistema di archiviazione di rete condiviso ed economico è altamente performante e fornisce un punto centrale per la gestione di dati e modelli per più server edge.</block>
  <block id="a27de0758c1fc778a0fb19ebcb6a8aff" category="paragraph">Le aziende generano volumi sempre più ingenti di dati ai margini della rete.  Per ottenere il massimo valore dai sensori intelligenti e dai dati IoT, le organizzazioni sono alla ricerca di una soluzione di streaming di eventi in tempo reale che consenta l'edge computing.  Per questo motivo, i lavori più impegnativi dal punto di vista computazionale vengono sempre più svolti ai margini, al di fuori dei data center.  L'inferenza dell'intelligenza artificiale è uno dei motori di questa tendenza.  I server edge forniscono una potenza di calcolo sufficiente per questi carichi di lavoro, soprattutto quando si utilizzano acceleratori, ma lo spazio di archiviazione limitato rappresenta spesso un problema, soprattutto negli ambienti multiserver.  In questo documento mostriamo come implementare un sistema di storage condiviso nell'ambiente edge e come ciò possa apportare vantaggi ai carichi di lavoro di inferenza dell'IA senza imporre una penalizzazione delle prestazioni.</block>
  <block id="c22ef83c0446b759f6cd8835206adaae" category="paragraph">Questo documento descrive un'architettura di riferimento per l'inferenza dell'IA all'edge.  Combina più server edge Lenovo ThinkSystem con un sistema di storage NetApp per creare una soluzione facile da implementare e gestire.  È concepito come una guida di base per implementazioni pratiche in varie situazioni, come ad esempio in fabbriche con più telecamere e sensori industriali, sistemi POS (Point-of-Sale) nelle transazioni al dettaglio o sistemi Full Self-Driving (FSD) che identificano anomalie visive nei veicoli autonomi.</block>
  <block id="36d77288dbd3663ec436c43b32682300" category="paragraph">Questo documento riguarda i test e la convalida di una configurazione di elaborazione e storage composta da Lenovo ThinkSystem SE350 Edge Server e un sistema di storage NetApp AFF ed EF-Series entry-level.  Le architetture di riferimento forniscono una soluzione efficiente e conveniente per le distribuzioni di intelligenza artificiale, offrendo al contempo servizi dati completi, protezione dati integrata, scalabilità senza interruzioni e archiviazione dati connessa al cloud con il software di gestione dati NetApp ONTAP e NetApp SANtricity .</block>
  <block id="5dd536dd8122d7ba5df3ce642e603305" category="paragraph">Il presente documento è destinato ai seguenti destinatari:</block>
  <block id="ebb25f3a3991f2ad744d7ec643c950fe" category="list-text">Leader aziendali e architetti aziendali che desiderano rendere produttiva l'intelligenza artificiale ai margini della rete.</block>
  <block id="c19c4b63370004c67b540d52ae4d0ba3" category="list-text">Data scientist, data engineer, ricercatori di intelligenza artificiale/apprendimento automatico (ML) e sviluppatori di sistemi di intelligenza artificiale.</block>
  <block id="d64b2d5963d22d2d9c15222cbbe4a41c" category="list-text">Architetti aziendali che progettano soluzioni per lo sviluppo di modelli e applicazioni AI/ML.</block>
  <block id="563f47ae807a7a985313a5186e239a5d" category="list-text">Data scientist e ingegneri dell'intelligenza artificiale cercano modi efficienti per implementare modelli di deep learning (DL) e ML.</block>
  <block id="c1df171c3c219ea01c2724d28fa03f93" category="list-text">I gestori dei dispositivi edge e gli amministratori dei server edge sono responsabili dell'implementazione e della gestione dei modelli di inferenza edge.</block>
  <block id="a40893fa754ed62d5268702b023fea91" category="section-title">Architettura della soluzione</block>
  <block id="cc402abc10a0191493024c4510783afc" category="paragraph">Questa soluzione di server Lenovo ThinkSystem e storage NetApp ONTAP o NetApp SANtricity è progettata per gestire l'inferenza AI su grandi set di dati utilizzando la potenza di elaborazione delle GPU insieme alle CPU tradizionali.  Questa convalida dimostra elevate prestazioni e una gestione ottimale dei dati con un'architettura che utilizza uno o più server edge Lenovo SR350 interconnessi con un singolo sistema di storage NetApp AFF , come mostrato nelle due figure seguenti.</block>
  <block id="f21cce3e60a01cff1e8e221c6536fe78" category="paragraph"><block ref="f21cce3e60a01cff1e8e221c6536fe78" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94aa1b43a547a9dd2c4d023dbc98322b" category="paragraph"><block ref="94aa1b43a547a9dd2c4d023dbc98322b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa68c0f0557e1b1d9b151c9be9aae26a" category="paragraph">La panoramica dell'architettura logica nella figura seguente mostra i ruoli degli elementi di elaborazione e di archiviazione in questa architettura.  Nello specifico, mostra quanto segue:</block>
  <block id="f2e5640bc98f623bd0a257e3088ead2c" category="list-text">Dispositivi di edge computing che eseguono inferenze sui dati ricevuti da telecamere, sensori e così via.</block>
  <block id="ba8dee772ce5a627767af000b8bbb826" category="list-text">Un elemento di archiviazione condiviso che svolge molteplici funzioni:</block>
  <block id="8a1d15a179258733a83884fac2d16e38" category="list-text">Fornisce una posizione centrale per i modelli di inferenza e altri dati necessari per eseguire l'inferenza.  I server di elaborazione accedono direttamente allo storage e utilizzano modelli di inferenza in tutta la rete senza doverli copiare localmente.</block>
  <block id="6c20432374a9a40cfb818250edf55367" category="list-text">Qui vengono pubblicati i modelli aggiornati.</block>
  <block id="4a32229da6d6fceda48d909ad92a952a" category="list-text">Archivia i dati di input che i server periferici ricevono per un'analisi successiva.  Ad esempio, se i dispositivi edge sono collegati alle telecamere, l'elemento di archiviazione conserva i video acquisiti dalle telecamere.</block>
  <block id="3c5974fb92ca4b40257a58c213d0f137" category="paragraph"><block ref="3c5974fb92ca4b40257a58c213d0f137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bda9643ac6601722a28f238714274da4" category="cell">rosso</block>
  <block id="48d6215903dff56238e52e8891380c8f" category="cell">blu</block>
  <block id="95e6ac9e87f07caf580a7b83adb1526b" category="cell">Sistema di elaborazione Lenovo</block>
  <block id="81a15d59c420e43b55830213cc8c16b9" category="cell">Sistema di archiviazione NetApp AFF</block>
  <block id="f46e4977aa2e9918471e011cafc5cbe1" category="cell">Dispositivi edge che eseguono inferenze su input provenienti da telecamere, sensori e così via.</block>
  <block id="edb1af4b83edf30ec5e56e3f4a6352f3" category="cell">Archiviazione condivisa che contiene modelli di inferenza e dati provenienti da dispositivi edge per analisi successive.</block>
  <block id="6fa1f5494d341a20c6c746a33cbb31b3" category="paragraph">Questa soluzione NetApp e Lenovo offre i seguenti vantaggi chiave:</block>
  <block id="f1bd3fc2711f634964362fb2a96445bf" category="list-text">Elaborazione accelerata tramite GPU all'edge.</block>
  <block id="a644cc245485a603217667e7cbdb7ef9" category="list-text">Distribuzione di più server edge supportati e gestiti da uno storage condiviso.</block>
  <block id="d649f2b00c65fe4953b1a7e7469c9431" category="list-text">Protezione dati affidabile per soddisfare obiettivi di punto di ripristino (RPO) e obiettivi di tempo di ripristino (RTO) bassi senza perdita di dati.</block>
  <block id="2d0fcf5abf2f152f10ecfbf80a62e9db" category="list-text">Gestione ottimizzata dei dati con copie e cloni NetApp Snapshot per semplificare i flussi di lavoro di sviluppo.</block>
  <block id="94d9a1cd726b8a3fed2b6beb07904959" category="section-title">Come utilizzare questa architettura</block>
  <block id="9a22eb3c4ef782aa04a39e5ad3ffc8b5" category="paragraph">Questo documento convalida la progettazione e le prestazioni dell'architettura proposta.  Tuttavia, non abbiamo testato determinati componenti a livello di software, come la gestione di container, carichi di lavoro o modelli e la sincronizzazione dei dati con il cloud o il data center in locale, perché sono specifici di uno scenario di distribuzione.  Qui le scelte sono molteplici.</block>
  <block id="543ca2d3d9aa63e1a63c69dd219d5f2a" category="inline-link-macro">Piano di controllo AI NetApp</block>
  <block id="bfbeeaf5d09672568692829ade4ca556" category="paragraph">A livello di gestione dei container, la gestione dei container Kubernetes è una buona scelta ed è ben supportata sia in una versione completamente upstream (Canonical) sia in una versione modificata adatta alle distribuzioni aziendali (Red Hat).  IL<block ref="cba35aa1f9d4aeed351c50bd57559a4d" category="inline-link-macro-rx"></block> che utilizza NetApp Trident e il nuovo aggiunto<block ref="18f9f1b3975974bec435249b1752c2d6" category="inline-link-rx"></block> fornisce tracciabilità integrata, funzioni di gestione dei dati, interfacce e strumenti che consentono a data scientist e data engineer di integrarsi con lo storage NetApp .  Kubeflow, il toolkit ML per Kubernetes, fornisce funzionalità di intelligenza artificiale aggiuntive insieme al supporto per il controllo delle versioni dei modelli e KFServing su diverse piattaforme come TensorFlow Serving o NVIDIA Triton Inference Server.  Un'altra opzione è la piattaforma NVIDIA EGX, che fornisce la gestione del carico di lavoro insieme all'accesso a un catalogo di contenitori di inferenza AI abilitati per GPU.  Tuttavia, queste opzioni potrebbero richiedere notevoli sforzi e competenze per essere messe in produzione e potrebbero richiedere l'assistenza di un fornitore di software indipendente (ISV) o di un consulente di terze parti.</block>
  <block id="1a667cf8dc2ace931f29baf9aeed69d9" category="section-title">Aree di soluzione</block>
  <block id="560d585bccd63f1ccf34b07b325adbcd" category="paragraph">Il vantaggio principale dell'inferenza AI e dell'edge computing è la capacità dei dispositivi di calcolare, elaborare e analizzare i dati con un elevato livello di qualità e senza latenza.  Gli esempi di casi d'uso dell'edge computing sono davvero troppi per essere descritti in questo documento, ma eccone alcuni tra i più importanti:</block>
  <block id="8106f228c3a2b774c2e47d0d2ca766eb" category="section-title">Automobili: veicoli autonomi</block>
  <block id="49f3cb6fe79fc77d0b151dcc2f7d7109" category="paragraph">L'esempio classico dell'edge computing è rappresentato dai sistemi avanzati di assistenza alla guida (ADAS) nei veicoli autonomi (AV).  L'intelligenza artificiale nelle auto senza conducente deve elaborare rapidamente una grande quantità di dati provenienti da telecamere e sensori per garantire la sicurezza dei conducenti.  Impiegare troppo tempo per interpretare i dati tra un oggetto e un essere umano può significare vita o morte, quindi è fondamentale riuscire a elaborare tali dati il più vicino possibile al veicolo.  In questo caso, uno o più server di edge computing gestiscono l'input proveniente da telecamere, RADAR, LiDAR e altri sensori, mentre l'archiviazione condivisa contiene modelli di inferenza e memorizza i dati di input provenienti dai sensori.</block>
  <block id="e5e51dcd521792cb797e6e3c53736987" category="section-title">Assistenza sanitaria: monitoraggio dei pazienti</block>
  <block id="bace962401fe7f588dcfdc4444fa9cfd" category="paragraph">Uno degli impatti più significativi dell'intelligenza artificiale e dell'edge computing è la loro capacità di migliorare il monitoraggio continuo dei pazienti affetti da malattie croniche, sia nell'assistenza domiciliare che nelle unità di terapia intensiva (UTI).  I dati provenienti da dispositivi edge che monitorano i livelli di insulina, la respirazione, l'attività neurologica, il ritmo cardiaco e le funzioni gastrointestinali richiedono un'analisi istantanea dei dati su cui è necessario intervenire immediatamente, perché il tempo a disposizione per salvare la vita di qualcuno è limitato.</block>
  <block id="7e4b8a4224f71143d7bd188ceeea4acd" category="section-title">Vendita al dettaglio: pagamento senza cassiere</block>
  <block id="a8712e81fee7af830aa2cd6466cfb339" category="paragraph">L'edge computing può potenziare l'intelligenza artificiale e l'apprendimento automatico per aiutare i rivenditori a ridurre i tempi di pagamento e ad aumentare il traffico pedonale.  I sistemi senza cassiere supportano vari componenti, come i seguenti:</block>
  <block id="dbc0817910529140e6894b79ec51b412" category="list-text">Autenticazione e accesso.  Collegare l'acquirente fisico a un account convalidato e consentire l'accesso allo spazio di vendita.</block>
  <block id="349a2650c71706ec201ef08d57dc58e7" category="list-text">Monitoraggio dell'inventario.  Utilizzo di sensori, tag RFID e sistemi di visione artificiale per aiutare gli acquirenti a confermare la selezione o la deselezione degli articoli.</block>
  <block id="86f5df5b4d7496a74d1d41bed2929983" category="paragraph">Qui, ciascuno dei server edge gestisce ogni cassa e il sistema di archiviazione condiviso funge da punto di sincronizzazione centrale.</block>
  <block id="498375fc1d2fd41616385f8abfd37893" category="section-title">Servizi finanziari: sicurezza delle persone ai chioschi e prevenzione delle frodi</block>
  <block id="1dd0f8c70693faa846f69d76af9ffbf7" category="paragraph">Le organizzazioni bancarie utilizzano l'intelligenza artificiale e l'edge computing per innovare e creare esperienze bancarie personalizzate.  I chioschi interattivi che utilizzano l'analisi dei dati in tempo reale e l'inferenza basata sull'intelligenza artificiale consentono ora agli sportelli bancomat non solo di aiutare i clienti a prelevare denaro, ma anche di monitorare proattivamente i chioschi attraverso le immagini catturate dalle telecamere per identificare rischi per la sicurezza umana o comportamenti fraudolenti.  In questo scenario, i server di edge computing e i sistemi di storage condiviso sono collegati a chioschi interattivi e telecamere per aiutare le banche a raccogliere ed elaborare dati con modelli di inferenza basati sull'intelligenza artificiale.</block>
  <block id="0014200d8a9f4fe7a8b65ae923557be6" category="section-title">Produzione: Industria 4.0</block>
  <block id="18bfb27ab22a9db6eb932a3bfe5f51a4" category="paragraph">La quarta rivoluzione industriale (Industria 4.0) è iniziata, insieme a tendenze emergenti come la Smart Factory e la stampa 3D.  Per prepararsi a un futuro basato sui dati, la comunicazione machine-to-machine (M2M) su larga scala e l'IoT vengono integrati per una maggiore automazione senza la necessità dell'intervento umano.  La produzione è già altamente automatizzata e l'aggiunta di funzionalità di intelligenza artificiale è la naturale continuazione di questa tendenza a lungo termine.  L'intelligenza artificiale consente di automatizzare operazioni che possono essere automatizzate con l'ausilio della visione artificiale e di altre funzionalità dell'intelligenza artificiale.  È possibile automatizzare il controllo qualità o le attività che si basano sulla visione umana o sul processo decisionale per eseguire analisi più rapide dei materiali sulle linee di assemblaggio negli stabilimenti produttivi, aiutando così gli stabilimenti di produzione a soddisfare gli standard ISO richiesti in materia di sicurezza e gestione della qualità.  Qui, ogni server edge di elaborazione è connesso a una serie di sensori che monitorano il processo di produzione e i modelli di inferenza aggiornati vengono inviati all'archiviazione condivisa, secondo necessità.</block>
  <block id="a2df8c6c694bb6d9b42851d95a6d7814" category="section-title">Telecomunicazioni: rilevamento della ruggine, ispezione delle torri e ottimizzazione della rete</block>
  <block id="d562d0e475687af21d44b6ea803c10a8" category="paragraph">Il settore delle telecomunicazioni utilizza tecniche di visione artificiale e intelligenza artificiale per elaborare immagini che rilevano automaticamente la ruggine e identificano le torri cellulari che presentano corrosione e, pertanto, necessitano di ulteriori ispezioni.  Negli ultimi anni è aumentato l'uso di immagini di droni e modelli di intelligenza artificiale per identificare le diverse aree di una torre e analizzarne ruggine, crepe superficiali e corrosione.  La domanda di tecnologie di intelligenza artificiale (IA) che consentano di ispezionare in modo efficiente le infrastrutture di telecomunicazione e le torri cellulari, di valutarne regolarmente il degrado e di ripararle tempestivamente quando necessario è in continua crescita.</block>
  <block id="d88e40cd850f8bd6b5e737761a1786fd" category="paragraph">Inoltre, un altro caso d'uso emergente nel settore delle telecomunicazioni è l'uso di algoritmi di intelligenza artificiale e apprendimento automatico per prevedere modelli di traffico dati, rilevare dispositivi compatibili con il 5G e automatizzare e potenziare la gestione energetica MIMO (multiple-input and multiple-output).  L'hardware MIMO viene utilizzato nelle torri radio per aumentare la capacità della rete; tuttavia, ciò comporta costi energetici aggiuntivi.  I modelli di apprendimento automatico per la "modalità di sospensione MIMO" implementati nei siti cellulari possono prevedere l'uso efficiente delle radio e contribuire a ridurre i costi di consumo energetico per gli operatori di rete mobile (MNO).  Le soluzioni di inferenza AI e di edge computing aiutano gli operatori di rete mobile a ridurre la quantità di dati trasmessi avanti e indietro ai data center, ad abbassare il costo totale di proprietà (TCO), a ottimizzare le operazioni di rete e a migliorare le prestazioni complessive per gli utenti finali.</block>
  <block id="228af426af79aabaa0b969d8cee05002" category="summary">Questo documento segue il codice MLPerf Inference v0.7, il codice e le regole MLPerf Inference v1.1.  Abbiamo eseguito benchmark progettati per l'inferenza al limite, come definito nelle tabelle presentate in questa sezione.</block>
  <block id="b3e6ac4f3c523ea5a90f4f79ca3e585d" category="doc">Piano di prova</block>
  <block id="c13367945d5d4c91047b3b50234aa7ab" category="inline-link">codice</block>
  <block id="a4f86f7bfc24194b276c22e0ef158197" category="inline-link">regole</block>
  <block id="eb190159f20d63d1c7687ecafd03fc73" category="paragraph">Questo documento segue MLPerf Inference v0.7<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> , Inferenza MLPerf v1.1<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> , E<block ref="efc21f34f290528320a21a8cc99ffcfc" category="inline-link-rx"></block> .  Abbiamo eseguito benchmark MLPerf progettati per l'inferenza al limite, come definito nella tabella seguente.</block>
  <block id="deec4ff19974f12ed781cb9a59064214" category="cell">Zona</block>
  <block id="a559b87068921eec05086ce5485e9784" category="cell">Modello</block>
  <block id="239658e016e3d5d06ae719d280a79fec" category="cell">Set di dati</block>
  <block id="e110cde47b67924ec0ef64500e8cb067" category="cell">Dimensione QSL</block>
  <block id="571094bb27864b600d8e6b561a137a55" category="cell">Qualità</block>
  <block id="77f086368f7402e03b21bb823cda2eb3" category="cell">Vincolo di latenza multistream</block>
  <block id="99a0628d9f7179c032e0cf59efbc0fad" category="cell">Visione</block>
  <block id="c84e3388f5bc3e4ce028dc81625bf819" category="cell">Classificazione delle immagini</block>
  <block id="4cf67db3abdf54de6064fce40cf27398" category="cell">Resnet50v1.5</block>
  <block id="05e96e35d2778a07f18ff8b414821ee8" category="cell">ImageNet (224x224)</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="79267804a18aa7217c234994e26bb5c7" category="cell">99% di FP32</block>
  <block id="c2010c9d1312ce345a2313d3acb5c6d5" category="cell">50 ms</block>
  <block id="5d9387d7bf46f8c6854a5caafd6cfbf3" category="cell">Rilevamento di oggetti (grandi)</block>
  <block id="7dd82182395c2720676a1e82b781ef04" category="cell">SSD-ResNet34</block>
  <block id="0505dc2363120e454308e12e47f6d354" category="cell">COCCO (1200x1200)</block>
  <block id="ea5d2f1c4608232e07d3aa3d998e5135" category="cell">64</block>
  <block id="f336aeb0ea3de7c70100c292338460e3" category="cell">66 ms</block>
  <block id="a3e1c35debe58b3684abba30911eb0f9" category="cell">Rilevamento di oggetti (piccoli)</block>
  <block id="d05a0b1a6c857a559314f24c10825416" category="cell">SSD-MobileNetsv1</block>
  <block id="f471fd17e298022a58bcbd05aa25a819" category="cell">COCCO (300x300)</block>
  <block id="f718499c1c8cef6730f9fd03c8125cab" category="cell">256</block>
  <block id="ed076605284997250d9cc771eedbfc61" category="cell">Segmentazione delle immagini mediche</block>
  <block id="b8ffefa5ddac895023e8ab6fe1b55b45" category="cell">3D UNET</block>
  <block id="5ea5e4840c21271f42762e8b9271527a" category="cell">BraTS 2019 (224x224x160)</block>
  <block id="c74d97b01eae257e44aa9d5bade97baf" category="cell">16</block>
  <block id="8322d3768dee2653e9cc15c955ee60a8" category="cell">99% e 99,9% di FP32</block>
  <block id="04a83927cfa1af6ae14f94e90aab9ebb" category="cell">Discorso</block>
  <block id="ade9e8d743e7e78d87c5c5603b0aa4ae" category="cell">Sintesi vocale</block>
  <block id="69ee0ff6f427bb2dfd286a55bbc181ea" category="cell">RNNT</block>
  <block id="d3c7d61f6e8ea0b76fd8b65e5115b28b" category="cell">Librispeech dev-clean</block>
  <block id="84b20b1f5a0d103f5710bb67a043cd78" category="cell">2513</block>
  <block id="4994a8ffeba4ac3140beb89e8d41f174" category="cell">Lingua</block>
  <block id="f8672b43ad1f9d3531557d69b6da380c" category="cell">Elaborazione del linguaggio</block>
  <block id="f50c0cca078c7426bed1eb196911c809" category="cell">SQuAD v1.1</block>
  <block id="d56da061d55e2175bd67901d5f0948be" category="cell">10833</block>
  <block id="816720c0b642aa1eef01c4f9108f54c5" category="paragraph">La tabella seguente presenta gli scenari di benchmark di Edge.</block>
  <block id="85051346c766b4444af7bfaaa0c189f5" category="cell">Scenari</block>
  <block id="4bb9c2b62dbc9558da74af948130693b" category="cell">Classificazione delle immagini</block>
  <block id="d5348bf8d0ff8e72043bdbb08aef9767" category="cell">Singolo flusso, offline, multiflusso</block>
  <block id="468acb809a41b49bb7fcdf7425dcd7ee" category="cell">Singolo flusso, offline</block>
  <block id="3d1aa46be43bf2f29633e829d42082af" category="cell">Sintesi vocale-testo</block>
  <block id="7966e67de4ba20fb5412257b4023f4d1" category="paragraph">Abbiamo eseguito questi benchmark utilizzando l'architettura di archiviazione in rete sviluppata in questa convalida e abbiamo confrontato i risultati con quelli delle esecuzioni locali sui server edge precedentemente inviati a MLPerf.  Il confronto serve a determinare l'impatto dell'archiviazione condivisa sulle prestazioni di inferenza.</block>
  <block id="b481424c052310e67a9b67a931165509" category="summary">In questa sezione vengono descritte le procedure di test utilizzate per convalidare questa soluzione.</block>
  <block id="3562305aa864cd56d3e2840eb5071caa" category="doc">Procedura di prova</block>
  <block id="1b0981f820949c10d68daad3fdf03976" category="section-title">Configurazione del sistema operativo e dell'inferenza dell'IA</block>
  <block id="fe03e7fb4a8d3a1afb24c94c4c88d32f" category="paragraph">Per AFF C190, abbiamo utilizzato Ubuntu 18.04 con driver NVIDIA e docker con supporto per GPU NVIDIA e utilizzato MLPerf<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> disponibile come parte della presentazione Lenovo a MLPerf Inference v0.7.</block>
  <block id="504812acf44740b8f536a0d166375734" category="paragraph">Per EF280, abbiamo utilizzato Ubuntu 20.04 con driver NVIDIA e docker con supporto per GPU NVIDIA e MLPerf<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> disponibile come parte della presentazione Lenovo a MLPerf Inference v1.1.</block>
  <block id="fbd2228a821a8ab1948d4a8c3121fb0e" category="paragraph">Per impostare l'inferenza dell'IA, seguire questi passaggi:</block>
  <block id="9177ba75c6dc50d818c52360f10e2fe1" category="list-text">Scarica i set di dati che richiedono la registrazione, il set di convalida ImageNet 2012, il set di dati Criteo Terabyte e il set di formazione BraTS 2019, quindi decomprimi i file.</block>
  <block id="12dda17fb1d76556387dceb2e85a9290" category="list-text">Crea una directory di lavoro con almeno 1 TB e definisci la variabile ambientale<block ref="597c05a331d3bca9b42845049a851c94" prefix=" " category="inline-code"></block> riferendosi alla directory.</block>
  <block id="342ecacc441a9548b60eae46065039f8" category="paragraph">È consigliabile condividere questa directory sull'archiviazione condivisa per il caso d'uso dell'archiviazione di rete oppure sul disco locale quando si eseguono test con dati locali.</block>
  <block id="7c5f7553ff57e0548889000668d1cf39" category="list-text">Esegui il make<block ref="ba8a3d8e03d727387e03ca6ef842d4c5" prefix=" " category="inline-code"></block> comando, che crea e avvia il contenitore Docker per le attività di inferenza richieste.</block>
  <block id="9cfc451dfe052c5c3835b0355375b1b7" category="admonition">Tutti i seguenti comandi vengono eseguiti dall'interno del contenitore Docker in esecuzione:</block>
  <block id="b25e1e6ba392fe4c0e0da7617a67fa4d" category="list-text">Scarica modelli di intelligenza artificiale pre-addestrati per le attività di inferenza MLPerf:<block ref="b59a4beb5c95f2e0e1fed56d89e16cf0" prefix=" " category="inline-code"></block></block>
  <block id="ed43016366915f1fc65fe332de60965f" category="list-text">Scarica altri set di dati scaricabili gratuitamente:<block ref="fd0245b042cdcee1ab8bd760c8b4bfbc" prefix=" " category="inline-code"></block></block>
  <block id="41165a10471c0644aef30b976f113946" category="list-text">Preelaborare i dati: creare<block ref="03275934d57d2ecfe9e68f7023f456ce" prefix=" " category="inline-code"></block></block>
  <block id="f0bacb5df46d2e8bed3d6d0d863fce01" category="list-text">Correre:<block ref="be647e69451a82a2f326980291e0f781" prefix=" " category="inline-code"></block> .</block>
  <block id="189eed4566c6894d64b4d4f8bc9df94c" category="list-text">Costruisci motori di inferenza ottimizzati per la GPU nei server di elaborazione:<block ref="37496efe33254cb883b0705fde55fcc1" prefix=" " category="inline-code"></block></block>
  <block id="4efea18a74f8c5a6fa0f4b239ff2d734" category="list-text">Per eseguire carichi di lavoro di inferenza, eseguire quanto segue (un comando):</block>
  <block id="9ce2624cb32bec75a2ad4e276fa594f6" category="section-title">Esecuzione di inferenza AI</block>
  <block id="2a71d3fa50a14f6fa9c62d9fe3935d5d" category="paragraph">Sono stati eseguiti tre tipi di prove:</block>
  <block id="3a4a320ee019614122e99baebf056b86" category="list-text">Inferenza AI su server singolo tramite archiviazione locale</block>
  <block id="adf25fe660bba733a104887732393fdd" category="list-text">Inferenza AI su server singolo tramite archiviazione di rete</block>
  <block id="34e4c32e4097a70208139be85d5dc892" category="list-text">Inferenza AI multi-server tramite archiviazione di rete</block>
  <block id="8708911de20cfce9bafb315fd0cde0a2" category="summary">Sono stati eseguiti numerosi test per valutare le prestazioni dell'architettura proposta.  Sono disponibili sei diversi carichi di lavoro (classificazione delle immagini, rilevamento di oggetti [piccolo], rilevamento di oggetti [grande], imaging medico, conversione di parlato in testo ed elaborazione del linguaggio naturale [NLP]), che è possibile eseguire in tre scenari diversi: offline, flusso singolo e multiflusso.</block>
  <block id="3274a50ba9f0d3c0adefdfa11c5094be" category="doc">Risultati dei test</block>
  <block id="a274daca2deace9b89099b24f248715c" category="paragraph">Sono stati eseguiti numerosi test per valutare le prestazioni dell'architettura proposta.</block>
  <block id="37bf74d7f686cd395d40af1cc2ed7c55" category="paragraph">Sono disponibili sei diversi carichi di lavoro (classificazione delle immagini, rilevamento di oggetti [piccolo], rilevamento di oggetti [grande], imaging medico, conversione di parlato in testo ed elaborazione del linguaggio naturale [NLP]), che è possibile eseguire in tre scenari diversi: offline, flusso singolo e multiflusso.</block>
  <block id="aaabb57453387e4d8fdae92cdf5d558b" category="admonition">L'ultimo scenario è implementato solo per la classificazione delle immagini e il rilevamento degli oggetti.</block>
  <block id="e7b8f9d880e5e20f44e5277ba99d101b" category="paragraph">Ciò fornisce 15 possibili carichi di lavoro, tutti testati in tre configurazioni diverse:</block>
  <block id="6beb824a1e58582d2c0c733600244087" category="list-text">Server singolo/archiviazione locale</block>
  <block id="0ce03975d1039901bae5d17f67b2ac39" category="list-text">Server singolo/archiviazione di rete</block>
  <block id="ffac1c611ceb8a0bd6268359872e3e68" category="list-text">Archiviazione multi-server/di rete</block>
  <block id="f5b98cda08f17c4b221c6ef2fbf7217f" category="paragraph">I risultati sono descritti nelle sezioni seguenti.</block>
  <block id="18d566b8a783b6684a78fc2924714180" category="section-title">Inferenza AI in uno scenario offline per AFF</block>
  <block id="0aee493b887954641c1ba2e779adcf85" category="paragraph">In questo scenario, tutti i dati erano disponibili sul server ed è stato misurato il tempo impiegato per elaborare tutti i campioni.  Come risultati dei test riportiamo le larghezze di banda in campioni al secondo.  Quando è stato utilizzato più di un server di elaborazione, riportiamo la larghezza di banda totale sommata su tutti i server.  I risultati per tutti e tre i casi d'uso sono mostrati nella figura seguente.  Nel caso di due server, riportiamo la larghezza di banda combinata di entrambi i server.</block>
  <block id="50c1d1baa999e0997ecc5b2fb7ce848c" category="paragraph"><block ref="50c1d1baa999e0997ecc5b2fb7ce848c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0d89c8c627ec0463d3f82a6cbbc04bd" category="paragraph">I risultati mostrano che l'archiviazione di rete non influisce negativamente sulle prestazioni: la modifica è minima e per alcune attività non si riscontra alcuna modifica.  Aggiungendo il secondo server, la larghezza di banda totale raddoppia esattamente o, nel peggiore dei casi, la variazione è inferiore all'1%.</block>
  <block id="d0be2e7e62dc4b0bdbb35ded9b6d842e" category="section-title">Inferenza AI in uno scenario a flusso singolo per AFF</block>
  <block id="fbbf5a4ee90b9175f00f7c8cab5a0670" category="paragraph">Questo benchmark misura la latenza.  Nel caso di più server di calcolo, riportiamo la latenza media.  I risultati per la serie di attività sono riportati nella figura sottostante.  Nel caso di due server, riportiamo la latenza media di entrambi i server.</block>
  <block id="e3a127ece515b351ac983cdc09f48eb3" category="paragraph"><block ref="e3a127ece515b351ac983cdc09f48eb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ef9ced66e0746938556409b4c473052" category="paragraph">I risultati dimostrano ancora una volta che lo storage di rete è sufficiente per gestire le attività.  Nel caso di un singolo server, la differenza tra storage locale e storage di rete è minima o nulla.  Allo stesso modo, quando due server utilizzano lo stesso storage, la latenza su entrambi i server rimane invariata o cambia di poco.</block>
  <block id="64a84459b695510c92164965941ad8f1" category="section-title">Inferenza AI in uno scenario multistream per AFF</block>
  <block id="22ca0fa830d8fd46fe137f6748374c21" category="paragraph">In questo caso, il risultato è il numero di flussi che il sistema può gestire rispettando il vincolo QoS.  Pertanto il risultato è sempre un numero intero.  Per più di un server, riportiamo il numero totale di flussi sommati su tutti i server.  Non tutti i carichi di lavoro supportano questo scenario, ma abbiamo eseguito quelli che lo supportano. I risultati dei nostri test sono riassunti nella figura seguente.  Nel caso di due server, riportiamo il numero combinato di flussi da entrambi i server.</block>
  <block id="79bd7075b14462178ff1e836cefd5d04" category="paragraph"><block ref="79bd7075b14462178ff1e836cefd5d04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3eefb9cc4232b7df67a3c63566ae707" category="paragraph">I risultati mostrano prestazioni perfette della configurazione: l'archiviazione locale e di rete danno gli stessi risultati e l'aggiunta del secondo server raddoppia il numero di flussi che la configurazione proposta può gestire.</block>
  <block id="4ecb5ff41d7f3bd6f1c92bc183f1cb32" category="section-title">Risultati dei test per EF</block>
  <block id="ee7c693721c881b091fdb1adf8a37707" category="paragraph">Sono stati eseguiti numerosi test per valutare le prestazioni dell'architettura proposta.  Sono stati eseguiti sei carichi di lavoro diversi (classificazione delle immagini, rilevamento di oggetti [piccolo], rilevamento di oggetti [grande], imaging medico, conversione di parlato in testo ed elaborazione del linguaggio naturale [NLP]), che sono stati eseguiti in due scenari diversi: offline e flusso singolo.  I risultati sono descritti nelle sezioni seguenti.</block>
  <block id="010bb9776a194ae73e567f4812c8be99" category="section-title">Inferenza AI in uno scenario offline per EF</block>
  <block id="f4fc0d2711e472dedfd5d2952191989c" category="paragraph">In questo scenario, tutti i dati erano disponibili sul server ed è stato misurato il tempo impiegato per elaborare tutti i campioni.  Come risultati dei test riportiamo le larghezze di banda in campioni al secondo.  Per le esecuzioni su un singolo nodo riportiamo la media di entrambi i server, mentre per le esecuzioni su due server riportiamo la larghezza di banda totale sommata su tutti i server.  I risultati per i casi d'uso sono mostrati nella figura seguente.</block>
  <block id="063dd3a1aadafc5ef1c52be7451bda1d" category="paragraph"><block ref="063dd3a1aadafc5ef1c52be7451bda1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb71ae4a7513a21f0771b9aa65aeef9c" category="section-title">Inferenza AI in uno scenario a flusso singolo per EF</block>
  <block id="ca0aa5c3a448e511d9334d94174b8b85" category="paragraph">Questo benchmark misura la latenza.  Per tutti i casi, riportiamo la latenza media su tutti i server coinvolti nelle esecuzioni.  Vengono forniti i risultati per la serie di attività.</block>
  <block id="bcd5a75126c6cafd37838b2f3c6e138b" category="paragraph"><block ref="bcd5a75126c6cafd37838b2f3c6e138b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02eaec2bc90de6689765cffde92e809" category="paragraph">I risultati dimostrano ancora una volta che lo storage di rete è sufficiente per gestire le attività.  La differenza tra l'archiviazione locale e quella di rete nel caso di un singolo server è minima o nulla.  Allo stesso modo, quando due server utilizzano lo stesso storage, la latenza su entrambi i server rimane invariata o cambia di poco.</block>
  <block id="354967c7509f48d7d8a6d2845803bfbc" category="summary">È possibile adattare la configurazione utilizzata per la convalida ad altri casi d'uso.</block>
  <block id="c4236be1a211aab0c15476d08b3e7e0c" category="doc">Opzioni di dimensionamento dell'architettura</block>
  <block id="9d8c4ebebb4b789e6ec48dda7ac54406" category="section-title">Server di elaborazione</block>
  <block id="1b3bfec82c01730e4379631c5f74db2d" category="paragraph">Abbiamo utilizzato una CPU Intel Xeon D-2123IT, che rappresenta il livello di CPU più basso supportato in SE350, con quattro core fisici e TDP da 60 W.  Sebbene il server non supporti la sostituzione delle CPU, è possibile ordinarne una con una CPU più potente.  La CPU più supportata è Intel Xeon D-2183IT con 16 core, 100 W e frequenza di 2,20 GHz.  Ciò aumenta considerevolmente la capacità di calcolo della CPU.  Sebbene la CPU non costituisca un collo di bottiglia per l'esecuzione dei carichi di lavoro di inferenza, essa agevola l'elaborazione dei dati e altre attività correlate all'inferenza.  Al momento, NVIDIA T4 è l'unica GPU disponibile per i casi d'uso edge; pertanto, al momento non è possibile effettuare l'upgrade o il downgrade della GPU.</block>
  <block id="928fe421f0c735b90f3b3ec353741235" category="section-title">Archiviazione condivisa</block>
  <block id="ba49c21e7aa335a8ea452042c02f306a" category="paragraph">Per i test e la convalida, ai fini del presente documento è stato utilizzato il sistema NetApp AFF C190 , che ha una capacità di archiviazione massima di 50,5 TB, una velocità effettiva di 4,4 GBps per letture sequenziali e 230 K IOPS per piccole letture casuali e si è dimostrato adatto per i carichi di lavoro di inferenza edge.</block>
  <block id="44114b1635cead15f56735bad0467251" category="inline-link">NetApp EF300</block>
  <block id="043774815e3806ded716086e0c8c3d03" category="paragraph">Tuttavia, se hai bisogno di maggiore capacità di archiviazione o velocità di rete più elevate, dovresti utilizzare i sistemi di archiviazione NetApp AFF A220 o NetApp AFF A250 .  Inoltre, per la convalida di questa soluzione è stato utilizzato anche il sistema NetApp EF280, con una capacità massima di 1,5 PB e una larghezza di banda di 10 Gbps.  Se preferisci una maggiore capacità di archiviazione con una larghezza di banda maggiore,<block ref="ab4f2e0c1e56faa457a7a1f93253a647" category="inline-link-rx"></block> può essere utilizzato.</block>
  <block id="6c2749dd86f49cdb85fde6976a317e4b" category="summary">Questa sezione descrive le basi tecnologiche di questa soluzione di intelligenza artificiale.</block>
  <block id="b2412d3528eff2c1e191154bf1ecfd60" category="section-title">Sistemi NetApp AFF</block>
  <block id="b7bec75e06d57a8576b1ec632131ea53" category="paragraph">I sistemi di storage NetApp AFF all'avanguardia consentono distribuzioni di inferenza AI all'edge per soddisfare i requisiti di storage aziendale con prestazioni leader del settore, flessibilità superiore, integrazione cloud e gestione dei dati di prima classe.  Progettati specificamente per flash, i sistemi NetApp AFF aiutano ad accelerare, gestire e proteggere i dati aziendali critici.</block>
  <block id="45f242ad7738d4805c03311378260bbf" category="list-text">I sistemi di storage NetApp AFF entry-level sono basati su hardware FAS2750 e supporti flash SSD</block>
  <block id="d308392edcd4d2f839897b51e24cf6f6" category="list-text">Due controller in configurazione HA</block>
  <block id="b2ed189fbf328f509ec4ca77960d3e1a" category="paragraph"><block ref="b2ed189fbf328f509ec4ca77960d3e1a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6b0a1e5585dc8095dd546c5930f1a6c" category="paragraph">I sistemi di storage NetApp AFF C190 entry-level supportano le seguenti funzionalità:</block>
  <block id="42087aa1683ece2ea30ab7fa45862cd6" category="list-text">Un numero massimo di unità pari a 24 SSD da 960 GB</block>
  <block id="d7123d8583ed65e3090da25ea5aee965" category="list-text">Due possibili configurazioni:</block>
  <block id="35b9fc01c3820062d5969f142bdc5ce5" category="list-text">Ethernet (10GbE): 4 porte 10GBASE-T (RJ-45)</block>
  <block id="f5e2ae88aead451be011eb9f8abfdd6e" category="list-text">Unificato (16 Gb FC o 10 GbE): 4 porte UTA2 (Unified Target Adapter 2)</block>
  <block id="1e927fd215e516034d85785b393b0efb" category="list-text">Capacità effettiva massima di 50,5 TB</block>
  <block id="aa9cba7f7b6d2ff8fb2251620a584dcd" category="admonition">Per i carichi di lavoro NAS, un singolo sistema AFF C190 entry-level supporta una velocità di trasmissione di 4,4 GBps per letture sequenziali e 230 K IOPS per piccole letture casuali con latenze di 1 ms o inferiori.</block>
  <block id="1672d070f346948fb25e819b40bb3ade" category="section-title">NetApp AFF A220</block>
  <block id="ac7bdd389786fda32ee572c48eef4838" category="paragraph">NetApp offre anche altri sistemi di storage entry-level che garantiscono prestazioni e scalabilità più elevate per distribuzioni su larga scala.  Per i carichi di lavoro NAS, un singolo sistema AFF A220 entry-level supporta:</block>
  <block id="732568c5581337c7341011c38721e2db" category="list-text">Throughput di 6,2 GBps per letture sequenziali</block>
  <block id="4900f6d90a4169888690f2c04f3c6603" category="list-text">375K IOPS per piccole letture casuali con latenze di 1 ms o inferiori</block>
  <block id="fbcd9d84b2d7be8631cbf7226884f17a" category="list-text">Numero massimo di unità: 144 SSD da 960 GB, 3,8 TB o 7,6 TB</block>
  <block id="db527e605a2eacc627448a70b8a745db" category="list-text">AFF A220 è scalabile fino a una capacità effettiva superiore a 1 PB</block>
  <block id="25297dbc8df2aecff2fa2e9e47638d35" category="section-title">NetApp AFF A250</block>
  <block id="cac36335022421f12e1c8e999ffeb1af" category="list-text">La capacità effettiva massima è di 35 PB con una scalabilità massima di 2-24 nodi (12 coppie HA)</block>
  <block id="62a23a7791227c5f5e3d068e70759128" category="list-text">Fornisce un aumento delle prestazioni ≥ 45% rispetto AFF A220</block>
  <block id="dc7ac33362f108fc7f4b7d8eb0e2cf4e" category="list-text">Letture casuali 440k IOPS a 1 ms</block>
  <block id="0f4615fb8d6105bcb2cbce504f8f091c" category="list-text">Basato sull'ultima versione NetApp ONTAP : ONTAP 9.8</block>
  <block id="440a976974d702d027543e058c1fffc0" category="list-text">Sfrutta due Ethernet da 25 Gb per HA e interconnessione del cluster</block>
  <block id="4dc1c0d5a0f0257d8d9e183bc226ab45" category="section-title">Sistemi NetApp E-Series EF</block>
  <block id="f5e23a285b378cde99c2d7fb43586c1b" category="paragraph">La serie EF è una famiglia di array di storage SAN all-flash di fascia media e base in grado di accelerare l'accesso ai dati e di aiutarti a ricavarne valore più velocemente grazie al software NetApp SANtricity .  Questi sistemi offrono storage flash sia SAS che NVMe e garantiscono IOPS da convenienti a estremi, tempi di risposta inferiori a 100 microsecondi e larghezza di banda fino a 44 GBps, il che li rende ideali per carichi di lavoro misti e applicazioni impegnative come l'inferenza AI e l'elaborazione ad alte prestazioni (HPC).</block>
  <block id="96e4797e3006bef737785f8627faae06" category="paragraph">La figura seguente mostra il sistema di archiviazione NetApp EF280.</block>
  <block id="94bb9af4c6eb62dbf44f691e2565e77e" category="paragraph"><block ref="94bb9af4c6eb62dbf44f691e2565e77e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6f17b7c2ad64f8977585fc43d702abf" category="section-title">NetApp EF280</block>
  <block id="2d6477e98cb834485323c97da975c640" category="list-text">Supporto FC da 32 Gb/16 Gb, iSCSI da 25 Gb/10 Gb e SAS da 12 Gb</block>
  <block id="d637a0904677ae775d98b9ce0beda3d6" category="list-text">La capacità massima effettiva è di 96 unità per un totale di 1,5 PB</block>
  <block id="6f409cb54d8cb27deac8a918fe03f3cc" category="list-text">Throughput di 10 GBps (letture sequenziali)</block>
  <block id="7c61b8793dbe5a66cbf144bdabcf76cd" category="list-text">300K IOPS (letture casuali)</block>
  <block id="4c5a963973ae3026e92baab2ef522c6c" category="list-text">NetApp EF280 è l'array all-flash (AFA) più economico del portafoglio NetApp</block>
  <block id="f1330bea5ad6aa446aa17d0a324bb579" category="list-text">24 unità SSD NVMe per una capacità totale di 367 TB</block>
  <block id="6768e0b9e957297070e3822e98a4b8f9" category="list-text">Opzioni di espansione per un totale di 240x HDD NL-SAS, 96x SSD SAS o una combinazione</block>
  <block id="0fa40de31cbd933cc9a954d82204feb9" category="list-text">NVMe/IB da 100 Gb, NVMe/RoCE, iSER/IB e SRP/IB</block>
  <block id="aee7a4e3788dbbff7166952ed0e2d2c9" category="list-text">NVMe/FC da 32 Gb, FCP</block>
  <block id="c4b9deb88d9cf1b1a2160cb28a2c41ca" category="list-text">iSCSI da 25 GB</block>
  <block id="03597240f9b0b4a23f3ffdf6e159d6ca" category="list-text">20 GBps (letture sequenziali)</block>
  <block id="ffe3b3adfe232ee25f1914e7e7d266c4" category="list-text">670K IOPS (letture casuali)</block>
  <block id="7105ea3513c2bdae1a0d63a9f0703579" category="inline-link">Scheda tecnica NetApp array all-flash NetApp EF-Series EF600, F300, EF570 ed EF280</block>
  <block id="6e69804b180359b12a32a56c17c0641e" category="admonition">Per maggiori informazioni, vedere il<block ref="5f5484869dc0c271e2b062d172d38bee" category="inline-link-rx"></block> .</block>
  <block id="a5119a6bd0f4d733e0f1f4c10f9d063b" category="section-title">NetApp ONTAP 9</block>
  <block id="b407d5a86fd662f03d5a1615963e0827" category="paragraph">ONTAP 9.8.1, l'ultima generazione di software di gestione dello storage di NetApp, consente alle aziende di modernizzare l'infrastruttura e passare a un data center pronto per il cloud.  Sfruttando le funzionalità di gestione dei dati leader del settore, ONTAP consente la gestione e la protezione dei dati con un unico set di strumenti, indipendentemente da dove risiedano.  È inoltre possibile spostare liberamente i dati ovunque siano necessari: edge, core o cloud.  ONTAP 9.8.1 include numerose funzionalità che semplificano la gestione dei dati, accelerano e proteggono i dati critici e abilitano le funzionalità infrastrutturali di nuova generazione nelle architetture cloud ibride.</block>
  <block id="2e2b24551fd50942c6da57d4f8efdfae" category="paragraph">La gestione dei dati è fondamentale per le operazioni IT aziendali, in modo da utilizzare le risorse appropriate per le applicazioni e i set di dati.  ONTAP include le seguenti funzionalità per semplificare e snellire le operazioni e ridurre il costo totale di esercizio:</block>
  <block id="4934cd09a8e487be128d2b6321ee3279" category="list-text">*Compattazione dei dati in linea e deduplicazione estesa.*  La compattazione dei dati riduce lo spazio sprecato all'interno dei blocchi di archiviazione, mentre la deduplicazione aumenta significativamente la capacità effettiva.  Ciò vale sia per i dati archiviati localmente sia per i dati archiviati a livelli nel cloud.</block>
  <block id="0ddc097c124782f16e8a0a1b014fc2bb" category="list-text">*Qualità del servizio minima, massima e adattiva (AQoS).*  I controlli granulari della qualità del servizio (QoS) aiutano a mantenere i livelli di prestazioni per le applicazioni critiche in ambienti altamente condivisi.</block>
  <block id="0c720f269a89477f24f77f6f027719cc" category="inline-link-macro">TR-4598</block>
  <block id="7920a2957aeb5c70e8ee2fa43c94e741" category="list-text">* NetApp FabricPool.*  Questa funzionalità consente la suddivisione automatica dei dati inattivi in opzioni di archiviazione cloud pubbliche e private, tra cui Amazon Web Services (AWS), Azure e la soluzione di archiviazione NetApp StorageGRID .  Per ulteriori informazioni su FabricPool, vedere<block ref="38e4393e170a142db2e52760317ecb7f" category="inline-link-macro-rx"></block> .</block>
  <block id="85e643b872d0d98ec2251220de803a1f" category="paragraph">ONTAP 9 offre livelli superiori di prestazioni e protezione dei dati ed estende queste capacità nei seguenti modi:</block>
  <block id="bfb9fa643243eb975ccd9d158cf97800" category="list-text">*Prestazioni e latenza inferiore.*  ONTAP offre la massima capacità di trasmissione possibile con la minima latenza possibile.</block>
  <block id="ef9770ee572f97c59254dc0d022afda8" category="list-text">*Protezione dei dati.*  ONTAP offre funzionalità integrate di protezione dei dati con gestione comune su tutte le piattaforme.</block>
  <block id="86a12b3dbbf039b371f714a515919535" category="list-text">* Crittografia del volume NetApp (NVE).*  ONTAP offre la crittografia nativa a livello di volume con supporto sia per la gestione delle chiavi integrate che per quella esterna.</block>
  <block id="b3023c0a4db125fc22f0d6056c6e379d" category="list-text">*Multitenancy e autenticazione multifattore.*  ONTAP consente la condivisione delle risorse infrastrutturali con i massimi livelli di sicurezza.</block>
  <block id="f9eaef0b2cf89b234c431c18aec36bf3" category="paragraph">ONTAP 9 aiuta a soddisfare le esigenze aziendali più esigenti e in continua evoluzione grazie alle seguenti funzionalità:</block>
  <block id="9e98379ad83b5c60933a3437c7fb61c7" category="list-text">*Scalabilità senza interruzioni e operazioni senza interruzioni.*  ONTAP supporta l'aggiunta non distruttiva di capacità ai controller esistenti e ai cluster scalabili.  I clienti possono effettuare l'aggiornamento alle tecnologie più recenti, come NVMe e FC da 32 Gb, senza costose migrazioni di dati o interruzioni.</block>
  <block id="7d97721ced74a2279b6645f506722980" category="list-text">*Connessione cloud.*  ONTAP è il software di gestione dello storage più connesso al cloud, con opzioni per lo storage definito dal software (ONTAP Select) e istanze cloud-native (Google Cloud NetApp Volumes) in tutti i cloud pubblici.</block>
  <block id="b5dc6026803056308b6bf7007af32a2b" category="list-text">*Integrazione con applicazioni emergenti.*  ONTAP offre servizi dati di livello aziendale per piattaforme e applicazioni di nuova generazione, come veicoli autonomi, città intelligenti e Industria 4.0, utilizzando la stessa infrastruttura che supporta le app aziendali esistenti.</block>
  <block id="e4872d9c30e978d9408425f0e08882c5" category="section-title">NetApp SANtricity</block>
  <block id="965539211ad2d7bc981e7e954db08850" category="inline-link">Scheda tecnica del software NetApp E-Series SANtricity</block>
  <block id="568549d316f6f749a07012e522e0bca3" category="paragraph">NetApp SANtricity è progettato per offrire prestazioni, affidabilità e semplicità leader del settore agli array ibridi flash E-Series e all-flash EF-Series.  Ottieni le massime prestazioni e il massimo utilizzo dei tuoi array flash ibridi serie E e all-flash serie EF per applicazioni con carichi di lavoro elevati, tra cui analisi dei dati, videosorveglianza, backup e ripristino.  Con SANtricity, è possibile completare la configurazione, la manutenzione, l'espansione della capacità e altre attività mentre lo storage rimane online.  SANtricity offre inoltre una protezione dei dati superiore, un monitoraggio proattivo e una sicurezza certificata, il tutto accessibile tramite l'interfaccia System Manager integrata e di facile utilizzo.  Per saperne di più, vedere il<block ref="64769f0652e98a060ba5d2cd17320298" category="inline-link-rx"></block> .</block>
  <block id="c4cf91172f1e96366d0dfa38c1167df9" category="section-title">Prestazioni ottimizzate</block>
  <block id="3d615c3559b8d33749ea23cf3a34b759" category="paragraph">Il software SANtricity ottimizzato per le prestazioni fornisce dati, con IOPS elevati, elevata produttività e bassa latenza, a tutte le tue app di analisi dati, videosorveglianza e backup.  Accelera le prestazioni per applicazioni ad alto IOPS e bassa latenza e applicazioni ad alta larghezza di banda e alta produttività.</block>
  <block id="8238dd9365065265be82d79d4dd38a98" category="section-title">Massimizza i tempi di attività</block>
  <block id="28ed557ae8b4ff60f83da71465cbcb9b" category="paragraph">Completa tutte le attività di gestione mentre l'archiviazione rimane online.  Modifica le configurazioni, esegui la manutenzione o espandi la capacità senza interrompere l'I/O.  Ottieni la migliore affidabilità della categoria con funzionalità automatizzate, configurazione online, tecnologia Dynamic Disk Pools (DPP) all'avanguardia e molto altro.</block>
  <block id="2b34e4806834294a7dd611ad1d7d0308" category="section-title">Riposa in pace</block>
  <block id="7847b3892c0f355acdb3fe824654e209" category="paragraph">Il software SANtricity garantisce una protezione dei dati superiore, un monitoraggio proattivo e una sicurezza certificata, il tutto tramite l'interfaccia System Manager integrata e di facile utilizzo.  Semplifica le attività di gestione dello storage.  Ottieni la flessibilità di cui hai bisogno per la messa a punto avanzata di tutti i sistemi di storage della serie E.  Gestisci il tuo sistema NetApp E-Series, sempre e ovunque.  La nostra interfaccia web integrata semplifica il flusso di lavoro di gestione.</block>
  <block id="10f0fa4079121b371145e16713fdbb44" category="inline-link">Trident</block>
  <block id="2758085534b10a85f702f6a61737eefb" category="paragraph"><block ref="d14308042ff124582c531f74c03d90f3" category="inline-link-rx"></block>di NetApp è un orchestratore di storage dinamico open source per Docker e Kubernetes che semplifica la creazione, la gestione e l'utilizzo di storage persistente.  Trident, un'applicazione nativa di Kubernetes, viene eseguita direttamente all'interno di un cluster Kubernetes.  Trident consente ai clienti di distribuire senza problemi immagini di container DL sullo storage NetApp e fornisce un'esperienza di livello aziendale per le distribuzioni di container AI.  Gli utenti di Kubernetes (come gli sviluppatori ML e gli scienziati dei dati) possono creare, gestire e automatizzare l'orchestrazione e la clonazione per sfruttare le funzionalità avanzate di gestione dei dati NetApp basate sulla tecnologia NetApp .</block>
  <block id="9b6334cb865bfb3ae702677852339a38" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block>è un servizio NetApp per la sincronizzazione rapida e sicura dei dati.  Che tu debba trasferire file tra condivisioni file NFS o SMB locali, NetApp StorageGRID, NetApp ONTAP S3, Google Cloud NetApp Volumes, Azure NetApp Files, Amazon Simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS), Azure Blob, Google Cloud Storage o IBM Cloud Object Storage, BlueXP Copy and Sync sposta i file dove ti servono in modo rapido e sicuro.  Una volta trasferiti, i dati saranno completamente disponibili per l'uso sia sulla sorgente che sulla destinazione.  BlueXP Copy and Sync sincronizza costantemente i dati, in base alla pianificazione predefinita, spostando solo i delta, riducendo al minimo il tempo e il denaro spesi per la replicazione dei dati.  BlueXP Copy and Sync è uno strumento software as a service (SaaS) estremamente semplice da configurare e utilizzare.  I trasferimenti di dati attivati da BlueXP Copy and Sync vengono eseguiti da broker di dati.  È possibile distribuire i broker di dati BlueXP Copy and Sync su AWS, Azure, Google Cloud Platform o in locale.</block>
  <block id="8eb0c6a27656d04de6abfc6d24a1a8d5" category="paragraph">I server Lenovo ThinkSystem sono dotati di hardware, software e servizi innovativi che risolvono le sfide odierne dei clienti e offrono un approccio progettuale modulare, evolutivo e su misura per affrontare le sfide di domani.  Questi server sfruttano le migliori tecnologie standard del settore, abbinate alle innovazioni differenziate di Lenovo, per offrire la massima flessibilità possibile nei server x86.</block>
  <block id="493e1540ce727fb5f465fff015aa4733" category="paragraph">I principali vantaggi dell'implementazione dei server Lenovo ThinkSystem includono:</block>
  <block id="b7c6c5eb82b90f69eddd06060626e5e3" category="list-text">Progetti modulari e altamente scalabili per crescere con la tua attività</block>
  <block id="c2599c559a0be54b242b8aa3c67325c8" category="list-text">Resilienza leader del settore per risparmiare ore di costosi tempi di inattività non programmati</block>
  <block id="c57cb88fcbeb47afa8496b8fc32cbf03" category="list-text">Tecnologie flash veloci per latenze più basse, tempi di risposta più rapidi e una gestione dei dati più intelligente in tempo reale</block>
  <block id="6d72d9a0181555ca86c9562861e47058" category="paragraph">Nell'ambito dell'intelligenza artificiale, Lenovo sta adottando un approccio pratico per aiutare le aziende a comprendere e adottare i vantaggi dell'apprendimento automatico e dell'intelligenza artificiale per i loro carichi di lavoro.  I clienti Lenovo possono esplorare e valutare le offerte Lenovo AI nei Lenovo AI Innovation Center per comprenderne appieno il valore per il loro specifico caso d'uso.  Per migliorare il time-to-value, questo approccio incentrato sul cliente fornisce ai clienti una prova di concetto per piattaforme di sviluppo di soluzioni pronte all'uso e ottimizzate per l'intelligenza artificiale.</block>
  <block id="6bf0f92a7340921305982a91f7277085" category="paragraph">L'edge computing consente di analizzare i dati provenienti dai dispositivi IoT ai margini della rete prima di inviarli al data center o al cloud.  Il Lenovo ThinkSystem SE350, come mostrato nella figura sottostante, è progettato per i requisiti specifici dell'implementazione in periferia, con particolare attenzione a flessibilità, connettività, sicurezza e gestibilità remota in un fattore di forma compatto, robusto e resistente agli agenti atmosferici.</block>
  <block id="72dd0df190a1bdc8d3043fafdba7122b" category="paragraph">Dotato del processore Intel Xeon D con la flessibilità necessaria per supportare l'accelerazione dei carichi di lavoro AI edge, il modello SE350 è progettato appositamente per affrontare la sfida delle distribuzioni di server in una varietà di ambienti al di fuori del data center.</block>
  <block id="c45cd4236e9fecc47291c206c4aac70a" category="paragraph"><block ref="c45cd4236e9fecc47291c206c4aac70a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16bb0d66e42a8bb99cbefc63c53bcfdc" category="paragraph"><block ref="16bb0d66e42a8bb99cbefc63c53bcfdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c08b3aee1d5fb5dc3447ec1271a853" category="inline-link">Inferenza MLPerf v0.7</block>
  <block id="f6922096e43c9e99d2be9d521357ff1c" category="paragraph">MLPerf è la suite di benchmark leader del settore per la valutazione delle prestazioni dell'intelligenza artificiale.  Copre molti ambiti dell'intelligenza artificiale applicata, tra cui la classificazione delle immagini, il rilevamento degli oggetti, l'imaging medico e l'elaborazione del linguaggio naturale (NLP).  In questa convalida abbiamo utilizzato i carichi di lavoro Inference v0.7, che rappresentano l'ultima iterazione di MLPerf Inference al completamento di questa convalida.  IL<block ref="1303efdddf9d8dbc0de31c402aa4ef22" category="inline-link-rx"></block> La suite include quattro nuovi benchmark per data center e sistemi edge:</block>
  <block id="c781a146774780843a929b97004ba720" category="list-text">*BERT.*  Rappresentazione dell'encoder bidirezionale dai trasformatori (BERT) ottimizzata per la risposta alle domande mediante l'utilizzo del set di dati SQuAD.</block>
  <block id="cb93b50c2b2216543a9eee4d9a38b38c" category="list-text">*DLRM.*  Il Deep Learning Recommendation Model (DLRM) è un modello di personalizzazione e raccomandazione addestrato per ottimizzare i tassi di clic (CTR).</block>
  <block id="16139bb6e8da8fe8f8aaf1e5fb8bde0d" category="list-text">*Rete U 3D.*  L'architettura 3D U-Net è addestrata sul set di dati Brain Tumor Segmentation (BraTS).</block>
  <block id="5691eec0e5e0ea401478ea67b8168d64" category="list-text">*RNN-T.* Il trasduttore di rete neurale ricorrente (RNN-T) è un modello di riconoscimento vocale automatico (ASR) addestrato su un sottoinsieme di LibriSpeech.  I risultati e il codice di MLPerf Inference sono disponibili al pubblico e rilasciati con licenza Apache.  MLPerf Inference ha una divisione Edge, che supporta i seguenti scenari:</block>
  <block id="e772865569495cb43ba25be1d6eed756" category="list-text">*Flusso singolo.*  Questo scenario imita i sistemi in cui la reattività è un fattore critico, come le query di intelligenza artificiale offline eseguite sugli smartphone.  Le singole query vengono inviate al sistema e i tempi di risposta vengono registrati.  Come risultato viene riportata la latenza del 90° percentile di tutte le risposte.</block>
  <block id="f9cf7025c2d80af397a9b960974631e2" category="list-text">*Multistream.*  Questo benchmark è per i sistemi che elaborano input da più sensori.  Durante il test, le query vengono inviate a intervalli di tempo fissi.  Viene imposto un vincolo QoS (latenza massima consentita).  Il test riporta il numero di flussi che il sistema può elaborare rispettando il vincolo QoS.</block>
  <block id="78a9abbe3c771a5882830fc8e2a73a8f" category="list-text">*Offline.*  Questo è lo scenario più semplice che riguarda le applicazioni di elaborazione batch e la metrica è la produttività in campioni al secondo.  Tutti i dati sono disponibili al sistema e il benchmark misura il tempo impiegato per elaborare tutti i campioni.</block>
  <block id="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link"><block ref="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link-rx"></block></block>
  <block id="13176cbb826705821e77b735791d29d4" category="paragraph">Lenovo ha pubblicato i punteggi MLPerf Inference per SE350 con T4, il server utilizzato in questo documento.  Vedi i risultati su<block ref="8efc95b379113ebfb6f66010213223ce" category="inline-link-rx"></block> nella sezione "Edge, Closed Division" nella voce n. 0.7-145.</block>
  <block id="686ebb62ce1be84dcfae0007fb84562d" category="summary">La configurazione utilizzata per la convalida può essere adattata ad altri casi d'uso.</block>
  <block id="bf46169695d75ff844d955af09f33e75" category="doc">Modifiche architettoniche</block>
  <block id="1cf27bd587c6c632877c322cf42c0d97" category="paragraph">La configurazione utilizzata per questa convalida può essere adattata ad altri casi d'uso.</block>
  <block id="a752efb5fb2512dc99b2045f032779f7" category="section-title">Regolazioni della CPU</block>
  <block id="122acc941b98ef5a11208d23ed0a8090" category="paragraph">Per questa convalida abbiamo utilizzato un processore Skylake Intel Xeon Platinum 8360Y, come consigliato da Lenovo.  Ci aspettiamo che la CPU Cascade Lake equivalente, un processore Intel Xeon Gold 6330, offra prestazioni simili perché questo carico di lavoro non è vincolato alla CPU.</block>
  <block id="3cc37c167d58a1828b00c13cc6018ae8" category="section-title">Aumento della capacità di archiviazione</block>
  <block id="f40ff1aaa4f2e4ccd4189adfb3584e29" category="paragraph">In base alle esigenze di capacità di archiviazione, è possibile aumentare lo spazio di archiviazione condiviso (volume NFS) su richiesta, a condizione di disporre di ulteriori modelli di controller e di ripiani per dischi.  È possibile eseguire questa operazione dalla CLI o dall'interfaccia Web NetApp del controller di storage come utente amministratore.</block>
  <block id="15977ebfd8c3685ca2d8911f74efcc2d" category="summary">Questa soluzione NetApp e Lenovo è un'architettura flessibile e scalabile, ideale per l'ingresso nell'intelligenza artificiale aziendale di medio livello.  Lo storage NetApp garantisce prestazioni uguali o migliori dello storage SSD locale e offre i seguenti vantaggi a data scientist, data engineer e decision maker IT.</block>
  <block id="994c1f46e0860094a86d2a822416646b" category="paragraph">La soluzione NetApp e Lenovo qui convalidata è un'architettura flessibile e scalabile, ideale per l'ingresso nell'intelligenza artificiale aziendale di medio livello.</block>
  <block id="bcbfcce438abee9a9a41cb7e588eb4de" category="paragraph">Lo storage NetApp garantisce prestazioni uguali o migliori dello storage SSD locale e offre i seguenti vantaggi a data scientist, data engineer e decision maker IT:</block>
  <block id="6127562591a3f60f8ac270d3967754dd" category="list-text">Elaborazione e archiviazione scalabili in modo indipendente per ridurre al minimo i costi e migliorare l'utilizzo delle risorse.</block>
  <block id="74902bcc2ed17395305301b925afee3f" category="list-text">Flussi di lavoro di sviluppo e distribuzione semplificati mediante snapshot e cloni integrati per spazi di lavoro utente istantanei e salvaspazio, controllo delle versioni integrato e distribuzione automatizzata.</block>
  <block id="42e2aaa2f651d8ad800a51f65a258f1e" category="list-text">Protezione dei dati di livello aziendale per il disaster recovery e la continuità aziendale.</block>
  <block id="2ea563f362255807faae7242f06c9881" category="list-text">Karthikeyan Nagalingam, Ingegnere tecnico di marketing, NetApp</block>
  <block id="cccf21ceeae034a9e54b62eb00d9b6b3" category="list-text">Jarrett Upton, amministratore, AI Lab Systems, Lenovo</block>
  <block id="fdc944d7a0de8d8e3dfff03c6a0e03c6" category="list-text">Pagina del prodotto NetApp All Flash Arrays</block>
  <block id="d875955d78b62e4aff0847425410f79a" category="inline-link"><block ref="d875955d78b62e4aff0847425410f79a" category="inline-link-rx"></block></block>
  <block id="45f6f9585c85146b389a4f896653a5f9" category="paragraph"><block ref="45f6f9585c85146b389a4f896653a5f9" category="inline-link-rx"></block></block>
  <block id="ec5282877903d9d2aceb3db45b21da54" category="list-text">Pagina NetApp AFF A400</block>
  <block id="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link"><block ref="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link-rx"></block></block>
  <block id="04438df627d0343d17b2f6f307b489ed" category="paragraph"><block ref="04438df627d0343d17b2f6f307b489ed" category="inline-link-rx"></block></block>
  <block id="9d92155996555576a58d20e697fc2bd6" category="list-text">Pagina del prodotto del software di gestione dati NetApp ONTAP</block>
  <block id="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link"><block ref="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link-rx"></block></block>
  <block id="2f08744b4a39af375744e1fc4a15b53a" category="paragraph"><block ref="2f08744b4a39af375744e1fc4a15b53a" category="inline-link-rx"></block></block>
  <block id="45913847e0b47b72b60766711f7a8c21" category="inline-link"><block ref="45913847e0b47b72b60766711f7a8c21" category="inline-link-rx"></block></block>
  <block id="229469a202dbd3052c7b165bd55eda87" category="paragraph"><block ref="229469a202dbd3052c7b165bd55eda87" category="inline-link-rx"></block></block>
  <block id="dedba6b3261804ab1e5c2b75051c62ac" category="list-text">NVIDIA SMI (nvidia-smi)</block>
  <block id="f5800a0bf7fbf711d11868c2913c218f" category="inline-link"><block ref="f5800a0bf7fbf711d11868c2913c218f" category="inline-link-rx"></block></block>
  <block id="41299b529a1014318d5e7776b9f92ad1" category="paragraph"><block ref="41299b529a1014318d5e7776b9f92ad1" category="inline-link-rx"></block></block>
  <block id="bd7c9d63c88eb380170362e93db6ba46" category="summary">Questa sezione descrive le configurazioni testate, l'infrastruttura di rete, il server SR670 V2 e i dettagli del provisioning dello storage.</block>
  <block id="a1052c50691421535c201fa50690a1ca" category="paragraph">Questa sezione descrive le configurazioni testate, l'infrastruttura di rete, il server SR670 V2 e i dettagli del provisioning dello storage NetApp .</block>
  <block id="7c8d74d4c719b2f2e30a143bb98717ad" category="paragraph">Per questa convalida abbiamo utilizzato i componenti della soluzione elencati nella tabella seguente.</block>
  <block id="35c99b744e4464f42b9b61595c1a1e79" category="list-text">Due server SR670 V2, ciascuno con otto schede GPU NVIDIA A100 da 80 GB</block>
  <block id="222a9edda77d8676279c651c1b06d653" category="list-text">Ogni server contiene 2 CPU Intel Xeon Platinum 8360Y (28 core fisici) e 1 TB di RAM</block>
  <block id="e18f1a9d73bf89b2b1245e5af1a99cf4" category="cell">Linux (Ubuntu – 20.04 con CUDA 11.8)</block>
  <block id="2113187ee3a9451b60e960fdea11bbac" category="cell">Sistema di archiviazione NetApp AFF (coppia HA)</block>
  <block id="73b4d2da39f967445be9b79a6016c84c" category="list-text">Software NetApp ONTAP 9.10.1</block>
  <block id="4028b206981977bc3aea334fd55f4cb9" category="list-text">1 gruppo di interfacce (ifgrp) per controller, con quattro indirizzi IP logici per i punti di montaggio</block>
  <block id="82693066c3bae0719e01ba8060494172" category="paragraph">In questa convalida abbiamo utilizzato ResNet v2.0 con il set di base ImageNet specificato da MLPerf v2.0.  Il set di dati è archiviato in un sistema di archiviazione NetApp AFF con protocollo NFS.  Gli SR670 erano collegati al sistema di storage NetApp AFF A400 tramite uno switch da 100 GbE.</block>
  <block id="e4869dda2a4e140bc138f43895626550" category="paragraph">ImageNet è un set di dati di immagini utilizzato frequentemente.  Contiene quasi 1,3 milioni di immagini per una dimensione totale di 144 GB.  La dimensione media dell'immagine è 108 KB.</block>
  <block id="3961f6874ee29dab2f4982bc3e0a1be5" category="paragraph">La figura seguente illustra la topologia di rete della configurazione testata.</block>
  <block id="d015822ec6fd4a7fc9867768f5a27898" category="inline-image-macro">Questa immagine mostra il livello di elaborazione, un Lenovo ThinkSystem SR670 V2, il livello di rete, uno switch Ethernet Lenovo e il livello di archiviazione, un controller di archiviazione NetApp AFF A400 .  Sono incluse tutte le connessioni di rete.</block>
  <block id="74ae44f09af988f16e87e4e2e31ef81a" category="paragraph"><block ref="74ae44f09af988f16e87e4e2e31ef81a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18866bc1d6ba54b48522f7a219e02740" category="paragraph">Nella tabella seguente è elencata la configurazione di archiviazione.</block>
  <block id="f64bc191156dac76ffce8622c16cb21d" category="cell">Dimensione aggregata</block>
  <block id="6bb41960470a19d97556b9240ac0b3ff" category="cell">Dimensione del volume</block>
  <block id="abd2beb6abe5072ffab5f1aad1a8c27f" category="cell">Punto di montaggio del sistema operativo</block>
  <block id="a38b6dcf7d1d2c2957803ba9a28b472e" category="cell">/a400-100g</block>
  <block id="43f5cd38d362fc55ace2f313e6b5cf09" category="cell">9,9 TB</block>
  <block id="09808554056bf39d02319e3dbc2d6667" category="cell">19 TB</block>
  <block id="a27053e11ec415312f3dc32f4e351b67" category="admonition">La cartella /a400-100g contiene il set di dati utilizzato per la convalida ResNet.</block>
  <block id="1f599c1b266e901a2c8d38e266e23c6f" category="summary">In questa sezione vengono descritti i risultati dettagliati della procedura di test.</block>
  <block id="c87fa6e515cf0976291b387e5a8ab6f6" category="doc">Procedura di prova e risultati dettagliati</block>
  <block id="b70dd619781891706b7d2f44c418a2b5" category="section-title">Addestramento al riconoscimento delle immagini tramite ResNet in ONTAP</block>
  <block id="bf523bb892b07c71c90bd7ea34a091a9" category="paragraph">Abbiamo eseguito il benchmark ResNet50 con uno e due server SR670 V2.  Questo test ha utilizzato il contenitore NGC MXNet 22.04-py3 per eseguire l'addestramento.</block>
  <block id="a08c4eedb9047aae68f44b82037739b0" category="paragraph">Per questa convalida abbiamo utilizzato la seguente procedura di test:</block>
  <block id="df1a5f60f20e6aa3336812f58095e04f" category="list-text">Abbiamo cancellato la cache dell'host prima di eseguire lo script per assicurarci che i dati non fossero già memorizzati nella cache:</block>
  <block id="ab93a65fabd2eaae21f5a6e097320730" category="list-text">Abbiamo eseguito lo script di benchmark con il set di dati ImageNet nell'archiviazione del server (archiviazione SSD locale) e sul sistema di archiviazione NetApp AFF .</block>
  <block id="9f98453c4a6eede45b87d72527b49e7e" category="list-text">Abbiamo convalidato le prestazioni di rete e di archiviazione locale utilizzando<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> comando.</block>
  <block id="47b048d9dcf1d84d76bddb033b842b3b" category="list-text">Per l'esecuzione su un singolo nodo, abbiamo utilizzato il seguente comando:</block>
  <block id="cf9a86ba8909a23b4d67d509b389a080" category="list-text">Per le esecuzioni distribuite, abbiamo utilizzato il modello di parallelizzazione del server dei parametri.  Abbiamo utilizzato due server di parametri per nodo e abbiamo impostato il numero di epoche in modo che fosse lo stesso dell'esecuzione a nodo singolo.  Lo abbiamo fatto perché la formazione distribuita spesso richiede più epoche a causa della sincronizzazione imperfetta tra i processi.  Il diverso numero di epoche può alterare i confronti tra casi a nodo singolo e casi distribuiti.</block>
  <block id="8f74be345dbaeac65cc3a488503b2a1f" category="section-title">Velocità di lettura dei dati: archiviazione locale rispetto a quella di rete</block>
  <block id="16d8fe364e1a7846c093983bec75e764" category="paragraph">La velocità di lettura è stata testata utilizzando il<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> comando su uno dei file per il set di dati ImageNet.  Nello specifico, abbiamo eseguito i seguenti comandi sia per i dati locali che per quelli di rete:</block>
  <block id="c685a224eb9a88c5b7bd2be45fe5a128" category="paragraph">Entrambi i valori sono simili, il che dimostra che l'archiviazione di rete può fornire dati a una velocità simile a quella dell'archiviazione locale.</block>
  <block id="aa613e8f689a1a64605aef401595bfd2" category="section-title">Caso d'uso condiviso: lavori multipli, indipendenti e simultanei</block>
  <block id="7e4312d3e922a98bfc1dc4a84c80f12c" category="paragraph">Questo test ha simulato il caso d'uso previsto per questa soluzione: formazione AI multi-lavoro e multi-utente.  Ogni nodo ha eseguito il proprio addestramento utilizzando l'archiviazione di rete condivisa.  I risultati sono visualizzati nella figura seguente, che mostra come il caso di soluzione abbia fornito prestazioni eccellenti, con tutti i processi eseguiti sostanzialmente alla stessa velocità dei singoli processi.  La produttività totale è proporzionale al numero di nodi.</block>
  <block id="2b9215e7cc3c2422637b6f95b0d47d97" category="inline-image-macro">Questa figura mostra le immagini aggregate al secondo.</block>
  <block id="568b99e77256e0aa65f03e3612709ffc" category="paragraph"><block ref="568b99e77256e0aa65f03e3612709ffc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f5fcaaad259a917b031b3169cd5ad4" category="inline-image-macro">Questa figura mostra il tempo di esecuzione in minuti.</block>
  <block id="c8a726b6eb44bab6b01c319420a7605a" category="paragraph"><block ref="c8a726b6eb44bab6b01c319420a7605a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="289b386724c768cabf5ad786a3842335" category="paragraph">Questi grafici presentano il tempo di esecuzione in minuti e le immagini aggregate al secondo per i nodi di elaborazione che hanno utilizzato otto GPU da ciascun server su una rete client da 100 GbE, combinando sia il modello di addestramento simultaneo che il modello di addestramento singolo.  Il tempo di esecuzione medio del modello di addestramento è stato di 35 minuti e 9 secondi.  La durata individuale è stata di 34 minuti e 32 secondi, 36 minuti e 21 secondi, 34 minuti e 37 secondi, 35 minuti e 25 secondi e 34 minuti e 31 secondi.  Le immagini medie al secondo per il modello di addestramento erano 22.573, mentre le singole immagini al secondo erano 21.764; 23.438; 22.556; 22.564; e 22.547.</block>
  <block id="ce47a442fe1dc7c09bf9a3ec5ed71236" category="paragraph">In base alla nostra convalida, un modello di addestramento indipendente con un runtime dati NetApp è durato 34 minuti e 54 secondi con 22.231 immagini/sec.  Un modello di addestramento indipendente con un runtime di dati locali (DAS) è stato di 34 minuti e 21 secondi con 22.102 immagini/sec.  Durante queste esecuzioni, l'utilizzo medio della GPU è stato del 96%, come osservato su nvidia-smi.  Si noti che questa media include la fase di test, durante la quale non sono state utilizzate GPU, mentre l'utilizzo della CPU è stato del 40%, come misurato da mpstat.  Ciò dimostra che la velocità di trasmissione dei dati è sufficiente in ogni caso.</block>
  <block id="1d126a9d86b70dcdbc0585754993a848" category="summary">Questa soluzione si concentra sull'architettura cluster sia entry-level che mid-range, utilizzando storage NetApp e server Lenovo ottimizzati per carichi di lavoro di intelligenza artificiale.  È pensato per team di piccole e medie dimensioni per i quali la maggior parte dei lavori di elaborazione sono a nodo singolo (con una o più GPU) o sono distribuiti su pochi nodi di elaborazione.  Questa non è una limitazione importante, perché la maggior parte delle attività quotidiane di addestramento dell'IA sono svolte su un singolo nodo.</block>
  <block id="119a956725a313a60a3ef97db900f9fa" category="doc">TR-4810: NetApp AFF A400 con Lenovo ThinkSystem SR670 V2 per la formazione di modelli AI e ML</block>
  <block id="db297dc3a6b72858a5039fa6507a2b34" category="paragraph">Sathish Thyagarajan, David Arnette, NetApp Mircea Troaca, Lenovo</block>
  <block id="252875fbe73a0c4ecbd42a23cc730022" category="paragraph">Questa soluzione presenta un'architettura cluster di fascia media che utilizza storage NetApp e server Lenovo ottimizzati per carichi di lavoro di intelligenza artificiale (AI).  È pensato per le piccole e medie imprese, per le quali la maggior parte dei processi di elaborazione avviene su un singolo nodo (con una o più GPU) o è distribuita su pochi nodi di elaborazione.  Questa soluzione si adatta alla maggior parte delle attività quotidiane di formazione sull'intelligenza artificiale svolte da molte aziende.</block>
  <block id="2fd79dc2b0743358191fe41cd806d103" category="paragraph">Questo documento riguarda i test e la convalida di una configurazione di elaborazione e storage composta da server Lenovo SR670V2 a otto GPU, un sistema di storage NetApp AFF A400 di fascia media e uno switch di interconnessione da 100 GbE.  Per misurare le prestazioni, abbiamo utilizzato ResNet50 con il set di dati ImageNet, una dimensione del batch di 408, mezza precisione, CUDA e cuDNN.  Questa architettura fornisce una soluzione efficiente e conveniente per le piccole e medie imprese che stanno appena avviando iniziative di intelligenza artificiale e che richiedono le funzionalità di livello aziendale dell'archiviazione dati connessa al cloud NetApp ONTAP .</block>
  <block id="a186cc4a556d59a6e7b787796afd96a6" category="list-text">Data scientist, data engineer, data administrator e sviluppatori di sistemi di intelligenza artificiale</block>
  <block id="9f16d751276619605acf16a23befe48e" category="list-text">Architetti aziendali che progettano soluzioni per lo sviluppo di modelli di intelligenza artificiale</block>
  <block id="e8982c30a351cd862612b0062923a81e" category="list-text">Data scientist e data engineer che cercano modi efficienti per raggiungere gli obiettivi di sviluppo di deep learning (DL) e machine learning (ML)</block>
  <block id="ca84e34dfe1115f7b462050a20377876" category="list-text">Leader aziendali e decisori OT/IT che desiderano raggiungere il time-to-market più rapido possibile per le iniziative di intelligenza artificiale</block>
  <block id="a2dac0ecb0b60ec2625d20a5003869fb" category="paragraph">Questa soluzione con server Lenovo ThinkSystem e NetApp ONTAP con storage AFF è progettata per gestire l'addestramento dell'intelligenza artificiale su grandi set di dati utilizzando la potenza di elaborazione delle GPU insieme alle CPU tradizionali.  Questa convalida dimostra elevate prestazioni e una gestione ottimale dei dati con un'architettura scalabile che utilizza uno, due o quattro server Lenovo SR670 V2 insieme a un singolo sistema di storage NetApp AFF A400 .  La figura seguente fornisce una panoramica architettonica.</block>
  <block id="9eaa73568302c6f5b850762b65b3f334" category="inline-image-macro">Questa immagine mostra uno switch Ethernet circondato dal server di gestione, quattro SR670 V2 con otto GPU ciascuno e un sistema di storage NetApp ONTAP .</block>
  <block id="98230d6fe5f2e966446d65810c888228" category="paragraph"><block ref="98230d6fe5f2e966446d65810c888228" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9336931f4103d973313cb8539e5c2613" category="list-text">Prestazioni altamente efficienti e convenienti durante l'esecuzione di più attività di formazione in parallelo</block>
  <block id="81c3992924ee5cdc4cb02692dcae98b4" category="list-text">Prestazioni scalabili basate su diversi numeri di server Lenovo e diversi modelli di controller di storage NetApp</block>
  <block id="bdcea52fecbcd9741f95a6bc0dbbde0f" category="list-text">Protezione dati robusta per soddisfare obiettivi di punto di ripristino (RPO) e obiettivi di tempo di ripristino (RTO) bassi senza perdita di dati</block>
  <block id="98393526d67c065feb588e5665301706" category="list-text">Gestione ottimizzata dei dati con snapshot e cloni per semplificare i flussi di lavoro di sviluppo</block>
  <block id="f737e7cc3d8aa89c5b49c4fe701e9e40" category="summary">In questa convalida, abbiamo eseguito l'addestramento al riconoscimento delle immagini come specificato da MLPerf v2.0.  Nello specifico, abbiamo addestrato il modello ResNet v2.0 con il set di dati ImageNet.  Il parametro principale è il tempo impiegato per raggiungere la precisione desiderata.  Riportiamo inoltre la larghezza di banda di addestramento in immagini al secondo per valutare meglio l'efficienza di scalabilità.</block>
  <block id="0f25983094bc4cf5cea830260da8ee75" category="paragraph">In questa convalida, abbiamo eseguito l'addestramento al riconoscimento delle immagini come specificato da MLPerf v2.0.  Nello specifico, abbiamo addestrato il modello ResNet v2.0 con il set di dati ImageNet fino a raggiungere una precisione del 76,1%.  Il parametro principale è il tempo impiegato per raggiungere la precisione desiderata.  Riportiamo inoltre la larghezza di banda di addestramento in immagini al secondo per valutare meglio l'efficienza di scalabilità.</block>
  <block id="ac3e6a4fbe8e02d639c2defeebeac17f" category="paragraph">Il caso di test primario ha valutato più processi di formazione indipendenti (uno per nodo) eseguiti contemporaneamente.  Questo simula il caso d'uso principale, un sistema condiviso utilizzato da più data scientist.  Il secondo caso di prova ha valutato l'efficienza di scalabilità.</block>
  <block id="2d316c5d9e0cd748d1890ee69f57dc6c" category="summary">Questa sezione riassume i risultati dei test effettuati su questa soluzione.</block>
  <block id="80b6b969d6707ba1b92d65466e8325f0" category="paragraph">La tabella seguente riassume i risultati di tutti i test eseguiti per questa soluzione.</block>
  <block id="f5bc14ae022ba581c26f3bdb35badef1" category="cell">Descrizione del test</block>
  <block id="34d8129946f1108a296f033dc66db266" category="cell">Riepilogo dei risultati</block>
  <block id="ab0d993807168c3a70cdd2952d4edfc0" category="cell">Formazione sul riconoscimento delle immagini: più lavori simultanei</block>
  <block id="290ba1c81812edd0651d8e18c5895054" category="cell">Prestazioni altamente efficienti.  Tutti i lavori venivano eseguiti alla massima velocità anche quando il cluster era completamente utilizzato.  I sistemi di storage NetApp hanno garantito prestazioni di formazione paragonabili allo storage SSD locale, consentendo al contempo una facile condivisione dei dati tra i server.</block>
  <block id="d58827ca3ccfccb5c83b1dc9c7e12289" category="cell">Formazione sul riconoscimento delle immagini: scalabilità</block>
  <block id="afb4fda11ecde317daa521e054df2bd4" category="cell">Altamente efficiente per un massimo di quattro nodi.  A quel punto, l'espansione era meno efficiente, ma comunque fattibile.  L'utilizzo di una rete di calcolo ad alta velocità migliora la scalabilità.  Il sistema di storage NetApp ha garantito prestazioni di formazione paragonabili allo storage SSD locale, consentendo al contempo una facile condivisione dei dati tra i server.</block>
  <block id="e59b92fc604ecde201ab865ddefca7c2" category="summary">In questa sezione vengono presentati in modo più dettagliato i componenti principali di questa soluzione.</block>
  <block id="995049066ee0a46858d3a35e74f687fc" category="paragraph">I sistemi di storage NetApp AFF consentono alle aziende di soddisfare i requisiti di storage aziendale con prestazioni leader del settore, flessibilità superiore, integrazione cloud e la migliore gestione dei dati della categoria.  Progettati specificamente per flash, i sistemi AFF aiutano ad accelerare, gestire e proteggere i dati critici per l'azienda.</block>
  <block id="9cdcb25bd8b8e9dd029f0c58f1c1ce14" category="inline-image-macro">Questa immagine mostra la parte anteriore del controller di storage NetApp AFF A400 .</block>
  <block id="f150868d2ce410023c5087a2a86bf51e" category="paragraph"><block ref="f150868d2ce410023c5087a2a86bf51e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4c41eb7420fce0589579f0f045df87" category="inline-image-macro">Questa immagine mostra il retro del controller di storage NetApp AFF A400 .</block>
  <block id="11540913656d83142b2b0f7aed3df7e4" category="paragraph"><block ref="11540913656d83142b2b0f7aed3df7e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32fbd740c28afd94422aeceef5424762" category="paragraph">NetApp AFF A400 è un sistema di archiviazione flash NVMe di fascia media che include le seguenti funzionalità:</block>
  <block id="4b78ed4e994ac9de0ed2b09e38067a6a" category="list-text">Capacità massima effettiva: ~20PB</block>
  <block id="9b150a217729988c3dd54fdaf7b0f9b3" category="list-text">Scalabilità massima: 2-24 nodi (12 coppie HA)</block>
  <block id="ae3b033d221455bb2825ac51bee7200e" category="list-text">Supporto host FC da 25 GbE e 16 Gb</block>
  <block id="e16f4e2b178ce47880c3556c501efea4" category="list-text">Connettività RDMA 100GbE su Ethernet convergente (RoCE) per ripiani di archiviazione di espansione NVMe</block>
  <block id="e9038c807b352c2a4dcfd8cf1ac2cdd4" category="list-text">Le porte RoCE da 100 GbE possono essere utilizzate per il collegamento alla rete host se non sono collegati scaffali NVMe</block>
  <block id="dff1410020c1b676f56ee973acea57d3" category="list-text">Scaffali di archiviazione con espansione completa della connettività SAS a 12 Gbps</block>
  <block id="565637725a05c879995851c50d41275c" category="list-text">Disponibile in due configurazioni:</block>
  <block id="8e707b713d26c4b020eda98a37207373" category="list-text">Ethernet: 4 porte Ethernet da 25 Gb (SFP28)</block>
  <block id="1d3c6ad9f15fc70a1cf63e449e90436a" category="list-text">Canale in fibra: 4 porte FC (SFP+) da 16 Gb</block>
  <block id="6a2a811bcec501901ab6f8f94694d1b2" category="list-text">Lettura casuale 8KB al 100% a 0,4 ms 400k IOPS</block>
  <block id="d3309961dfabc3043c3ea1878752450b" category="paragraph">Le funzionalità di NetApp AFF A250 per le distribuzioni AI/ML entry-level includono quanto segue:</block>
  <block id="68448ae40d26fce5bb74cd3bf75999c4" category="list-text">Capacità massima effettiva: 35 PB</block>
  <block id="83fa45e9cc2def5751527547e3c57b61" category="list-text">Scalabilità massima: 2-24 nodi (12 coppie HA)</block>
  <block id="1283cfcd2651148a611c2c4b105458c3" category="list-text">Basato sull'ultima versione di NetApp ONTAP ONTAP 9.8 o successiva</block>
  <block id="f31903137775862e1157677f447b0f52" category="list-text">Due porte Ethernet da 25 Gb per HA e interconnessione cluster</block>
  <block id="f6c48fdc99c510156e0364e03a6fbd9e" category="paragraph">NetApp offre anche altri sistemi di storage, come AFF A800 e AFF A700, che garantiscono prestazioni e scalabilità più elevate per implementazioni AI/ML su larga scala.</block>
  <block id="3f0cb8a376b551c058cd6886f68bceb0" category="paragraph">ONTAP 9, l'ultima generazione di software di gestione dello storage di NetApp, consente alle aziende di modernizzare l'infrastruttura e passare a un data center pronto per il cloud.  Sfruttando le funzionalità di gestione dei dati leader del settore, ONTAP consente la gestione e la protezione dei dati con un unico set di strumenti, indipendentemente da dove risiedano.  I dati possono anche essere spostati liberamente ovunque siano necessari: edge, core o cloud.  ONTAP 9 include numerose funzionalità che semplificano la gestione dei dati, accelerano e proteggono i dati critici e rendono l'infrastruttura a prova di futuro nelle architetture cloud ibride.</block>
  <block id="c5b25bb449b07e8b863f41dbe3b90a2a" category="list-text">*Qualità del servizio (QoS) minima, massima e adattiva.*  I controlli QoS granulari aiutano a mantenere i livelli di prestazioni per le applicazioni critiche in ambienti altamente condivisi.</block>
  <block id="ddf38f965aeb6f6b5785254e6f143a09" category="list-text">* ONTAP FabricPool.*  Questa funzionalità suddivide automaticamente i dati inattivi in livelli per opzioni di archiviazione cloud pubbliche e private, tra cui Amazon Web Services (AWS), Azure e l'archiviazione di oggetti NetApp StorageGRID .</block>
  <block id="2a228ac6322b6d496b4cb0cf22cfbfe4" category="list-text">*Prestazioni e latenza inferiore.*  ONTAP offre la massima capacità di trasmissione possibile con la minima latenza possibile.</block>
  <block id="493a7caad772a79b06f5d4a7dd98afcd" category="list-text">* Crittografia del volume NetApp .*  ONTAP offre la crittografia nativa a livello di volume con supporto per la gestione delle chiavi sia integrate che esterne.</block>
  <block id="cf4d3359e3cce4324a54d8e1864d2647" category="paragraph">ONTAP 9 aiuta a soddisfare le esigenze aziendali più esigenti e in continua evoluzione:</block>
  <block id="99f4fd3a9ea4a861a7095bfe26937f28" category="list-text">*Scalabilità senza interruzioni e operazioni senza interruzioni.*  ONTAP supporta l'aggiunta non distruttiva di capacità ai controller esistenti e ai cluster scalabili.  I clienti possono effettuare l'aggiornamento alle tecnologie più recenti, come NVMe e FC da 32 Gb, senza costose migrazioni di dati o interruzioni.</block>
  <block id="ba1e7aff40da44f3c5b86ba78a62e7d0" category="list-text">*Integrazione con applicazioni emergenti.*  ONTAP offre servizi dati di livello aziendale per piattaforme e applicazioni di nuova generazione come OpenStack, Hadoop e MongoDB, utilizzando la stessa infrastruttura che supporta le app aziendali esistenti.</block>
  <block id="0fdd508a09442b5caa00e47bc0563112" category="section-title">Volumi NetApp FlexGroup</block>
  <block id="641653fdc449e0b1e30f3ee9d04182ab" category="paragraph">I set di dati di addestramento sono in genere una raccolta di potenzialmente miliardi di file.  I file possono contenere testo, audio, video e altre forme di dati non strutturati che devono essere archiviati ed elaborati per poter essere letti in parallelo.  Il sistema di archiviazione deve memorizzare molti file di piccole dimensioni e deve leggere tali file in parallelo per l'I/O sequenziale e casuale.</block>
  <block id="e6ad1152aea2aa4f79a47e3b80410fce" category="paragraph">Un volume FlexGroup (figura seguente) è un singolo namespace composto da più volumi membri costituenti, gestito e che agisce come un volume NetApp FlexVol volume per gli amministratori di storage.  I file in un volume FlexGroup vengono assegnati ai singoli volumi membri e non vengono distribuiti tra volumi o nodi.  Abilitano le seguenti funzionalità:</block>
  <block id="381a99cae8c29b3b8fd64a207b811935" category="list-text">Fino a 20 petabyte di capacità e bassa latenza prevedibile per carichi di lavoro con metadati elevati</block>
  <block id="b0e05251a53a0118d23cd469db4b1903" category="list-text">Fino a 400 miliardi di file nello stesso namespace</block>
  <block id="4eb6665794643a2afabf63f90ddbe4da" category="list-text">Operazioni parallelizzate nei carichi di lavoro NAS su CPU, nodi, aggregati e volumi FlexVol costituenti</block>
  <block id="55f5279d0b1378eee63af77d4c7ac7bd" category="inline-image-macro">Questa immagine mostra una coppia HA di controller di archiviazione contenenti molti volumi con file principali all'interno di un FlexGroup.</block>
  <block id="27f19cee54b11d13039a99839ca83e4c" category="paragraph"><block ref="27f19cee54b11d13039a99839ca83e4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f52dbcd9b43086f1d2957e6eb89f4113" category="section-title">Portafoglio Lenovo ThinkSystem</block>
  <block id="c5ac419e5467e7539d60c18be3da4b99" category="paragraph">I principali vantaggi dell'implementazione dei server Lenovo ThinkSystem includono quanto segue:</block>
  <block id="c19629173ec04d03fae09e96ce30b98c" category="list-text">Progetti modulari e altamente scalabili che crescono con la tua attività</block>
  <block id="9ac34c98220e3dd285a7cd6c8679caeb" category="paragraph">Nell'ambito dell'intelligenza artificiale, Lenovo sta adottando un approccio pratico per aiutare le aziende a comprendere e adottare i vantaggi dell'apprendimento automatico e dell'intelligenza artificiale per i loro carichi di lavoro.  I clienti Lenovo possono esplorare e valutare le offerte Lenovo AI nei Lenovo AI Innovation Center per comprenderne appieno il valore per il loro specifico caso d'uso.  Per migliorare il time-to-value, questo approccio incentrato sul cliente fornisce ai clienti prove di concetto per piattaforme di sviluppo di soluzioni pronte all'uso e ottimizzate per l'intelligenza artificiale.</block>
  <block id="7cbc0e3d7cff391aa0e61b487dc29df1" category="section-title">Lenovo SR670 V2</block>
  <block id="5889950b76dcc45f10977523225c92a8" category="paragraph">Il server rack Lenovo ThinkSystem SR670 V2 offre prestazioni ottimali per l'intelligenza artificiale accelerata e l'elaborazione ad alte prestazioni (HPC).  Grazie al supporto fino a otto GPU, l'SR670 V2 è adatto ai requisiti di carico di lavoro computazionale intensivo di ML, DL e inferenza.</block>
  <block id="327669874a587f6f9336f608f83d451d" category="inline-image-macro">Questa immagine mostra tre configurazioni SR670.  La prima mostra quattro GPU SXM con otto unità HS da 2,5 pollici e 2 slot PCIe I/O.  Il secondo mostra quattro slot GPU doppi o otto singoli e due slot PCIe I/O con otto unità HS da 2,5 pollici o quattro da 3,5 pollici.  Il terzo mostra otto slot GPU doppi con sei unità EDSFF HS e due slot PCIe I/O.</block>
  <block id="20b8a0ab50b43efab313a63b4c461c6e" category="paragraph"><block ref="20b8a0ab50b43efab313a63b4c461c6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="85b1e2eb4bc61f3bdaea9a9f040eb3a0" category="paragraph">Grazie alle più recenti CPU Intel Xeon scalabili che supportano GPU di fascia alta (tra cui la GPU NVIDIA A100 80GB PCIe 8x), ThinkSystem SR670 V2 offre prestazioni ottimizzate e accelerate per carichi di lavoro AI e HPC.</block>
  <block id="d7ed5fdb2102567c3c051078e7c72e11" category="paragraph">Poiché un numero maggiore di carichi di lavoro sfrutta le prestazioni degli acceleratori, la richiesta di densità GPU è aumentata.  Settori come il commercio al dettaglio, i servizi finanziari, l'energia e l'assistenza sanitaria utilizzano le GPU per estrarre informazioni più approfondite e promuovere l'innovazione con tecniche di apprendimento automatico, apprendimento automatico (DL) e inferenza.</block>
  <block id="89a846b0823ae167964c8a02382225cf" category="paragraph">ThinkSystem SR670 V2 è una soluzione ottimizzata di livello enterprise per l'implementazione di carichi di lavoro HPC e AI accelerati in produzione, massimizzando le prestazioni del sistema e mantenendo al contempo la densità del data center per cluster di supercomputing con piattaforme di nuova generazione.</block>
  <block id="9378d87a3787bb6ab3fe4605dd558aaf" category="paragraph">Altre caratteristiche includono:</block>
  <block id="fe62ffc0b0188329f10e2bfc0c560ece" category="list-text">Supporto per I/O RDMA diretto GPU in cui gli adattatori di rete ad alta velocità sono collegati direttamente alle GPU per massimizzare le prestazioni I/O.</block>
  <block id="03e5fd8f257caa94eae847639e18b1a9" category="list-text">Supporto per l'archiviazione diretta GPU in cui le unità NVMe sono collegate direttamente alle GPU per massimizzare le prestazioni di archiviazione.</block>
  <block id="ad7857a40388167e99516cfe367478d5" category="paragraph">MLPerf è la suite di benchmark leader del settore per la valutazione delle prestazioni dell'intelligenza artificiale.  In questa convalida, abbiamo utilizzato il benchmark di classificazione delle immagini con MXNet, uno dei framework di intelligenza artificiale più diffusi.  Per guidare l'addestramento dell'IA è stato utilizzato lo script di addestramento MXNet_benchmarks.  Lo script contiene implementazioni di diversi modelli convenzionali diffusi ed è progettato per essere il più veloce possibile.  Può essere eseguito su una singola macchina oppure in modalità distribuita su più host.</block>
  <block id="75c1d09e56fd67f885464b85c424c1a6" category="summary">In questo documento viene presentato un progetto di riferimento convalidato di NetApp AIPod per Enterprise RAG con tecnologie e funzionalità combinate dei processori Intel Xeon 6 e delle soluzioni di gestione dati NetApp .  La soluzione illustra un'applicazione ChatQnA downstream che sfrutta un ampio modello linguistico, fornendo risposte accurate e contestualmente rilevanti agli utenti simultanei.  Le risposte vengono recuperate dal repository di conoscenze interno di un'organizzazione tramite una pipeline di inferenza RAG air-gapped.</block>
  <block id="98082f297da0ed06e10c426d26145b83" category="doc">NetApp AIPod Mini - Inferenza RAG aziendale con NetApp e Intel</block>
  <block id="f7b06c1111212ddff169549b5e723f7d" category="inline-image-macro">Logo Intel</block>
  <block id="0e15068b5c1105ba9f4537e00817149b" category="paragraph"><block ref="0e15068b5c1105ba9f4537e00817149b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad17078c7a931a9c4e7e96f485d5a504" category="section-title">Convalida del partner di storage Intel</block>
  <block id="56f2eda910ca62395eb64d1a789a0edd" category="paragraph">I server basati su processori Intel Xeon 6 sono progettati per gestire carichi di lavoro di inferenza AI impegnativi, utilizzando Intel AMX per le massime prestazioni.  Per consentire prestazioni di archiviazione e scalabilità ottimali, la soluzione è stata convalidata con successo utilizzando NetApp ONTAP, consentendo alle aziende di soddisfare le esigenze delle applicazioni RAG.  Questa convalida è stata condotta su server dotati di processori Intel Xeon 6.  Intel e NetApp hanno una solida partnership incentrata sulla fornitura di soluzioni di intelligenza artificiale ottimizzate, scalabili e allineate alle esigenze aziendali dei clienti.</block>
  <block id="679a14435daad5bf55fe65cf54175466" category="section-title">Vantaggi dell'esecuzione di sistemi RAG con NetApp</block>
  <block id="18fb2614ff78418dcaae1e9141862c62" category="list-text">Velocità e scalabilità.  È possibile gestire grandi set di dati ad alta velocità per il controllo delle versioni, con la possibilità di scalare prestazioni e capacità in modo indipendente.</block>
  <block id="71861e9c8f9e5be0d026ab6bdf1a8a1a" category="list-text">Accesso ai dati.  Il supporto multiprotocollo consente alle applicazioni client di leggere i dati utilizzando i protocolli di condivisione file S3, NFS e SMB.  I bucket ONTAP S3 NAS possono facilitare l'accesso ai dati in scenari di inferenza LLM multimodali.</block>
  <block id="27a2888f3fc62ef093e756c75c45081e" category="list-text">Affidabilità e riservatezza.  ONTAP offre protezione dei dati, protezione autonoma dai ransomware (ARP) NetApp integrata e provisioning dinamico dello storage, oltre a offrire crittografia basata sia su software che su hardware per migliorare la riservatezza e la sicurezza.  ONTAP è conforme allo standard FIPS 140-2 per tutte le connessioni SSL.</block>
  <block id="104d96e571b334e50365e35ae17299d9" category="paragraph">Questo documento è destinato ai decisori in materia di intelligenza artificiale, agli ingegneri dei dati, ai leader aziendali e ai dirigenti di reparto che desiderano sfruttare un'infrastruttura creata per fornire soluzioni RAG e GenAI aziendali.  Una conoscenza pregressa dell'inferenza dell'IA, degli LLM, di Kubernetes e delle reti e dei relativi componenti sarà utile durante la fase di implementazione.</block>
  <block id="d8f5efc84f626ba14a7b3cf5ec1b06c7" category="inline-link">Processore Xeon 6</block>
  <block id="9dc22cb886e2ea682197d9ab3292ba79" category="paragraph">Con Xeon 6 come CPU host, i sistemi accelerati traggono vantaggio da elevate prestazioni single-thread, maggiore larghezza di banda di memoria, maggiore affidabilità, disponibilità e manutenibilità (RAS) e più corsie I/O.  Intel AMX accelera l'inferenza per INT8 e BF16 e offre supporto per modelli addestrati da FP16, con un massimo di 2.048 operazioni in virgola mobile per ciclo per core per INT8 e 1.024 operazioni in virgola mobile per ciclo per core per BF16/FP16.  Per implementare una soluzione RAG utilizzando processori Xeon 6, in genere si consiglia una RAM minima di 250 GB e 500 GB di spazio su disco.  Tuttavia, ciò dipende fortemente dalle dimensioni del modello LLM.  Per ulteriori informazioni, fare riferimento a Intel<block ref="5d6ada86cc7a762cca0505b98060c709" category="inline-link-rx"></block> descrizione del prodotto.</block>
  <block id="c3f5f2ae46fce3305ec2b138111a93b9" category="inline-image-macro">300.300</block>
  <block id="1e2eb4a765ee46d2a2a5ec4ace0544fc" category="paragraph">Figura 1 - Server di elaborazione con processori Intel Xeon 6<block ref="791fbab5dd410f620397cbb8a7265767" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7c9993f09f717fcec0e1d09837e1efc" category="section-title">Archiviazione NetApp AFF</block>
  <block id="969e81477626b41849d992785dfcd02d" category="paragraph">I sistemi NetApp AFF A-Series di livello base e intermedio offrono prestazioni più potenti, densità e maggiore efficienza.  I sistemi NetApp AFF A20, AFF A30 e AFF A50 forniscono un vero storage unificato che supporta blocchi, file e oggetti, basato su un singolo sistema operativo in grado di gestire, proteggere e mobilitare senza problemi i dati per le applicazioni RAG al costo più basso nel cloud ibrido.</block>
  <block id="f89af68595f296408d40bf9a33b8df16" category="paragraph">Figura 2 - Sistema NetApp AFF A-Series.<block ref="f19ab1d9dc0e27bd83c8759fade26d2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="958c530ea1ae0e18b942f8784148734c" category="cell">*Hardware*</block>
  <block id="ddcac68770926479de530a8b7b73319e" category="cell">*Quantità*</block>
  <block id="9bdc480955b350f1fe8089392ad36cbe" category="cell">*Commento*</block>
  <block id="e5cb14453a0aa5c9218e9b6f4a2468d1" category="cell">Server del piano di controllo con processore Intel</block>
  <block id="f5aa1aa461d9a8bb35210fb241f42cda" category="cell">Piano di controllo Kubernetes/server 1U.</block>
  <block id="5a0cd1929a98cebd107b65ee74abdd78" category="cell">Scelta dello switch Ethernet da 100 Gb</block>
  <block id="8bfef0f2ef10319beae9f37e53900e5a" category="cell">Switch del centro dati.</block>
  <block id="7a2bdeec28cc635e8de5bbcea81978e1" category="cell">NetApp AFF A20 (o AFF A30; AFF A50)</block>
  <block id="4e42b39bc940168c6df430c647a36a11" category="cell">Capacità di archiviazione massima: 9,3 PB.  Nota: Rete: porte 10/25/100 GbE.</block>
  <block id="44959688d91c76b11d501b550db01844" category="paragraph">Per la convalida di questo progetto di riferimento sono stati utilizzati server con processori Intel Xeon 6 di Supermicro (222HA-TN-OTO-37) e uno switch 100GbE di Arista (7280R3A).</block>
  <block id="aa6ecfe41f4b8c352896cd6cf7bc99f7" category="section-title">Piattaforma aperta per l'intelligenza artificiale aziendale</block>
  <block id="6fbfd0726b7202aebde976680ced22c4" category="paragraph">L'Open Platform for Enterprise AI (OPEA) è un'iniziativa open source guidata da Intel in collaborazione con i partner dell'ecosistema.  Fornisce una piattaforma modulare di blocchi di costruzione componibili progettati per accelerare lo sviluppo di sistemi di intelligenza artificiale generativa all'avanguardia, con una forte attenzione al RAG.  OPEA include un framework completo che comprende LLM, datastore, motori di prompt, progetti architettonici RAG e un metodo di valutazione in quattro fasi che valuta i sistemi di intelligenza artificiale generativa in base a prestazioni, funzionalità, affidabilità e prontezza aziendale.</block>
  <block id="cbe45632fbbac4e94036260c2653169b" category="paragraph">L'OPEA è costituito essenzialmente da due componenti chiave:</block>
  <block id="4293e41be4afaf5127828398b7c550da" category="list-text">GenAIComps: un toolkit basato sui servizi composto da componenti di microservizi</block>
  <block id="b93ca66f4736b98ad6d348c3b08a6806" category="list-text">GenAIExamples: soluzioni pronte per l'implementazione come ChatQnA che dimostrano casi d'uso pratici</block>
  <block id="de3c6a3259d3e324c7703889f55a4dde" category="inline-link">Documentazione del progetto OPEA</block>
  <block id="95a35f38b1c8257e521a361226ddc22d" category="paragraph">Per maggiori dettagli, vedere il<block ref="61827ec0b891f01987001b685543f04f" category="inline-link-rx"></block></block>
  <block id="1671448a75b3c116c61a1ac925267b0b" category="inline-link">Scopri di più sulla configurazione ONTAP S3</block>
  <block id="90c6a896851e2b2d442ba1cd9d8de55a" category="paragraph">NetApp ONTAP è la tecnologia fondamentale su cui si fondano le soluzioni di archiviazione dati critici di NetApp.  ONTAP include diverse funzionalità di gestione e protezione dei dati, come la protezione automatica contro i ransomware e gli attacchi informatici, funzionalità integrate di trasporto dei dati e capacità di efficienza di archiviazione.  Questi vantaggi si applicano a una vasta gamma di architetture, da quelle on-premise a quelle multicloud ibride in NAS, SAN, storage object-defined e software-defined per distribuzioni LLM.  È possibile utilizzare un server di archiviazione oggetti ONTAP S3 in un cluster ONTAP per distribuire applicazioni RAG, sfruttando l'efficienza di archiviazione e la sicurezza di ONTAP, fornite tramite utenti autorizzati e applicazioni client.  Per maggiori informazioni, fare riferimento a<block ref="5ba5b9c5717eb24d2b5fdfe0fd9cfc0e" category="inline-link-rx"></block></block>
  <block id="c1b379b8a85b20135cbeae3496ac9cb9" category="inline-link">NetApp Trident su Git</block>
  <block id="05ff24c52b7f489f2df6dab1ac93a444" category="paragraph">Il software NetApp Trident è un orchestratore di storage open source e completamente supportato per container e distribuzioni Kubernetes, tra cui Red Hat OpenShift.  Trident funziona con l'intero portfolio di storage NetApp , incluso NetApp ONTAP , e supporta anche connessioni NFS e iSCSI.  Per maggiori informazioni, fare riferimento a<block ref="b09494428fb81fc17c232fdf3cd6ebfd" category="inline-link-rx"></block></block>
  <block id="7eef23b11d6e87eee968a9bef33fd707" category="cell">*Software*</block>
  <block id="45cc01ab5f209e8760027e9c30097025" category="cell">*Versione*</block>
  <block id="cec6a9b163aa2911c259a1fd129fafec" category="cell">Piattaforma RAG aziendale basata sui microservizi OPEA</block>
  <block id="7b02c13e31cd24ff2d950fc29a8f9d53" category="cell">Interfaccia di archiviazione del contenitore (driver CSI)</block>
  <block id="4d437b953db79f111d6140d4d62384e4" category="cell">Abilita il provisioning dinamico, le copie Snapshot NetApp e i volumi.</block>
  <block id="3d945423f8e9496c429a5d8c65b4604f" category="cell">Ubuntu</block>
  <block id="5e3add1fd258bd782aade74ed9a9877d" category="cell">22.04.5</block>
  <block id="d7ac58512991ed45f3abecbfbb9cddf1" category="cell">Orchestrazione dei contenitori</block>
  <block id="382fc90b48fccde9d59f816ea9dc9b4a" category="cell">Ambiente per eseguire il framework RAG</block>
  <block id="77e4d80ae2f4257081e17476b146608a" category="section-title">Distribuzione della soluzione</block>
  <block id="e137b1b38be73f6e2bb5d628d2325215" category="section-title">Stack software</block>
  <block id="4b9b3f178d68004f22177def38ac1a0a" category="paragraph">La soluzione è distribuita su un cluster Kubernetes costituito da nodi applicativi basati su Intel Xeon.  Per implementare l'alta disponibilità di base per il piano di controllo Kubernetes sono necessari almeno tre nodi.  Abbiamo convalidato la soluzione utilizzando il seguente layout di cluster.</block>
  <block id="9a5c044d129dc6879fa0ab37fdf1da36" category="paragraph">Tabella 3 - Layout del cluster Kubernetes</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">Nodo</block>
  <block id="bbbabdbe1b262f75d99d62880b953be1" category="cell">Ruolo</block>
  <block id="f6deba375b4908f8ab44946cb1ac15ec" category="cell">Server con processori Intel Xeon 6 e 1 TB di RAM</block>
  <block id="5e13dbdc232ae09e4bcf3ca30f51de88" category="cell">Nodo app, nodo piano di controllo</block>
  <block id="c8b75ba615f900ff258046bb36a7fc62" category="cell">Server generico</block>
  <block id="6f8f92d5847446fe4b0ae5b71badd7cd" category="cell">Nodo del piano di controllo</block>
  <block id="b1ee6de34c23dd606b6401a06907e658" category="inline-image-macro">600.600</block>
  <block id="13c96942dd3c3b3bdb84e02b2a303778" category="paragraph">La figura seguente illustra una "vista dello stack software" della soluzione.<block ref="841e6c807fed1e7947a5b7ebff264e4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8388066510b59c8d3387373b6969a7af" category="section-title">Fasi di distribuzione</block>
  <block id="6c00804e5ebc94e7610086e3e0f7e581" category="section-title">Distribuisci l'appliance di archiviazione ONTAP</block>
  <block id="ec6e72d1c4bb7dccdc62b6caf35c95f7" category="inline-link">Documentazione dei sistemi hardware ONTAP</block>
  <block id="c5ba881390fd2c8d5f9d0fb165ad1049" category="paragraph">Distribuisci e fornisci il tuo dispositivo di storage NetApp ONTAP .  Fare riferimento al<block ref="8f6fc8fb2a7bb6f821a0fddf6c335b91" category="inline-link-rx"></block> per i dettagli.</block>
  <block id="9df0c5d4eab5f45fac1c5ad20e8fdade" category="section-title">Configurare un ONTAP SVM per l'accesso NFS e S3</block>
  <block id="b0e271f740ae6f03e699c988b5b7c576" category="paragraph">Configurare una macchina virtuale di archiviazione ONTAP (SVM) per l'accesso NFS e S3 su una rete accessibile dai nodi Kubernetes.</block>
  <block id="05ef9b22209f0e35efc9b6f875ad3c55" category="inline-link">Documentazione ONTAP .</block>
  <block id="a647bfcaa1b11c3008439f5c2a0a888f" category="paragraph">Per creare una SVM utilizzando ONTAP System Manager, accedere a Storage &gt; Storage VM e fare clic sul pulsante + Aggiungi.  Quando si abilita l'accesso S3 per la SVM, scegliere l'opzione per utilizzare un certificato firmato da una CA (autorità di certificazione) esterna, non un certificato generato dal sistema.  È possibile utilizzare un certificato autofirmato oppure un certificato firmato da una CA pubblicamente attendibile.  Per ulteriori dettagli, fare riferimento al<block ref="9162972b1d9e1d587a9c620aa7cb22be" category="inline-link-rx"></block></block>
  <block id="59ea3be65306f9546fb9ed8da06a4fc4" category="paragraph">La seguente schermata illustra la creazione di una SVM utilizzando ONTAP System Manager.  Modifica i dettagli in base alle tue esigenze in base all'ambiente.</block>
  <block id="6e98de7098944681485c37173696a48b" category="section-title">Configurare le autorizzazioni S3</block>
  <block id="9e677f1fe64f248526596041ab78f505" category="paragraph">Configurare le impostazioni utente/gruppo S3 per l'SVM creato nel passaggio precedente.  Assicurati di avere un utente con accesso completo a tutte le operazioni API S3 per quella SVM.  Per maggiori dettagli, consultare la documentazione di ONTAP S3.</block>
  <block id="c00a2800b71457eb0e0cabb2511b615a" category="paragraph">Per modificare le autorizzazioni per questo utente, vai su Archiviazione &gt; VM di archiviazione, fai clic sul nome della SVM creata nel passaggio precedente, fai clic su Impostazioni, quindi fai clic sull'icona della matita accanto a "S3".  Per dare<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> accesso completo a tutte le operazioni API S3, crea un nuovo gruppo che associa<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> con il<block ref="0268c876e4588f7ad98bacb113933dab" prefix=" " category="inline-code"></block> politica come illustrato nello screenshot seguente.</block>
  <block id="3ce7236b065597bbadf2a14e9845558e" category="paragraph"><block ref="3ce7236b065597bbadf2a14e9845558e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cc27c397bf2aa7589869b84e048e24c" category="section-title">Crea un bucket S3</block>
  <block id="bd31776e6efcf27fc82ed6ba0862c4fb" category="paragraph">Crea un bucket S3 all'interno dell'SVM creato in precedenza.  Per creare una SVM utilizzando ONTAP System Manager, vai su Storage &gt; Bucket e fai clic sul pulsante + Aggiungi.  Per ulteriori dettagli, fare riferimento alla documentazione ONTAP S3.</block>
  <block id="0b755fcdfc7b6b61938269f21db3f841" category="paragraph">La seguente schermata illustra la creazione di un bucket S3 utilizzando ONTAP System Manager.</block>
  <block id="847d5eae44750df0abbb4d655d69c6a7" category="section-title">Configurare le autorizzazioni del bucket S3</block>
  <block id="c23ccda8191e76cb192f1bd40cae534b" category="paragraph">Configurare le autorizzazioni per il bucket S3 creato nel passaggio precedente.  Assicurati che l'utente configurato in un passaggio precedente disponga delle seguenti autorizzazioni:<block ref="82cabf6bd017130caa599103617f61df" prefix=" " category="inline-code"></block></block>
  <block id="c3bf5d608f066a6b405a40012a2fc10c" category="inline-link">Documentazione ONTAP S3</block>
  <block id="cc944a7541814572eb9767d03e306277" category="paragraph">Per modificare le autorizzazioni del bucket S3 tramite ONTAP System Manager, accedere a Storage &gt; Bucket, fare clic sul nome del bucket, fare clic su Autorizzazioni e quindi su Modifica.  Fare riferimento al<block ref="3c678e24d354397cff48df8b3cf3f717" category="inline-link-rx"></block> per ulteriori dettagli.</block>
  <block id="0d1bf17e818c5b150c239afaa05e5f17" category="paragraph">La seguente schermata illustra le autorizzazioni bucket necessarie in ONTAP System Manager.</block>
  <block id="000356058e153b3be211db974d645a75" category="section-title">Crea una regola di condivisione delle risorse multiorigine del bucket</block>
  <block id="004935665424a8d10e5e54b7140e97e1" category="paragraph">Utilizzando l'interfaccia della riga di comando ONTAP , crea una regola CORS (cross-origin resource sharing) per il bucket creato in un passaggio precedente:</block>
  <block id="d2a899c39e099bd681cfe52af554b20c" category="section-title">Distribuisci server</block>
  <block id="fa3bc02ffb34d7c680db187aa209dddd" category="paragraph">Distribuisci i tuoi server e installa Ubuntu 22.04 LTS su ogni server.  Dopo aver installato Ubuntu, installare le utility NFS su ogni server.  Per installare le utilità NFS, eseguire il seguente comando:</block>
  <block id="c17b9b6d3e5d228bcc6c08edc3438f7f" category="inline-link">Documentazione di installazione Trident</block>
  <block id="c64dcda39c59bb872461bbb0e651a561" category="paragraph">Quando<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block> è abilitato, l'applicazione controlla automaticamente i bucket S3 di origine per file nuovi o aggiornati.  Tutti i file nuovi o aggiornati rilevati durante questo processo di sincronizzazione vengono automaticamente acquisiti e aggiunti alla knowledge base RAG.  L'applicazione controlla i bucket di origine in base a un intervallo di tempo preimpostato.  L'intervallo di tempo predefinito è di 60 secondi, il che significa che l'applicazione verifica le modifiche ogni 60 secondi.  Potresti voler modificare questo intervallo in base alle tue esigenze specifiche.</block>
  <block id="71b202e61cbdf7d879691cc22fff5944" category="section-title">Acquisizione dati per RAG</block>
  <block id="1e5926c65c9a0919b7d73b19b2df9d53" category="paragraph">Ora è possibile acquisire file da includere nell'aumento delle query basato su RAG.  Esistono diverse opzioni per l'acquisizione dei file.  Scegli l'opzione più adatta alle tue esigenze.</block>
  <block id="1aab14042462d545cbc81ccbd5144183" category="section-title">Eseguire query di chat</block>
  <block id="2ed19e65997a81f69c25a47d5bf28407" category="paragraph">Nell'ambito del nostro impegno di convalida, abbiamo condotto test delle prestazioni in coordinamento con Intel.  Da questi test sono emerse le indicazioni sulle dimensioni riportate nella tabella seguente.</block>
  <block id="b0e166baec472090eb9b8fe69dd5736a" category="cell">Caratterizzazioni</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">Valore</block>
  <block id="a48c8e3a66454b67fa81ad9e940c8b27" category="cell">Dimensioni del modello</block>
  <block id="4f4ccdf1d741c3c95db91bbc2930fb82" category="cell">20 miliardi di parametri</block>
  <block id="9be9211aab4b7a1e7b93895b22cac265" category="cell">Llama-8B, Llama-13B, Mistral 7B, Qwen 14B, DeepSeek Distill 8B</block>
  <block id="5b176800a4fa5f818733bbc47bf50c58" category="cell">Dimensione di input</block>
  <block id="5da438d3d127ea08ac04b3ad27565f86" category="cell">~2k gettoni</block>
  <block id="ec110f5087b1200011dcf2f34914001b" category="cell">~4 pagine</block>
  <block id="2e422b9da98e2d0a7b8c31aa22986312" category="cell">Dimensione di output</block>
  <block id="0de7dbc3b2f780207078fda7fe5f5312" category="cell">Utenti simultanei</block>
  <block id="2dda44ea1754f4e550f1a5cc97bd2f88" category="cell">Per "utenti simultanei" si intendono le richieste rapide che inviano query contemporaneamente.</block>
  <block id="37bea4d3bbce78210e52efa42aff98fc" category="section-title">Riconoscimento</block>
  <block id="638409a97591a74cbaf8ecaac7bc356a" category="section-title">distinta base</block>
  <block id="faf3c2849bae24ab9045ae5add024400" category="paragraph">Di seguito è riportato il BOM utilizzato per la convalida funzionale di questa soluzione e può essere utilizzato come riferimento.  È possibile utilizzare qualsiasi server o componente di rete (o anche una rete esistente con larghezza di banda preferibilmente di 100 GbE) che si allinei alla seguente configurazione.</block>
  <block id="74953ad13674266e8135ca232d6d7d5d" category="paragraph">Per il server dell'app:</block>
  <block id="6737192650f0c3a81629128ea7774174" category="cell">*Codice parte*</block>
  <block id="eb6fa4e6fed41e388b4d654a174c1b82" category="cell">*Descrizione del prodotto*</block>
  <block id="a3b91229cc5a5eb0d50908cc956824b3" category="cell">222HA-TN-OTO-37</block>
  <block id="2302a4ae44cddff506100b112f4645c6" category="cell">Hyper SuperServer SYS-222HA-TN /2U</block>
  <block id="e53619c1fe611a51eeeb8d148ba6e532" category="cell">Memoria RAM</block>
  <block id="673b9923dda6787459c6a0ae7f711593" category="cell">MEM-DR564MC-ER64(x16)64GB DDR5-6400 2RX4 (16Gb) ECC RDIMM</block>
  <block id="0be247e8eaad16189d4e7ce0829add7a" category="cell">HDS-M2N4-960G0-E1-TXD-NON-080(x2) SSD M.2 NVMe PCIe4 960 GB 1DWPD TLC D, 80 mm</block>
  <block id="c3ca791a9361b57a8fa217067084b891" category="cell">Alimentatore ridondante a singola uscita WS-1K63A-1R(x2)1U da 692W/1600W.  Dissipazione del calore di 2361 BTU/ora con temperatura massima di 59 °C (circa)</block>
  <block id="7d83e48371fe2b2bd396527bf08497f1" category="paragraph">Per il server di controllo:</block>
  <block id="4bf51ddd79708218d2ca40addbf3f2fb" category="cell">511R-M-OTO-17</block>
  <block id="870f227b084b6f0c047a533d218e9874" category="cell">OTTIMIZZATO FINO A 1U X13SCH-SYS, CSE-813MF2TS-R0RCNBP, PWS-602A-1R</block>
  <block id="7c3e6ed807c306444b3bddd7fc90cb2a" category="cell">MEM-DR516MB-EU48(x2)UDIMM ECC DDR5-4800 1Rx8 (16Gb) da 16 GB</block>
  <block id="c104b47ab1794697f8c929d251599740" category="paragraph">Per lo switch di rete:</block>
  <block id="1bf595c07879a3e4909b5196570ee253" category="cell">DCS-7280CR3A</block>
  <block id="60e4b729f0a2b5471a6c6209bc49aac5" category="cell">Arista 7280R3A 28x100 GbE</block>
  <block id="40f46282e86b9c228e0cce6e2011f35c" category="paragraph">Archiviazione NetApp AFF :</block>
  <block id="39ff721f18a3edbb373a8c8f54cd3f14" category="cell">AFF-A20A-100-C</block>
  <block id="c133ed5a1928378c2f6a29bf6b6f1135" category="cell">Sistema AFF A20 HA, -C</block>
  <block id="52b142796a871ab98369e293ae4d91c2" category="cell">X800-42U-R6-C</block>
  <block id="c6b0cc56d77c17a08efb3742ab92e776" category="cell">Jumper Crd, In-Cab, C13-C14, -C</block>
  <block id="128bdeded7a535e68b0f98e463111407" category="cell">X97602A-C</block>
  <block id="f14bf71f2d74fbf0d0560b5a355bbf63" category="cell">Alimentatore, 1600W, Titanio, -C</block>
  <block id="2a0cfc5d71abb55759a510240510f87a" category="cell">X66211B-2-N-C</block>
  <block id="d50feb7d1470a9fb63d75f5a39b4b8bd" category="cell">Cavo, 100 GbE, QSFP28-QSFP28, Cu, 2 m, -C</block>
  <block id="9d4b1f9c3df948f2260e6332be9d5aed" category="cell">X66240A-05-N-C</block>
  <block id="7229ff7ba1f700db7ec3bd4b5221db26" category="cell">Cavo, 25 GbE, SFP28-SFP28, Cu, 0,5 m, -C</block>
  <block id="1ab2d2badc8592e1d029782bd25632a5" category="cell">X5532A-N-C</block>
  <block id="4688dd909d449010ca4b23347351a707" category="cell">Binario, 4 montanti, sottile, foro rotondo/quadrato, piccolo, regolabile, 24-32, -C</block>
  <block id="b24ac50247ba189d666fdae929cede64" category="cell">X4024A-2-A-C</block>
  <block id="25630a46b821a822994c9b1e0dd238d5" category="cell">Unità Pack 2X1,92 TB, NVMe4, SED, -C</block>
  <block id="326b6bb4ee61f9700e237d78e0a70b27" category="cell">X60130A-C</block>
  <block id="f2acaac754bf0c08463a09096b25ebd5" category="cell">Modulo IO, 2PT, 100 GbE, -C</block>
  <block id="826f0d850b56b5bcd6026118ee4048b5" category="cell">X60132A-C</block>
  <block id="f567279f3d616d5bcfbd134b1e39b047" category="cell">Modulo IO, 4PT, 10/25 GbE, -C</block>
  <block id="7090ee7c22ea0bf45e028538870d276f" category="cell">SW-ONTAPB-FLASH-A20-C</block>
  <block id="c2375e9a630d78f92c99f36859f2dc63" category="cell">SW, pacchetto base ONTAP , per TB, Flash, A20, -C</block>
  <block id="37693cfc748049e45d87b8c7d8b9aacd" category="cell">23</block>
  <block id="9bf497d692d0e146d05a76e3a34ae95f" category="inline-link-macro">Progetto OPEA</block>
  <block id="feeb32cac2847bc01bfab8eb7dfbbbfe" category="paragraph"><block ref="feeb32cac2847bc01bfab8eb7dfbbbfe" category="inline-link-macro-rx"></block></block>
  <block id="a64127d2271b6c8ff07ae84c3a53c90c" category="inline-link">Manuale di distribuzione OPEA Enterprise RAG</block>
  <block id="a5e99aa2ffae2218fdcf2038b1b3fd1b" category="doc">TR-4851: Data lake NetApp StorageGRID per carichi di lavoro di guida autonoma - Progettazione della soluzione</block>
  <block id="981ed5a5ebc4fbc2a64f69a42d9ef36c" category="paragraph">David Arnette, NetApp</block>
  <block id="0e2b7ed1591c52ac15ea956ecb6a5701" category="paragraph">TR-4851 dimostra l'uso dell'archiviazione di oggetti NetApp StorageGRID come repository di dati e sistema di gestione per lo sviluppo di software di apprendimento automatico (ML) e apprendimento profondo (DL).  In questo documento vengono descritti il flusso di dati e i requisiti nello sviluppo di software per veicoli autonomi, nonché le funzionalità StorageGRID che semplificano il ciclo di vita dei dati.  Questa soluzione si applica a qualsiasi flusso di lavoro di pipeline di dati multifase tipico dei processi di sviluppo ML e DL.</block>
  <block id="ba9a0dcacc73fb54c527ad33eceb30c1" category="paragraph"><block ref="ba9a0dcacc73fb54c527ad33eceb30c1" category="inline-link-macro-rx"></block></block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">Note legali</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="paragraph">Le note legali forniscono accesso a dichiarazioni di copyright, marchi commerciali, brevetti e altro ancora.</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">Copyright</block>
  <block id="52009bb7ee17227f566cd26a02caee56" category="inline-link-macro"><block ref="52009bb7ee17227f566cd26a02caee56" category="inline-link-rx"></block></block>
  <block id="a1a9afcf552a769c282769271829889a" category="paragraph"><block ref="a1a9afcf552a769c282769271829889a" category="inline-link-macro-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">Marchi</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NETAPP, il logo NETAPP e i marchi elencati nella pagina Marchi NetApp sono marchi di NetApp, Inc. Altri nomi di aziende e prodotti possono essere marchi dei rispettivi proprietari.</block>
  <block id="f99aa604031e5049799e73b5c3748a98" category="inline-link-macro"><block ref="f99aa604031e5049799e73b5c3748a98" category="inline-link-rx"></block></block>
  <block id="5d545fe5152641e2ebe654e336e520e5" category="paragraph"><block ref="5d545fe5152641e2ebe654e336e520e5" category="inline-link-macro-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">Brevetti</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">Un elenco aggiornato dei brevetti di proprietà di NetApp è disponibile all'indirizzo:</block>
  <block id="88e5eabd3917048b6927c42496b98f86" category="inline-link-macro"><block ref="88e5eabd3917048b6927c42496b98f86" category="inline-link-rx"></block></block>
  <block id="dd38f906b37d412de7d1c1dcf4cbf31c" category="paragraph"><block ref="dd38f906b37d412de7d1c1dcf4cbf31c" category="inline-link-macro-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">Politica sulla riservatezza</block>
  <block id="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-macro"><block ref="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-rx"></block></block>
  <block id="2352c4e1f4d0024ade0869e00e6243f4" category="paragraph"><block ref="2352c4e1f4d0024ade0869e00e6243f4" category="inline-link-macro-rx"></block></block>
  <block id="91bc87f1c8c087219cec868bb9eec3e7" category="summary">Per questa convalida, abbiamo eseguito l'inferenza per un caso d'uso di rilevamento delle immagini utilizzando un set di immagini grezze.  Abbiamo quindi eseguito lo stesso compito di inferenza sullo stesso set di immagini aggiungendo l'offuscamento Protopia prima dell'inferenza.  Abbiamo ripetuto l'attività utilizzando diversi valori di ALPHA per il componente di offuscamento di Protopia.</block>
  <block id="f63c4677c27e0489f346c0711720cc39" category="doc">Confronto dell'accuratezza dell'inferenza</block>
  <block id="0c71eb4e1fba60fba81db988197da57d" category="paragraph">Per questa convalida, abbiamo eseguito l'inferenza per un caso d'uso di rilevamento delle immagini utilizzando un set di immagini grezze.  Abbiamo quindi eseguito lo stesso compito di inferenza sullo stesso set di immagini aggiungendo l'offuscamento Protopia prima dell'inferenza.  Abbiamo ripetuto l'attività utilizzando diversi valori di ALPHA per il componente di offuscamento di Protopia.  Nel contesto dell'offuscamento di Protopia, il valore ALPHA rappresenta la quantità di offuscamento applicata, dove un valore ALPHA più alto rappresenta un livello di offuscamento più elevato.  Abbiamo poi confrontato l'accuratezza dell'inferenza in queste diverse esecuzioni.</block>
  <block id="93d52a2c23957d4188c7b2ce8b2ae884" category="paragraph">Le due tabelle seguenti forniscono dettagli sul nostro caso d'uso e ne descrivono i risultati.</block>
  <block id="65a3419ae19e457df9db4c0e110b2538" category="paragraph">Protopia collabora direttamente con i clienti per determinare il valore ALPHA appropriato per un caso d'uso specifico.</block>
  <block id="e558777bd1568637c97294a33389e930" category="cell">FaceBoxes (PyTorch) -</block>
  <block id="20172a059ee71423ad0d94393e819e10" category="cell">Set di dati FDDB</block>
  <block id="06a8fb4576a28a6488c929097c870fe1" category="cell">Offuscamento della protopia</block>
  <block id="002101f8725e5c78d9f30d87f3fa4c87" category="cell">ALFA</block>
  <block id="d78f1fb7e69f7cddcf3e168f2663db20" category="cell">Precisione</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">NO</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">N / A</block>
  <block id="646738dcd35eaf5c3f3c9bfdc6a90b78" category="cell">0,9337148153739079</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">SÌ</block>
  <block id="b14399cbaac6da4b5b733b483106383f" category="cell">0,05</block>
  <block id="bcf8c22771ff8c7065180f5a6526d4a6" category="cell">0,9028766627325002</block>
  <block id="cb5ae17636e975f9bf71ddf5bc542075" category="cell">0,1</block>
  <block id="1336b1cb08d93aa0a453c53e27efa594" category="cell">0,9024301009661478</block>
  <block id="3d522deaf85577451c01974654b36ad3" category="cell">0,2</block>
  <block id="b1cb1b288bfae3850c74795f5691dc4e" category="cell">0,9081836283186224</block>
  <block id="54fbf38cf649866815e0fefc46a1f6c7" category="cell">0,4</block>
  <block id="b9e8c964d5c5d3e7c815896cd6235239" category="cell">0,9073066107482036</block>
  <block id="e95e1ca27d0e39aa03eb5a611ce4122f" category="cell">0,6</block>
  <block id="57489d9101ec373d9e2841292a5b3af9" category="cell">0,8847816568680239</block>
  <block id="57eeec0a6974ecb4e9fcf68fab052f7b" category="cell">0,8</block>
  <block id="8ab8d7756b82eb70d635bc66c1bc532b" category="cell">0,8841195749171925</block>
  <block id="a894124cc6d5c5c71afe060d5dde0762" category="cell">0,9</block>
  <block id="226cc0951c1f30973a4c71f0f567936a" category="cell">0,8455427675252052</block>
  <block id="248a7444f08189bb31ba143eabebe4e5" category="cell">0,95</block>
  <block id="cf285ec96f684d6597b7ffbbfcf16197" category="doc">Dove trovare ulteriori informazioni e ringraziamenti</block>
  <block id="89f170193efdf8434f549c8e91adf860" category="list-text">Protopia AI: inferenza riservata</block>
  <block id="62faa8d62bfb6098877b809cce925de5" category="inline-link"><block ref="62faa8d62bfb6098877b809cce925de5" category="inline-link-rx"></block></block>
  <block id="45b79877f4c11139882c88df94d50fa6" category="paragraph"><block ref="45b79877f4c11139882c88df94d50fa6" category="inline-link-rx"></block></block>
  <block id="2c5e74d45708e2fae638e03f88353b75" category="list-text">Server di inferenza NVIDIA Triton</block>
  <block id="2c54e28a12ce15452929a28550a30a96" category="inline-link"><block ref="2c54e28a12ce15452929a28550a30a96" category="inline-link-rx"></block></block>
  <block id="bc5345c4517d46bdf8a87f10d404839f" category="paragraph"><block ref="bc5345c4517d46bdf8a87f10d404839f" category="inline-link-rx"></block></block>
  <block id="fba4b133e329411c361e02e05efed0b9" category="list-text">Documentazione del server di inferenza NVIDIA Triton</block>
  <block id="cce40efbd4a717916ccbab694b676e9c" category="inline-link"><block ref="cce40efbd4a717916ccbab694b676e9c" category="inline-link-rx"></block></block>
  <block id="170ba65f4e4807f3643de39afb3f2e16" category="paragraph"><block ref="170ba65f4e4807f3643de39afb3f2e16" category="inline-link-rx"></block></block>
  <block id="ba1d5cc71378020998752955821460b2" category="list-text">FaceBox in PyTorch</block>
  <block id="ace8d80d2ede0fadf07325408b376b83" category="inline-link"><block ref="ace8d80d2ede0fadf07325408b376b83" category="inline-link-rx"></block></block>
  <block id="a688d324b63c4f882d06673058aa2f61" category="paragraph"><block ref="a688d324b63c4f882d06673058aa2f61" category="inline-link-rx"></block></block>
  <block id="121ef407a6a3c08ce9fa247e382d7637" category="list-text">Mark Cates, Responsabile prodotti principali, NetApp</block>
  <block id="fb345adb43ea24ffc891d20327bdca09" category="list-text">Sufian Ahmad, Ingegnere tecnico di marketing, NetApp</block>
  <block id="711ba3fec382e550526a6ab0f49bdf3a" category="list-text">Hadi Esmaeilzadeh, Direttore tecnico e professore, Protopia AI</block>
  <block id="cd24a85c5cf2d1a7af0bade6066be0aa" category="summary">I dati esistono in tre stati: a riposo, in transito e in elaborazione.  Una parte importante di qualsiasi servizio di inferenza AI dovrebbe essere la protezione dei dati dalle minacce durante l'intero processo.  La protezione dei dati durante l'inferenza è fondamentale perché il processo può rivelare informazioni private sia sui clienti esterni sia sull'azienda che fornisce il servizio di inferenza.</block>
  <block id="cd9ef21e97d9c9e701bfc6d1a77634d5" category="paragraph">I dati esistono in tre stati: a riposo, in transito e in elaborazione.  Una parte importante di qualsiasi servizio di inferenza AI dovrebbe essere la protezione dei dati dalle minacce durante l'intero processo.  La protezione dei dati durante l'inferenza è fondamentale perché il processo può rivelare informazioni private sia sui clienti esterni sia sull'azienda che fornisce il servizio di inferenza.  Protopia AI è una soluzione software non invasiva per l'inferenza IA riservata nel mercato odierno.  Con Protopia, l'IA riceve solo le informazioni trasformate nei record di dati essenziali per svolgere l'attività di IA/ML in questione e nient'altro.  Questa trasformazione stocastica non è una forma di mascheramento e si basa sulla modifica matematica della rappresentazione dei dati mediante l'utilizzo di rumore curato.</block>
  <block id="945691f1b395ce7af4d5e818b4e62b9b" category="paragraph">I sistemi di storage NetApp con funzionalità ONTAP garantiscono prestazioni uguali o migliori rispetto allo storage SSD locale e, in combinazione con NetApp DataOps Toolkit, offrono i seguenti vantaggi a data scientist, data engineer, sviluppatori di intelligenza artificiale/apprendimento automatico e responsabili delle decisioni IT aziendali:</block>
  <block id="2d1d64cb5768a8ce2a6d6bda322d2ecd" category="list-text">Protezione dei dati e governance dei dati di livello aziendale per il disaster recovery, la continuità aziendale e i requisiti normativi.</block>
  <block id="58b8e67477c25a96d3b430f4ee8d75cf" category="list-text">Invocazione semplificata delle operazioni di gestione dei dati; creazione rapida di copie snapshot degli spazi di lavoro dei data scientist per il backup e la tracciabilità dal NetApp DataOps Toolkit nei notebook Jupyter.</block>
  <block id="57e858ddb0a3e1c340cfe4ba7d5c3a14" category="paragraph">La soluzione NetApp e Protopia fornisce un'architettura flessibile e scalabile, ideale per implementazioni di inferenza AI di livello aziendale.  Consente la protezione dei dati e garantisce la privacy delle informazioni sensibili, laddove i requisiti di inferenza AI riservata possono essere soddisfatti con pratiche di AI responsabili sia nelle distribuzioni on-premise che in quelle cloud ibride.</block>
  <block id="a41206687a4ac62c15fc883554a75883" category="summary">Questa sezione descrive l'ambiente di convalida della progettazione della soluzione.</block>
  <block id="0d013965bb31fe1cc0ba44ef3b846d09" category="paragraph">La tabella seguente descrive l'ambiente di convalida della progettazione della soluzione.</block>
  <block id="30136395f01879792198317c11831ea4" category="cell">Kubernetes</block>
  <block id="32f014d18e1f60596057834de2864322" category="cell">1.21.6</block>
  <block id="8b2b11d27dd7d347de30cae2db2ab86d" category="cell">Driver NetApp Trident CSI</block>
  <block id="8e232cd005846e0f66f39f19aa03103c" category="cell">22.01.0</block>
  <block id="297924c1d3fec9d97f9a1f3b49ee0709" category="cell">Kit degli strumenti NetApp DataOps per Kubernetes</block>
  <block id="70e2b24f7d348efe6b30b41469d5070c" category="cell">2.3.0</block>
  <block id="099d96b4d8f70fb73f1d4661f98c337a" category="cell">21.11-py3</block>
  <block id="6d01d0026564c98aa0d6274cd39c586a" category="summary">Questo documento descrive una soluzione di progettazione convalidata in tre diversi scenari con e senza offuscamento delle immagini, rilevante per preservare la privacy e implementare una soluzione di intelligenza artificiale responsabile.</block>
  <block id="236e54165aafef697c2c82c667e05d36" category="doc">TR-4928: IA responsabile e inferenza riservata - NetApp AI con trasformazione di immagini e dati Protopia</block>
  <block id="0bbb7f0a0d464779fc0832c366f3a4e7" category="paragraph">Sathish Thyagarajan, Michael Oglesby, NetApp Byung Hoon Ahn, Jennifer Cwagenberg, Protopia</block>
  <block id="c110f3156d66710a207ebd7135164ec1" category="paragraph">Con l'avvento della cattura e dell'elaborazione delle immagini, le interpretazioni visive sono diventate parte integrante della comunicazione.  L'intelligenza artificiale (IA) nell'elaborazione delle immagini digitali offre nuove opportunità di business, ad esempio in campo medico per l'identificazione del cancro e di altre malattie, nell'analisi visiva geospaziale per lo studio dei rischi ambientali, nel riconoscimento di modelli, nell'elaborazione video per la lotta alla criminalità e così via.  Tuttavia, questa opportunità comporta anche delle responsabilità straordinarie.</block>
  <block id="0159205b6d54375adfabd56a2258fcb9" category="paragraph">Più decisioni le organizzazioni affidano all'intelligenza artificiale, più accettano rischi legati alla privacy e alla sicurezza dei dati, nonché a questioni legali, etiche e normative.  L'intelligenza artificiale responsabile consente una pratica che consente alle aziende e alle organizzazioni governative di creare fiducia e governance, fondamentali per l'intelligenza artificiale su larga scala nelle grandi aziende.  Questo documento descrive una soluzione di inferenza AI convalidata da NetApp in tre scenari diversi, utilizzando le tecnologie di gestione dei dati NetApp con il software di offuscamento dei dati Protopia per privatizzare i dati sensibili e ridurre i rischi e le preoccupazioni etiche.</block>
  <block id="fade8b24490b0ba74a7ffa05d3f8631a" category="paragraph">Ogni giorno milioni di immagini vengono generate tramite vari dispositivi digitali, sia da consumatori che da aziende.  La conseguente enorme esplosione di dati e di carico di lavoro computazionale spinge le aziende a rivolgersi alle piattaforme di cloud computing per ottenere scalabilità ed efficienza.  Nel frattempo, sorgono preoccupazioni relative alla privacy delle informazioni sensibili contenute nei dati delle immagini con il trasferimento su un cloud pubblico.  La mancanza di garanzie di sicurezza e privacy diventa il principale ostacolo all'implementazione di sistemi di intelligenza artificiale per l'elaborazione delle immagini.</block>
  <block id="e9ac7ec9dd27fe52477986ab1dccbcae" category="inline-link">diritto alla cancellazione</block>
  <block id="49dca35d3e0662046425327194fd8965" category="inline-link">Legge sulla privacy</block>
  <block id="f615b294f87bd53494e01691ab95c654" category="paragraph">Inoltre, c'è il<block ref="ac9ac606204db63758cb1efd6e89e43e" category="inline-link-rx"></block> dal GDPR, il diritto di un individuo di richiedere a un'organizzazione di cancellare tutti i suoi dati personali.  C'è anche il<block ref="fd57f794f9c27951b4a5b543db96bdb6" category="inline-link-rx"></block> , che stabilisce un codice di corrette pratiche informative.  Le immagini digitali, come le fotografie, possono costituire dati personali ai sensi del GDPR, che disciplina le modalità di raccolta, elaborazione e cancellazione dei dati.  La mancata osservanza di tale norma costituisce una violazione del GDPR, che potrebbe comportare pesanti sanzioni per violazione delle norme, con conseguenti gravi danni per le organizzazioni.  I principi di privacy sono tra i pilastri dell'implementazione di un'intelligenza artificiale responsabile che garantisca l'equità nelle previsioni dei modelli di apprendimento automatico (ML) e di apprendimento profondo (DL) e riduca i rischi associati alla violazione della privacy o della conformità normativa.</block>
  <block id="d365f4ef3ed2b414236f81df850880a3" category="paragraph">Questo documento descrive una soluzione di progettazione convalidata in tre diversi scenari con e senza offuscamento delle immagini, rilevanti per preservare la privacy e implementare una soluzione di intelligenza artificiale responsabile:</block>
  <block id="bd12a6b0ed0be7808c1e30b1e360bee6" category="list-text">*Scenario 1.*  Inferenza su richiesta all'interno del notebook Jupyter.</block>
  <block id="bf93b5af78256f2e49d2c0351133b08d" category="list-text">*Scenario 2.*  Inferenza batch su Kubernetes.</block>
  <block id="d5a10e810e1d293a064388e4980bde15" category="list-text">*Scenario 3.*  Server di inferenza NVIDIA Triton.</block>
  <block id="870f1cf4b101c66b438e8dd024f24118" category="paragraph">Per questa soluzione utilizziamo il Face Detection Data Set and Benchmark (FDDB), un set di dati di regioni del viso progettato per studiare il problema del rilevamento del viso senza vincoli, combinato con il framework di apprendimento automatico PyTorch per l'implementazione di FaceBox.  Questo set di dati contiene le annotazioni per 5171 volti in un set di 2845 immagini di varie risoluzioni.  Inoltre, questo rapporto tecnico presenta alcune delle aree di soluzione e dei casi d'uso rilevanti raccolti dai clienti NetApp e dai tecnici sul campo in situazioni in cui questa soluzione è applicabile.</block>
  <block id="e28a169eb64ee1d32c878a26595922f0" category="paragraph">Il presente rapporto tecnico è destinato ai seguenti destinatari:</block>
  <block id="167e9693dfa764051f26b64ec22356a9" category="list-text">Leader aziendali e architetti aziendali che desiderano progettare e implementare un'intelligenza artificiale responsabile e affrontare le problematiche relative alla protezione dei dati e alla privacy relative all'elaborazione delle immagini facciali negli spazi pubblici.</block>
  <block id="304e871b0b1ea55fe3e4f07ead7a7d42" category="list-text">Data scientist, data engineer, ricercatori di intelligenza artificiale/apprendimento automatico (ML) e sviluppatori di sistemi di intelligenza artificiale/ML che mirano a proteggere e preservare la privacy.</block>
  <block id="dcf26996b3ab9f385a95f72c1d0a0dce" category="list-text">Architetti aziendali che progettano soluzioni di offuscamento dei dati per modelli e applicazioni AI/ML conformi agli standard normativi quali GDPR, CCPA o il Privacy Act del Dipartimento della Difesa (DoD) e delle organizzazioni governative.</block>
  <block id="bb6887ed7c7b07cbb7bd3ec71f951e6f" category="list-text">Data scientist e ingegneri dell'intelligenza artificiale cercano modi efficienti per implementare modelli di deep learning (DL) e di inferenza AI/ML/DL che proteggano le informazioni sensibili.</block>
  <block id="69adf8f52a6229e7062bda4b2b9679fb" category="paragraph">Questa soluzione è progettata per gestire carichi di lavoro di intelligenza artificiale in tempo reale e in batch su grandi set di dati, sfruttando la potenza di elaborazione delle GPU insieme alle CPU tradizionali.  Questa convalida dimostra l'inferenza che preserva la privacy per l'apprendimento automatico e la gestione ottimale dei dati richiesta alle organizzazioni che cercano implementazioni di intelligenza artificiale responsabili.  Questa soluzione fornisce un'architettura adatta per una piattaforma Kubernetes a nodo singolo o multiplo per l'edge computing e il cloud computing interconnessi con NetApp ONTAP AI nel core on-premise, NetApp DataOps Toolkit e il software di offuscamento Protopia utilizzando le interfacce Jupyter Lab e CLI.  La figura seguente mostra la panoramica dell'architettura logica del data fabric basato su NetApp con DataOps Toolkit e Protopia.</block>
  <block id="28afcbd6e097b781313de9c75adccb13" category="paragraph"><block ref="28afcbd6e097b781313de9c75adccb13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7dfea85fd355e4966805c3504348aa8b" category="paragraph">Il software di offuscamento Protopia funziona perfettamente su NetApp DataOps Toolkit e trasforma i dati prima di lasciare il server di archiviazione.</block>
  <block id="46ded0be5f6c48090d38435b6dafa3e2" category="summary">Questa sezione fornisce una panoramica dei tre scenari convalidati in questa soluzione.</block>
  <block id="71446ef316489c70b5279867eb81a86b" category="doc">Piano di test e convalida</block>
  <block id="68cdc250e271cc43502e5f009d0ebec7" category="paragraph">Per la progettazione di questa soluzione sono stati convalidati i seguenti tre scenari:</block>
  <block id="83c38d8dc6bc37fe6bb9691e75d0f881" category="list-text">Un'attività di inferenza, con e senza offuscamento Protopia, all'interno di un'area di lavoro JupyterLab, orchestrata utilizzando NetApp DataOps Toolkit per Kubernetes.</block>
  <block id="da4ec54ac3b4b67b77d52ccf0ebaefc0" category="list-text">Un lavoro di inferenza batch, con e senza offuscamento Protopia, su Kubernetes con un volume di dati orchestrato utilizzando NetApp DataOps Toolkit per Kubernetes.</block>
  <block id="5526e24c695504cfa8b2187b0a3da212" category="list-text">Un'attività di inferenza che utilizza un'istanza di NVIDIA Triton Inference Server, orchestrata tramite NetApp DataOps Toolkit per Kubernetes.  Abbiamo applicato l'offuscamento di Protopia all'immagine prima di richiamare l'API di inferenza Triton per simulare il requisito comune secondo cui tutti i dati trasmessi sulla rete devono essere offuscati.  Questo flusso di lavoro è applicabile ai casi d'uso in cui i dati vengono raccolti all'interno di una zona attendibile ma devono essere trasmessi al di fuori di tale zona attendibile per l'inferenza.  Senza l'offuscamento di Protopia, non è possibile implementare questo tipo di flusso di lavoro senza che i dati sensibili escano dalla zona attendibile.</block>
  <block id="6bee97571af49e4c38ff85a4abbbe0e9" category="summary">In questa sezione vengono descritte le attività necessarie per completare la convalida.</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">Prerequisiti</block>
  <block id="df06a8aa3d194f798e70c253c55d915c" category="paragraph">Per eseguire le attività descritte in questa sezione, è necessario avere accesso a un host Linux o macOS con i seguenti strumenti installati e configurati:</block>
  <block id="c0ffe26d3756a5c964ff9bc591e1fc16" category="list-text">Kubectl (configurato per l'accesso a un cluster Kubernetes esistente)</block>
  <block id="e436fe7c4ecfcca0f0327b41471955df" category="list-text">Le istruzioni per l'installazione e la configurazione possono essere trovate<block ref="f6d4f9e359e394de0cb3015a4518672c" category="inline-link-rx"></block> .</block>
  <block id="e3e34254666d96b8967227676b54e135" category="list-text">Le istruzioni di installazione possono essere trovate<block ref="9535953c30e005e9672e48b24a3ac733" category="inline-link-rx"></block> .</block>
  <block id="1a66086f406852b100e9d8f85d007b87" category="section-title">Scenario 1 – Inferenza su richiesta in JupyterLab</block>
  <block id="28876e2d40a33fcbc3630d7408b14046" category="list-text">Creare uno spazio dei nomi Kubernetes per carichi di lavoro di inferenza AI/ML.</block>
  <block id="1464ad61957a8ed3db5f67edbc20cc41" category="list-text">Utilizzare NetApp DataOps Toolkit per predisporre un volume persistente in cui archiviare i dati su cui eseguire l'inferenza.</block>
  <block id="da33a6119aa0b49526bd284e9a865ed5" category="list-text">Utilizzare NetApp DataOps Toolkit per creare un nuovo spazio di lavoro JupyterLab.  Montare il volume persistente creato nel passaggio precedente utilizzando<block ref="49477e975a03ac8fbc68aea44a67d49d" prefix=" " category="inline-code"></block> opzione.  Assegnare le GPU NVIDIA all'area di lavoro secondo necessità utilizzando<block ref="dfc4755b60ee7dfab3c1e88693efd099" prefix=" " category="inline-code"></block> opzione.</block>
  <block id="810e88d69a6b7f454f24db3a25ba375a" category="paragraph">Nell'esempio seguente, il volume persistente<block ref="682303bbf677ac9a205caf2d086b33d3" prefix=" " category="inline-code"></block> è montato sul contenitore dell'area di lavoro JupyterLab in<block ref="a88bf20c35f897f8c2c3a03189e90c09" prefix=" " category="inline-code"></block> .  Quando si utilizzano immagini ufficiali del contenitore Project Jupyter,<block ref="3b8e9b793a1a95056575343e279719df" prefix=" " category="inline-code"></block> viene presentata come directory di primo livello all'interno dell'interfaccia web di JupyterLab.</block>
  <block id="ecca64929aad192e0cdba66d89af6fc2" category="list-text">Accedi all'area di lavoro JupyterLab utilizzando l'URL specificato nell'output del<block ref="d9eb9b67c69b49a1b002e09de33d9ed9" prefix=" " category="inline-code"></block> comando.  La directory dati rappresenta il volume persistente montato nell'area di lavoro.</block>
  <block id="87209231def3204e4e4d9a18544294dd" category="paragraph"><block ref="87209231def3204e4e4d9a18544294dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5989087fa6f30a7b2ad79b3b28f4f68" category="list-text">Apri il<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block> directory e caricare i file su cui eseguire l'inferenza.  Quando i file vengono caricati nella directory dati, vengono automaticamente archiviati sul volume persistente montato nell'area di lavoro.  Per caricare i file, fare clic sull'icona Carica file, come mostrato nell'immagine seguente.</block>
  <block id="e3b5f0c1efdf69526c759b1d33d05e5b" category="paragraph"><block ref="e3b5f0c1efdf69526c759b1d33d05e5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6da42e23b9d4e193c2fb146b8189581" category="list-text">Torna alla directory di livello superiore e crea un nuovo notebook.</block>
  <block id="8c8d84a9a1e17bebaa40920247f46e13" category="paragraph"><block ref="8c8d84a9a1e17bebaa40920247f46e13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d6d5c0ae1c38484d2d4fd513ff80f90" category="list-text">Aggiungere il codice di inferenza al notebook.  L'esempio seguente mostra il codice di inferenza per un caso d'uso di rilevamento delle immagini.</block>
  <block id="cf7a1e02f4be1c22e175847fae951746" category="paragraph"><block ref="cf7a1e02f4be1c22e175847fae951746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fa1b8c326d7c59c16ba99f22361e9e4" category="paragraph"><block ref="9fa1b8c326d7c59c16ba99f22361e9e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="296d40736553e2033f5cf8817174bc7c" category="list-text">Aggiungi l'offuscamento Protopia al tuo codice di inferenza.  Protopia collabora direttamente con i clienti per fornire documentazione specifica per i casi d'uso e non rientra nell'ambito di questo rapporto tecnico.  L'esempio seguente mostra il codice di inferenza per un caso d'uso di rilevamento delle immagini con aggiunta dell'offuscamento Protopia.</block>
  <block id="a782d09a204dcf45c8852abf7684c340" category="paragraph"><block ref="a782d09a204dcf45c8852abf7684c340" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b937401d5d173ae3750bccadcff9481e" category="paragraph"><block ref="b937401d5d173ae3750bccadcff9481e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5709eb5c3d3d4a700397ee447f9818" category="section-title">Scenario 2 – Inferenza batch su Kubernetes</block>
  <block id="77b69d61f1889c8321dce66f3c3e2e1a" category="list-text">Popolare il nuovo volume persistente con i dati su cui si eseguirà l'inferenza.</block>
  <block id="8b6983cc7986c7b0553983d8ab669289" category="inline-link">Funzionalità di NetApp DataOps Toolkit S3 Data Mover</block>
  <block id="685f44c17611b1391b579c696f310b98" category="paragraph">Esistono diversi metodi per caricare dati su un PVC.  Se i tuoi dati sono attualmente archiviati in una piattaforma di archiviazione di oggetti compatibile con S3, come NetApp StorageGRID o Amazon S3, puoi utilizzare<block ref="5d1617256d53e0547b237f3cf3fda5b0" category="inline-link-rx"></block> .  Un altro metodo semplice è quello di creare uno spazio di lavoro JupyterLab e quindi caricare i file tramite l'interfaccia web di JupyterLab, come descritto nei passaggi da 3 a 5 nella sezione "<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block> ."</block>
  <block id="a62147e18dbac7ad5eab17791c371ad4" category="list-text">Crea un processo Kubernetes per la tua attività di inferenza batch.  L'esempio seguente mostra un processo di inferenza batch per un caso d'uso di rilevamento delle immagini.  Questo lavoro esegue l'inferenza su ciascuna immagine in un set di immagini e scrive le metriche di accuratezza dell'inferenza su stdout.</block>
  <block id="a883fb9f7bda67c6fbcab6dfb8f091ce" category="list-text">Conferma che il processo di inferenza è stato completato correttamente.</block>
  <block id="590888c60942c47f5268c19f273109ee" category="list-text">Aggiungi l'offuscamento di Protopia al tuo lavoro di inferenza.  È possibile trovare istruzioni specifiche per i casi d'uso per aggiungere l'offuscamento di Protopia direttamente da Protopia, il che esula dall'ambito di questo rapporto tecnico.  L'esempio seguente mostra un processo di inferenza batch per un caso d'uso di rilevamento facciale con offuscamento Protopia aggiunto utilizzando un valore ALPHA di 0,8.  Questo lavoro applica l'offuscamento di Protopia prima di eseguire l'inferenza per ogni immagine in un set di immagini e quindi scrive le metriche di accuratezza dell'inferenza su stdout.</block>
  <block id="babeb9cd0280f29f38c9a4c3029f7ba0" category="inline-link-macro">Confronto dell'accuratezza dell'inferenza.</block>
  <block id="f4d99d417d0adde7f8d0f1a70caac126" category="paragraph">Abbiamo ripetuto questo passaggio per i valori ALPHA 0,05, 0,1, 0,2, 0,4, 0,6, 0,8, 0,9 e 0,95.  Puoi vedere i risultati in<block ref="b3380bdc8f9311566c95bcb62c7aea42" category="inline-link-macro-rx"></block></block>
  <block id="76d6540fbdbbcd913fb6272a50d0e3f2" category="section-title">Scenario 3 – Server di inferenza NVIDIA Triton</block>
  <block id="c470d7124546c64e8539c39ced806428" category="list-text">Utilizzare NetApp DataOps Toolkit per predisporre un volume persistente da utilizzare come repository di modelli per NVIDIA Triton Inference Server.</block>
  <block id="1ddcb92ade31c8fbd370001f9b29a7d9" category="inline-link">formato</block>
  <block id="898dfcda591317ac60dd8d6af3aff189" category="list-text">Memorizza il tuo modello sul nuovo volume persistente in un<block ref="2001a6caf72de652d98c6c64bc75a4e8" category="inline-link-rx"></block> riconosciuto dal server di inferenza NVIDIA Triton.</block>
  <block id="23ed8d1b8cbc461ebdbedcdb67ee7718" category="paragraph">Esistono diversi metodi per caricare dati su un PVC.  Un metodo semplice è quello di creare uno spazio di lavoro JupyterLab e quindi caricare i file tramite l'interfaccia web di JupyterLab, come descritto nei passaggi da 3 a 5 in "<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block> .  "</block>
  <block id="fc35606f82a544f9c79f09561d7a234d" category="list-text">Utilizzare NetApp DataOps Toolkit per distribuire una nuova istanza di NVIDIA Triton Inference Server.</block>
  <block id="27a920b35a8f949700a98b22803c70fc" category="list-text">Utilizzare un SDK client Triton per eseguire un'attività di inferenza.  Il seguente estratto di codice Python utilizza l'SDK client Python Triton per eseguire un'attività di inferenza per un caso d'uso di rilevamento dei volti.  Questo esempio richiama l'API Triton e passa un'immagine per l'inferenza.  Il server di inferenza Triton riceve quindi la richiesta, richiama il modello e restituisce l'output di inferenza come parte dei risultati dell'API.</block>
  <block id="7b5e296090a5d063fdbd3ebb69fc6547" category="list-text">Aggiungi l'offuscamento Protopia al tuo codice di inferenza.  È possibile trovare istruzioni specifiche per i casi d'uso per aggiungere l'offuscamento di Protopia direttamente da Protopia; tuttavia, questo processo esula dall'ambito di questo rapporto tecnico.  L'esempio seguente mostra lo stesso codice Python mostrato nel passaggio 5 precedente, ma con l'aggiunta dell'offuscamento di Protopia.</block>
  <block id="c3069165ee6fb9d5dde8d8472d8b4602" category="paragraph">Si noti che l'offuscamento Protopia viene applicato all'immagine prima che venga passata all'API Triton.  In questo modo, l'immagine non offuscata non lascia mai la macchina locale.  Solo l'immagine offuscata viene trasmessa attraverso la rete.  Questo flusso di lavoro è applicabile ai casi d'uso in cui i dati vengono raccolti all'interno di una zona attendibile ma devono poi essere trasmessi al di fuori di tale zona attendibile per l'inferenza.  Senza l'offuscamento di Protopia, non è possibile implementare questo tipo di flusso di lavoro senza che i dati sensibili escano dalla zona attendibile.</block>
  <block id="fb0e25ed6b061ae8d5a55a94457e445e" category="summary">Per questa convalida, abbiamo applicato l'offuscamento Protopia a un'immagine da 1920 x 1080 pixel cinque volte e abbiamo misurato il tempo impiegato ogni volta per completare la fase di offuscamento.</block>
  <block id="9c6852dd5556b48ff70dd2583a5d3aa0" category="doc">Velocità di offuscamento</block>
  <block id="6977bb3543f8de6dcfa78f7970349ba1" category="paragraph">Abbiamo utilizzato PyTorch in esecuzione su una singola GPU NVIDIA V100 per applicare l'offuscamento e abbiamo cancellato la cache della GPU tra un'esecuzione e l'altra.  La fase di offuscamento ha richiesto rispettivamente 5,47 ms, 5,27 ms, 4,54 ms, 5,24 ms e 4,84 ms per essere completata nelle cinque esecuzioni.  La velocità media è stata di 5,072 ms.</block>
  <block id="4c787c1632a0a940cb0b44706b1d24c6" category="summary">Questa sezione fornisce una panoramica dei vari componenti tecnici necessari per completare questa soluzione.</block>
  <block id="a6d48b22bcf266404bdb8c57102c14a4" category="section-title">Protopia</block>
  <block id="b2cbc1ff8afd6c872961a852572e1782" category="paragraph">Protopia AI offre oggi sul mercato una soluzione software discreta per l'inferenza riservata.  La soluzione Protopia offre una protezione senza pari per i servizi di inferenza riducendo al minimo l'esposizione di informazioni sensibili.  All'intelligenza artificiale vengono fornite solo le informazioni presenti nel record di dati che sono realmente essenziali per svolgere il compito in questione e nient'altro.  La maggior parte delle attività di inferenza non utilizza tutte le informazioni presenti in ogni record di dati.  Indipendentemente dal fatto che la tua intelligenza artificiale utilizzi immagini, voce, video o persino dati tabellari strutturati, Protopia fornisce solo ciò di cui il servizio di inferenza ha bisogno.  La tecnologia di base brevettata utilizza rumore elaborato matematicamente per trasformare in modo stocastico i dati e confondere le informazioni non necessarie per un determinato servizio di apprendimento automatico.  Questa soluzione non maschera i dati, ma ne modifica la rappresentazione utilizzando rumore casuale curato.</block>
  <block id="46ce082967eab6fe2e33798614d50861" category="paragraph">La soluzione Protopia formula il problema della modifica della rappresentazione come un metodo di massimizzazione della perturbazione basato sul gradiente che conserva comunque le informazioni pertinenti nello spazio delle caratteristiche di input rispetto alla funzionalità del modello.  Questo processo di scoperta viene eseguito come passaggio di messa a punto al termine dell'addestramento del modello ML.  Dopo che il passaggio genera automaticamente un set di distribuzioni di probabilità, una trasformazione dei dati a basso overhead applica campioni di rumore da queste distribuzioni ai dati, offuscandoli prima di passarli al modello per l'inferenza.</block>
  <block id="af2063646dcea30a4bac90a1c51b14aa" category="section-title">NetApp ONTAP AI</block>
  <block id="4fb9892dc0183c3142a3629cecc3104a" category="paragraph">L'architettura di riferimento NetApp ONTAP AI, basata sui sistemi DGX A100 e sui sistemi di storage connessi al cloud NetApp , è stata sviluppata e verificata da NetApp e NVIDIA.  Offre alle organizzazioni IT un'architettura che offre i seguenti vantaggi:</block>
  <block id="9c6bd300c8cf3ca98c8548bbb27cc34a" category="list-text">Elimina le complessità di progettazione</block>
  <block id="cee5abf75433f502c31530bc72eecd6a" category="list-text">Consente il ridimensionamento indipendente di elaborazione e archiviazione</block>
  <block id="eccaf37681e446d183db0332d1e50552" category="list-text">Consente ai clienti di iniziare in piccolo e di crescere senza problemi</block>
  <block id="410a2fbd85ad3d74051034eac2b94889" category="list-text">Offre una gamma di opzioni di archiviazione per vari livelli di prestazioni e costi</block>
  <block id="988d7b305f79b990bbacdaed46f4b2bf" category="paragraph">ONTAP AI integra strettamente i sistemi DGX A100 e i sistemi di storage NetApp AFF A800 con reti all'avanguardia.  ONTAP AI semplifica le implementazioni dell'intelligenza artificiale eliminando la complessità di progettazione e le congetture.  I clienti possono iniziare in piccolo e crescere senza interruzioni, gestendo in modo intelligente i dati dall'edge al core, al cloud e viceversa.</block>
  <block id="57e22b018aa5130ece9890cd6b45e779" category="paragraph">La figura seguente mostra diverse varianti della famiglia di soluzioni ONTAP AI con sistemi DGX A100.  Le prestazioni del sistema AFF A800 vengono verificate con un massimo di otto sistemi DGX A100.  Aggiungendo coppie di controller di storage al cluster ONTAP , l'architettura può essere scalata su più rack per supportare molti sistemi DGX A100 e petabyte di capacità di storage con prestazioni lineari.  Questo approccio offre la flessibilità di modificare i rapporti tra elaborazione e storage in modo indipendente, in base alle dimensioni dei modelli DL utilizzati e alle metriche prestazionali richieste.</block>
  <block id="a28d0dc585dd816bf7bcce4c5f5f6dd9" category="paragraph"><block ref="a28d0dc585dd816bf7bcce4c5f5f6dd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ecc164061fb57b585c892f0faa6f4dcf" category="inline-link">NVA-1153: NetApp ONTAP AI con sistemi NVIDIA DGX A100 e switch Ethernet Mellanox Spectrum.</block>
  <block id="3046083f382853b50c004323f2cda8f9" category="paragraph">Per ulteriori informazioni su ONTAP AI, vedere<block ref="2c1616ab9baa55036487e7ef75b3821d" category="inline-link-rx"></block></block>
  <block id="862dcadd0f2887701abaa60bf59d5aa5" category="paragraph">ONTAP 9.11, l'ultima generazione di software di gestione dello storage di NetApp, consente alle aziende di modernizzare l'infrastruttura e passare a un data center pronto per il cloud.  Sfruttando le funzionalità di gestione dei dati leader del settore, ONTAP consente la gestione e la protezione dei dati con un unico set di strumenti, indipendentemente da dove risiedano.  È inoltre possibile spostare liberamente i dati ovunque siano necessari: edge, core o cloud.  ONTAP 9.11 include numerose funzionalità che semplificano la gestione dei dati, accelerano e proteggono i dati critici e abilitano le funzionalità infrastrutturali di nuova generazione nelle architetture cloud ibride.</block>
  <block id="94c4b42bd5bfaa12f328387b161a1686" category="paragraph">NetApp DataOps Toolkit è una libreria Python che semplifica per sviluppatori, data scientist, ingegneri DevOps e data engineer l'esecuzione di varie attività di gestione dei dati, come il provisioning quasi istantaneo di un nuovo volume di dati o di un'area di lavoro JupyterLab, la clonazione quasi istantanea di un volume di dati o di un'area di lavoro JupyterLab e l'acquisizione quasi istantanea di snapshot di un volume di dati o di un'area di lavoro JupyterLab per la tracciabilità o la baselining.  Questa libreria Python può funzionare sia come utilità da riga di comando sia come libreria di funzioni che è possibile importare in qualsiasi programma Python o notebook Jupyter.</block>
  <block id="2dcb054d023d8770b9ba0125434b8f20" category="paragraph">NVIDIA Triton Inference Server è un software di inferenza open source che aiuta a standardizzare la distribuzione e l'esecuzione dei modelli per fornire un'intelligenza artificiale rapida e scalabile in produzione.  Triton Inference Server semplifica l'inferenza dell'IA consentendo ai team di distribuire, eseguire e scalare modelli di IA addestrati da qualsiasi framework su qualsiasi infrastruttura basata su GPU o CPU.  Triton Inference Server supporta tutti i principali framework, come TensorFlow, NVIDIA TensorRT, PyTorch, MXNet, OpenVINO e così via.  Triton si integra con Kubernetes per l'orchestrazione e il ridimensionamento, che puoi utilizzare in tutte le principali piattaforme di intelligenza artificiale e Kubernetes del cloud pubblico.  È inoltre integrato con numerose soluzioni software MLOps.</block>
  <block id="6532191b754c006509ce4006a972990e" category="paragraph"><block ref="7b17fc2d2143dfdbd3bff6783f73e17c" category="inline-link-rx"></block>è un framework ML open source.  Si tratta di una libreria di tensori ottimizzata per l'apprendimento profondo che utilizza GPU e CPU.  Il pacchetto PyTorch contiene strutture dati per tensori multidimensionali che, tra le altre utili utilità, forniscono numerose utilità per la serializzazione efficiente dei tensori.  Dispone inoltre di una controparte CUDA che consente di eseguire i calcoli dei tensori su una GPU NVIDIA con capacità di elaborazione.  In questa convalida, utilizziamo la libreria OpenCV-Python (cv2) per convalidare il nostro modello, sfruttando al contempo i concetti di visione artificiale più intuitivi di Python.</block>
  <block id="cdea8196113c492688981e0a035baa29" category="list-text">Prestazioni e latenza più bassa.  ONTAP offre la massima capacità di trasmissione possibile con la minima latenza possibile.</block>
  <block id="fa126db4297464dd03b3ceef190df0d0" category="list-text">Protezione dei dati.  ONTAP offre funzionalità integrate di protezione dei dati con gestione comune su tutte le piattaforme.</block>
  <block id="1f17e94c6f48114ff29ad3267277420c" category="list-text">Multitenancy e autenticazione multifattore.  ONTAP consente la condivisione delle risorse infrastrutturali con i massimi livelli di sicurezza.</block>
  <block id="b816bfff9511bcd88a9aa06fe0fd6389" category="list-text">Scalabilità fluida e operazioni senza interruzioni.  ONTAP supporta l'aggiunta non distruttiva di capacità ai controller esistenti e ai cluster scalabili.  I clienti possono effettuare l'aggiornamento alle tecnologie più recenti, come NVMe e FC da 32 Gb, senza costose migrazioni di dati o interruzioni.</block>
  <block id="377c9a91b43c5423691b5ce75db91350" category="section-title">Controllo NetApp Astra</block>
  <block id="35b46e301702b6fcb16192f9f4cf4533" category="inline-link">Servizio di controllo Astra</block>
  <block id="eb75cc706ac8cc6c0f4cb17f4fb073dd" category="paragraph">La famiglia di prodotti NetApp Astra offre servizi di gestione dei dati e di storage basati sulle applicazioni per le applicazioni Kubernetes in sede e nel cloud pubblico, basati sulle tecnologie di gestione dei dati e di storage NetApp .  Consente di eseguire facilmente il backup delle applicazioni Kubernetes, migrare i dati su un cluster diverso e creare istantaneamente cloni di applicazioni funzionanti.  Se devi gestire le applicazioni Kubernetes in esecuzione in un cloud pubblico, consulta la documentazione per<block ref="6d442ad773e9d31651277931acd1583a" category="inline-link-rx"></block> .  Astra Control Service è un servizio gestito da NetApp che fornisce una gestione dei dati basata sulle applicazioni dei cluster Kubernetes in Google Kubernetes Engine (GKE) e Azure Kubernetes Service (AKS).</block>
  <block id="545b3003eeeed3a05db492712188eaa8" category="paragraph">Astra<block ref="b792e70a7bbe82fe69049fd18abe3c18" category="inline-link-rx"></block> di NetApp è un orchestratore di storage dinamico open source per Docker e Kubernetes che semplifica la creazione, la gestione e l'utilizzo di storage persistente.  Trident, un'applicazione nativa di Kubernetes, viene eseguita direttamente all'interno di un cluster Kubernetes.  Trident consente ai clienti di distribuire senza problemi immagini di container DL sullo storage NetApp e fornisce un'esperienza di livello aziendale per le distribuzioni di container AI.  Gli utenti di Kubernetes (sviluppatori ML, data scientist e così via) possono creare, gestire e automatizzare l'orchestrazione e la clonazione per sfruttare le funzionalità avanzate di gestione dei dati basate sulla tecnologia NetApp .</block>
  <block id="45a189f17e7eec44ce720f6a979e501e" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block>è un servizio NetApp per la sincronizzazione rapida e sicura dei dati.  Che tu debba trasferire file tra condivisioni file NFS o SMB locali, NetApp StorageGRID, NetApp ONTAP S3, Google Cloud NetApp Volumes, Azure NetApp Files, Amazon Simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS), Azure Blob, Google Cloud Storage o IBM Cloud Object Storage, BlueXP Copy and Sync sposta i file dove ti servono in modo rapido e sicuro.  Una volta trasferiti, i dati saranno completamente disponibili per l'uso sia sulla sorgente che sulla destinazione.  BlueXP Copy and Syncc sincronizza costantemente i dati in base alla pianificazione predefinita, spostando solo i delta, in modo da ridurre al minimo il tempo e il denaro spesi per la replica dei dati.  BlueXP Copy and Sync è uno strumento software-as-a-service (SaaS) estremamente semplice da configurare e utilizzare.  I trasferimenti di dati attivati da BlueXP Copy and Sync vengono eseguiti da broker di dati.  È possibile distribuire i broker di dati BlueXP Copy and Sync su AWS, Azure, Google Cloud Platform o in locale.</block>
  <block id="b8bc3287c1345ab1a36c796d2de0aaa2" category="section-title">Classificazione NetApp BlueXP</block>
  <block id="196f1872673d3381d912260929325605" category="paragraph">Guidato da potenti algoritmi di intelligenza artificiale,<block ref="860dd213c65646bc2292a7454f4cfbac" category="inline-link-rx"></block> fornisce controlli automatizzati e governance dei dati sull'intero patrimonio di dati.  È possibile individuare facilmente risparmi sui costi, identificare problemi di conformità e privacy e trovare opportunità di ottimizzazione.  La dashboard di classificazione BlueXP fornisce informazioni utili per identificare i dati duplicati per eliminare la ridondanza, mappare i dati personali, non personali e sensibili e attivare avvisi per dati sensibili e anomalie.</block>
  <block id="c46aabfbeb0af662ede62f7325853fa2" category="summary">L'elaborazione digitale delle immagini offre numerosi vantaggi, consentendo a molte organizzazioni di sfruttare al meglio i dati associati alle rappresentazioni visive.  Questa soluzione NetApp e Protopia fornisce un design di inferenza AI unico per proteggere e privatizzare i dati AI/ML durante l'intero ciclo di vita ML/DL.  Consente ai clienti di mantenere la proprietà dei dati sensibili, di utilizzare modelli di distribuzione cloud pubblici o ibridi per ottenere scalabilità ed efficienza, attenuando le preoccupazioni relative alla privacy, e di implementare l'inferenza AI all'edge.</block>
  <block id="55ece983a5251583397e3db1cd3926ec" category="section-title">Intelligenza ambientale</block>
  <block id="d0f24bc92f5b7838f03e893b41066a90" category="paragraph">Esistono molti modi in cui le industrie possono trarre vantaggio dall'analisi geospaziale nei settori dei rischi ambientali.  I governi e il dipartimento dei lavori pubblici possono ricavare informazioni utili sulla salute pubblica e sulle condizioni meteorologiche per fornire migliori consigli al pubblico durante una pandemia o un disastro naturale come gli incendi boschivi.  Ad esempio, è possibile identificare un paziente positivo al COVID in spazi pubblici, come aeroporti o ospedali, senza compromettere la privacy della persona interessata e avvisare le autorità competenti e il pubblico nelle vicinanze per le necessarie misure di sicurezza.</block>
  <block id="4f9352e4f65872238d755155cd23edec" category="section-title">Dispositivi indossabili Edge</block>
  <block id="315a1bbca88dbcbdc95471a0061c333f" category="paragraph">In ambito militare e sui campi di battaglia, è possibile utilizzare l'inferenza dell'intelligenza artificiale sui dispositivi indossabili per monitorare la salute dei soldati, monitorare il comportamento dei conducenti e avvisare le autorità sulla sicurezza e sui rischi associati all'avvicinamento di veicoli militari, preservando e proteggendo al contempo la privacy dei soldati.  Il futuro dell'esercito è all'insegna dell'alta tecnologia con l'Internet of Battlefield Things (IoBT) e l'Internet of Military Things (IoMT) per equipaggiamenti da combattimento indossabili che aiutano i soldati a identificare i nemici e a ottenere prestazioni migliori in battaglia utilizzando il rapid edge computing.  Proteggere e preservare i dati visivi raccolti da dispositivi edge come droni e dispositivi indossabili è fondamentale per tenere a bada hacker e nemici.</block>
  <block id="d6dded41a42f767150e641793fc0c929" category="section-title">Operazioni di evacuazione non combattenti</block>
  <block id="c5b381de9b2a4ee73bcc524aa380d725" category="paragraph">Le operazioni di evacuazione dei non combattenti (NEO) sono condotte dal Dipartimento della Difesa per aiutare a evacuare cittadini e cittadini statunitensi, personale civile del Dipartimento della Difesa e persone designate (cittadini della nazione ospitante (HN) e cittadini di paesi terzi (TCN)) la cui vita è in pericolo verso un rifugio sicuro appropriato.  I controlli amministrativi in atto utilizzano in larga parte processi manuali di selezione degli sfollati.  Tuttavia, l'accuratezza, la sicurezza e la velocità dell'identificazione degli sfollati, del loro tracciamento e dello screening delle minacce potrebbero essere potenzialmente migliorate utilizzando strumenti di intelligenza artificiale/apprendimento automatico altamente automatizzati combinati con tecnologie di offuscamento video basate su intelligenza artificiale/apprendimento automatico.</block>
  <block id="19c95c19bd7c939577775cd0ecce3df1" category="section-title">Assistenza sanitaria e ricerca biomedica</block>
  <block id="a047c61461aba5a84a0a221900c33984" category="paragraph">L'elaborazione delle immagini viene utilizzata per diagnosticare patologie ai fini della pianificazione chirurgica a partire da immagini 3D ottenute tramite tomografia computerizzata (TC) o risonanza magnetica (RM).  Le norme sulla privacy HIPAA disciplinano il modo in cui le organizzazioni devono raccogliere, elaborare e cancellare i dati di tutte le informazioni personali e le immagini digitali, come le fotografie.  Affinché i dati possano essere considerati condivisibili ai sensi delle normative HIPAA Safe Harbor, è necessario rimuovere le immagini fotografiche a viso intero e qualsiasi immagine comparabile.  Tecniche automatizzate come gli algoritmi di deidentificazione o di estrazione del cranio, utilizzati per oscurare i tratti del viso di un individuo dalle immagini strutturali TC/RM, sono diventate una parte essenziale del processo di condivisione dei dati per gli istituti di ricerca biomedica.</block>
  <block id="2d930616ec617ae047b7b7eaefb0822c" category="section-title">Migrazione cloud dell'analisi AI/ML</block>
  <block id="073395e7b5fc53b602884ac0aaf757fb" category="inline-link">protezione dei dati</block>
  <block id="2c5c3872e94de8a36eac45213c5bf2e6" category="paragraph">Tradizionalmente i clienti aziendali hanno formato e distribuito modelli di intelligenza artificiale/apprendimento automatico in sede.  Per ragioni di economie di scala ed efficienza, questi clienti si stanno espandendo per spostare le funzioni di intelligenza artificiale/apprendimento automatico in implementazioni cloud pubbliche, ibride o multi-cloud.  Tuttavia, sono vincolati dai dati che possono essere esposti ad altre infrastrutture.  Le soluzioni NetApp affrontano una gamma completa di minacce alla sicurezza informatica richieste per<block ref="9da3a9a08c9461b229d33f221e8caa37" category="inline-link-rx"></block> e valutazione della sicurezza e, se combinati con la trasformazione dei dati di Protopia, riducono al minimo i rischi associati alla migrazione dei carichi di lavoro di elaborazione delle immagini AI/ML sul cloud.</block>
  <block id="c9f2e6462caf995f1d336ab4bb33a7c2" category="inline-link-macro">Inferenza AI TR-4886 al limite</block>
  <block id="ae1b6ac445119145d739025d55fe616f" category="inline-link">Intelligenza contro privacy</block>
  <block id="7c93429acdde399d280f2e20425ac745" category="paragraph">Per ulteriori casi d'uso per l'edge computing e l'inferenza dell'intelligenza artificiale in altri settori, vedere<block ref="c2ef3f1fa710d59c08d58b9025616182" category="inline-link-macro-rx"></block> e il blog NetApp AI,<block ref="bc130be57ffb0325128dc7274bbdbc64" category="inline-link-rx"></block> .</block>
  <block id="59a6ec9eb2075dc5ac847799c3c9b4e0" category="summary">MLOps multicloud ibrido con Domino Data Lab e NetApp : dove trovare ulteriori informazioni</block>
  <block id="3887d417240a72ab69f6d0301efd3b2b" category="doc">Dove trovare ulteriori informazioni</block>
  <block id="44997fb529c7b7d20853c30af9ad918a" category="list-text">Domino Data Lab</block>
  <block id="1182c61de35b31af3e72f77e61442c77" category="inline-link-macro"><block ref="1182c61de35b31af3e72f77e61442c77" category="inline-link-rx"></block></block>
  <block id="bd0007c3dcc92207ee01f0427da0a4be" category="paragraph"><block ref="bd0007c3dcc92207ee01f0427da0a4be" category="inline-link-macro-rx"></block></block>
  <block id="d7574cd2803b94ddaa90cab193a19ba2" category="list-text">Domino Nexus</block>
  <block id="2703dd45bd40545fb60997c2d3afe208" category="inline-link-macro"><block ref="2703dd45bd40545fb60997c2d3afe208" category="inline-link-rx"></block></block>
  <block id="14a3e5a8d5046236b5959a8860c405eb" category="paragraph"><block ref="14a3e5a8d5046236b5959a8860c405eb" category="inline-link-macro-rx"></block></block>
  <block id="1273c8a63109161e6fd1f18d6998523f" category="list-text">NetApp BlueXP</block>
  <block id="43e196fd7d1a86adce26084a27e3d664" category="inline-link-macro"><block ref="43e196fd7d1a86adce26084a27e3d664" category="inline-link-rx"></block></block>
  <block id="2edabab990aa6b9914f978e6885781f2" category="paragraph"><block ref="2edabab990aa6b9914f978e6885781f2" category="inline-link-macro-rx"></block></block>
  <block id="5339d389f2f896062fb28b05454dc94a" category="list-text">Software di gestione dati NetApp ONTAP</block>
  <block id="5b8aea48f614361f60f00e194e1b0976" category="inline-link-macro"><block ref="5b8aea48f614361f60f00e194e1b0976" category="inline-link-rx"></block></block>
  <block id="59f3782142c74894e9aa57873085e394" category="paragraph"><block ref="59f3782142c74894e9aa57873085e394" category="inline-link-macro-rx"></block></block>
  <block id="13ed1686110be86a2aeef6d76d4ec65e" category="list-text">Soluzioni di intelligenza artificiale NetApp</block>
  <block id="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-macro"><block ref="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-rx"></block></block>
  <block id="501b3e03ab68e967ec7e74647ece575b" category="paragraph"><block ref="501b3e03ab68e967ec7e74647ece575b" category="inline-link-macro-rx"></block></block>
  <block id="5acaa2031a97473b7a185dc30ce9e62d" category="list-text">Josh Mineroff, Direttore di SA per le alleanze tecnologiche, Domino Data Lab</block>
  <block id="ed2311020217442776d108d1f99b7521" category="list-text">Nicholas Jablonski, CTO sul campo, Domino Data Lab</block>
  <block id="5c38b0c6106b026873b5212202e5eb20" category="list-text">Prabu Arjunan, Architetto di soluzioni, NetApp</block>
  <block id="958996b71437140af7dadceec3c0acf1" category="list-text">Brian Young, Direttore dell'alleanza globale, Technology Alliance Partners, NetApp</block>
  <block id="182f685e8ff46f3bde7c8c63a6d3e8eb" category="summary">MLOps multicloud ibrido con Domino Data Lab e NetApp - Architettura</block>
  <block id="22a02f1b77fcd49462c4d58a6e2425fb" category="paragraph">Questa soluzione combina le funzionalità di pianificazione dei carichi di lavoro multicloud ibridi di Domino Nexus con i servizi dati NetApp per creare una piattaforma MLOps cloud ibrida unificata.  Per i dettagli, vedere la tabella seguente.</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="cell">Ambiente</block>
  <block id="1a01eb6a884a288b667e023501d09eea" category="cell">Piano di controllo MLOps</block>
  <block id="51c0d15bebbbdb19d5e1bde9bf2bc1ba" category="inline-link-macro">Piattaforma di intelligenza artificiale Domino Enterprise con Domino Nexus</block>
  <block id="a0133d74aa4167bee7ec6bb2830b32ab" category="cell"><block ref="a0133d74aa4167bee7ec6bb2830b32ab" category="inline-link-macro-rx"></block></block>
  <block id="4847e034bb0a55fcbc8a3380d6a3ab80" category="cell">AWS</block>
  <block id="dedb71b645ad83baa13a64e834ea32a3" category="cell">Ambienti di elaborazione della piattaforma MLOps</block>
  <block id="1f26213ee3d03d1bce28558ef8ff15ff" category="inline-link-macro">Piani dati Domino Nexus</block>
  <block id="f2d3c460a5a76b316899ec775650d7ea" category="cell"><block ref="f2d3c460a5a76b316899ec775650d7ea" category="inline-link-macro-rx"></block></block>
  <block id="89f5a1a21bf30d5f2db943911b2d22f2" category="cell">AWS, data center in sede</block>
  <block id="1698863d644408b6fdc41803a6a1c234" category="cell">Piattaforma di elaborazione on-premise</block>
  <block id="2c02a900da9ea696e0b13c405974ca0b" category="cell"><block ref="e08fa5b25dd32bed0a8727bee0e3fdd0" category="inline-link-macro-rx"></block>con<block ref="c8e9826c7461e34f8a6ee68d2d629f27" category="inline-link-macro-rx"></block></block>
  <block id="59f10558cba0587bc03fb56826f8cd4b" category="cell">Data center in sede</block>
  <block id="29e13ea538f81a8bf3cea3900519c8a1" category="cell">Piattaforma di cloud computing</block>
  <block id="480c9b5f979d1ce95ea2a58b09826d1b" category="inline-link-macro">Servizio Amazon Elastic Kubernetes (EKS)</block>
  <block id="ff969739d0750911a50d47ea892fad80" category="cell"><block ref="4ecdb2c4c840fbc0e496687cc8bf58fe" category="inline-link-macro-rx"></block>con<block ref="c8e9826c7461e34f8a6ee68d2d629f27" category="inline-link-macro-rx"></block></block>
  <block id="cd3aefaae18f11e3ecc3de62739183f3" category="cell">Piattaforma dati on-premise</block>
  <block id="e16a11bc6041db3c2b26ef054c8b8847" category="inline-link-macro">Dispositivo di archiviazione NetApp</block>
  <block id="b331d50869bea7c3b019d322cffc1f03" category="cell"><block ref="ea0807fcd7c8182254e93c3bfdf94abc" category="inline-link-macro-rx"></block>offerto da<block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="0c9ae535d9e81d6e268c0ea087be535f" category="cell">Piattaforma dati cloud</block>
  <block id="35f7c29efc923e8a7920a0b331095d71" category="inline-link-macro">Amazon FSx ONTAP</block>
  <block id="2a9165a68b73a53b924deda7b9ec0251" category="cell"><block ref="2a9165a68b73a53b924deda7b9ec0251" category="inline-link-macro-rx"></block></block>
  <block id="b497a71f092b521e07c06ade7296c159" category="paragraph"><block ref="b497a71f092b521e07c06ade7296c159" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f92651ef1a171bf24e3a0279a4f656f" category="summary">MLOps multicloud ibrido con Domino Data Lab e NetApp : accedi agli stessi dati in ambienti diversi</block>
  <block id="2167fcd754f38c037a8a5fc219634638" category="doc">Accedi agli stessi dati in ambienti diversi</block>
  <block id="2b2213cc89a71238bd2629046704d311" category="paragraph">In questa sezione vengono descritte le attività che devono essere eseguite per accedere agli stessi dati in diversi ambienti di elaborazione.  Nella piattaforma Domino MLOps, gli ambienti di elaborazione sono denominati "piani dati".  Seguire le attività descritte in questa sezione se i dati risiedono su un volume NetApp in un piano dati, ma è necessario accedervi in un altro piano dati.  Questo tipo di scenario viene spesso definito "bursting" o, quando l'ambiente di destinazione è il cloud, "cloud bursting".  Questa capacità è spesso necessaria quando si ha a che fare con risorse di elaborazione limitate o sovraccaricate.  Ad esempio, se il cluster di elaborazione locale è sovraccaricato, potresti voler pianificare i carichi di lavoro sul cloud, dove potranno essere avviati immediatamente.</block>
  <block id="8e259831056b970e9e9ad97044e756ea" category="paragraph">Per accedere a un volume NetApp che risiede in un piano dati diverso, sono consigliate due opzioni.  Queste opzioni sono descritte nelle sottosezioni seguenti.  Scegli una di queste opzioni in base alle tue esigenze specifiche.  I vantaggi e gli svantaggi delle due opzioni sono descritti nella tabella seguente.</block>
  <block id="054b4f3ea543c990f6b125f41af6ebf7" category="cell">Opzione</block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="cell">Benefici</block>
  <block id="0cfc0523189294ac086e11c8e286ba2d" category="cell">Svantaggi</block>
  <block id="a5a315a3bc09fc65d5b92a61203e604b" category="cell">Opzione 1 - Cache</block>
  <block id="542d0200f163f8f3533463dd59fe0270" category="cell">- Flusso di lavoro più semplice - Possibilità di memorizzare nella cache un sottoinsieme di dati in base alle esigenze - Possibilità di riscrivere i dati nella sorgente - Nessuna copia remota da gestire</block>
  <block id="7426e3bde1c62fb806a70f18c6134316" category="cell">- Aumento della latenza nell'accesso iniziale ai dati poiché la cache viene idratata.</block>
  <block id="aaa4d30d61e64cea712b7c05c68eb117" category="cell">Opzione 2 - Specchio</block>
  <block id="cbefd7ef29f92291b21681c43ba469b7" category="cell">- Copia completa del volume sorgente - Nessun aumento di latenza dovuto all'idratazione della cache (dopo il completamento dell'operazione di mirroring)</block>
  <block id="03dab0d003c274e0f366cd0df3efb059" category="cell">- È necessario attendere il completamento dell'operazione di mirroring prima di accedere ai dati. - È necessario gestire una copia remota. - Non è possibile riscrivere sulla sorgente.</block>
  <block id="f794ea935b3f3b976964bf0990d05005" category="section-title">Opzione 1: creare una cache di un volume che risiede in un piano dati diverso</block>
  <block id="79849c69657d54d5bfdd901f71375897" category="inline-link-macro">Tecnologia NetApp FlexCache</block>
  <block id="a816bf9775484a9a7049d55ece7f5396" category="paragraph">Con<block ref="bb0419306e9b544a3e597acbf1d444f1" category="inline-link-macro-rx"></block> , è possibile creare una cache di un volume NetApp che risiede in un piano dati diverso.  Ad esempio, se hai un volume NetApp nel tuo piano dati locale e devi accedere a quel volume nel tuo piano dati AWS, puoi creare una cache del volume in AWS.  In questa sezione vengono descritte le attività che devono essere eseguite per creare una cache di un volume NetApp che risiede in un piano dati diverso.</block>
  <block id="d93488703b54616875bcacc4afd140a7" category="section-title">Crea volume FlexCache nell'ambiente di destinazione</block>
  <block id="5d03f3f921e1e11afbd6bc02646a4b6f" category="admonition">Se l'ambiente di destinazione è il data center locale, creerai il volume FlexCache sul sistema ONTAP locale.  Se l'ambiente di destinazione è AWS, creerai il volume FlexCache sulla tua istanza Amazon FSx ONTAP .</block>
  <block id="a53f62411ee21cbe84822e3eba531ca4" category="paragraph">Per prima cosa, è necessario creare un volume FlexCache nell'ambiente di destinazione.</block>
  <block id="671e0b00bec7311fe1a27ae3b1374868" category="inline-link-macro">Documentazione BlueXP volume caching</block>
  <block id="25d1d7fbc173abf20974acc2fd19014b" category="paragraph">Si consiglia di utilizzare BlueXP per creare il volume FlexCache .  Per creare un volume FlexCache con BlueXP, seguire le istruzioni descritte in<block ref="13882193b90946980fb2e14f0dc3f833" category="inline-link-macro-rx"></block> .</block>
  <block id="597fd5f01aeae294735b75c08203b6dd" category="paragraph">Se preferisci non utilizzare BlueXP, puoi utilizzare ONTAP System Manager o ONTAP CLI per creare il volume FlexCache .  Per creare un volume FlexCache con System Manager, fare riferimento alle istruzioni descritte in<block ref="01bbf1f7353a360c52874272bfd82e21" category="inline-link-macro-rx"></block> .  Per creare un volume FlexCache con ONTAP CLI, fare riferimento alle istruzioni descritte in<block ref="91e4088944fb7c016c63d36e00422b16" category="inline-link-macro-rx"></block> .</block>
  <block id="e4de6f9df9cd48ef525131de3cb21481" category="inline-link-macro">API BlueXP</block>
  <block id="0ec641cfacd36c8e22a334135e2abdac" category="inline-link-macro">API REST ONTAP</block>
  <block id="ebf440be7bdce857e55ec25910ae837b" category="inline-link-macro">Raccolta ONTAP Ansible</block>
  <block id="dd7a007ea7e610e168238b6d6ab542a1" category="paragraph">Se desideri automatizzare questo processo, puoi utilizzare il<block ref="f07bcb7e875f8bb20680b339fb58364a" category="inline-link-macro-rx"></block> , IL<block ref="0966e902a53f3a5becbd165bbdc18e79" category="inline-link-macro-rx"></block> , o il<block ref="62c3d824298cc8f488bda82279b91e73" category="inline-link-macro-rx"></block> .</block>
  <block id="2f37e297d79532f437d3ab48727a61c0" category="admonition">System Manager non è disponibile in Amazon FSx ONTAP.</block>
  <block id="20f99b2a7f22945f3d769fa1def1e403" category="section-title">Esporre il volume FlexCache a Domino</block>
  <block id="c9743d6f9b7fcd7047ce3eb9d1f2a273" category="inline-link-macro">Sezione "Esponi volumi NetApp esistenti a Domino"</block>
  <block id="82a25bd099304632e33529b36f2ac5de" category="paragraph">Successivamente, è necessario esporre il volume FlexCache alla piattaforma Domino MLOps.  Per esporre il volume FlexCache a Domino, seguire le istruzioni descritte nella sottosezione "Esporre volumi NFS esistenti che non sono stati forniti da Trident" del<block ref="37f39ecc5e06a679f4975effd49fb9b8" category="inline-link-macro-rx"></block> di questa soluzione.</block>
  <block id="1d25e828bd3386ce7ef8b97572c88781" category="paragraph">Ora sarà possibile montare il volume FlexCache quando si avviano processi e spazi di lavoro nel piano dati di destinazione, come mostrato nelle schermate seguenti.</block>
  <block id="edaa69742537cd645340e6ec55f0e7c2" category="section-title">Prima di creare il volume FlexCache</block>
  <block id="7708950a83e2f559b43ad1d7bc08a440" category="paragraph"><block ref="7708950a83e2f559b43ad1d7bc08a440" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7bf27913e6097a43d318c500146c1e1" category="section-title">Dopo aver esposto il volume FlexCache a Domino</block>
  <block id="acacf35ed5b32878a29f6d32e6a11ffe" category="paragraph"><block ref="acacf35ed5b32878a29f6d32e6a11ffe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9be78ccf5bdf4dc10f0e5d25b893eeb" category="section-title">Opzione 2: replicare un volume che risiede in un piano dati diverso</block>
  <block id="0e6ab030c4eacec9efa80d3df6cd643b" category="inline-link-macro">Tecnologia di replicazione dei dati NetApp SnapMirror</block>
  <block id="124468d30e8b5047c5fe1b160b4fcbd2" category="paragraph">Con<block ref="ebe914c00393f99bd92af5cffa8376b0" category="inline-link-macro-rx"></block> , è possibile creare una copia di un volume NetApp che risiede in un piano dati diverso.  Ad esempio, se hai un volume NetApp nel tuo piano dati locale e devi accedere a quel volume nel tuo piano dati AWS, puoi creare una copia del volume in AWS.  In questa sezione vengono descritte le attività che devono essere eseguite per creare una copia di un volume NetApp che risiede in un piano dati diverso.</block>
  <block id="050a227810327b3bcfd311be38b7d202" category="section-title">Crea relazione SnapMirror</block>
  <block id="fef6b7d4f88331bab85d2eb944d43e9b" category="paragraph">Per prima cosa, devi creare una relazione SnapMirror tra il volume di origine e un nuovo volume di destinazione nell'ambiente di destinazione.  Si noti che il volume di destinazione verrà creato come parte del processo di creazione della relazione SnapMirror .</block>
  <block id="62390de09bd56fbb6d4533a188f4f201" category="inline-link-macro">Documentazione BlueXP replication</block>
  <block id="6fbd84bba212db826d8a94b992bd6324" category="paragraph">Consigliamo di utilizzare BlueXP per creare la relazione SnapMirror .  Per creare una relazione SnapMirror con BlueXP, seguire le istruzioni descritte in<block ref="b08e4ece79f7d1aa7f110b298b659fae" category="inline-link-macro-rx"></block> .</block>
  <block id="052be79cbb457a1391bb0a6839e610d3" category="paragraph">Se preferisci non utilizzare BlueXP, puoi utilizzare ONTAP System Manager o ONTAP CLI per creare la relazione SnapMirror .  Per creare una relazione SnapMirror con System Manager, fare riferimento alle istruzioni descritte in<block ref="665d2354c4ea508e65993c5ec9dc3fa1" category="inline-link-macro-rx"></block> .  Per creare una relazione SnapMirror con ONTAP CLI, fare riferimento alle istruzioni descritte in<block ref="bf03311f5c6980a3d817528b27741438" category="inline-link-macro-rx"></block> .</block>
  <block id="805b58c51fa6bf98d530bbc76f317e74" category="section-title">Interrompi la relazione SnapMirror</block>
  <block id="9ee42869e01344256cee7824a61c3f00" category="paragraph">Successivamente, è necessario interrompere la relazione SnapMirror per attivare il volume di destinazione per l'accesso ai dati.  Attendere il completamento della replica iniziale prima di eseguire questo passaggio.</block>
  <block id="c16b6b1cdf70d97ab9f143b23f304ee5" category="admonition">È possibile determinare se la replica è completa o meno controllando lo stato del mirror in BlueXP, ONTAP System Manager o ONTAP CLI.  Una volta completata la replica, lo stato mirror sarà "snapmirrored".</block>
  <block id="acab4369131a8c646dc85deedc5c4abb" category="paragraph">Consigliamo di utilizzare BlueXP per interrompere la relazione SnapMirror .  Per interrompere una relazione SnapMirror con BlueXP, seguire le istruzioni descritte in<block ref="eb8fade3a2fe398b39f82043fade1a22" category="inline-link-macro-rx"></block> .</block>
  <block id="96009cd50e3918957734c7c1dbe9bbb1" category="paragraph">Se preferisci non utilizzare BlueXP, puoi utilizzare ONTAP System Manager o ONTAP CLI per interrompere la relazione SnapMirror .  Per interrompere una relazione SnapMirror con System Manager, fare riferimento alle istruzioni descritte in<block ref="2feb8ad9799acf2d659fb0cab9f5c802" category="inline-link-macro-rx"></block> .  Per interrompere una relazione SnapMirror con ONTAP CLI, fare riferimento alle istruzioni descritte in<block ref="a5d68b350f5308762130d0f350fbb93c" category="inline-link-macro-rx"></block> .</block>
  <block id="67a1a8de2d55c1b2a31ec40db952c0cf" category="section-title">Esporre il volume di destinazione a Domino</block>
  <block id="0de56c363db9af31c3fe36cd53b5deaf" category="paragraph">Successivamente, è necessario esporre il volume di destinazione alla piattaforma Domino MLOps.  Per esporre il volume di destinazione a Domino, seguire le istruzioni descritte nella sottosezione "Esporre volumi NFS esistenti che non sono stati forniti da Trident" del<block ref="37f39ecc5e06a679f4975effd49fb9b8" category="inline-link-macro-rx"></block> di questa soluzione.</block>
  <block id="aa4e6b2b0a9165bbe6adb64ff972dbb0" category="paragraph">Ora sarà possibile montare il volume di destinazione quando si avviano processi e spazi di lavoro nel piano dati di destinazione, come mostrato negli screenshot seguenti.</block>
  <block id="6c2d9f4c43e6e539a1b0bf3be24de513" category="section-title">Prima di creare la relazione SnapMirror</block>
  <block id="800f74671431bfc6b9efb2f7e294020f" category="section-title">Dopo aver esposto il volume di destinazione a Domino</block>
  <block id="a2207225ebdd3d675188d927e34ace5a" category="summary">Domino Nexus è un unico pannello di controllo che consente di eseguire carichi di lavoro di data science e machine learning su qualsiasi cluster di elaborazione, in qualsiasi cloud, regione o in locale.</block>
  <block id="1882311bf64ae464a0b9653b463c8584" category="doc">MLOps multicloud ibrido con Domino Data Lab e NetApp</block>
  <block id="f0829d8f9d70b9de9de7beae86dc2129" category="paragraph">Mike Oglesby, NetApp</block>
  <block id="c716184d878cbe2fda94903e01c21291" category="paragraph">Le organizzazioni di tutto il mondo stanno attualmente adottando l'intelligenza artificiale per trasformare le proprie attività e i propri processi.  Per questo motivo, le infrastrutture di elaborazione predisposte per l'intelligenza artificiale sono spesso carenti.  Le aziende stanno adottando architetture MLOps multicloud ibride per sfruttare gli ambienti di elaborazione disponibili in diverse regioni, data center e cloud, bilanciando costi, disponibilità e prestazioni.</block>
  <block id="542493ebb9768d33d834c6edcade57dc" category="paragraph">Domino Nexus, di Domino Data Lab, è un piano di controllo MLOps unificato che consente di eseguire carichi di lavoro di data science e machine learning su qualsiasi cluster di elaborazione, in qualsiasi cloud, regione o locale.  Unifica i silos di data science in tutta l'azienda, in modo da avere un unico posto in cui creare, distribuire e monitorare i modelli.  Allo stesso modo, le funzionalità di gestione dei dati cloud ibridi di NetApp ti consentono di portare i tuoi dati nei tuoi processi e spazi di lavoro, indipendentemente da dove siano in esecuzione.  Abbinando Domino Nexus a NetApp, avrai la flessibilità di pianificare i carichi di lavoro tra più ambienti senza doverti preoccupare della disponibilità dei dati.  In altre parole, hai la possibilità di inviare i tuoi carichi di lavoro e i tuoi dati all'ambiente di elaborazione appropriato, il che ti consente di accelerare le distribuzioni di intelligenza artificiale e al contempo di rispettare le normative sulla privacy e la sovranità dei dati.</block>
  <block id="3eb3ace35104f92d82777b3219f769d7" category="paragraph">Questa soluzione dimostra l'implementazione di un piano di controllo MLOps unificato che incorpora un cluster Kubernetes on-premise e un cluster Elastic Kubernetes Service (EKS) in esecuzione in Amazon Web Services (AWS).</block>
  <block id="5be0395276ff3840daa0a0cb7643b68d" category="summary">MLOps multicloud ibrido con Domino Data Lab e NetApp - Configurazione iniziale</block>
  <block id="6641666d7bc2748bab0ac80cdec3a2a3" category="doc">Configurazione iniziale</block>
  <block id="ef81709626b455fffcd99d9f67085d18" category="paragraph">Questa sezione descrive le attività di configurazione iniziale che devono essere eseguite per utilizzare Domino Nexus con i servizi dati NetApp in un ambiente ibrido che incorpora un data center locale e AWS.</block>
  <block id="87b13b0a04193ccc830f23d041d6f3ba" category="paragraph">Prima di eseguire i passaggi descritti in questa sezione, diamo per scontato che tu abbia già eseguito le seguenti attività:</block>
  <block id="677ae9330aedf715db07a33be39cbbeb" category="list-text">Hai già distribuito e configurato la tua piattaforma di storage NetApp ONTAP on-premise. Per ulteriori informazioni, fare riferimento al <block ref="077b296918e9131d07388450dbd7a243" category="inline-link-macro-rx"></block> .</block>
  <block id="8f117f8e1e04a7113b95048bd0077b28" category="inline-link-macro">Pagina del prodotto Amazon FSx ONTAP</block>
  <block id="837adf3f87eb8a7f5893e4b6a6f7cee5" category="list-text">Hai già eseguito il provisioning di un'istanza Amazon FSx ONTAP in AWS. Per ulteriori informazioni, fare riferimento al <block ref="88e07f6417e37f8ff711e34864e5d89c" category="inline-link-macro-rx"></block> .</block>
  <block id="6bd1aa1204077ccb610d72dbc07f11b1" category="inline-link-macro">Guida per l'amministratore di Domino</block>
  <block id="83a12488d43dae9419d61f6f83fa014a" category="list-text">Hai già predisposto un cluster Kubernetes nel tuo data center locale. Per ulteriori informazioni, fare riferimento al <block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block> .</block>
  <block id="6b59c41a4554c4e0f63a7da5ad17b347" category="list-text">Hai già eseguito il provisioning di un cluster Amazon EKS in AWS. Per ulteriori informazioni, fare riferimento al <block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block> .</block>
  <block id="be3455a34c69a26df1a5f04a6245249b" category="inline-link-macro">Documentazione NetApp Trident</block>
  <block id="1ac8e4f74be6c2aad80e2d33e0bdef83" category="list-text">Hai installato NetApp Trident nel tuo cluster Kubernetes locale.  Inoltre, hai configurato questa istanza Trident per utilizzare la tua piattaforma di storage NetApp ONTAP locale durante il provisioning e la gestione delle risorse di storage. Per ulteriori informazioni, fare riferimento al <block ref="eaacbbbc0da023a88cdd2b5800b9ea3b" category="inline-link-macro-rx"></block> .</block>
  <block id="6c45529675023ab110b59c01a71b6038" category="list-text">Hai installato NetApp Trident nel tuo cluster Amazon EKS.  Inoltre, hai configurato questa istanza Trident per utilizzare la tua istanza Amazon FSx ONTAP durante il provisioning e la gestione delle risorse di storage. Per ulteriori informazioni, fare riferimento al <block ref="eaacbbbc0da023a88cdd2b5800b9ea3b" category="inline-link-macro-rx"></block> .</block>
  <block id="f8090d27d981a98d65c4401bdd84b3bf" category="inline-link-macro">Documentazione sulla rete privata virtuale (VPN) di Amazon</block>
  <block id="c09961db559c7c906d851ebf8ba40ac5" category="list-text">È necessario disporre di connettività di rete bidirezionale tra il data center locale e il Virtual Private Cloud (VPC) in AWS.  Per maggiori dettagli sulle varie opzioni per l'implementazione di questa, fare riferimento a<block ref="f5c50c4f502917d968e827ba0a3b9d8e" category="inline-link-macro-rx"></block> .</block>
  <block id="077b7144cc60353e8c8fdc9663398f24" category="section-title">Installa la piattaforma Domino Enterprise AI su AWS</block>
  <block id="5e1251e5d0134550a0ea5f1f02c14c3a" category="paragraph">Per installare la piattaforma Domino Enterprise MLOps in AWS, seguire le istruzioni descritte in<block ref="7ebd1f818144f08a887fe5d8dbad016a" category="inline-link-macro-rx"></block> .  È necessario distribuire Domino nello stesso cluster Amazon EKS precedentemente predisposto.  Inoltre, NetApp Trident deve essere già installato e configurato in questo cluster EKS ed è necessario specificare una classe di storage gestita da Trident come classe di storage condivisa nel file di configurazione di installazione domino.yml.</block>
  <block id="feee67bbfd0f30a09eeb08ca21cdf38d" category="inline-link-macro">Guida di riferimento alla configurazione dell'installazione di Domino</block>
  <block id="8facc83d9ba07b807b37a1cf4c7f8a74" category="admonition">Fare riferimento al<block ref="ace9eaa491d11b57c3774d7e21b1cd72" category="inline-link-macro-rx"></block> per i dettagli su come specificare una classe di archiviazione condivisa nel file di configurazione di installazione domino.yml.</block>
  <block id="11f21d6309deb4cfcdc7f2cdb4fd0839" category="inline-link-macro">Rapporto tecnico TR-4952</block>
  <block id="78dd0d0a7a9f103f53daa672d459adb9" category="admonition"><block ref="3de90155c2505cad82b61f16af3049bc" category="inline-link-macro-rx"></block>illustra la distribuzione di Domino in AWS con Amazon FSx ONTAP e può essere un utile riferimento per la risoluzione di eventuali problemi che si presentano.</block>
  <block id="aa2a36e425ea068322a0e37b07481ba8" category="section-title">Abilita Domino Nexus</block>
  <block id="1a942f929d8ad029b828b8e738a86a07" category="paragraph">Successivamente, è necessario abilitare Domino Nexus.  Fare riferimento al<block ref="31b0fd9bf4991ddcfdb80d02c1415fe4" category="inline-link-macro-rx"></block> per i dettagli.</block>
  <block id="fa64dcf7a96dbbcd90b8729d4d59ab2f" category="section-title">Distribuisci un Domino Data Plane nel tuo data center locale</block>
  <block id="4ad85753a09f6b6e21cf6089aa28f2b2" category="paragraph">Successivamente, è necessario distribuire un Domino Data Plane nel data center locale.  È necessario distribuire questo piano dati nel cluster Kubernetes locale precedentemente sottoposto a provisioning.  Inoltre, NetApp Trident deve essere già installato e configurato in questo cluster Kubernetes.  Fare riferimento al<block ref="d46974ff7fcd2c0e55b6b55f2aa698e1" category="inline-link-macro-rx"></block> per i dettagli.</block>
  <block id="9fac4fc4e1be67e589c110f0c4647f2e" category="summary">MLOps multicloud ibrido con Domino Data Lab e NetApp - Panoramica sulla tecnologia</block>
  <block id="d8b778c81ae11eb5edbd4291a3cf8fff" category="doc">Panoramica della tecnologia</block>
  <block id="f0bbbdb43782a17fdb1b5541f4c2d25f" category="paragraph">Questa sezione fornisce una panoramica tecnologica per Hybrid Multicloud MLOps con Domino Data Lab e NetApp.</block>
  <block id="4e00c35efcd0578992f4821557db1c9e" category="paragraph">Domino Data Lab supporta le aziende basate su modelli con la sua piattaforma di intelligenza artificiale aziendale leader, a cui si affida oltre il 20% delle aziende Fortune 100.  Domino accelera lo sviluppo e l'implementazione del lavoro di data science, aumentando al contempo la collaborazione e la governance.  Grazie a Domino, le aziende di tutto il mondo possono sviluppare medicinali migliori, coltivare raccolti più produttivi, costruire automobili migliori e molto altro ancora.  Fondata nel 2013, Domino è sostenuta da Coatue Management, Great Hill Partners, Highland Capital, Sequoia Capital e altri importanti investitori.</block>
  <block id="582cc4e2654a5d265b3a9c8960a43e88" category="paragraph">Domino consente alle aziende e ai loro data scientist di creare, implementare e gestire l'intelligenza artificiale su una piattaforma unificata end-to-end, in modo rapido, responsabile e conveniente.  I team possono accedere a tutti i dati, gli strumenti, i calcoli, i modelli e i progetti di cui hanno bisogno in qualsiasi ambiente, in modo da poter collaborare, riutilizzare il lavoro precedente, monitorare i modelli in produzione per migliorare la precisione, standardizzare con le migliori pratiche e rendere l'intelligenza artificiale responsabile e governata.</block>
  <block id="79aba99e2c2c50a4d5627b787bde8eae" category="list-text">*Aperto e flessibile:* accedi al più ampio ecosistema di strumenti e infrastrutture open source e commerciali, per le migliori innovazioni e senza vincoli con i fornitori.</block>
  <block id="720b80ab9ad18c5e500ae8203bb712f2" category="list-text">*Sistema di registrazione:* hub centrale per le operazioni e le conoscenze di intelligenza artificiale in tutta l'azienda, che consente best practice, collaborazione interfunzionale, innovazione più rapida ed efficienza.</block>
  <block id="8d89627678490a8b88c851ea2fac357d" category="list-text">*Integrato:* Flussi di lavoro e automazione integrati, pensati per processi, controlli e governance aziendali, soddisfano le tue esigenze di conformità e normative.</block>
  <block id="9e390a9660aa9f11963ef8d4ebe9b58a" category="list-text">*Multicloud ibrido:* esegui carichi di lavoro di intelligenza artificiale vicino ai tuoi dati ovunque (in locale, ibrido, su qualsiasi cloud o multi-cloud) per costi inferiori, prestazioni ottimali e conformità.</block>
  <block id="5bfd375703bc2df982ba9c5193150b90" category="paragraph"><block ref="5bfd375703bc2df982ba9c5193150b90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80603873e677eebf28ec5645b40f7453" category="paragraph">Domino Nexus è un unico pannello di controllo che consente di eseguire carichi di lavoro di data science e machine learning su qualsiasi cluster di elaborazione, in qualsiasi cloud, regione o in locale.  Unifica i silos di data science in tutta l'azienda, in modo da avere un unico posto in cui creare, distribuire e monitorare i modelli.</block>
  <block id="991a53642be15661dc9369ee1ae2085c" category="paragraph">NetApp BlueXP unifica tutti i servizi di storage e dati di NetApp in un unico strumento che ti consente di creare, proteggere e gestire il tuo patrimonio di dati multicloud ibrido.  Offre un'esperienza unificata per i servizi di archiviazione e dati in ambienti on-premise e cloud e consente semplicità operativa attraverso la potenza di AIOps, con parametri di consumo flessibili e protezione integrata richiesti per il mondo odierno guidato dal cloud.</block>
  <block id="8814f8d780d4b85a940aa27445d68549" category="list-text">Connessione cloud.  ONTAP è il software di gestione dello storage più connesso al cloud, con opzioni per lo storage definito dal software e istanze cloud native in tutti i cloud pubblici.</block>
  <block id="5dbf44a3195cc10e2873e76a30df05ac" category="section-title">Amazon FSx for NetApp ONTAP (FSx ONTAP)</block>
  <block id="bca10fd5d70f83556ba989ecf392df97" category="paragraph">Amazon FSx ONTAP è un servizio AWS proprietario e completamente gestito che fornisce un archivio file altamente affidabile, scalabile, ad alte prestazioni e ricco di funzionalità, basato sul famoso file system ONTAP di NetApp. FSx ONTAP combina le caratteristiche, le prestazioni, le capacità e le operazioni API note dei file system NetApp con l'agilità, la scalabilità e la semplicità di un servizio AWS completamente gestito.</block>
  <block id="193e0bb6f3a76822b629d0fae08bdb7e" category="paragraph">Trident consente l'utilizzo e la gestione delle risorse di storage su tutte le piattaforme di storage NetApp più diffuse, nel cloud pubblico o in locale, tra cui ONTAP (AFF, FAS, Select, Cloud, Amazon FSx ONTAP), Element Software (NetApp HCI, SolidFire), il servizio Azure NetApp Files e Google Cloud NetApp Volumes su Google Cloud.  Trident è un orchestratore di storage dinamico compatibile con Container Storage Interface (CSI) che si integra in modo nativo con Kubernetes.</block>
  <block id="978ecccb92a71c90363dfd222ebdfe77" category="paragraph">Kubernetes è una piattaforma di orchestrazione di container distribuita e open source, originariamente progettata da Google e ora gestita dalla Cloud Native Computing Foundation (CNCF).  Kubernetes consente l'automazione delle funzioni di distribuzione, gestione e ridimensionamento per le applicazioni containerizzate ed è la piattaforma di orchestrazione dei container dominante negli ambienti aziendali.</block>
  <block id="b2a7a79ed7fe83cbfb6fe2140e6fb60a" category="paragraph">Amazon Elastic Kubernetes Service (Amazon EKS) è un servizio Kubernetes gestito nel cloud AWS.  Amazon EKS gestisce automaticamente la disponibilità e la scalabilità dei nodi del piano di controllo Kubernetes responsabili della pianificazione dei container, della gestione della disponibilità delle applicazioni, dell'archiviazione dei dati del cluster e di altre attività chiave.  Con Amazon EKS puoi sfruttare tutte le prestazioni, la scalabilità, l'affidabilità e la disponibilità dell'infrastruttura AWS, nonché le integrazioni con i servizi di rete e sicurezza AWS.</block>
  <block id="7bdb77faa0d23db500f55d38c7812837" category="summary">MLOps multicloud ibrido con Domino Data Lab e NetApp : esposizione dei volumi NetApp esistenti a Domino</block>
  <block id="5f385895d8f69d19670414fea115c17e" category="doc">Esporre i volumi NetApp esistenti a Domino</block>
  <block id="012942ee2856a3a30e386d999ab4decd" category="paragraph">In questa sezione vengono descritte le attività che devono essere eseguite per esporre i volumi NetApp ONTAP NFS esistenti alla piattaforma Domino MLOps.  Gli stessi passaggi si applicano sia in locale che in AWS.</block>
  <block id="216745145dbb2663dd8ef64d1e7b70ce" category="section-title">Perché esporre i volumi NetApp ONTAP a Domino?</block>
  <block id="4f49bbf1791537d3f9cea32729bcf171" category="paragraph">L'utilizzo di volumi NetApp insieme a Domino offre i seguenti vantaggi:</block>
  <block id="bdf339cbdff188396b615acb6642682f" category="list-text">È possibile eseguire carichi di lavoro su set di dati estremamente grandi sfruttando le funzionalità di scalabilità orizzontale di NetApp ONTAP.</block>
  <block id="ad859808af9509052afa68845ee13abf" category="list-text">È possibile eseguire carichi di lavoro su più nodi di elaborazione senza dover copiare i dati sui singoli nodi.</block>
  <block id="3019efb93cfae9d2074cee3ecba248ce" category="list-text">Puoi sfruttare le funzionalità di sincronizzazione e spostamento dei dati multicloud ibridi di NetApp per accedere ai tuoi dati su più data center e/o cloud.</block>
  <block id="72410fa7689169a336be6540fbab04cb" category="list-text">Vuoi poter creare in modo rapido e semplice una cache dei tuoi dati in un data center o cloud diverso.</block>
  <block id="6d4734babb6928dd0a6f21c21a95be6a" category="section-title">Esporre i volumi NFS esistenti che non sono stati forniti da Trident</block>
  <block id="908d8e50ed4f87ffd16293ce7689ffa3" category="paragraph">Se il volume NetApp ONTAP NFS esistente non è stato fornito da Trident, seguire i passaggi descritti in questa sottosezione.</block>
  <block id="b0604699a0737b4da7a79ed81a611605" category="section-title">Crea PV e PVC in Kubernetes</block>
  <block id="0b8e803956828c77b5f9c0745c726ca8" category="admonition">Per i volumi on-premise, crea PV e PVC nel tuo cluster Kubernetes on-premise.  Per i volumi Amazon FSx ONTAP , creare PV e PVC in Amazon EKS.</block>
  <block id="7ea686752cd0065765a1f236f52b6a86" category="inline-link-macro">Esempio NFS PV/PVC</block>
  <block id="21daa905ac0fe45b36e98c4b7c6cbfaf" category="paragraph">Per prima cosa, devi creare un volume persistente (PV) e una richiesta di volume persistente (PVC) nel tuo cluster Kubernetes.  Per creare il PV e il PVC, utilizzare il<block ref="a25b642a6322d7659714e6bd71e7cd4f" category="inline-link-macro-rx"></block> dalla guida di amministrazione di Domino e aggiorna i valori in modo che si adattino al tuo ambiente.  Assicurarsi di specificare i valori corretti per<block ref="89801e9e98979062e84647433a8ed3e9" prefix=" " category="inline-code"></block> ,<block ref="0a087fd97387c110f029a7a2550ff280" prefix=" " category="inline-code"></block> , E<block ref="34ae7d3a708b57f81af8fcfcd13c7a55" prefix=" " category="inline-code"></block> campi.  Inoltre, consigliamo di assegnare ai PV e PVC nomi univoci che rappresentino la natura dei dati archiviati sul volume ONTAP NFS corrispondente.  Ad esempio, se il volume contiene immagini di difetti di fabbricazione, è possibile denominare il PV,<block ref="7146834334002e1c2c8bbb00348a951c" prefix=" " category="inline-code"></block> e il PVC,<block ref="2d04ce24c553ffe8e7f9b69269696618" prefix=" " category="inline-code"></block> .</block>
  <block id="3a0e23ff2bfd7dc5b55c1aeb14b0ce33" category="section-title">Registra il volume di dati esterni in Domino</block>
  <block id="cbde2df6a7c89370edc449dc5705d30c" category="inline-link-macro">istruzioni</block>
  <block id="6d38ad9604bf23123ad6f1505f8f64ce" category="paragraph">Successivamente, è necessario registrare un volume di dati esterno in Domino.  Per registrare un volume di dati esterno, fare riferimento a<block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block> nella guida per l'amministratore di Domino.  Quando si registra il volume, assicurarsi di selezionare "NFS" dal menu a discesa "Tipo di volume".  Dopo aver selezionato "NFS", dovresti vedere il tuo PVC nell'elenco "Volumi disponibili".</block>
  <block id="f759d0a96176c0ce67a4269c5b45bc42" category="paragraph"><block ref="f759d0a96176c0ce67a4269c5b45bc42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f91c183558f2466e2e75a92424f7a3bf" category="section-title">Esporre i volumi esistenti forniti da Trident</block>
  <block id="733e83e8c2052942f7f0e96fcd19e8a4" category="paragraph">Se il volume esistente è stato fornito da Trident, seguire i passaggi descritti in questa sottosezione.</block>
  <block id="57a045b809f3298056d203360becbd66" category="section-title">Modifica PVC esistente</block>
  <block id="aaf6f0a313e2fa37d3584aa97603489a" category="paragraph">Se il tuo volume è stato fornito da Trident, allora hai già una richiesta di volume persistente (PVC) corrispondente al tuo volume.  Per esporre questo volume a Domino, è necessario modificare il PVC e aggiungere la seguente etichetta all'elenco delle etichette nel<block ref="9cc59534218c9b00f7eb481861d14401" prefix=" " category="inline-code"></block> campo:</block>
  <block id="d2790ed8ab25c08ee1efd69f0773cade" category="paragraph">Successivamente, è necessario registrare un volume di dati esterno in Domino.  Per registrare un volume di dati esterno, fare riferimento a<block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block> nella guida per l'amministratore di Domino.  Quando si registra il volume, assicurarsi di selezionare "Generico" dal menu a discesa "Tipo di volume".  Dopo aver selezionato "Generico", dovresti vedere il tuo PVC nell'elenco "Volumi disponibili".</block>
  <block id="922b9696b39b06f6a4d313569231a446" category="summary">NVIDIA AI Enterprise con NetApp e VMware: dove trovare ulteriori informazioni</block>
  <block id="913e298a14c5b49185ced898ccea22bd" category="list-text">NVIDIA AI Enterprise con VMware</block>
  <block id="c85cb3eda6d429393778efbed7420a50" category="list-text">Bobby Oommen, Direttore senior, NetApp</block>
  <block id="c4321e9f60724f09a097b4d8b79c6e7b" category="list-text">Ramesh Isaac, amministratore di sistema, NetApp</block>
  <block id="cf4995eac87d7ce5351e1043fe85683c" category="list-text">Roney Daniel, ingegnere tecnico di marketing, NetApp</block>
  <block id="d8299632c247aca8f771d7368ee36f9d" category="summary">NVIDIA AI Enterprise con NetApp e VMware - Architettura</block>
  <block id="37810ec69b6e321b4b377d835e7d84ac" category="paragraph">Questa soluzione si basa su un'architettura collaudata e familiare che comprende sistemi certificati NetApp, VMware e NVIDIA.  Per i dettagli, vedere la tabella seguente.</block>
  <block id="95a502ec0ddaf3352c2540e3e9f65a1b" category="cell">Software di intelligenza artificiale e analisi dei dati</block>
  <block id="61da586210da33a8abab150a7d7d0972" category="inline-link-macro">NVIDIA AI Enterprise per VMware</block>
  <block id="7865e440c1b499e7942ca9b659d737d6" category="cell"><block ref="7865e440c1b499e7942ca9b659d737d6" category="inline-link-macro-rx"></block></block>
  <block id="102995a1cdd2c719d7d0aa4d888fa019" category="cell">Piattaforma di virtualizzazione</block>
  <block id="8887a9a417a1629326acdb917d224337" category="inline-link-macro">VMware vSphere</block>
  <block id="4ce5f3794d6e351daaaaa4f211e419ee" category="cell"><block ref="4ce5f3794d6e351daaaaa4f211e419ee" category="inline-link-macro-rx"></block></block>
  <block id="8cf5fbd26a1d5d924600d38015860908" category="cell">Piattaforma di calcolo</block>
  <block id="aee87e9fe5cc4cf9193cd27c74a0a6e7" category="inline-link-macro">Sistemi certificati NVIDIA</block>
  <block id="b3cdb2e0e953c1639ad63fe06b8c7a37" category="cell"><block ref="b3cdb2e0e953c1639ad63fe06b8c7a37" category="inline-link-macro-rx"></block></block>
  <block id="ddca712fc3b0dad3d85e423eb97d58ea" category="cell">Piattaforma di gestione dei dati</block>
  <block id="1c317db419d669c4b6473c6d462e881e" category="cell"><block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="3e549e3b22de98c96646fb0586a93db3" category="paragraph"><block ref="3e549e3b22de98c96646fb0586a93db3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69e8c6aef5e50150d499e7fa39f846ed" category="summary">NVIDIA AI Enterprise è una suite completa e cloud-native di software di analisi dei dati e intelligenza artificiale, ottimizzata per consentire a ogni organizzazione di avere successo con l'intelligenza artificiale.</block>
  <block id="68cdb7bf3dabd26e338e1ba72b549c69" category="doc">NVIDIA AI Enterprise con NetApp e VMware</block>
  <block id="61cb0c1b4a32d4815eb2a785c0c84cb8" category="paragraph">Per gli architetti e gli amministratori IT, gli strumenti di intelligenza artificiale possono risultare complessi e poco familiari.  Inoltre, molte piattaforme di intelligenza artificiale non sono pronte per l'uso aziendale.  NVIDIA AI Enterprise, basato su NetApp e VMware, è stato creato per offrire un'architettura di intelligenza artificiale semplificata e di livello aziendale.</block>
  <block id="eb7e5009de0ce355dc9131d958a1541e" category="paragraph"><block ref="eb7e5009de0ce355dc9131d958a1541e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d6b1f830356956d1f4b73438f8604232" category="summary">NVIDIA AI Enterprise con NetApp e VMware - Utilizzo del software NVIDIA NGC - Configurazione</block>
  <block id="ad2376beebecdcf7846ba973fa1a005b" category="doc">Impostare</block>
  <block id="7bb37c1d3fb64e908e6704f53b5fe4a8" category="paragraph">In questa sezione vengono descritte le attività di configurazione iniziale che devono essere eseguite per utilizzare il software aziendale NVIDIA NGC in un ambiente NVIDIA AI Enterprise.</block>
  <block id="1eb5d19d2c5071a5a7a569f58f2c9613" category="paragraph">Prima di eseguire i passaggi descritti in questa sezione, si presume che sia già stato distribuito il software host NVIDIA AI Entrprise seguendo le istruzioni descritte nel<block ref="b97b75086b5941ac63fab1eee89b4777" category="inline-link-macro-rx"></block> pagina.</block>
  <block id="c23799b3650257af14b8af5acb107354" category="section-title">Creare una VM guest Ubuntu con vGPU</block>
  <block id="0271f6ade1f60c92c6548f0e5c440e4e" category="inline-link-macro">Guida all'implementazione aziendale NVIDIA AI</block>
  <block id="4be8ecb3320915437222a84e9761bcec" category="paragraph">Per prima cosa, devi creare una VM guest Ubuntu 20.04 con vGPU.  Per creare una VM guest Ubuntu 20.04 con vGPU, seguire le istruzioni descritte in<block ref="2009ba36309e23fc0bb68cec4d4a3e0d" category="inline-link-macro-rx"></block> .</block>
  <block id="70c95294a49e1475adbde86d8eae754e" category="section-title">Scarica e installa il software guest NVIDIA</block>
  <block id="6148d2809a69d7225df7c6dcc1b5f94f" category="inline-link-macro">Guida rapida all'avvio di NVIDIA AI Enterprise</block>
  <block id="8f3d19df984dedd40b9998136343e036" category="paragraph">Successivamente, è necessario installare il software guest NVIDIA richiesto nella VM guest creata nel passaggio precedente.  Per scaricare e installare il software guest NVIDIA richiesto all'interno della VM guest, seguire le istruzioni descritte nelle sezioni 5.1-5.4 nella<block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block> .</block>
  <block id="15186686bd7e9c36683658388b6865b0" category="admonition">Quando si eseguono le attività di verifica descritte nella sezione 5.4, potrebbe essere necessario utilizzare un tag di versione dell'immagine del contenitore CUDA diverso, poiché l'immagine del contenitore CUDA è stata aggiornata dopo la stesura della guida.  Nella nostra convalida abbiamo utilizzato 'nvidia/cuda:11.0.3-base-ubuntu20.04'.</block>
  <block id="f43e7f8a79b8984748fff81eeb0f8c5f" category="section-title">Scarica i contenitori del framework AI/Analytics</block>
  <block id="939ac3b79a18fc027a13bea0aeebcd3c" category="paragraph">Successivamente, è necessario scaricare le immagini dei container del framework di analisi o di intelligenza artificiale necessarie da NVIDIA NGC, in modo che siano disponibili nella VM guest.  Per scaricare i contenitori del framework all'interno della VM guest, seguire le istruzioni descritte in<block ref="7ea494a5b1819fa63a0ad0f42cf94b43" category="inline-link-macro-rx"></block> .</block>
  <block id="5a8b2b886d790892b5beca474e789276" category="section-title">Installa e configura NetApp DataOps Toolkit</block>
  <block id="a225239f36328db667324928281cd834" category="paragraph">Successivamente, è necessario installare NetApp DataOps Toolkit for Traditional Environemnts nella VM guest.  NetApp DataOps Toolkit può essere utilizzato per gestire volumi di dati scalabili sul sistema ONTAP direttamente dal terminale all'interno della VM guest.  Per installare NetApp DataOps Toolkit nella VM guest, eseguire le seguenti attività.</block>
  <block id="e0288a23fbe1bfdb5f5b06d39e315992" category="list-text">Installa pip.</block>
  <block id="bb5f723fd408b79a93de1e726de66dd1" category="list-text">Disconnettersi dal terminale della VM guest e quindi effettuare nuovamente l'accesso.</block>
  <block id="c456f18c285a54b87c3bc96f0ee32ebb" category="list-text">Configurare NetApp DataOps Toolkit.  Per completare questo passaggio, avrai bisogno dei dettagli di accesso API per il tuo sistema ONTAP .  Potrebbe essere necessario richiederli all'amministratore del tuo archivio.</block>
  <block id="defe5f6be79f86b85d956d3e53c7ac4d" category="section-title">Creare un modello di VM guest</block>
  <block id="d5d979be97f5a76cf2676ef5a9c7f071" category="paragraph">Infine, è necessario creare un modello di VM basato sulla VM guest.  Sarà possibile utilizzare questo modello per creare rapidamente VM guest per l'utilizzo del software NVIDIA NGC.</block>
  <block id="fec1fe0b41ba3927cfb9ac7c0507a1f5" category="paragraph">Per creare un modello di VM basato sulla VM guest, accedi a VMware vSphere, fai clic con il pulsante destro del mouse sul nome della VM guest, seleziona "Clona", quindi "Clona su modello..." e segui la procedura guidata.</block>
  <block id="ae46b5fec5e9fa6540317c6aff2886d0" category="paragraph"><block ref="ae46b5fec5e9fa6540317c6aff2886d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54d7050762b4d8c4af04f27ce33f1f9b" category="summary">NVIDIA AI Enterprise con NetApp e VMware - Configurazione iniziale</block>
  <block id="cb8b0bf52601ee3b7c48b31850f1a45a" category="paragraph">Questa sezione descrive le attività di configurazione iniziale che devono essere eseguite per utilizzare NVIDIA AI Enterprise con NetApp e VMware.</block>
  <block id="5600e01753ba1c962c6d52ee6f0bdc72" category="inline-link-macro">Matrice di supporto dei prodotti NVIDIA AI Enterprise</block>
  <block id="b46df8af05863c37f3cd1fd611e5d2d9" category="inline-link-macro">Documentazione delle soluzioni NetApp e VMware</block>
  <block id="06a8848af5cbb48d04a6b9d27ea22cae" category="paragraph">Prima di eseguire i passaggi descritti in questa sezione, presumiamo che tu abbia già distribuito VMware vSphere e NetApp ONTAP.  Fare riferimento al<block ref="fca8480728eb091fdea60a7b3cdc16f7" category="inline-link-macro-rx"></block> per i dettagli sulle versioni vSphere supportate.  Fare riferimento al<block ref="dde322875ea0d7cfe426ecec0c0dad4c" category="inline-link-macro-rx"></block> per i dettagli sulla distribuzione di VMware vSphere con NetApp ONTAP.</block>
  <block id="a067b320746c7952a2b152f5a3af42b4" category="section-title">Installa il software NVIDIA AI Enterprise Host</block>
  <block id="ee9d732a57ce821e52e753e2b4bd4a84" category="paragraph">Per installare il software host NVIDIA AI Entrprise, seguire le istruzioni descritte nelle sezioni 1-4 del<block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block> .</block>
  <block id="f0de4adaf6568678921cef0d0e69b81f" category="summary">NVIDIA AI Enterprise con NetApp e VMware - Panoramica sulla tecnologia</block>
  <block id="d54433e43cda21e1ff5ab715c73883de" category="paragraph">Questa sezione fornisce una panoramica della tecnologia per NVIDIA AI Enterprise con NetApp e VMware.</block>
  <block id="0719941ec04c59670033b3b1f0e3c239" category="paragraph">NVIDIA AI Enterprise è una suite end-to-end e cloud-native di software di analisi dei dati e intelligenza artificiale, ottimizzata, certificata e supportata da NVIDIA per l'esecuzione su VMware vSphere con sistemi certificati NVIDIA.  Questo software semplifica e velocizza l'implementazione, la gestione e il ridimensionamento dei carichi di lavoro di intelligenza artificiale nel moderno ambiente cloud ibrido.</block>
  <block id="cbd4c44d2b7fc45943b834d2a03f2a63" category="paragraph">NVIDIA NGC ospita un catalogo di software ottimizzati per GPU che consente ai professionisti dell'intelligenza artificiale di sviluppare le proprie soluzioni di intelligenza artificiale.  Fornisce inoltre accesso a vari servizi di intelligenza artificiale, tra cui NVIDIA Base Command per l'addestramento dei modelli, NVIDIA Fleet Command per distribuire e monitorare i modelli e NGC Private Registry per l'accesso e la gestione sicuri del software di intelligenza artificiale proprietario.  Inoltre, i clienti NVIDIA AI Enterprise possono richiedere supporto tramite il portale NGC.</block>
  <block id="7ee50a783ac86f99c7b7db29b77e7a2a" category="paragraph">VMware vSphere è la piattaforma di virtualizzazione di VMware che trasforma i data center in infrastrutture di elaborazione aggregate che includono risorse di CPU, storage e rete. vSphere gestisce queste infrastrutture come un ambiente operativo unificato e fornisce agli amministratori gli strumenti per gestire i data center che partecipano a tale ambiente.</block>
  <block id="a8b821c11b6c83cd7165137d4f68a45b" category="paragraph">I due componenti principali di vSphere sono ESXi e vCenter Server.  ESXi è la piattaforma di virtualizzazione in cui gli amministratori creano ed eseguono macchine virtuali e appliance virtuali. vCenter Server è il servizio tramite il quale gli amministratori gestiscono più host connessi in rete e mettono in pool le risorse host.</block>
  <block id="7cc4f632835e2377fd90f38601a3e0eb" category="paragraph">NetApp DataOps Toolkit è uno strumento basato su Python che semplifica la gestione degli spazi di lavoro di sviluppo/formazione e dei server di inferenza supportati da storage NetApp ad alte prestazioni e scalabile.  Le principali funzionalità includono:</block>
  <block id="23b97f551923a166ae2d3223b0ed84cc" category="list-text">Clonare quasi istantaneamente gli spazi di lavoro JupyterLab ad alta capacità per consentire la sperimentazione o l'iterazione rapida.</block>
  <block id="27c7d5bdafd6a9d64ad337b08e104c87" category="list-text">Salvataggio quasi istantaneo di snapshot di spazi di lavoro JupyterLab ad alta capacità per backup e/o tracciabilità/baselining.</block>
  <block id="86f28dd8fdffc90314bf94c94e1b3c1c" category="list-text">Esegui il provisioning, la clonazione e l'istantanea di volumi di dati ad alta capacità e ad alte prestazioni in modo quasi istantaneo.</block>
  <block id="e4f8ad54c095217d5da72f9ba2ad87d4" category="summary">NVIDIA AI Enterprise con NetApp e VMware - Utilizzo del software NVIDIA NGC - Esempio di caso d'uso - Formazione TensorFlow</block>
  <block id="b26247c1865d93ea590ef10d1150c2ae" category="doc">Esempio di caso d'uso: lavoro di formazione TensorFlow</block>
  <block id="ff35b7c65e31b6103dee61bd8d89ee4f" category="paragraph">Questa sezione descrive le attività che devono essere eseguite per eseguire un processo di training TensorFlow in un ambiente NVIDIA AI Enterprise.</block>
  <block id="0733928d94b0eba77ac6cf7f3c950257" category="paragraph">Prima di eseguire i passaggi descritti in questa sezione, si presume che sia già stato creato un modello di VM guest seguendo le istruzioni descritte in<block ref="ad0d852572366b07cdb7f9f854b3aedf" category="inline-link-macro-rx"></block> pagina.</block>
  <block id="c8281ef65e7f967dfd74821eada0aed1" category="section-title">Crea una VM guest dal modello</block>
  <block id="8f195db6a3d092a2d990de535475fb82" category="paragraph">Per prima cosa, devi creare una nuova VM guest dal modello creato nella sezione precedente.  Per creare una nuova VM guest dal tuo modello, accedi a VMware vSphere, fai clic con il pulsante destro del mouse sul nome del modello, scegli "Nuova VM da questo modello..." e segui la procedura guidata.</block>
  <block id="d31d5f91fee0f03911daa3d20a90e607" category="paragraph"><block ref="d31d5f91fee0f03911daa3d20a90e607" category="inline-image-macro-rx" type="image"></block></block>
  <block id="229fea3a8aa56b262dc3dbb996d81052" category="section-title">Crea e monta il volume dati</block>
  <block id="bbdc3bf8e16f6c828df2941c605e4ef3" category="paragraph">Successivamente, è necessario creare un nuovo volume di dati su cui archiviare il set di dati di addestramento.  È possibile creare rapidamente un nuovo volume di dati utilizzando NetApp DataOps Toolkit.  Il comando di esempio che segue mostra la creazione di un volume denominato 'imagenet' con una capacità di 2 TB.</block>
  <block id="bed0c39c2a853526e026bbd1d13b0a29" category="paragraph">Prima di poter popolare il volume dati con i dati, è necessario montarlo nella VM guest.  È possibile montare rapidamente un volume di dati utilizzando NetApp DataOps Toolkit.  Il comando di esempio che segue mostra il montaggio del volume creato nel passaggio precedente.</block>
  <block id="3418ebfa9c3ff38c1bfcd27521d4e641" category="section-title">Popola il volume dei dati</block>
  <block id="ec123d1ef57b0ab158b8c891c6b936da" category="paragraph">Dopo aver eseguito il provisioning e il montaggio del nuovo volume, il set di dati di training può essere recuperato dalla posizione di origine e posizionato sul nuovo volume.  In genere, ciò comporta l'estrazione dei dati da un data lake S3 o Hadoop e talvolta richiede l'aiuto di un data engineer.</block>
  <block id="d3e84e47f561be23742b30b8c3dd7d10" category="section-title">Esegui il job di training di TensorFlow</block>
  <block id="f6a0596efc5c96edbcbffd2d19e48f41" category="paragraph">Ora sei pronto per eseguire il tuo job di training TensorFlow.  Per eseguire il processo di addestramento TensorFlow, eseguire le seguenti attività.</block>
  <block id="83c4072e784e0048974a7fbaef9e7567" category="list-text">Estrarre l'immagine del contenitore NVIDIA NGC Enterprise TensorFlow.</block>
  <block id="26857c717c90aa9ca7c999304a47e6ad" category="list-text">Avvia un'istanza del contenitore NVIDIA NGC Enterprise TensorFlow.  Utilizzare l'opzione '-v' per allegare il volume di dati al contenitore.</block>
  <block id="c8dc137f2972d72ed031b7e9000c2b58" category="list-text">Esegui il programma di addestramento TensorFlow all'interno del contenitore.  Il comando di esempio seguente mostra l'esecuzione di un programma di formazione ResNet-50 di esempio incluso nell'immagine del contenitore.</block>
  <block id="9dd88053035e8518106da3a40ce3aa3b" category="summary">MLOps open source con NetApp - Distribuzione di Apache Airflow</block>
  <block id="7d2a9e50f39ee00c2b180900e7bacc92" category="doc">Distribuzione di Apache Airflow</block>
  <block id="c2ae2e58baf01933984b63bbfd58c6c2" category="paragraph">Questa sezione descrive le attività che devi completare per distribuire Airflow nel tuo cluster Kubernetes.</block>
  <block id="1874d60ac69d2a867825b1b7ab0f9297" category="admonition">È possibile distribuire Airflow su piattaforme diverse da Kubernetes.  L'implementazione di Airflow su piattaforme diverse da Kubernetes esula dall'ambito di questa soluzione.</block>
  <block id="e5595c75c723712666f834213ee6568f" category="paragraph">Prima di eseguire l'esercizio di distribuzione descritto in questa sezione, diamo per scontato che tu abbia già eseguito le seguenti attività:</block>
  <block id="c7a7dda60a4edd19d3b5bad13d43d605" category="list-text">Hai già un cluster Kubernetes funzionante.</block>
  <block id="40ef3fb23e015d9b4b46a16fa50f10d3" category="inline-link-macro">Documentazione Trident</block>
  <block id="85dd9fb465515fcb64ad8d6b67591898" category="list-text">Hai già installato e configurato NetApp Trident nel tuo cluster Kubernetes.  Per maggiori dettagli su Trident, fare riferimento al<block ref="6bc4e9e49caf522f01de7c1314cd2006" category="inline-link-macro-rx"></block> .</block>
  <block id="ead9806c164633fcb334dc844a3d588f" category="section-title">Installa Helm</block>
  <block id="7586dbf5f3ac1a66383f6c201a17a341" category="inline-link">istruzioni di installazione</block>
  <block id="f9093f3279eca680041e957a2a0505dd" category="paragraph">Airflow viene distribuito tramite Helm, un noto gestore di pacchetti per Kubernetes.  Prima di distribuire Airflow, è necessario installare Helm sull'host di distribuzione.  Per installare Helm sull'host di distribuzione jump, seguire le istruzioni<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> nella documentazione ufficiale di Helm.</block>
  <block id="72727333279dd1f9e8b63f969075bca8" category="section-title">Imposta la classe di archiviazione Kubernetes predefinita</block>
  <block id="124793fd2a85b1699a94b12bf4661758" category="inline-link-macro">Distribuzione di Kubeflow</block>
  <block id="53b8c224038ee8370989019811dd9379" category="paragraph">Prima di distribuire Airflow, è necessario designare una StorageClass predefinita all'interno del cluster Kubernetes.  Il processo di distribuzione di Airflow tenta di effettuare il provisioning di nuovi volumi persistenti utilizzando la StorageClass predefinita.  Se non viene designata alcuna StorageClass come StorageClass predefinita, la distribuzione fallisce.  Per designare una StorageClass predefinita all'interno del cluster, seguire le istruzioni descritte in<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block> sezione.  Se hai già designato una StorageClass predefinita all'interno del tuo cluster, puoi saltare questo passaggio.</block>
  <block id="c7feb8d7350bb5372c4dd0dfc1383865" category="section-title">Usa Helm per distribuire il flusso d'aria</block>
  <block id="a781e1f3dbd7b5f15c3257febe820528" category="paragraph">Per distribuire Airflow nel cluster Kubernetes tramite Helm, eseguire le seguenti attività dall'host di jump di distribuzione:</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link">istruzioni di distribuzione</block>
  <block id="fe1b26293aba127732d69bdc90866794" category="list-text">Distribuisci Airflow utilizzando Helm seguendo le istruzioni<block ref="e4140084ec840191180d755827375d89" category="inline-link-rx"></block> per il grafico ufficiale del flusso d'aria su Artifact Hub.  I comandi di esempio che seguono mostrano la distribuzione di Airflow tramite Helm.  Modificare, aggiungere e/o rimuovere valori in<block ref="b03054dec41b4d504351d411d8221d7f" prefix=" " category="inline-code"></block> file secondo necessità, a seconda dell'ambiente e della configurazione desiderata.</block>
  <block id="fa7edbfc4d9facbb8db918116ff0ae46" category="list-text">Verificare che tutti i pod Airflow siano attivi e funzionanti.  Potrebbero essere necessari alcuni minuti prima che tutti i pod si avviino.</block>
  <block id="9bb040ffef8c89d0861be81732ca17de" category="list-text">Ottieni l'URL del servizio Web Airflow seguendo le istruzioni visualizzate sulla console quando hai distribuito Airflow tramite Helm nel passaggio 1.</block>
  <block id="0db6a8f601b49c6c3780b668eac398a8" category="list-text">Conferma di poter accedere al servizio web Airflow.</block>
  <block id="ae954beef496ebe087806e1ce5f985b1" category="paragraph"><block ref="ae954beef496ebe087806e1ce5f985b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1358ee6f6793d8ad5c774e77af0ef2f8" category="summary">Open Source MLOps con NetApp : utilizza NetApp DataOps Toolkit con Airflow</block>
  <block id="a6341ca5ab25e7d3076dec050c9e5a97" category="doc">Utilizzare NetApp DataOps Toolkit con Airflow</block>
  <block id="a408a973f45f990bcd545653e35109ff" category="paragraph">IL<block ref="d2f8e20a78f43c00804244e7ccbfa516" category="inline-link-rx"></block> può essere utilizzato insieme ad Airflow.  Utilizzando NetApp DataOps Toolkit con Airflow è possibile integrare le operazioni di gestione dei dati NetApp , come la creazione di snapshot e cloni, in flussi di lavoro automatizzati orchestrati da Airflow.</block>
  <block id="dee957e8ec77b256b931e812220f0553" category="inline-link">Esempi di flusso d'aria</block>
  <block id="b6cc356bf5062501529145b3a4643413" category="paragraph">Fare riferimento al<block ref="7c367129528d87aa1adf73a57a51aa4d" category="inline-link-rx"></block> sezione all'interno del repository GitHub di NetApp DataOps Toolkit per i dettagli sull'utilizzo del toolkit con Airflow.</block>
  <block id="95cd1b9d487589b619592ac7a94f1001" category="summary">MLOps open source con NetApp - Architettura</block>
  <block id="21d5dd37b5f077a36d22ba32af4054e6" category="paragraph">Questa soluzione non dipende da hardware specifico.  La soluzione è compatibile con qualsiasi dispositivo di storage fisico NetApp , istanza definita dal software o servizio cloud supportato da NetApp Trident.  Tra gli esempi figurano un sistema di archiviazione NetApp AFF , Amazon FSx ONTAP, Azure NetApp Files, Google Cloud NetApp Volumes o un'istanza NetApp Cloud Volumes ONTAP .  Inoltre, la soluzione può essere implementata su qualsiasi cluster Kubernetes, a condizione che la versione di Kubernetes utilizzata sia supportata da NetApp Trident e dagli altri componenti della soluzione implementati.  Per un elenco delle versioni di Kubernetes supportate da Trident, vedere<block ref="7e5b92b70f9fb8a6ea9680492953995f" category="inline-link-rx"></block> .  Per i dettagli sugli ambienti utilizzati per convalidare i vari componenti di questa soluzione, consultare le tabelle seguenti.</block>
  <block id="f9004e284a207cf92c8642965dc258f6" category="section-title">Ambiente di convalida Apache Airflow</block>
  <block id="68782f72ebeb2cac06f03226a6e941bb" category="cell">Componente software</block>
  <block id="385904ba8ac27bcacafadf2113386df4" category="cell">Apache Airflow</block>
  <block id="78fd3ce4c7835c8336b8c4f52bbd8570" category="inline-link-macro">Grafico del timone Apache Airflow</block>
  <block id="923fc06abfe0b856f72313cb88706558" category="cell">2.0.1, distribuito tramite<block ref="d1ea82e80be31e00d2b939c38f87e0a0" category="inline-link-macro-rx"></block> 8.0.8</block>
  <block id="836eb480bf66641d4fb44675e000d22b" category="cell">1,18</block>
  <block id="d029b605d0129cdb050642645b32b1db" category="cell">21,01</block>
  <block id="44ce1bc6a7380dccbb311f0fa6cd1972" category="section-title">Ambiente di convalida JupyterHub</block>
  <block id="6a1bd94b05289cc97fd96ec055920439" category="cell">JupyterHub</block>
  <block id="263ec1d326c1f5a1bfd24b88cb972a38" category="inline-link-macro">Grafico Helm di JupyterHub</block>
  <block id="6af30397902bd26914df2ae5955c4be8" category="cell">4.1.5, distribuito tramite<block ref="26830a1e301761faef592d8e74481ce6" category="inline-link-macro-rx"></block> 3.3.7</block>
  <block id="c272116b61605b9462784a01f5899785" category="cell">1,29</block>
  <block id="4e9b156e7e2788c8cd4b0877fd922657" category="cell">24,02</block>
  <block id="aa3652d1dedca9375b76c8e59797d756" category="section-title">Ambiente di convalida MLflow</block>
  <block id="c8d3451e7307fb1b46769ec23ea7906a" category="cell">Flusso ML</block>
  <block id="04d257103d25b778df7089d6dbb0cb44" category="inline-link-macro">Grafico Helm MLflow</block>
  <block id="4814bad32946214124af37f70a7bee91" category="cell">2.14.1, distribuito tramite<block ref="4baf34adb826df0481d498e42290114c" category="inline-link-macro-rx"></block> 1.4.12</block>
  <block id="6eeb675638e9c361028379b88415e2de" category="section-title">Ambiente di convalida Kubeflow</block>
  <block id="bb643a3a76aab569f9245a19f77d4b65" category="cell">Kubeflow</block>
  <block id="e0d8584ae6ed8fd534954ae8ed8755a3" category="inline-link-macro">deployKF</block>
  <block id="bb675cbb86ae4db4a1f3da16e57113cd" category="cell">1.7, distribuito tramite<block ref="f0761e2008489c964db22d8d03da0a67" category="inline-link-macro-rx"></block> 0.1.1</block>
  <block id="32b2e96c4f6d14da1df5b25db372de8f" category="cell">1,26</block>
  <block id="217af7d1776d22530d98be04d104fd49" category="cell">23,07</block>
  <block id="db5eb84117d06047c97c9a0191b5fffe" category="section-title">Supporto</block>
  <block id="b2e75bbfb9933bc21b7f875e8676641d" category="inline-link-macro">contattare NetApp</block>
  <block id="952c6ea6549ebf347f6aae3d6b029756" category="paragraph">NetApp non offre supporto aziendale per Apache Airflow, JupyterHub, MLflow, Kubeflow o Kubernetes.  Se sei interessato a una piattaforma MLOps completamente supportata,<block ref="15a32e54137b30751a17b6bf2b412f99" category="inline-link-macro-rx"></block> sulle soluzioni MLOps completamente supportate che NetApp offre insieme ai partner.</block>
  <block id="6999319a5a39a9ca41436977f2cb8b8d" category="summary">MLOps open source con NetApp - Panoramica della tecnologia</block>
  <block id="4c9ffff73cd2c66ec9f6be3cb2b21333" category="paragraph">Questa sezione si concentra sulla panoramica tecnologica per OpenSource MLOps con NetApp.</block>
  <block id="5cd2adc9e2a5254e4c1da803519f298b" category="section-title">Intelligenza artificiale</block>
  <block id="c2fabc0982aa161064ff2b73f50800d5" category="paragraph">L'intelligenza artificiale è una disciplina informatica in cui i computer vengono addestrati a imitare le funzioni cognitive della mente umana.  Gli sviluppatori di intelligenza artificiale addestrano i computer ad apprendere e a risolvere i problemi in un modo simile, o addirittura superiore, a quello degli esseri umani.  L'apprendimento profondo e l'apprendimento automatico sono sottocampi dell'intelligenza artificiale.  Le organizzazioni stanno adottando sempre più intelligenza artificiale, apprendimento automatico e apprendimento automatico (DL) per supportare le loro esigenze aziendali critiche.  Ecco alcuni esempi:</block>
  <block id="b3e764d3292b880c63140b20b9a90e6c" category="list-text">Analizzare grandi quantità di dati per scoprire informazioni aziendali precedentemente sconosciute</block>
  <block id="30512c04b26c269ec31ecd09f1f3a208" category="list-text">Interagire direttamente con i clienti utilizzando l'elaborazione del linguaggio naturale</block>
  <block id="4ee20869dbb821d3744d87176797401f" category="list-text">Automazione di vari processi e funzioni aziendali</block>
  <block id="5919922c658bd2a4f33f0cf546be3ea9" category="paragraph">I moderni carichi di lavoro di addestramento e inferenza dell'intelligenza artificiale richiedono capacità di elaborazione parallela estremamente elevate.  Per questo motivo, le GPU vengono sempre più utilizzate per eseguire operazioni di intelligenza artificiale, perché le capacità di elaborazione parallela delle GPU sono di gran lunga superiori a quelle delle CPU generiche.</block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="section-title">Contenitori</block>
  <block id="2154bae452b2343b649ee4b088b399f6" category="paragraph">I container sono istanze isolate dello spazio utente che vengono eseguite su un kernel del sistema operativo host condiviso.  L'adozione dei container è in rapida crescita.  I container offrono molti degli stessi vantaggi dell'application sandboxing offerti dalle macchine virtuali (VM).  Tuttavia, poiché sono stati eliminati i livelli dell'hypervisor e del sistema operativo guest su cui si basano le VM, i container sono molto più leggeri.  La figura seguente illustra una visualizzazione delle macchine virtuali rispetto ai container.</block>
  <block id="91945d3c9ebb2261142b9c7fc516b559" category="inline-link">Sito web Docker</block>
  <block id="d1920cb2aa1d83b6e74ea477546e30a3" category="paragraph">I contenitori consentono inoltre di impacchettare in modo efficiente le dipendenze delle applicazioni, i tempi di esecuzione e così via, direttamente con un'applicazione.  Il formato di packaging dei container più comunemente utilizzato è il container Docker.  Un'applicazione che è stata containerizzata nel formato contenitore Docker può essere eseguita su qualsiasi macchina in grado di eseguire contenitori Docker.  Ciò è vero anche se le dipendenze dell'applicazione non sono presenti sulla macchina, perché tutte le dipendenze sono impacchettate nel contenitore stesso.  Per maggiori informazioni, visita il<block ref="f3aa778c455b7c9002cc51cdc41e7924" category="inline-link-rx"></block> .</block>
  <block id="0d64529eaeaf491f582b2ba0df6149c7" category="paragraph"><block ref="0d64529eaeaf491f582b2ba0df6149c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1304134d4f70b5d09af5fb5a8bda1de8" category="inline-link">Sito web di Kubernetes</block>
  <block id="f0ce8ef614fdf23fe30bc43ff89f53d3" category="paragraph">Kubernetes è una piattaforma di orchestrazione di container distribuita e open source, originariamente progettata da Google e ora gestita dalla Cloud Native Computing Foundation (CNCF).  Kubernetes consente l'automazione delle funzioni di distribuzione, gestione e ridimensionamento per le applicazioni containerizzate.  Negli ultimi anni, Kubernetes si è affermato come la piattaforma di orchestrazione dei container dominante.  Per maggiori informazioni, visita il<block ref="b99a36b6d7a8af9ad1172136115f0275" category="inline-link-rx"></block> .</block>
  <block id="759b696484e9a0ab24afe3237dd85e66" category="paragraph"><block ref="0d26e0900d0eeb1b6e1c8f5cfee8510e" category="inline-link-macro-rx"></block>consente l'utilizzo e la gestione delle risorse di storage su tutte le piattaforme di storage NetApp più diffuse, nel cloud pubblico o in locale, tra cui ONTAP (AFF, FAS, Select, Cloud, Amazon FSx ONTAP), il servizio Azure NetApp Files e Google Cloud NetApp Volumes.  Trident è un orchestratore di storage dinamico compatibile con Container Storage Interface (CSI) che si integra in modo nativo con Kubernetes.</block>
  <block id="db7f413e96e248375d3fabd005ca4fee" category="paragraph">IL<block ref="c4bca757471e0afa8bcb4da8a5f5e802" category="inline-link-macro-rx"></block> è uno strumento basato su Python che semplifica la gestione degli spazi di lavoro di sviluppo/formazione e dei server di inferenza supportati da storage NetApp ad alte prestazioni e scalabile.  Le principali funzionalità includono:</block>
  <block id="b96dbbd391395e38a8ba72ae75c21dc9" category="list-text">Fornisci rapidamente nuovi spazi di lavoro ad alta capacità supportati da storage NetApp scalabile e ad alte prestazioni.</block>
  <block id="629509198041b5749e015afa6a9b2629" category="list-text">Clonare quasi istantaneamente spazi di lavoro ad alta capacità per consentire la sperimentazione o l'iterazione rapida.</block>
  <block id="01f719401b5bc2f16f328b588b0bef97" category="list-text">Salvataggio quasi istantaneo di snapshot di spazi di lavoro ad alta capacità per backup e/o tracciabilità/baselining.</block>
  <block id="8b4d3b8f8e04f8cfef020d43ad93e87a" category="paragraph">Apache Airflow è una piattaforma open source per la gestione dei flussi di lavoro che consente la creazione, la pianificazione e il monitoraggio programmatici di flussi di lavoro aziendali complessi.  Viene spesso utilizzato per automatizzare i flussi di lavoro ETL e di pipeline di dati, ma non si limita a questi tipi di flussi di lavoro.  Il progetto Airflow è stato avviato da Airbnb, ma nel frattempo è diventato molto popolare nel settore e ora rientra sotto l'egida della Apache Software Foundation.  Airflow è scritto in Python, i flussi di lavoro di Airflow vengono creati tramite script Python e Airflow è progettato secondo il principio della "configurazione come codice".  Molti utenti aziendali di Airflow ora eseguono Airflow su Kubernetes.</block>
  <block id="8fb4a72500791f0bea82c5c9b4c33772" category="section-title">Grafi aciclici diretti (DAG)</block>
  <block id="afd712bbacf94fbaf2852bd23c6b1a84" category="paragraph">In Airflow, i flussi di lavoro sono chiamati grafi aciclici diretti (DAG).  I DAG sono costituiti da attività eseguite in sequenza, in parallelo o con una combinazione delle due, a seconda della definizione del DAG.  Lo scheduler Airflow esegue singole attività su una serie di worker, rispettando le dipendenze a livello di attività specificate nella definizione del DAG.  I DAG vengono definiti e creati tramite script Python.</block>
  <block id="802125395813e0bec35472d0403ab94e" category="section-title">Quaderno di Jupyter</block>
  <block id="a0b0430a41f582a12dac8f4d63ab450d" category="inline-link">Sito web di Jupyter</block>
  <block id="2ea401316bb56cd0dd460196fdb8bddc" category="paragraph">I Jupyter Notebook sono documenti simili a wiki che contengono codice live e testo descrittivo.  I notebook Jupyter sono ampiamente utilizzati nella comunità AI e ML come mezzo per documentare, archiviare e condividere progetti AI e ML.  Per maggiori informazioni sui Jupyter Notebooks, visita il<block ref="412a2c3f2a7af96a2a4f6a512ee2088e" category="inline-link-rx"></block> .</block>
  <block id="cc68740519bf7afc9dc5c17acc7db61e" category="section-title">Server Jupyter Notebook</block>
  <block id="1ceb0a3b747e9e685e69bf855aa91001" category="paragraph">Un server Jupyter Notebook è un'applicazione web open source che consente agli utenti di creare Jupyter Notebook.</block>
  <block id="d837769caeb4d9edfd53e4a5a4b94fce" category="inline-link">Sito web JupyterHub</block>
  <block id="aa77da24b3b7d00c6c4b22044c64a028" category="paragraph">JupyterHub è un'applicazione multiutente che consente a un singolo utente di effettuare il provisioning e accedere al proprio server Jupyter Notebook.  Per maggiori informazioni su JupyterHub, visita il<block ref="8b235ac1daecf8d06ace248b8ac07b97" category="inline-link-rx"></block> .</block>
  <block id="891056fdef376263d6563716a06437cd" category="inline-link">Sito web MLflow</block>
  <block id="ea79d93ff06996ce8a177ec9a6f59b26" category="paragraph">MLflow è una popolare piattaforma open source per la gestione del ciclo di vita dell'intelligenza artificiale.  Le caratteristiche principali di MLflow includono il monitoraggio degli esperimenti AI/ML e un repository di modelli AI/ML.  Per maggiori informazioni su MLflow, visita il<block ref="7d5e77d7cbcfeeed8850444afe1d66af" category="inline-link-rx"></block> .</block>
  <block id="173c35c4ef789d6956a0cd6fbd9a0cfc" category="inline-link">Sito web di Kubeflow</block>
  <block id="9a9c31b74376d75ed88c300dfd734acf" category="paragraph">Kubeflow è un toolkit open source di intelligenza artificiale e apprendimento automatico per Kubernetes, originariamente sviluppato da Google.  Il progetto Kubeflow rende le distribuzioni di flussi di lavoro di intelligenza artificiale e apprendimento automatico su Kubernetes semplici, portabili e scalabili.  Kubeflow astrae le complessità di Kubernetes, consentendo agli scienziati dei dati di concentrarsi su ciò che conoscono meglio: la scienza dei dati.  Per una visualizzazione, vedere la figura seguente.  Kubeflow è una buona opzione open source per le organizzazioni che preferiscono una piattaforma MLOps all-in-one.  Per maggiori informazioni, visita il<block ref="bbfd4ba68f44e2ff98f04ea32205485d" category="inline-link-rx"></block> .</block>
  <block id="e569c07c88fe6f8af1f63410c200abd1" category="section-title">Pipeline Kubeflow</block>
  <block id="7236436bac67d8eaadbf52811774b916" category="inline-link">documentazione ufficiale di Kubeflow</block>
  <block id="f69bb06b79f60baced2f6faf97fc9e14" category="paragraph">Le pipeline di Kubeflow sono un componente chiave di Kubeflow.  Le pipeline Kubeflow sono una piattaforma e uno standard per la definizione e l'implementazione di flussi di lavoro AI e ML portatili e scalabili. Per maggiori informazioni, vedere il<block ref="34d1e4686e190f53e3511c4faa8ac68b" category="inline-link-rx"></block> .</block>
  <block id="7724cfbda1ff4c3052c280f6b4af599c" category="section-title">Notebook Kubeflow</block>
  <block id="352ec4b0886cdd10b69d3efaa4071648" category="paragraph">Kubeflow semplifica il provisioning e la distribuzione dei server Jupyter Notebook su Kubernetes.  Per ulteriori informazioni sui Jupyter Notebook nel contesto di Kubeflow, vedere<block ref="273f9b54e4f57ca19b4597f14d191196" category="inline-link-rx"></block> .</block>
  <block id="d8d51bb44e1cdcb1d7fde82b687339bd" category="section-title">Katib</block>
  <block id="8f5f81b63b950128a2104cb77339c846" category="paragraph">Katib è un progetto nativo di Kubernetes per l'apprendimento automatico automatizzato (AutoML).  Katib supporta la sintonizzazione degli iperparametri, l'arresto anticipato e la ricerca dell'architettura neurale (NAS).  Katib è un progetto indipendente dai framework di apprendimento automatico (ML).  Può ottimizzare gli iperparametri delle applicazioni scritte in qualsiasi linguaggio scelto dall'utente e supporta in modo nativo molti framework ML, come TensorFlow, MXNet, PyTorch, XGBoost e altri.  Katib supporta molti algoritmi AutoML diversi, come l'ottimizzazione bayesiana, gli stimatori dell'albero di Parzen, la ricerca casuale, la strategia di evoluzione dell'adattamento della matrice di covarianza, l'iperbanda, la ricerca efficiente dell'architettura neurale, la ricerca dell'architettura differenziabile e molti altri.  Per ulteriori informazioni sui Jupyter Notebook nel contesto di Kubeflow, vedere<block ref="5b959b0f3dbfc4557138b63a781b201c" category="inline-link-rx"></block> .</block>
  <block id="592d6ad3868437ff65a70353ab870f50" category="list-text">Scalabilità fluida e operazioni senza interruzioni.  ONTAP supporta l'aggiunta non distruttiva di capacità ai controller esistenti e ai cluster scalabili.  I clienti possono passare alle tecnologie più recenti senza costose migrazioni di dati o interruzioni.</block>
  <block id="49a023178611b07475bac0823fc2dd53" category="section-title">Copie snapshot NetApp</block>
  <block id="42884680ea9780d61f4cce71fdc606b1" category="paragraph">Una copia Snapshot NetApp è un'immagine di un volume, di sola lettura e in un determinato momento.  L'immagine consuma uno spazio di archiviazione minimo e comporta un sovraccarico di prestazioni trascurabile, poiché registra solo le modifiche apportate ai file creati dopo l'ultima copia Snapshot, come illustrato nella figura seguente.</block>
  <block id="13455e6dd452fcc850acd6696e670600" category="paragraph">Le copie snapshot devono la loro efficienza alla tecnologia di virtualizzazione dello storage ONTAP di base, Write Anywhere File Layout (WAFL).  Come un database, WAFL utilizza i metadati per puntare ai blocchi di dati effettivi sul disco.  Tuttavia, a differenza di un database, WAFL non sovrascrive i blocchi esistenti.  Scrive i dati aggiornati in un nuovo blocco e modifica i metadati.  Le copie Snapshot sono così efficienti perché ONTAP fa riferimento ai metadati quando crea una copia Snapshot, anziché copiare blocchi di dati.  In questo modo si elimina il tempo di ricerca impiegato da altri sistemi per individuare i blocchi da copiare, nonché il costo della copia stessa.</block>
  <block id="921d0d1d37872e6233bf4da3688b03ef" category="paragraph">È possibile utilizzare una copia Snapshot per recuperare singoli file o LUN oppure per ripristinare l'intero contenuto di un volume.  ONTAP confronta le informazioni del puntatore nella copia Snapshot con i dati sul disco per ricostruire l'oggetto mancante o danneggiato, senza tempi di inattività o costi significativi in termini di prestazioni.</block>
  <block id="fbfe7fb9706620c5ddb7b53cd9e06fa0" category="paragraph"><block ref="fbfe7fb9706620c5ddb7b53cd9e06fa0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76a33b697177fedefd70387e86214ebd" category="section-title">Tecnologia NetApp FlexClone</block>
  <block id="78e8cd917c99154d22a94ba80186ac33" category="paragraph">La tecnologia NetApp FlexClone fa riferimento ai metadati Snapshot per creare copie scrivibili e puntuali di un volume.  Le copie condividono blocchi di dati con i loro genitori, senza consumare spazio di archiviazione, se non quello necessario per i metadati, finché le modifiche non vengono scritte sulla copia, come illustrato nella figura seguente.  Mentre le copie tradizionali possono richiedere minuti o addirittura ore per essere create, il software FlexClone consente di copiare anche i set di dati più grandi in modo quasi istantaneo.  Ciò lo rende ideale per le situazioni in cui sono necessarie più copie di set di dati identici (ad esempio, un'area di lavoro di sviluppo) o copie temporanee di un set di dati (per testare un'applicazione rispetto a un set di dati di produzione).</block>
  <block id="f28d7ba8bb28ad8ce873b4ec7ed61164" category="paragraph"><block ref="f28d7ba8bb28ad8ce873b4ec7ed61164" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f67824f4f94415299484432a092f76b1" category="section-title">Tecnologia di replicazione dei dati NetApp SnapMirror</block>
  <block id="553416a55e03cc49df61e631d17b8011" category="paragraph">Il software NetApp SnapMirror è una soluzione di replica unificata conveniente e facile da usare nell'intero data fabric.  Replica i dati ad alta velocità su LAN o WAN.  Offre un'elevata disponibilità dei dati e una rapida replicazione dei dati per applicazioni di tutti i tipi, comprese le applicazioni aziendali critiche in ambienti sia virtuali che tradizionali.  Quando si replicano i dati su uno o più sistemi di storage NetApp e si aggiornano continuamente i dati secondari, i dati vengono mantenuti aggiornati e sono disponibili ogni volta che ne hai bisogno.  Non sono richiesti server di replicazione esterni.  Per un esempio di architettura che sfrutta la tecnologia SnapMirror , vedere la figura seguente.</block>
  <block id="5a12ba5d186c9ffcce65438f531e7c47" category="paragraph">Il software SnapMirror sfrutta l'efficienza di archiviazione NetApp ONTAP inviando sulla rete solo i blocchi modificati.  Il software SnapMirror utilizza anche la compressione di rete integrata per accelerare i trasferimenti di dati e ridurre l'utilizzo della larghezza di banda di rete fino al 70%.  Grazie alla tecnologia SnapMirror , è possibile sfruttare un flusso di dati di replica sottile per creare un singolo repository che gestisce sia il mirror attivo sia le copie point-in-time precedenti, riducendo il traffico di rete fino al 50%.</block>
  <block id="2ab1a10694bb0d67320839630a1c9ccb" category="paragraph"><block ref="c4152c5b1804294b9bc91a2fa3a92230" category="inline-link-macro-rx"></block>è un servizio NetApp per la sincronizzazione rapida e sicura dei dati.  Che tu debba trasferire file tra condivisioni file NFS o SMB locali, NetApp StorageGRID, NetApp ONTAP S3, Google Cloud NetApp Volumes, Azure NetApp Files, AWS S3, AWS EFS, Azure Blob, Google Cloud Storage o IBM Cloud Object Storage, BlueXP Copy and Sync sposta i file dove ti servono in modo rapido e sicuro.</block>
  <block id="7e333cc0e24ef7489559129fd944c91f" category="paragraph">Una volta trasferiti, i dati saranno completamente disponibili per l'uso sia sulla sorgente che sulla destinazione.  BlueXP Copy and Sync può sincronizzare i dati su richiesta quando viene attivato un aggiornamento oppure sincronizzare i dati in modo continuo in base a una pianificazione predefinita.  In ogni caso, BlueXP Copy and Sync sposta solo i delta, riducendo al minimo il tempo e il denaro spesi per la replicazione dei dati.</block>
  <block id="22716a1c6493f7fb09f4caf2084ad23c" category="paragraph">BlueXP Copy and Sync è uno strumento software as a service (SaaS) estremamente semplice da configurare e utilizzare.  I trasferimenti di dati attivati da BlueXP Copy and Sync vengono eseguiti da broker di dati.  I broker di dati BlueXP Copy and Sync possono essere distribuiti su AWS, Azure, Google Cloud Platform o in locale.</block>
  <block id="204b9ffafe28e07fef53f08e2924e621" category="paragraph"><block ref="8eb894646a418e33ca3d088f11e4914c" category="inline-link-macro-rx"></block>è un software basato su client per migrazioni di dati da NetApp a NetApp e da NetApp a NetApp e per analisi del file system.  XCP è progettato per scalare e raggiungere le massime prestazioni utilizzando tutte le risorse di sistema disponibili per gestire set di dati di grandi volumi e migrazioni ad alte prestazioni.  XCP ti aiuta ad ottenere una visibilità completa del file system con la possibilità di generare report.</block>
  <block id="957e30f73566564bd8a99a6fac13e015" category="section-title">Volumi NetApp ONTAP FlexGroup</block>
  <block id="22bd32dacc144ffc2601e6685260b4c3" category="paragraph">Un set di dati di addestramento può essere una raccolta di potenzialmente miliardi di file.  I file possono contenere testo, audio, video e altre forme di dati non strutturati che devono essere archiviati ed elaborati per poter essere letti in parallelo.  Il sistema di archiviazione deve memorizzare un gran numero di file di piccole dimensioni e deve leggere tali file in parallelo per l'I/O sequenziale e casuale.</block>
  <block id="6d7d8c1311f5ac7d2ed289e012822f78" category="paragraph">Un volume FlexGroup è un singolo spazio dei nomi che comprende più volumi membri costituenti, come mostrato nella figura seguente.  Dal punto di vista di un amministratore di storage, un volume FlexGroup viene gestito e si comporta come un FlexVol volume NetApp FlexVol.  I file in un volume FlexGroup vengono assegnati ai singoli volumi membri e non vengono distribuiti tra volumi o nodi.  Abilitano le seguenti funzionalità:</block>
  <block id="28f25e3d6de5d5fe801c8d194234f0a5" category="list-text">I volumi FlexGroup forniscono diversi petabyte di capacità e una latenza bassa e prevedibile per carichi di lavoro con metadati elevati.</block>
  <block id="82b42713e1be50bb140b7e85eecdd91f" category="list-text">Supportano fino a 400 miliardi di file nello stesso namespace.</block>
  <block id="50af21bd57d5360eb9ffc8dbc4b9a5bd" category="list-text">Supportano operazioni parallelizzate nei carichi di lavoro NAS su CPU, nodi, aggregati e volumi FlexVol costituenti.</block>
  <block id="b0d8567b3e8a1e892d0b59f7a3c27292" category="paragraph"><block ref="b0d8567b3e8a1e892d0b59f7a3c27292" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6459218853a974bb2b38718e6db79ed" category="summary">Questa soluzione ha lo scopo di dimostrare diversi strumenti e framework open source che possono essere incorporati in un flusso di lavoro MLOps.  Questi diversi strumenti e framework possono essere utilizzati insieme o singolarmente, a seconda delle esigenze e del caso d'uso.</block>
  <block id="eb1b19572557d2f13528a30754e9997a" category="doc">MLOps open source con NetApp</block>
  <block id="aa27e598d8d01ff612acd83b47a13b21" category="paragraph">Mike Oglesby, NetApp Sufian Ahmad, NetApp Rick Huang, NetApp Mohan Acharya, NetApp</block>
  <block id="36160a80da6291faa3ebc68ede194279" category="paragraph">Aziende e organizzazioni di tutte le dimensioni e provenienti da numerosi settori si stanno rivolgendo all'intelligenza artificiale (IA) per risolvere problemi del mondo reale, offrire prodotti e servizi innovativi e ottenere un vantaggio in un mercato sempre più competitivo.  Molte organizzazioni si stanno rivolgendo agli strumenti MLOps open source per stare al passo con il rapido ritmo dell'innovazione nel settore.  Questi strumenti open source offrono funzionalità avanzate e all'avanguardia, ma spesso non tengono conto della disponibilità e della sicurezza dei dati.  Sfortunatamente, ciò significa che gli scienziati dei dati altamente qualificati sono costretti a trascorrere molto tempo in attesa di accedere ai dati o di completare le operazioni rudimentali relative ai dati.  Abbinando i popolari strumenti MLOps open source a un'infrastruttura dati intelligente di NetApp, le organizzazioni possono accelerare i propri pipeline di dati, che a loro volta accelerano le loro iniziative di intelligenza artificiale.  Possono liberare il valore dei propri dati garantendone al contempo la protezione e la sicurezza.  Questa soluzione dimostra l'abbinamento delle funzionalità di gestione dei dati NetApp con diversi strumenti e framework open source diffusi per affrontare queste sfide.</block>
  <block id="ad3ca69dbfa62630ace9a188e93d1f45" category="paragraph">L'elenco seguente evidenzia alcune delle funzionalità chiave abilitate da questa soluzione:</block>
  <block id="e6ffdd80d6efdfae1a367b394ef6afdf" category="list-text">Gli utenti possono rapidamente fornire nuovi volumi di dati ad alta capacità e spazi di lavoro di sviluppo supportati da storage NetApp scalabile e ad alte prestazioni.</block>
  <block id="24f5e64e89b475fca21e0a2d5536aa48" category="list-text">Gli utenti possono clonare quasi istantaneamente volumi di dati ad alta capacità e spazi di sviluppo per consentire la sperimentazione o l'iterazione rapida.</block>
  <block id="4657d40d11cf0257f60a599a2bc266b6" category="list-text">Gli utenti possono salvare quasi istantaneamente snapshot di volumi di dati ad alta capacità e di aree di lavoro di sviluppo per il backup e/o la tracciabilità/baselining.</block>
  <block id="953c95173b5d3944693633d3b6ae7711" category="paragraph"><block ref="953c95173b5d3944693633d3b6ae7711" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3e3d207c7705b0f7dc0142df9cc2790a" category="inline-link-macro">Quaderni Jupyter</block>
  <block id="d1a5554bae0723fdaf349b8047aa0d08" category="paragraph">Un tipico flusso di lavoro MLOps incorpora spazi di lavoro di sviluppo, solitamente sotto forma di<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> ; monitoraggio degli esperimenti; pipeline di formazione automatizzate; pipeline di dati; e inferenza/distribuzione.  Questa soluzione mette in evidenza diversi strumenti e framework che possono essere utilizzati in modo indipendente o combinato per affrontare i diversi aspetti del flusso di lavoro.  Mostreremo inoltre l'abbinamento delle funzionalità di gestione dei dati NetApp con ciascuno di questi strumenti.  Questa soluzione è pensata per offrire elementi costitutivi da cui un'organizzazione può costruire un flusso di lavoro MLOps personalizzato, specifico per i propri casi d'uso e requisiti.</block>
  <block id="0b34fcae55a765c46410fb4116433e75" category="paragraph">Questa soluzione comprende i seguenti strumenti/framework:</block>
  <block id="074cd5ab3a3581efcb92b990cd4ed3b6" category="list-text"><block ref="074cd5ab3a3581efcb92b990cd4ed3b6" category="inline-link-macro-rx"></block></block>
  <block id="ac10ff0174545b18e3fd3b7ab41ebc08" category="list-text"><block ref="ac10ff0174545b18e3fd3b7ab41ebc08" category="inline-link-macro-rx"></block></block>
  <block id="4275daa2701a7c7ad4c1c5df1088ada8" category="list-text"><block ref="4275daa2701a7c7ad4c1c5df1088ada8" category="inline-link-macro-rx"></block></block>
  <block id="a0cf58c060e740cca7f48b1bb399e974" category="list-text"><block ref="a0cf58c060e740cca7f48b1bb399e974" category="inline-link-macro-rx"></block></block>
  <block id="9717b9722e82e47dc4445d7ffc90b79d" category="paragraph">L'elenco seguente descrive i modelli comuni per l'implementazione di questi strumenti in modo indipendente o combinato.</block>
  <block id="3f7626e711a1e660dae85d17fdc35882" category="list-text">Distribuisci JupyterHub, MLflow e Apache Airflow insieme - JupyterHub per<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> , MLflow per il monitoraggio degli esperimenti e Apache Airflow per la formazione automatizzata e le pipeline di dati.</block>
  <block id="1dceee44b0bde0ef7364704241dced5a" category="list-text">Distribuisci Kubeflow e Apache Airflow insieme - Kubeflow per<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> , monitoraggio degli esperimenti, pipeline di formazione automatizzate e inferenza; e Apache Airflow per pipeline di dati.</block>
  <block id="aa815dfaf0c405504952ea2a361a2a3e" category="list-text">Distribuisci Kubeflow come soluzione di piattaforma MLOps all-in-one per<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> , monitoraggio degli esperimenti, formazione automatizzata e pipeline di dati e inferenza.</block>
  <block id="6ca687fb1fabca3bf671bc9bf39dbf27" category="summary">MLOps open source con NetApp - Distribuzione JupyterHub</block>
  <block id="09d2043b79460eb224957589f59ab494" category="doc">Distribuzione di JupyterHub</block>
  <block id="2ab6902fa61e1ea6912baf903a3b0bf1" category="paragraph">Questa sezione descrive le attività che devi completare per distribuire JupyterHub nel tuo cluster Kubernetes.</block>
  <block id="26e29fcdb4d615c34b7fedb3a0564f8f" category="admonition">È possibile distribuire JupyterHub su piattaforme diverse da Kubernetes.  L'implementazione di JupyterHub su piattaforme diverse da Kubernetes esula dall'ambito di questa soluzione.</block>
  <block id="99b37bb800ce4a91a3634a32f40b891b" category="list-text">Hai già installato e configurato NetApp Trident nel tuo cluster Kubernetes.  Per maggiori dettagli su Trident, fare riferimento al<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> .</block>
  <block id="2ac6b5f4951f689f17ae54334df0112f" category="paragraph">JupyterHub viene distribuito tramite Helm, un noto gestore di pacchetti per Kubernetes.  Prima di distribuire JupyterHub, devi installare Helm sul tuo nodo di controllo Kubernetes.  Per installare Helm, seguire le istruzioni<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> nella documentazione ufficiale di Helm.</block>
  <block id="c0b1a9427c281e6178bd6cbeb95bc3a8" category="paragraph">Prima di distribuire JupyterHub, è necessario designare una StorageClass predefinita all'interno del cluster Kubernetes.  Per designare una StorageClass predefinita all'interno del cluster, seguire le istruzioni descritte in<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block> sezione.  Se hai già designato una StorageClass predefinita all'interno del tuo cluster, puoi saltare questo passaggio.</block>
  <block id="771d8827304382e84db174fab916e726" category="section-title">Distribuisci JupyterHub</block>
  <block id="cca32ccd336a1d99e57fe4b732c1db03" category="paragraph">Dopo aver completato i passaggi precedenti, sei pronto per distribuire JupyterHub.  Per distribuire JupyterHub sono necessari i seguenti passaggi:</block>
  <block id="02e6e3cd99fedc7e13d22d86bad5b831" category="section-title">Configurare la distribuzione di JupyterHub</block>
  <block id="ce95551547fa8ef240a593be5a20f5ee" category="paragraph">Prima della distribuzione è buona norma ottimizzare la distribuzione di JupyterHub per il proprio ambiente.  È possibile creare un file *config.yaml* e utilizzarlo durante la distribuzione tramite il grafico Helm.</block>
  <block id="53db901aeed4328fe567404ccb21206d" category="paragraph">Un esempio di file *config.yaml* può essere trovato qui<block ref="8c152549701847c833121b3ad8e4af72" category="inline-link-rx"></block></block>
  <block id="d4acad87b1acbfd617a3b4988bfb1864" category="admonition">In questo file config.yaml è possibile impostare il parametro *(singleuser.storage.dynamic.storageClass)* per NetApp Trident StorageClass.  Questa è la classe di archiviazione che verrà utilizzata per predisporre i volumi per gli spazi di lavoro dei singoli utenti.</block>
  <block id="fc1be4924094aec74f37b59bbd957af8" category="section-title">Aggiunta di volumi condivisi</block>
  <block id="67e834a52ce0a7019fd9a1bec4bae36f" category="paragraph">Se vuoi utilizzare un volume condiviso per tutti gli utenti di JupyterHub, puoi modificare di conseguenza il tuo *config.yaml*.  Ad esempio, se hai un PersistentVolumeClaim condiviso denominato jupyterhub-shared-volume, puoi montarlo come /home/shared in tutti i pod utente come:</block>
  <block id="a66a54102aa462ebdfe0146ca96eaf33" category="admonition">Questo è un passaggio facoltativo, puoi adattare questi parametri alle tue esigenze.</block>
  <block id="67c7fe5cd005737db341f115281a5f71" category="section-title">Distribuisci JupyterHub con Helm Chart</block>
  <block id="54ad8b66fcd369a80298610d95ca37d9" category="paragraph">Informa Helm del repository dei grafici JupyterHub Helm.</block>
  <block id="f98aad3b24c5bab5b4737b8fad3a723f" category="paragraph">Dovrebbe apparire un output simile a questo:</block>
  <block id="4e29332ac1db944879502e11ab327960" category="paragraph">Ora installa il grafico configurato dal tuo config.yaml eseguendo questo comando dalla directory che contiene il tuo config.yaml:</block>
  <block id="be118fb1d0e987a9d25c71312374ffdf" category="admonition">In questo esempio:</block>
  <block id="750e13a1159e4f2b96ba2d8fadfb1aab" category="paragraph">&lt;helm-release-name&gt; è impostato su my-jupyterhub, che sarà il nome della tua release JupyterHub.  &lt;k8s-namespace&gt; è impostato su my-namespace, che è lo spazio dei nomi in cui si desidera installare JupyterHub.  Il flag --create-namespace viene utilizzato per creare lo spazio dei nomi se non esiste già.  Il flag --values specifica il file config.yaml che contiene le opzioni di configurazione desiderate.</block>
  <block id="0873eec3dcb328f01cc596581047ae60" category="section-title">Controlla la distribuzione</block>
  <block id="5b252fe874ba4bfb32f7c039993801ab" category="paragraph">Mentre è in esecuzione il passaggio 2, puoi vedere i pod creati tramite il seguente comando:</block>
  <block id="828e0f094cad198231ffd340f281e098" category="paragraph">Attendi che l'hub e il proxy pod entrino nello stato In esecuzione.</block>
  <block id="4f8f16ff2582a84eb01cbef90f467393" category="section-title">Accedi a JupyterHub</block>
  <block id="c7433009ea218afe4c1117491e4afccb" category="paragraph">Trova l'IP che possiamo usare per accedere a JupyterHub.  Eseguire il seguente comando finché l'indirizzo EXTERNAL-IP del servizio proxy-public non è disponibile, come nell'output di esempio.</block>
  <block id="7261a4593eb504b7857e5e4dd9a5459c" category="admonition">Abbiamo utilizzato il servizio NodePort nel nostro file config.yaml; puoi adattarlo al tuo ambiente in base alla configurazione (ad esempio LoadBalancer).</block>
  <block id="a5673ab624b33fdb767b6ec77b9901ca" category="paragraph">Per utilizzare JupyterHub, inserisci l'IP esterno per il servizio proxy-public in un browser.</block>
  <block id="9b5d03606d5f2609a4b9a6f1ac626a8d" category="summary">Open Source MLOps con NetApp : utilizza NetApp DataOps Toolkit con JupyterHub</block>
  <block id="8fc5f752dfcb57cd9232177f28b14765" category="doc">Utilizzare NetApp DataOps Toolkit con JupyterHub</block>
  <block id="0162e970f8577425266cb5c97d21c2a7" category="paragraph">IL<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> può essere utilizzato insieme a JupyterHub.  Utilizzando NetApp DataOps Toolkit con JupyterHub, gli utenti finali possono creare snapshot di volumi per il backup dell'area di lavoro e/o la tracciabilità del set di dati al modello direttamente da un Jupyter Notebook.</block>
  <block id="8f08aaf2916d1654fc96af766c150251" category="paragraph">Prima di poter utilizzare DataOps Toolkit con JupyterHub, è necessario concedere le autorizzazioni appropriate all'account del servizio Kubernetes che JupyterHub assegna ai singoli pod utente di Jupyter Notebook Server.  JupyterHub utilizza l'account di servizio specificato da<block ref="b8c80a6db053e98d7341438c2eb0aea3" prefix=" " category="inline-code"></block> variabile nel file di configurazione del grafico Helm di JupyterHub.</block>
  <block id="a815fb28e94390b627bc7915911578cf" category="section-title">Crea un ruolo cluster per DataOps Toolkit</block>
  <block id="333372e6f3961af5df82304243a2d5ba" category="paragraph">Per prima cosa, crea un ruolo cluster denominato "netapp-dataops" che disponga delle autorizzazioni API Kubernetes necessarie per la creazione di snapshot del volume.</block>
  <block id="3805f69a30879fb016e5c3d0a85fab77" category="section-title">Assegnare il ruolo del cluster all'account del servizio Notebook Server</block>
  <block id="19506ab4aa03158eeea933145bd0471d" category="paragraph">Creare un'associazione di ruolo che assegni il ruolo del cluster 'netapp-dataops-snapshots' all'account di servizio appropriato nello spazio dei nomi appropriato.  Ad esempio, se hai installato JupyterHub nello spazio dei nomi 'jupyterhub' e hai specificato l'account di servizio 'predefinito' tramite<block ref="b8c80a6db053e98d7341438c2eb0aea3" prefix=" " category="inline-code"></block> variabile, dovresti assegnare il ruolo del cluster 'netapp-dataops-snapshots' all'account di servizio 'default' nello spazio dei nomi 'jupyterhub' come mostrato nell'esempio seguente.</block>
  <block id="fe7233ebd9f644239a2437c55d3419e1" category="section-title">Creare snapshot di volume all'interno di Jupyter Notebook</block>
  <block id="02dd051970bea675e5def458342cd6e3" category="paragraph">Ora gli utenti di JupyterHub possono utilizzare NetApp DataOps Toolkit per creare snapshot di volumi direttamente da un Jupyter Notebook, come mostrato nell'esempio seguente.</block>
  <block id="6bd0178572fd0f85ae777cd2c67d0907" category="paragraph"><block ref="6bd0178572fd0f85ae777cd2c67d0907" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ffc4debfa03808ebe14380555e9a891" category="summary">Acquisizione dati con NetApp SnapMirror</block>
  <block id="c9cfa55f76ce30116dc6c4a9d937fa9d" category="doc">Importa dati in JupyterHub con NetApp SnapMirror</block>
  <block id="98aa5dbb610473a52540e5d0699bd079" category="paragraph">NetApp SnapMirror è una tecnologia di replicazione che consente di replicare i dati tra i sistemi di storage NetApp .  SnapMirror può essere utilizzato per importare dati da ambienti remoti in JupyterHub.</block>
  <block id="815eb616a6188ae082d3024fbb91e45e" category="section-title">Esempio di flusso di lavoro e demo</block>
  <block id="a3e50a098653f80e6a42662ee52e8b55" category="inline-link-macro">questo post del blog Tech ONTAP</block>
  <block id="5eae3f83c7f60bb551b097ccf3a4012b" category="paragraph">Fare riferimento a<block ref="585bdb2d9e21d8036a261701b86d814c" category="inline-link-macro-rx"></block> per un esempio dettagliato del flusso di lavoro e una demo dell'utilizzo di NetApp SnapMirror per l'acquisizione di dati in JupyterHub.</block>
  <block id="ba47b65d29a2bcf968281d1e04ee29bb" category="summary">MLOps open source con NetApp - Distribuzione Kubeflow</block>
  <block id="e560b8ed748180150ee1a196f2247fce" category="paragraph">Questa sezione descrive le attività che devi completare per distribuire Kubeflow nel tuo cluster Kubernetes.</block>
  <block id="f3538dfada37d551dd71f26249dd82c6" category="list-text">Hai già un cluster Kubernetes funzionante e stai eseguendo una versione di Kubernetes supportata dalla versione di Kubeflow che intendi distribuire.  Per un elenco delle versioni di Kubernetes supportate, fare riferimento alle dipendenze per la versione di Kubeflow in<block ref="b84967824090781ee960169bb3232fc6" category="inline-link-macro-rx"></block> .</block>
  <block id="84d21063d216560d873bc66cd38d62e8" category="paragraph">Prima di distribuire Kubeflow, ti consigliamo di designare una StorageClass predefinita all'interno del tuo cluster Kubernetes.  Il processo di distribuzione di Kubeflow potrebbe tentare di effettuare il provisioning di nuovi volumi persistenti utilizzando la StorageClass predefinita.  Se non viene designata alcuna StorageClass come StorageClass predefinita, la distribuzione potrebbe non riuscire.  Per designare una StorageClass predefinita all'interno del cluster, eseguire la seguente attività dall'host di jump di distribuzione.  Se hai già designato una StorageClass predefinita all'interno del tuo cluster, puoi saltare questo passaggio.</block>
  <block id="d371ec612c125519e69855ad89d4445b" category="list-text">Designa una delle StorageClass esistenti come StorageClass predefinita.  I comandi di esempio che seguono mostrano la designazione di una StorageClass denominata<block ref="19a55e78496416c8db6565a114cfd5f3" prefix=" " category="inline-code"></block> come StorageClass predefinito.</block>
  <block id="f830a6eea70ae3a0e7af4606462ad281" category="admonition">IL<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Il tipo Trident Backend ha una dimensione minima del PVC piuttosto grande.  Per impostazione predefinita, Kubeflow tenta di fornire PVC di dimensioni pari solo a pochi GB.  Pertanto, non dovresti designare una StorageClass che utilizza<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Tipo di backend come StorageClass predefinito ai fini della distribuzione di Kubeflow.</block>
  <block id="7724a5f9edc284eef2e4bc112adc1dd9" category="section-title">Opzioni di distribuzione di Kubeflow</block>
  <block id="e135506d2171533787a405262eeb67bc" category="paragraph">Esistono molte opzioni diverse per distribuire Kubeflow.  Fare riferimento al<block ref="59d814781a574912b676e75f9fe0e882" category="inline-link-macro-rx"></block> per un elenco delle opzioni di distribuzione e scegli l'opzione più adatta alle tue esigenze.</block>
  <block id="07379a7db414d96104f4d3ab35ee3d59" category="admonition">Per scopi di convalida, abbiamo distribuito Kubeflow 1.7 utilizzando<block ref="f36b6222867dc75589b32398e1411061" category="inline-link-macro-rx"></block> 0.1.1.</block>
  <block id="0dbcc7b3c9a4c5ed6afff19c771a989d" category="summary">Open Source MLOps con NetApp : utilizza NetApp DataOps Toolkit con Kubeflow</block>
  <block id="3b70474868bce72e0d5d1fac42d1f643" category="doc">Utilizzare NetApp DataOps Toolkit con Kubeflow</block>
  <block id="6e4cd672cd8bd06c42a9e4ba697c61de" category="inline-link">NetApp Data Science Toolkit per Kubernetes</block>
  <block id="4065ea77b68b6d949a165c54fc532d2a" category="paragraph">IL<block ref="6f920cea43eeb6dd3a1bfb8ce1f9946a" category="inline-link-rx"></block> può essere utilizzato insieme a Kubeflow.  L'utilizzo di NetApp Data Science Toolkit con Kubeflow offre i seguenti vantaggi:</block>
  <block id="0a19b387d7028ea674dc64f74ecb97ea" category="list-text">Gli scienziati dei dati possono eseguire operazioni avanzate di gestione dei dati NetApp , come la creazione di snapshot e cloni, direttamente da un Jupyter Notebook.</block>
  <block id="f4a972e1ae8aa85c6e67d7ad0ccc6dc4" category="list-text">Le operazioni avanzate di gestione dei dati NetApp , come la creazione di snapshot e cloni, possono essere integrate in flussi di lavoro automatizzati utilizzando il framework Kubeflow Pipelines.</block>
  <block id="5e646a4ae4330cb948544333980f9f49" category="inline-link">Esempi di Kubeflow</block>
  <block id="f1db0bc6ea6a4eee559e5d9946fd92ea" category="paragraph">Fare riferimento al<block ref="a5886b5aa215f1fd67a69d09a2725b9d" category="inline-link-rx"></block> sezione all'interno del repository GitHub del NetApp Data Science Toolkit per i dettagli sull'utilizzo del toolkit con Kubeflow.</block>
  <block id="0e82e7615bc43e60306731cd1402df29" category="summary">MLOps open source con NetApp : predisponi uno spazio di lavoro Jupyter Notebook per l'uso da parte di data scientist o sviluppatori</block>
  <block id="7fad49a67f130cbd7629be2d6c719aea" category="doc">Fornire un'area di lavoro Jupyter Notebook per l'uso da parte di Data Scientist o Sviluppatori</block>
  <block id="b09a995a770ac7d1022303afcc4effb0" category="paragraph">Kubeflow è in grado di fornire rapidamente nuovi server Jupyter Notebook che fungano da spazi di lavoro per gli scienziati dei dati.  Per ulteriori informazioni sui notebook Jupyter nel contesto Kubeflow, vedere<block ref="05932219411c169f9e48f874e56f1ed3" category="inline-link-rx"></block> .</block>
  <block id="6b9617f7154782faea34239e9eb5ea4a" category="paragraph"><block ref="6b9617f7154782faea34239e9eb5ea4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e6dc629616db1f269870318e89e7522" category="summary">MLOps open source con NetApp - Esempio di flusso di lavoro - Addestrare un modello di riconoscimento delle immagini utilizzando Kubeflow e NetApp DataOps Toolkit</block>
  <block id="659e23f00660c05c4b7cf730eae0befe" category="doc">Esempio di flusso di lavoro: addestrare un modello di riconoscimento delle immagini utilizzando Kubeflow e NetApp DataOps Toolkit</block>
  <block id="cc799f8653f5775220453347865834a9" category="paragraph">Questa sezione descrive i passaggi necessari per addestrare e distribuire una rete neurale per il riconoscimento delle immagini utilizzando Kubeflow e NetApp DataOps Toolkit.  Questo esempio vuole mostrare un lavoro di formazione che incorpora l'archiviazione NetApp .</block>
  <block id="b759ef76b26f922987fbf418c77766cb" category="paragraph">Creare un Dockerfile con le configurazioni richieste da utilizzare per i passaggi di training e test all'interno della pipeline Kubeflow.  Ecco un esempio di Dockerfile:</block>
  <block id="d1658ed5f5e35aee28cc518869591c5b" category="paragraph">A seconda delle tue esigenze, installa tutte le librerie e i pacchetti necessari per eseguire il programma.  Prima di addestrare il modello di Machine Learning, si presuppone che si disponga già di una distribuzione Kubeflow funzionante.</block>
  <block id="1d7fb7fa777edda515304ad19af75036" category="section-title">Addestrare una piccola rete neurale su dati MNIST utilizzando pipeline PyTorch e Kubeflow</block>
  <block id="a2d6c085b2bfbb3fc92caceedba6806e" category="paragraph">Utilizziamo l'esempio di una piccola rete neurale addestrata sui dati MNIST.  Il set di dati MNIST è costituito da immagini manoscritte di cifre da 0 a 9.  Le immagini hanno una dimensione di 28x28 pixel.  Il set di dati è suddiviso in 60.000 immagini di treno e 10.000 immagini di convalida.  La rete neurale utilizzata per questo esperimento è una rete feedforward a 2 strati.  La formazione viene eseguita utilizzando Kubeflow Pipelines. Fare riferimento alla documentazione<block ref="bcb10ee1db2d847a3cadc06c872375ac" category="inline-link-rx"></block> per maggiori informazioni.  La nostra pipeline Kubeflow incorpora l'immagine Docker dalla sezione Prerequisiti.</block>
  <block id="edfa32db89306c0de4efde13667133a5" category="inline-image-macro">Visualizzazione dell'esecuzione della pipeline di Kubeflow</block>
  <block id="c0bdd0d6d088108de0d2d172bd2f25be" category="paragraph"><block ref="c0bdd0d6d088108de0d2d172bd2f25be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7d85cbff0f5dec5d5092004b5b8774e" category="section-title">Visualizza i risultati utilizzando Tensorboard</block>
  <block id="d3246eab9678602f9301a80184803dff" category="inline-link">Tensorboard</block>
  <block id="12e2a8be9c4e17ffc7dc66217d8530ff" category="paragraph">Una volta addestrato il modello, possiamo visualizzare i risultati utilizzando Tensorboard.<block ref="a07862d9a0e51dec9c3587e87c541181" category="inline-link-rx"></block> è disponibile come funzionalità nella dashboard di Kubeflow.  Puoi creare un tensorboard personalizzato per il tuo lavoro.  Di seguito è riportato un esempio che mostra il grafico dell'accuratezza dell'addestramento rispetto al numero di epoche e della perdita dell'addestramento rispetto al numero di epoche.</block>
  <block id="1618fe0e500d9ed850d5e614c6620fd8" category="inline-image-macro">Grafico Tensorboard per la perdita di allenamento e la precisione</block>
  <block id="cd45b495d2fd4d214ea7c430a9980d0a" category="paragraph"><block ref="cd45b495d2fd4d214ea7c430a9980d0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbdd778d6f4497497010df3f4ae35a67" category="section-title">Sperimentare con gli iperparametri utilizzando Katib</block>
  <block id="a47bff2eb2b867ca89a553eeb14da493" category="paragraph"><block ref="98b590f3a453d1e0809708b45d553c8f" category="inline-link-rx"></block>è uno strumento all'interno di Kubeflow che può essere utilizzato per sperimentare con gli iperparametri del modello.  Per creare un esperimento, definisci prima una metrica/un obiettivo desiderato.  Di solito questa è la precisione del test.  Una volta definita la metrica, scegli gli iperparametri con cui vuoi sperimentare (ottimizzatore/tasso di apprendimento/numero di livelli).  Katib esegue una scansione degli iperparametri con i valori definiti dall'utente per trovare la migliore combinazione di parametri che soddisfi la metrica desiderata.  È possibile definire questi parametri in ogni sezione dell'interfaccia utente.  In alternativa, è possibile definire un file *YAML* con le specifiche necessarie.  Di seguito è riportata un'illustrazione di un esperimento di Katib:</block>
  <block id="70e367edef0d0f2a63f6fff084365aa4" category="inline-image-macro">Dashboard dell'esperimento Katib con iperparametri</block>
  <block id="12f61d15ca34416b644cbd8238634541" category="paragraph"><block ref="12f61d15ca34416b644cbd8238634541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd53955b02bf4a8bb0a318390df24ae6" category="inline-image-macro">Controllo di prova riuscito</block>
  <block id="600782cca16442259d603526a7cd0b29" category="paragraph"><block ref="600782cca16442259d603526a7cd0b29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18d3e96caf95415deff9bb8b5bc25063" category="section-title">Utilizzare gli snapshot NetApp per salvare i dati per la tracciabilità</block>
  <block id="0b6ef7f84e44ffbb76d4eef1ef587269" category="paragraph">Durante l'addestramento del modello, potremmo voler salvare un'istantanea del set di dati di addestramento per la tracciabilità.  Per fare ciò, possiamo aggiungere un passaggio di snapshot alla pipeline come mostrato di seguito.  Per creare lo snapshot, possiamo usare il<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> .</block>
  <block id="9f205d5330ff4142363e15d261753156" category="inline-image-macro">Codice per creare una pipeline Snapshot in Kubeflow</block>
  <block id="18242bdffd149a4d04c88b7208997f55" category="paragraph"><block ref="18242bdffd149a4d04c88b7208997f55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe2b6f01ffb206a03c2e0fd0a802a4ca" category="inline-link">Esempio di NetApp DataOps Toolkit per Kubeflow</block>
  <block id="7ba41dac79bc84ef4a806ce87fc4f97a" category="paragraph">Fare riferimento al <block ref="f0b3c05b3c22509c21d3296c77ee92d9" category="inline-link-rx"></block> per maggiori informazioni.</block>
  <block id="8ec1b3ffcff14d3a7476fee4a3e80bbd" category="summary">Open Source MLOps con NetApp - Distribuzione MLflow</block>
  <block id="1e24ddb7a6a8df2478eebd688cf1f1df" category="doc">Distribuzione MLflow</block>
  <block id="eba75f7702c8d580f100f5c6e819419a" category="paragraph">Questa sezione descrive le attività che devi completare per distribuire MLflow nel tuo cluster Kubernetes.</block>
  <block id="1988a9fc415911c1b6cb091f9672aa99" category="admonition">È possibile distribuire MLflow su piattaforme diverse da Kubernetes.  L'implementazione di MLflow su piattaforme diverse da Kubernetes esula dall'ambito di questa soluzione.</block>
  <block id="effe3b356a9db8beeafdbe3692a3df6b" category="paragraph">MLflow viene distribuito tramite Helm, un noto gestore di pacchetti per Kubernetes.  Prima di distribuire MLflow, è necessario installare Helm sul nodo di controllo Kubernetes.  Per installare Helm, seguire le istruzioni<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> nella documentazione ufficiale di Helm.</block>
  <block id="01fb0f36d01f7edcdcc66273b214f218" category="paragraph">Prima di distribuire MLflow, è necessario designare una StorageClass predefinita all'interno del cluster Kubernetes.  Per designare una StorageClass predefinita all'interno del cluster, seguire le istruzioni descritte in<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block> sezione.  Se hai già designato una StorageClass predefinita all'interno del tuo cluster, puoi saltare questo passaggio.</block>
  <block id="6369a4aa768b1882566ceb106febe885" category="section-title">Distribuisci MLflow</block>
  <block id="4996360f41c2160eefec53bc938631c4" category="paragraph">Una volta soddisfatti i prerequisiti, è possibile iniziare la distribuzione di MLflow utilizzando il grafico Helm.</block>
  <block id="9b40c49f5b19b6b30c8e46c9a322cfa9" category="section-title">Configurare la distribuzione del grafico Helm di MLflow.</block>
  <block id="54662ab0339cacf58980938d0d2997f6" category="paragraph">Prima di distribuire MLflow utilizzando il grafico Helm, possiamo configurare la distribuzione per utilizzare NetApp Trident Storage Class e modificare altri parametri in base alle nostre esigenze utilizzando un file *config.yaml*.  Un esempio del file *config.yaml* può essere trovato qui:<block ref="3fb631fe4b90fe5302819c1b11e0f768" category="inline-link-rx"></block></block>
  <block id="3ffd497fc5215b526be90b762ad3c730" category="admonition">È possibile impostare Trident storageClass nel parametro *global.defaultStorageClass* nel file config.yaml (ad esempio storageClass: "ontap-flexvol").</block>
  <block id="b0e9e89059c66feb24d2bae1faade5b4" category="section-title">Installazione della tabella del timone</block>
  <block id="e2de44bdf60d5282b2d1f5dce8ef9fb8" category="paragraph">Il grafico Helm può essere installato con il file *config.yaml* personalizzato per MLflow utilizzando il seguente comando:</block>
  <block id="b8fe21ea18633e2ba5c911e2b6c64135" category="admonition">Il comando distribuisce MLflow sul cluster Kubernetes nella configurazione personalizzata tramite il file *config.yaml* fornito.  MLflow viene distribuito nello spazio dei nomi specificato e per la release viene assegnato un nome di rilascio casuale tramite Kubernetes.</block>
  <block id="fe92b5543c9bb0daa69543a737a9937a" category="paragraph">Dopo aver completato la distribuzione del grafico Helm, puoi verificare se il servizio è accessibile utilizzando:</block>
  <block id="5001194091e3ac05acb36e50188181cd" category="admonition">Sostituisci *jupyterhub* con lo spazio dei nomi utilizzato durante la distribuzione.</block>
  <block id="624995aae5a71a1b6b698d125dfa593f" category="paragraph">Dovresti vedere i seguenti servizi:</block>
  <block id="0727c036d98dcf728bf3678abc379532" category="admonition">Abbiamo modificato il file config.yaml per utilizzare il servizio NodePort per accedere a MLflow sulla porta 30002.</block>
  <block id="49ed0a1879305290bd3f5a83a6ebc4a2" category="section-title">Accedi a MLflow</block>
  <block id="4336069c7c6830c86e24b3590bc33968" category="paragraph">Una volta che tutti i servizi relativi a MLflow sono attivi e funzionanti, è possibile accedervi utilizzando l'indirizzo IP NodePort o LoadBalancer specificato (ad esempio<block ref="4470100f30fdceb8d4bf43ad086f55fe" prefix=" " category="inline-code"></block> )</block>
  <block id="4cdff711c1556a59f967422b42a85088" category="summary">MLOps open source con NetApp : tracciabilità dal set di dati al modello con NetApp e MLflow</block>
  <block id="96ea5f01f5435b957b4ccda05e9edc2a" category="doc">Tracciabilità dal set di dati al modello con NetApp e MLflow</block>
  <block id="49f4e58115751b6e777c0881bed17f7b" category="paragraph">IL<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> può essere utilizzato insieme alle funzionalità di tracciamento degli esperimenti di MLflow per implementare la tracciabilità dal set di dati al modello o dall'area di lavoro al modello.</block>
  <block id="a6086bfa36daf4e19b000df54ab1dd1e" category="paragraph">Per implementare la tracciabilità dal set di dati al modello o dall'area di lavoro al modello, è sufficiente creare uno snapshot del volume del set di dati o dell'area di lavoro utilizzando DataOps Toolkit come parte dell'esecuzione dell'addestramento, come mostrato nel seguente frammento di codice di esempio.  Questo codice salverà il nome del volume di dati e il nome dello snapshot come tag associati all'esecuzione di addestramento specifica che stai registrando sul tuo server di monitoraggio degli esperimenti MLflow.</block>
  <block id="f8e6fa4a88901fdc129b3ce376463f53" category="summary">MLOps open source con NetApp : esegui un carico di lavoro di intelligenza artificiale distribuito sincrono</block>
  <block id="8725f0c1877790fea82aedbc23e26e70" category="doc">Eseguire un carico di lavoro di intelligenza artificiale distribuito sincrono</block>
  <block id="deb7f52575de614a91ae7472b76138ec" category="paragraph">Per eseguire un processo di intelligenza artificiale e apprendimento automatico multinodo sincrono nel cluster Kubernetes, eseguire le seguenti attività sull'host di jump di distribuzione.  Questo processo consente di sfruttare i dati archiviati su un volume NetApp e di utilizzare più GPU di quelle che un singolo nodo worker può fornire.  Per una rappresentazione di un lavoro di intelligenza artificiale distribuita sincrona, vedere la figura seguente.</block>
  <block id="c073d47c72ebccdc821d9e6419b3008c" category="admonition">I lavori distribuiti sincroni possono contribuire ad aumentare le prestazioni e la precisione della formazione rispetto ai lavori distribuiti asincroni.  Una discussione sui pro e contro dei lavori sincroni rispetto a quelli asincroni esula dallo scopo di questo documento.</block>
  <block id="dd02d155f88fd3ea2f5dfd5720641a55" category="paragraph"><block ref="dd02d155f88fd3ea2f5dfd5720641a55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46300fa439cc237919f854816fc89fc2" category="inline-link-macro">Eseguire un carico di lavoro AI a nodo singolo</block>
  <block id="252bb749f76608017bf1d4a822ebba6d" category="list-text">I seguenti comandi di esempio mostrano la creazione di un worker che partecipa all'esecuzione sincrona distribuita dello stesso lavoro di benchmark TensorFlow eseguito su un singolo nodo nell'esempio nella sezione<block ref="055e86cc3668b8856dedbd3ee4c3f307" category="inline-link-macro-rx"></block> .  In questo esempio specifico, viene distribuito un solo worker perché il lavoro viene eseguito su due nodi worker.</block>
  <block id="8f811f6151a10e9d15de57c2af8fcfed" category="inline-link">documentazione ufficiale di Kubernetes</block>
  <block id="e3a5f2bdfc8576b6847bcbf0d53889d4" category="paragraph">Questa distribuzione di worker di esempio richiede otto GPU e può quindi essere eseguita su un singolo nodo worker GPU che dispone di otto o più GPU.  Se i nodi worker GPU dispongono di più di otto GPU, per massimizzare le prestazioni potresti voler aumentare questo numero in modo che corrisponda al numero di GPU presenti nei nodi worker.  Per ulteriori informazioni sulle distribuzioni di Kubernetes, vedere<block ref="29c4feb256f061356947baec0e1bfcb2" category="inline-link-rx"></block> .</block>
  <block id="4b59e69845bd812b9cddcb0b700f3680" category="paragraph">In questo esempio viene creata una distribuzione Kubernetes perché questo specifico worker containerizzato non verrebbe mai completato da solo.  Pertanto, non ha senso distribuirlo utilizzando la struttura dei job di Kubernetes.  Se il tuo worker è progettato o scritto per completarsi da solo, allora potrebbe essere sensato utilizzare la struttura del lavoro per distribuire il tuo worker.</block>
  <block id="57e84b8262eb9db582d9f861e85ed291" category="paragraph">Al pod specificato in questa specifica di distribuzione di esempio viene assegnato un<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valore di<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> .  Questo valore indica che il pod utilizza lo stack di rete del nodo worker host anziché lo stack di rete virtuale che Kubernetes crea solitamente per ogni pod.  Questa annotazione viene utilizzata in questo caso perché il carico di lavoro specifico si basa su Open MPI, NCCL e Horovod per eseguire il carico di lavoro in modo sincrono e distribuito.  Pertanto, richiede l'accesso allo stack di rete host.  Una discussione su Open MPI, NCCL e Horovod esula dallo scopo di questo documento.  Che questo sia o meno<block ref="02cbe2b15bc778c7658250053bbc5a5c" prefix=" " category="inline-code"></block> l'annotazione è necessaria a seconda dei requisiti del carico di lavoro specifico che si sta eseguendo.  Per maggiori informazioni sul<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> campo, vedere il<block ref="f46b1bf9e67570ceac06230c1e502909" category="inline-link-rx"></block> .</block>
  <block id="b3f8c0432fa807543e6e24f429362a32" category="list-text">Verifica che la distribuzione del worker creata nel passaggio 1 sia stata avviata correttamente.  I seguenti comandi di esempio confermano che è stato creato un singolo pod worker per la distribuzione, come indicato nella definizione di distribuzione, e che questo pod è attualmente in esecuzione su uno dei nodi worker GPU.</block>
  <block id="77fed810b2a592adcab667c30e5c0bdb" category="list-text">Creare un job Kubernetes per un master che avvia, partecipa e monitora l'esecuzione del job multinodo sincrono.  I seguenti comandi di esempio creano un master che avvia, partecipa e tiene traccia dell'esecuzione sincrona distribuita dello stesso processo di benchmark TensorFlow eseguito su un singolo nodo nell'esempio nella sezione<block ref="055e86cc3668b8856dedbd3ee4c3f307" category="inline-link-macro-rx"></block> .</block>
  <block id="4161928cbea20386310894ea85fd3711" category="paragraph">Questo esempio di master job richiede otto GPU e può quindi essere eseguito su un singolo nodo worker GPU dotato di otto o più GPU.  Se i nodi worker GPU dispongono di più di otto GPU, per massimizzare le prestazioni potresti voler aumentare questo numero in modo che corrisponda al numero di GPU presenti nei nodi worker.</block>
  <block id="3e04ef9469e6953d66ae9c7536ed9b26" category="paragraph">Al pod master specificato in questa definizione di lavoro di esempio viene assegnato un<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valore di<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> , proprio come è stato dato al pod dei lavoratori un<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valore di<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> nel passaggio 1.  Per maggiori dettagli sul motivo per cui questo valore è necessario, vedere il passaggio 1.</block>
  <block id="8600ba20f40fb5668a1b2c02f92e220d" category="list-text">Verificare che il processo master creato nel passaggio 3 sia in esecuzione correttamente.  Il seguente comando di esempio conferma che è stato creato un singolo pod master per il job, come indicato nella definizione del job, e che questo pod è attualmente in esecuzione su uno dei nodi worker GPU.  Dovresti anche vedere che il pod worker che hai visto originariamente nel passaggio 1 è ancora in esecuzione e che i pod master e worker sono in esecuzione su nodi diversi.</block>
  <block id="0f27ae3c630b411ce8f8dc123361f1b1" category="list-text">Verificare che il processo master creato nel passaggio 3 venga completato correttamente.  I seguenti comandi di esempio confermano che il lavoro è stato completato correttamente.</block>
  <block id="6fe5035373f479ed2a1c1d457e64ae9d" category="list-text">Elimina la distribuzione del worker quando non ti serve più.  I seguenti comandi di esempio mostrano l'eliminazione dell'oggetto di distribuzione del worker creato nel passaggio 1.</block>
  <block id="e3861d1527373e7d8eeea1704f818a15" category="paragraph">Quando elimini l'oggetto di distribuzione del worker, Kubernetes elimina automaticamente tutti i pod worker associati.</block>
  <block id="7e4d2c0ae78fc38eeb38ffe12f736290" category="list-text">*Facoltativo:* ripulisci gli artefatti del lavoro master.  I seguenti comandi di esempio mostrano l'eliminazione dell'oggetto master del processo creato nel passaggio 3.</block>
  <block id="d844794bfc5a0949dc2c38fecacf9ff1" category="paragraph">Quando elimini l'oggetto master job, Kubernetes elimina automaticamente tutti i master pod associati.</block>
  <block id="3b1ef0ea9661ba5d2eeba15fab13cf00" category="summary">MLOps open source con NetApp : esegui un carico di lavoro AI a nodo singolo</block>
  <block id="9e339bbe1fec0fc2a91b7c2f8dd9d7f7" category="paragraph">Per eseguire un job di intelligenza artificiale e apprendimento automatico a nodo singolo nel cluster Kubernetes, esegui le seguenti attività dall'host di jump di distribuzione.  Con Trident puoi rendere accessibile in modo rapido e semplice un volume di dati, potenzialmente contenente petabyte di dati, a un carico di lavoro Kubernetes.  Per rendere accessibile tale volume di dati dall'interno di un pod Kubernetes, è sufficiente specificare un PVC nella definizione del pod.</block>
  <block id="e3305581bc1f67d1989e08e42a43c113" category="admonition">Questa sezione presuppone che tu abbia già containerizzato (nel formato container Docker) il carico di lavoro AI e ML specifico che stai tentando di eseguire nel tuo cluster Kubernetes.</block>
  <block id="6bdbab1141be3c52dec1f29c4c5fdf52" category="inline-link">Sito web di ImageNet</block>
  <block id="08eb6cc7203ec1b36805e4767d450467" category="list-text">I seguenti comandi di esempio mostrano la creazione di un job Kubernetes per un carico di lavoro di benchmark TensorFlow che utilizza il dataset ImageNet.  Per ulteriori informazioni sul set di dati ImageNet, vedere<block ref="19a9693db577a40175aef26761f77fe7" category="inline-link-rx"></block> .</block>
  <block id="56920225f5c2d474925baad76ae3e7ce" category="paragraph">Questo esempio di lavoro richiede otto GPU e pertanto può essere eseguito su un singolo nodo worker GPU dotato di otto o più GPU.  Questo esempio di lavoro potrebbe essere inviato in un cluster per il quale non è presente un nodo worker con otto o più GPU oppure è attualmente occupato da un altro carico di lavoro.  In tal caso, il processo rimane in sospeso finché non diventa disponibile un nodo worker.</block>
  <block id="dd36f0d653a70e6e6c7e838454ee7e20" category="paragraph">Inoltre, per massimizzare la larghezza di banda di archiviazione, il volume che contiene i dati di formazione necessari viene montato due volte all'interno del pod creato da questo processo.  Un altro volume è montato nel contenitore.  Questo secondo volume verrà utilizzato per archiviare risultati e metriche.  Questi volumi sono indicati nella definizione del lavoro utilizzando i nomi dei PVC.  Per ulteriori informazioni sui lavori Kubernetes, vedere<block ref="0ceaf9ba0112a862c5fa5f8d38bee04b" category="inline-link-rx"></block> .</block>
  <block id="c1cf1b159caffa27246be2b5201cdd54" category="paragraph">UN<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> volume con un<block ref="075a3e36a0a52dcbc568c05788e8a713" prefix=" " category="inline-code"></block> valore di<block ref="4789f23283b3a61f858b641a1bef19a3" prefix=" " category="inline-code"></block> è montato su<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> nel pod creato da questo lavoro di esempio.  La dimensione predefinita del<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> Il volume virtuale creato automaticamente dal runtime del contenitore Docker può talvolta essere insufficiente per le esigenze di TensorFlow.  Montare un<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> volume come nell'esempio seguente fornisce un sufficientemente grande<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> volume virtuale.  Per maggiori informazioni su<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> volumi, vedere il<block ref="ad2ab91baa5517930a567ac7588e61fd" category="inline-link-rx"></block> .</block>
  <block id="ac5f33311bbfb696a5966510fc4a38b8" category="paragraph">Al singolo contenitore specificato in questa definizione di lavoro di esempio viene assegnato un<block ref="616a0bdac22bb48049712f2f41741fd1" prefix=" " category="inline-code"></block> valore di<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> .  Questo valore indica che il contenitore ha effettivamente accesso root sull'host.  Questa annotazione viene utilizzata in questo caso perché il carico di lavoro specifico in esecuzione richiede l'accesso root.  Nello specifico, un'operazione di cancellazione della cache eseguita dal carico di lavoro richiede l'accesso root.  Che questo sia o meno<block ref="8be504a312b42bc24ff61c9c2c31990d" prefix=" " category="inline-code"></block> l'annotazione è necessaria a seconda dei requisiti del carico di lavoro specifico che si sta eseguendo.</block>
  <block id="8db728b0062c29a77e48bcd3be77be7f" category="list-text">Verificare che il processo creato nel passaggio 1 venga eseguito correttamente.  Il seguente comando di esempio conferma che è stato creato un singolo pod per il job, come specificato nella definizione del job, e che questo pod è attualmente in esecuzione su uno dei nodi worker GPU.</block>
  <block id="7b2880ed5066d8fda6f6d5a4ec8f39ac" category="list-text">Verificare che il processo creato nel passaggio 1 venga completato correttamente.  I seguenti comandi di esempio confermano che il lavoro è stato completato correttamente.</block>
  <block id="bead823acab8a06d478eb02c7ff84d35" category="list-text">*Facoltativo:* Pulisci gli artefatti del lavoro.  I seguenti comandi di esempio mostrano l'eliminazione dell'oggetto processo creato nel passaggio 1.</block>
  <block id="cb215cf0e9fb88bd1fc97b4ba53fd36f" category="paragraph">Quando elimini l'oggetto job, Kubernetes elimina automaticamente tutti i pod associati.</block>
  <block id="91ab0152618ead1fcdc42eff8c2d0735" category="summary">MLOps open source con NetApp : esempi di backend Trident per distribuzioni NetApp AIPod</block>
  <block id="9137107e8d97a11b9174eb6766c2051f" category="doc">Esempi di backend Trident per distribuzioni NetApp AIPod</block>
  <block id="bf498d2b211c45a57e0eaa477b958b58" category="inline-link-macro">NetApp AIPod</block>
  <block id="8b57fa6d8107ac5ef8cc72bed591a355" category="paragraph">Prima di poter utilizzare Trident per effettuare il provisioning dinamico delle risorse di storage all'interno del cluster Kubernetes, è necessario creare uno o più backend Trident .  Gli esempi che seguono rappresentano diversi tipi di backend che potresti voler creare se stai distribuendo componenti di questa soluzione su un<block ref="b2fcf1ac0e8df6bdaefce420e27d6368" category="inline-link-macro-rx"></block> .  Per ulteriori informazioni sui backend e, ad esempio, sui backend per altre piattaforme/ambienti, vedere<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> .</block>
  <block id="5bce19d939aea54f55df565bb07b573b" category="list-text">NetApp consiglia di creare un backend Trident abilitato per FlexGroup per il tuo AIPod.</block>
  <block id="987adc3703d1f7aeb77e70a3d25e35ca" category="paragraph">I comandi di esempio che seguono mostrano la creazione di un backend Trident abilitato per FlexGroup per una macchina virtuale di archiviazione AIPod (SVM).  Questo Backend utilizza il<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> driver di archiviazione.  ONTAP supporta due tipi principali di volumi di dati: FlexVol e FlexGroup.  I volumi FlexVol hanno dimensioni limitate (al momento della stesura di questo documento, la dimensione massima dipende dalla distribuzione specifica).  I volumi FlexGroup , d'altro canto, possono essere scalati linearmente fino a 20 PB e 400 miliardi di file, fornendo un singolo namespace che semplifica notevolmente la gestione dei dati.  Pertanto, i volumi FlexGroup sono ottimali per i carichi di lavoro di intelligenza artificiale e apprendimento automatico che si basano su grandi quantità di dati.</block>
  <block id="ba9f56aafb45a750a8dffe5de6d2ed78" category="paragraph">Se si lavora con una piccola quantità di dati e si desidera utilizzare volumi FlexVol anziché volumi FlexGroup , è possibile creare backend Trident che utilizzano<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> driver di archiviazione invece del<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> driver di archiviazione.</block>
  <block id="112efecf6dc8105639ea7e0b2a19f0e1" category="list-text">NetApp consiglia inoltre di creare un backend Trident abilitato per FlexVol .  È possibile utilizzare i volumi FlexVol per ospitare applicazioni persistenti, archiviare risultati, output, informazioni di debug e così via.  Se si desidera utilizzare i volumi FlexVol , è necessario creare uno o più backend Trident abilitati per FlexVol .  I comandi di esempio che seguono mostrano la creazione di un singolo backend Trident abilitato per FlexVol .</block>
  <block id="860fee506515550a9fba4086f9358bf0" category="summary">MLOps open source con NetApp - Esempio di operazioni Trident</block>
  <block id="3642f282b12269091ab196a3aabf0858" category="doc">Esempio di operazioni Trident</block>
  <block id="7f41e102595a65d30401b887b75060a4" category="paragraph">Questa sezione include esempi di varie operazioni che potresti voler eseguire con Trident.</block>
  <block id="5a95bc44d2d93c77b65585a52a71d631" category="section-title">Importa un volume esistente</block>
  <block id="37e60d34ab15afa59aac0989309fc77a" category="paragraph">Se sul sistema/piattaforma di storage NetApp sono presenti volumi che si desidera montare sui container all'interno del cluster Kubernetes, ma che non sono collegati ai PVC nel cluster, è necessario importare tali volumi.  Per importare questi volumi è possibile utilizzare la funzionalità di importazione dei volumi Trident .</block>
  <block id="8a87b71bee3405ddd29416b675ef7c61" category="paragraph">I comandi di esempio che seguono mostrano l'importazione di un volume denominato<block ref="49f0544a1f0d45f5d68ad2e883eaec4a" prefix=" " category="inline-code"></block> .  Per maggiori informazioni sui PVC, vedere<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> .  Per ulteriori informazioni sulla funzionalità di importazione del volume, vedere<block ref="7e5b92b70f9fb8a6ea9680492953995f" category="inline-link-rx"></block> .</block>
  <block id="313da63dfeb95842dd6a105fdcf40ebc" category="paragraph">UN<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> valore di<block ref="c24ad3d99a666c95edd149419c958ee0" prefix=" " category="inline-code"></block> è specificato nei file di specifiche PVC di esempio.  Per maggiori informazioni sul<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> campo, vedere il<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> .</block>
  <block id="533fff63e0b7486b2768ad15b5e2981c" category="section-title">Fornire un nuovo volume</block>
  <block id="6b2d9cc0e6416b1fddc173d87e1ebad4" category="paragraph">Puoi utilizzare Trident per predisporre un nuovo volume sul tuo sistema o piattaforma di storage NetApp .</block>
  <block id="4268e244b7de91b44bea226a48855c28" category="section-title">Fornire un nuovo volume utilizzando kubectl</block>
  <block id="d5c5993dfd543be5e01f6d98516d64cb" category="paragraph">I seguenti comandi di esempio mostrano il provisioning di un nuovo FlexVol volume utilizzando kubectl.</block>
  <block id="78b7c8c28867630a421236d6f1ff9ba3" category="paragraph">UN<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> valore di<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block> è specificato nel seguente file di definizione PVC di esempio.  Per maggiori informazioni sul<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> campo, vedere il<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> .</block>
  <block id="3b12f01a10ad45fb526861fc286c7953" category="section-title">Fornire un nuovo volume utilizzando NetApp DataOps Toolkit</block>
  <block id="55876228853abf632dec9346a4f372ec" category="inline-link-macro">documentazione</block>
  <block id="b1e49394b547d60433afdf0d608bc52b" category="paragraph">Puoi anche utilizzare NetApp DataOps Toolkit per Kubernetes per effettuare il provisioning di un nuovo volume sul tuo sistema o piattaforma di storage NetApp .  NetApp DataOps Toolkit per Kubernetes utilizza Trident per il provisioning dei volumi, semplificando però il processo per l'utente.  Fare riferimento al<block ref="37e4d77423419479f43c92e2fdd640ea" category="inline-link-macro-rx"></block> per i dettagli.</block>
  <block id="fdc02d1c80a87a40b5361ca1abf33964" category="summary">MLOps open source con NetApp : esempi di classi di archiviazione Kubernetes per distribuzioni NetApp AIPod</block>
  <block id="d25894e802e87270d1f6b560c3332055" category="doc">Esempi di classi di archiviazione Kubernetes per distribuzioni NetApp AIPod</block>
  <block id="98384d229f6fec246185f9bfa14fcb7a" category="paragraph">Prima di poter utilizzare Trident per effettuare il provisioning dinamico delle risorse di storage all'interno del cluster Kubernetes, è necessario creare una o più StorageClass Kubernetes.  Gli esempi che seguono rappresentano diversi tipi di StorageClasses che potresti voler creare se stai distribuendo componenti di questa soluzione su un<block ref="b2fcf1ac0e8df6bdaefce420e27d6368" category="inline-link-macro-rx"></block> .  Per ulteriori informazioni su StorageClasses e, ad esempio, su StorageClasses per altre piattaforme/ambienti, vedere<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> .</block>
  <block id="3f91a2c4d8ba66304e817a6c1c8d8086" category="inline-link-macro">NFS su RDMA</block>
  <block id="5f9e4626ef73df529e1be620feb3c403" category="list-text">NetApp consiglia di creare una StorageClass per il backend Trident abilitato per FlexGroup creato nella sezione<block ref="ba9f980165fbda795fa9abfedd793128" category="inline-link-macro-rx"></block> , passo 1.  I comandi di esempio che seguono mostrano la creazione di più StorageClass che corrispondono al Backend di esempio creato nella sezione<block ref="ba9f980165fbda795fa9abfedd793128" category="inline-link-macro-rx"></block> , passo 1 - uno che utilizza<block ref="2f98f20aaeb2334cc6d03f1e60eea86f" category="inline-link-macro-rx"></block> e uno che non lo fa.</block>
  <block id="d9348d075dc7b3c91cff99d56dfc327b" category="inline-link">Documentazione di Kubernetes</block>
  <block id="063f66d6e76f1f9cc44a56824e67f49c" category="paragraph">Per evitare che un volume persistente venga eliminato quando viene eliminato il PersistentVolumeClaim (PVC) corrispondente, l'esempio seguente utilizza un<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> valore di<block ref="afece4245269582cb2f1009d4fb52047" prefix=" " category="inline-code"></block> .  Per maggiori informazioni sul<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> campo, vedere l'ufficiale<block ref="2b8f9bbf9efeff879b3debc5484f0056" category="inline-link-rx"></block> .</block>
  <block id="b1c0c18c267e82c16a2fb0fd855fea96" category="paragraph">Nota: le seguenti StorageClass di esempio utilizzano una dimensione di trasferimento massima di 262144.  Per utilizzare questa dimensione massima di trasferimento, è necessario configurare di conseguenza la dimensione massima di trasferimento sul sistema ONTAP .  Fare riferimento al<block ref="e88143f84eca8f5af17b24d59e272642" category="inline-link-macro-rx"></block> per i dettagli.</block>
  <block id="611c47063b50d4e29ff14b57ac5d1a76" category="paragraph">Nota: per utilizzare NFS su RDMA, è necessario configurare NFS su RDMA sul sistema ONTAP .  Fare riferimento al<block ref="299f3386ca6234337ede91409b59779f" category="inline-link-macro-rx"></block> per i dettagli.</block>
  <block id="8dffb2755e3c128c00970dd619da5b34" category="paragraph">Nota: nell'esempio seguente, un Backend specifico è specificato nel campo storagePool nel file di definizione StorageClass.</block>
  <block id="cce8016ccbbe58eeb47eb8596b78018e" category="inline-link-macro">Esempi di backend Trident per distribuzioni AIPod</block>
  <block id="6c9233cf2164bf9b74bbca02d5360c85" category="list-text">NetApp consiglia inoltre di creare una StorageClass che corrisponda al Trident Backend abilitato per FlexVol creato nella sezione<block ref="f93f354f4df9d1f116edb5ebdff3f7d5" category="inline-link-macro-rx"></block> , passo 2.  I comandi di esempio che seguono mostrano la creazione di una singola StorageClass per i volumi FlexVol .</block>
  <block id="fc614170d6c05a82aef1df8658cdddbb" category="paragraph">Nota: nell'esempio seguente, un particolare Backend non è specificato nel campo storagePool nel file di definizione StorageClass.  Quando si utilizza Kubernetes per amministrare i volumi utilizzando questa StorageClass, Trident tenta di utilizzare qualsiasi backend disponibile che utilizza<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> autista.</block>
  <block id="3ad98aba8e7b278dbcb8d707671576f7" category="list-text">Clona quasi istantaneamente gli spazi di lavoro JupyterLab ad alta capacità per consentire la sperimentazione o l'iterazione rapida.</block>
  <block id="85ca8d103a016e6e8898855c4ecfa6e2" category="list-text">Salvataggio quasi istantaneo di snapshot di spazi di lavoro JupyterLab ad alta capacità per backup e/o tracciabilità/baselining.</block>
  <block id="60a1b5ff80d3333df7174eb4d8d7f4e1" category="list-text">Fornitura, clonazione e snapshot di volumi di dati ad alta capacità e prestazioni pressoché istantanei.</block>
  <block id="c4bca757471e0afa8bcb4da8a5f5e802" category="paragraph"><block ref="c4bca757471e0afa8bcb4da8a5f5e802" category="inline-link-macro-rx"></block></block>
  <block id="e74b9287ad8cc207ad48fbfdff9cf078" category="summary">conclusione - soluzione di database vettoriale per netapp</block>
  <block id="b4eb3fd5fa52ba6b8d0eac43bac21d6f" category="paragraph">Questa sezione conclude la soluzione del database vettoriale per NetApp.</block>
  <block id="ec77b1d1c933a6b137ec223a695b5ace" category="paragraph">In conclusione, questo documento fornisce una panoramica completa sull'implementazione e la gestione di database vettoriali, come Milvus e pgvector, sulle soluzioni di storage NetApp .  Abbiamo discusso le linee guida dell'infrastruttura per sfruttare l'archiviazione di oggetti NetApp ONTAP e StorageGRID e convalidato il database Milvus in AWS FSx ONTAP tramite l'archiviazione di file e oggetti.</block>
  <block id="9799eea6b7d21ae2ad3b8f14f6de8b57" category="paragraph">Abbiamo esplorato la dualità file-oggetto di NetApp, dimostrandone l'utilità non solo per i dati nei database vettoriali, ma anche per altre applicazioni.  Abbiamo anche evidenziato come SnapCenter, il prodotto di gestione aziendale di NetApp, offra funzionalità di backup, ripristino e clonazione per i dati dei database vettoriali, garantendone l'integrità e la disponibilità.</block>
  <block id="31068d7cc739be3f40f71a1c2165b247" category="paragraph">Il documento approfondisce anche il modo in cui la soluzione Hybrid Cloud di NetApp offre replicazione e protezione dei dati in ambienti on-premise e cloud, garantendo un'esperienza di gestione dei dati fluida e sicura.  Abbiamo fornito approfondimenti sulla convalida delle prestazioni di database vettoriali come Milvus e pgvecto su NetApp ONTAP, offrendo informazioni preziose sulla loro efficienza e scalabilità.</block>
  <block id="48b5d59439c5cbfd986de5db0e4585aa" category="paragraph">Infine, abbiamo discusso due casi d'uso dell'intelligenza artificiale generativa: RAG con LLM e ChatAI interna di NetApp.  Questi esempi pratici sottolineano le applicazioni e i vantaggi concreti dei concetti e delle pratiche delineati nel presente documento.  Nel complesso, questo documento costituisce una guida completa per chiunque voglia sfruttare le potenti soluzioni di storage di NetApp per la gestione di database vettoriali.</block>
  <block id="95ab8b5192fec6278c61d897cbcc59b7" category="paragraph">L'autore desidera ringraziare sentitamente i collaboratori indicati di seguito, coloro che hanno fornito feedback e commenti per rendere questo documento utile ai clienti NetApp e ai settori NetApp .</block>
  <block id="cf069f89f8b650e3f6d927f7417a21f1" category="list-text">Sathish Thyagarajan, Ingegnere tecnico di marketing, ONTAP AI e analisi, NetApp</block>
  <block id="74f47434914d29c7ec7d7d42593303b7" category="list-text">Mike Oglesby, ingegnere tecnico di marketing, NetApp</block>
  <block id="633e7060d92a08658a3f5248a7c7cdf2" category="list-text">AJ Mahajan, Direttore Senior, NetApp</block>
  <block id="4963f582fdf68104e20554eb28bcf2ca" category="list-text">Joe Scott, Responsabile, Ingegneria delle prestazioni del carico di lavoro, NetApp</block>
  <block id="710fcc80e2c0809a7239d471028d8f70" category="list-text">Puneet Dhawan, Direttore senior, Gestione prodotti Fsx, NetApp</block>
  <block id="7b62519a4ae964c6b307925c68166ca7" category="list-text">Yuval Kalderon, Senior Product Manager, FSx Product Team, NetApp</block>
  <block id="b97cdeb80b669ea57564c9bf0542d2ef" category="list-text">Documentazione Milvus -<block ref="35e085709f47cfca6bbc0746cd0ba49f" category="inline-link-rx"></block></block>
  <block id="f7356e8678620084b93884e3b7a23a9f" category="list-text">Documentazione autonoma di Milvus -<block ref="a47fb3f2bfaa36fa0b44dc5f5ba452a4" category="inline-link-rx"></block></block>
  <block id="8b8bc5296c7be638754abb2f408d2099" category="list-text">Documentazione del prodotto NetApp<block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="3852b719e664b2ae1596e622f21daba3" category="inline-link-macro">documentazione di instalclustr</block>
  <block id="9351f6d4d819e15d23724c78a36aea99" category="list-text">instaclustr -<block ref="39b68163c56ae9979050121a6264d765" category="inline-link-macro-rx"></block></block>
  <block id="3b3d7bce734c0832c20ba464b1f2d199" category="cell">Aprile 2024</block>
  <block id="123ffe6774f72f5d1c22607445987e46" category="summary">Prepara i dati per la soluzione di database vettoriale per NetApp</block>
  <block id="f7ab9b609aa315a4d224e6e33b2a10ee" category="doc">Appendice B: prepare_data_netapp_new.py</block>
  <block id="8d5099e275cc435c14417dc8e6bd49aa" category="paragraph">Questa sezione fornisce un esempio di script Python utilizzato per preparare i dati per il database vettoriale.</block>
  <block id="fe51a53701c4e0dd7696bed40b6f70db" category="summary">vector-database-deployment-procedure - soluzione di database vettoriale per NetApp</block>
  <block id="19988795e8f88dfff005718f72472b6c" category="paragraph">In questa sezione viene illustrata la procedura di distribuzione per la soluzione di database vettoriale per NetApp.</block>
  <block id="fa0b3671f099fc4fc4fbe3ac8374d92c" category="section-title">Procedura di distribuzione</block>
  <block id="b63c54c37cdb817c256ef1a7e50fc5fe" category="paragraph">In questa sezione di distribuzione, abbiamo utilizzato il database vettoriale Milvus con Kubernetes per la configurazione del laboratorio come di seguito.</block>
  <block id="e275837fe1aa897ebc01eed7a7354278" category="paragraph"><block ref="e275837fe1aa897ebc01eed7a7354278" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b4b9b6998f8b3056b486430aa9c6fd" category="paragraph">NetApp Storage fornisce lo spazio di archiviazione per il cluster in cui conservare i dati dei clienti e i dati del cluster Milvus.</block>
  <block id="46d201d3a5d870036bd7573752054979" category="section-title">Configurazione dello storage NetApp – ONTAP</block>
  <block id="1fa9de5db47759d3e586f783f647d3e8" category="paragraph">Per NFS (Network File System) seguire i passaggi sottostanti:</block>
  <block id="932d306add3eb18c39b41633590f1ad6" category="list-text">Creare un volume FlexGroup per NFSv4.  Nella nostra configurazione per questa convalida, abbiamo utilizzato 48 SSD, 1 SSD dedicato al volume root del controller e 47 SSD distribuiti per NFSv4. Verificare che la policy di esportazione NFS per il volume FlexGroup disponga di autorizzazioni di lettura/scrittura per la rete dei nodi Kubernetes (K8).  Se queste autorizzazioni non sono disponibili, concedere autorizzazioni di lettura/scrittura (rw) per la rete dei nodi K8s.</block>
  <block id="a53a2ae8c8ba1b0def8ad999e086f94c" category="list-text">Su tutti i nodi K8s, creare una cartella e montare il volume FlexGroup su questa cartella tramite un'interfaccia logica (LIF) su ciascun nodo K8s.</block>
  <block id="b02cc86a747fc07392e2eceafa48816f" category="paragraph">Per NAS S3 (Network Attached Storage Simple Storage Service), seguire i passaggi indicati di seguito:</block>
  <block id="a1ec6ff754c8c8958a577b43995e9caf" category="list-text">Creare un volume FlexGroup per NFS.</block>
  <block id="c550fe4970f3cf4781625e620b4e30a9" category="list-text">Creare un bucket NAS impostandone il tipo su "nas" e specificando il percorso al volume NFSv3.  A questo scopo è anche possibile utilizzare un bucket S3.</block>
  <block id="81f40424ce0b0dbbc91e2bc42bee8924" category="section-title">Configurazione dell'archiviazione NetApp – StorageGRID</block>
  <block id="c8462ad4cf62a8bf6b594e7929097b68" category="list-text">Installare il software storageGRID.</block>
  <block id="aec1f80331e64507a359fd96a93d2dee" category="list-text">Crea un tenant e un bucket.</block>
  <block id="6eea00d5693e3a2106cc3859939c6e8e" category="list-text">Crea un utente con l'autorizzazione richiesta.</block>
  <block id="5288dc14a18d189389b382eda1a7f83a" category="paragraph">Per maggiori dettagli consultare<block ref="c095f7864703639165de914bdacb9488" category="inline-link-rx"></block></block>
  <block id="1b4b1bbd037e26c942386744e0c37fb6" category="summary">docker-compose.xml - soluzione di database vettoriale per NetApp</block>
  <block id="05b4af2cc796ae07ae3efb49a12abe45" category="doc">Appendice D: docker-compose.yml</block>
  <block id="4f50d45b7589f5ba7443aff7e641e0ce" category="paragraph">Questa sezione include un codice YAML di esempio per la soluzione di database vettoriale per NetApp.</block>
  <block id="1746460223f3daa35634698cf8a11429" category="summary">Protezione del database vettoriale tramite snapcenter - soluzione per database vettoriale per NetApp</block>
  <block id="72043cdd90d91317b18d2fcdc935eea8" category="doc">Protezione del database vettoriale tramite SnapCenter</block>
  <block id="0cbe53988249acb8210e165c8f9d4ff1" category="paragraph">Questa sezione descrive come fornire protezione dei dati per il database vettoriale utilizzando NetApp SnapCenter.</block>
  <block id="62e16ceab82346a15bf6bb06f5076498" category="section-title">Protezione del database vettoriale tramite NetApp SnapCenter.</block>
  <block id="03e2211bf15aaf80440217e34090ab7a" category="paragraph">Ad esempio, nel settore della produzione cinematografica, i clienti spesso possiedono dati critici incorporati, come file video e audio.  La perdita di questi dati, dovuta a problemi come guasti al disco rigido, può avere un impatto significativo sulle loro attività, mettendo potenzialmente a repentaglio iniziative multimilionarie.  Ci siamo imbattuti in casi in cui contenuti di inestimabile valore sono andati persi, causando notevoli disagi e perdite finanziarie.  Garantire la sicurezza e l'integrità di questi dati essenziali è quindi di fondamentale importanza in questo settore.  In questa sezione approfondiamo il modo in cui SnapCenter salvaguarda i dati del database vettoriale e i dati Milvus residenti in ONTAP.  Per questo esempio, abbiamo utilizzato un bucket NAS (milvusdbvol1) derivato da un volume NFS ONTAP (vol1) per i dati dei clienti e un volume NFS separato (vectordbpv) per i dati di configurazione del cluster Milvus. Si prega di controllare<block ref="d81f12ee1ce058489f6dd74377fd8f1e" category="inline-link-macro-rx"></block> per il flusso di lavoro di backup di SnapCenter</block>
  <block id="e159df91d2537b3f0b589d157dfbffd9" category="list-text">Impostare l'host che verrà utilizzato per eseguire i comandi SnapCenter .</block>
  <block id="0d3b27c161709a06da0484a310f325e3" category="paragraph"><block ref="0d3b27c161709a06da0484a310f325e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00ebf5cec061915cd0462d73602dcad8" category="inline-link-macro">Negozio di automazione NetApp</block>
  <block id="e5dbb47baa2442a0c626c78cd3791dfb" category="list-text">Installa e configura il plugin di archiviazione.  Dall'host aggiunto, seleziona "Altre opzioni".  Passare e selezionare il plug-in di archiviazione scaricato da<block ref="6d50396c8bd3accea0ce09d72830daea" category="inline-link-macro-rx"></block> .  Installa il plugin e salva la configurazione.</block>
  <block id="4225308f0df24ace1516a7673df5f583" category="paragraph"><block ref="4225308f0df24ace1516a7673df5f583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="56efc857e5b28976189acb94af8f4ac8" category="list-text">Impostare il sistema di archiviazione e il volume: aggiungere il sistema di archiviazione in "Sistema di archiviazione" e selezionare SVM (Storage Virtual Machine).  In questo esempio abbiamo scelto "vs_nvidia".</block>
  <block id="6d0b2d59ec18c3814b7e5430ff27609f" category="paragraph"><block ref="6d0b2d59ec18c3814b7e5430ff27609f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2dcb622158143845f18538a410575a" category="list-text">Stabilire una risorsa per il database vettoriale, incorporando una politica di backup e un nome di snapshot personalizzato.</block>
  <block id="a8f4ce53516fd9e67b7eb9a099d49120" category="list-text">Abilita il backup del gruppo di coerenza con i valori predefiniti e abilita SnapCenter senza coerenza del file system.</block>
  <block id="6230f7a2a3dc9bac46ff1cd677466af1" category="list-text">Nella sezione Impronta di archiviazione, selezionare i volumi associati ai dati dei clienti del database vettoriale e ai dati del cluster Milvus.  Nel nostro esempio, si tratta di "vol1" e "vectordbpv".</block>
  <block id="61f90f32ea94cd1e612c6ce7a1713b45" category="list-text">Creare una policy per la protezione del database vettoriale e proteggere le risorse del database vettoriale utilizzando la policy.</block>
  <block id="de59432e970871e34ec01050d133ea25" category="paragraph"><block ref="de59432e970871e34ec01050d133ea25" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc8a652b9ab6e0d4b7d2a344da503ff6" category="list-text">Inserire i dati nel bucket NAS S3 utilizzando uno script Python.  Nel nostro caso, abbiamo modificato lo script di backup fornito da Milvus, ovvero 'prepare_data_netapp.py', ed eseguito il comando 'sync' per eliminare i dati dal sistema operativo.</block>
  <block id="3474edc9b3792a7404f86710df9ef875" category="list-text">Verificare i dati nel bucket NAS S3.  Nel nostro esempio, i file con timestamp '2024-04-08 21:22' sono stati creati dallo script 'prepare_data_netapp.py'.</block>
  <block id="d47a679804c0cbffd0dc44fe5bb8fd17" category="list-text">Avvia un backup utilizzando lo snapshot del gruppo di coerenza (CG) dalla risorsa 'milvusdb'</block>
  <block id="fe4f644e0cbbb28bc2dc58c59ba4712f" category="paragraph"><block ref="fe4f644e0cbbb28bc2dc58c59ba4712f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="511f6b9ef02b86884feaa7670c95ad25" category="list-text">Per testare la funzionalità di backup, abbiamo aggiunto una nuova tabella dopo il processo di backup oppure abbiamo rimosso alcuni dati dall'NFS (bucket NAS S3).</block>
  <block id="b32454a703c99d763bb542ccb4127d18" category="paragraph">Per questo test, immagina uno scenario in cui qualcuno ha creato una nuova raccolta non necessaria o inappropriata dopo il backup.  In tal caso, dovremmo ripristinare il database vettoriale allo stato in cui si trovava prima dell'aggiunta della nuova raccolta.  Ad esempio, sono state inserite nuove raccolte come 'hello_milvus_netapp_sc_testnew' e 'hello_milvus_netapp_sc_testnew2'.</block>
  <block id="90fecf651d0359e3ca580f04477241cd" category="list-text">Eseguire un ripristino completo del bucket NAS S3 dallo snapshot precedente.</block>
  <block id="aad1d0bff0a7a377e2981515a3b2b613" category="paragraph"><block ref="aad1d0bff0a7a377e2981515a3b2b613" category="inline-image-macro-rx" type="image"></block></block>
  <block id="78a091f299be6eaf4277ba82c2e35823" category="list-text">Utilizzare uno script Python per verificare i dati dalle raccolte 'hello_milvus_netapp_sc_test' e 'hello_milvus_netapp_sc_test2'.</block>
  <block id="d680ce42e26a573726db92b9c2422bcc" category="list-text">Verificare che la raccolta non necessaria o inappropriata non sia più presente nel database.</block>
  <block id="9a792fb5937b90853e4c8d032e6cb887" category="paragraph">In conclusione, l'utilizzo di SnapCenter di NetApp per salvaguardare i dati del database vettoriale e i dati Milvus residenti in ONTAP offre notevoli vantaggi ai clienti, in particolare nei settori in cui l'integrità dei dati è fondamentale, come la produzione cinematografica.  La capacità di SnapCenter di creare backup coerenti ed eseguire ripristini completi dei dati garantisce che i dati critici, come i file video e audio incorporati, siano protetti da perdite dovute a guasti del disco rigido o altri problemi.  Ciò non solo previene interruzioni operative, ma tutela anche da perdite finanziarie sostanziali.</block>
  <block id="2f51cfb1dd79ff854c52264b771ee6f7" category="paragraph">In questa sezione abbiamo dimostrato come configurare SnapCenter per proteggere i dati residenti in ONTAP, inclusa la configurazione degli host, l'installazione e la configurazione dei plugin di archiviazione e la creazione di una risorsa per il database vettoriale con un nome snapshot personalizzato.  Abbiamo anche mostrato come eseguire un backup utilizzando lo snapshot del Consistency Group e verificare i dati nel bucket NAS S3.</block>
  <block id="f3b4f7a7e2767144ed9c5f0d9d729580" category="paragraph">Inoltre, abbiamo simulato uno scenario in cui è stata creata una raccolta non necessaria o inappropriata dopo il backup.  In questi casi, la capacità di SnapCenter di eseguire un ripristino completo da uno snapshot precedente garantisce che il database vettoriale possa essere ripristinato allo stato in cui si trovava prima dell'aggiunta della nuova raccolta, mantenendo così l'integrità del database.  Questa capacità di ripristinare i dati a un punto specifico nel tempo è di inestimabile valore per i clienti, poiché fornisce loro la garanzia che i loro dati non solo sono protetti, ma anche correttamente mantenuti.  Pertanto, il prodotto SnapCenter di NetApp offre ai clienti una soluzione solida e affidabile per la protezione e la gestione dei dati.</block>
  <block id="8ceee6fd58c3c198cf913f99da69f893" category="summary">Disaster Recovery tramite NetApp SnapMirror - soluzione di database vettoriale per NetApp</block>
  <block id="e55b3630a4d66c6bf27e22779ce5d63e" category="doc">Ripristino di emergenza tramite NetApp SnapMirror</block>
  <block id="86e29a6d4e0a7a64c8112c7cec13c84f" category="paragraph">Questa sezione illustra il DR (disaster recovery) con SnapMirror per la soluzione di database vettoriale per NetApp.</block>
  <block id="b8bf217f690a13ed504fd70caf142a75" category="paragraph"><block ref="b8bf217f690a13ed504fd70caf142a75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b0f055a15ce6f9f633fb54c0d2436b6" category="paragraph">Il ripristino dopo un disastro è fondamentale per mantenere l'integrità e la disponibilità di un database vettoriale, soprattutto considerando il suo ruolo nella gestione di dati ad alta dimensionalità e nell'esecuzione di ricerche di similarità complesse.  Una strategia di disaster recovery ben pianificata e implementata garantisce che i dati non vengano persi o compromessi in caso di incidenti imprevisti, come guasti hardware, calamità naturali o attacchi informatici.  Ciò è particolarmente significativo per le applicazioni che si basano su database vettoriali, in cui la perdita o il danneggiamento dei dati potrebbe causare notevoli interruzioni operative e perdite finanziarie.  Inoltre, un solido piano di disaster recovery garantisce la continuità aziendale riducendo al minimo i tempi di inattività e consentendo il rapido ripristino dei servizi.  Ciò è possibile grazie al prodotto di replicazione dei dati NetApp SnapMirrror in diverse posizioni geografiche, backup regolari e meccanismi di failover.  Pertanto, il disaster recovery non è solo una misura protettiva, ma una componente fondamentale per una gestione responsabile ed efficiente dei database vettoriali.</block>
  <block id="c37567d5fe01335124697e36ce452df7" category="paragraph">SnapMirror di NetApp consente la replica dei dati da un controller di storage NetApp ONTAP a un altro, ed è utilizzato principalmente per soluzioni ibride e di disaster recovery (DR).  Nel contesto di un database vettoriale, questo strumento facilita la transizione fluida dei dati tra ambienti on-premise e cloud.  Questa transizione viene realizzata senza richiedere alcuna conversione di dati o refactoring delle applicazioni, migliorando così l'efficienza e la flessibilità della gestione dei dati su più piattaforme.</block>
  <block id="b6c8a7338bea39b5f253444e1d873d4d" category="paragraph">La soluzione NetApp Hybrid in uno scenario di database vettoriale può apportare ulteriori vantaggi:</block>
  <block id="bea498b35d669ee9af3e28b8fdb8e155" category="list-text">Scalabilità: la soluzione cloud ibrida di NetApp offre la possibilità di scalare le risorse in base alle proprie esigenze.  È possibile utilizzare risorse on-premise per carichi di lavoro regolari e prevedibili e risorse cloud come Amazon FSx ONTAP per NetApp ONTAP e Google Cloud NetApp Volume (NetApp Volumes) per periodi di punta o carichi imprevisti.</block>
  <block id="c471a0669949fb6902a8ba657759604f" category="list-text">Efficienza dei costi: il modello di cloud ibrido di NetApp consente di ottimizzare i costi utilizzando risorse on-premise per carichi di lavoro regolari e pagando le risorse cloud solo quando ne hai bisogno.  Questo modello di pagamento a consumo può rivelarsi piuttosto conveniente con un'offerta di servizi NetApp Instaclustr.  Instaclustr offre supporto e consulenza ai principali fornitori di servizi cloud e on-premise.</block>
  <block id="6544e3cb40acee466e12bad4b51cee88" category="list-text">Flessibilità: il cloud ibrido di NetApp ti offre la flessibilità di scegliere dove elaborare i tuoi dati.  Ad esempio, potresti scegliere di eseguire operazioni vettoriali complesse in locale, dove hai hardware più potente, e operazioni meno intensive nel cloud.</block>
  <block id="2a11cdb9dd362247d7154c07bd516471" category="list-text">Continuità aziendale: in caso di disastro, avere i dati in un cloud ibrido NetApp può garantire la continuità aziendale.  Se le tue risorse locali sono interessate, puoi passare rapidamente al cloud.  Possiamo sfruttare NetApp SnapMirror per spostare i dati da locale a cloud e viceversa.</block>
  <block id="3350f193c79eb670e977c23ae0a74f52" category="list-text">Innovazione: le soluzioni cloud ibride di NetApp possono anche favorire un'innovazione più rapida, offrendo accesso a servizi e tecnologie cloud all'avanguardia.  Le innovazioni NetApp nel cloud, come Amazon FSx ONTAP per NetApp ONTAP, Azure NetApp Files e Google Cloud NetApp Volumes, sono prodotti innovativi e NAS preferiti dai provider di servizi cloud.</block>
  <block id="2adc0d5a06f39e5bd606c62ac1bdec94" category="summary">instaclustr con pgvector - soluzione di database vettoriale per netapp</block>
  <block id="8505d7d1a5bb8f0709861077b6053aac" category="doc">Database vettoriale con Instaclustr utilizzando PostgreSQL: pgvector</block>
  <block id="45b4ccfe4060d903229f2ce1dcae0219" category="paragraph">Questa sezione illustra le specifiche di come il prodotto instaclustr si integra con postgreSQL sulla funzionalità pgvector nella soluzione di database vettoriale per NetApp.</block>
  <block id="126ac9f6149081eb0e97c2e939eaad52" category="inline-link-macro">blog</block>
  <block id="d2674849e623e64434efc8a6aa010be4" category="paragraph">In questa sezione approfondiamo i dettagli di come il prodotto instaclustr si integra con postgreSQL sulla funzionalità pgvector.  Abbiamo un esempio di "Come migliorare l'accuratezza e le prestazioni del tuo LLM con PGVector e PostgreSQL: introduzione agli incorporamenti e al ruolo di PGVector".  Si prega di controllare il<block ref="f7c4562444dacce2474e07621eb487a5" category="inline-link-macro-rx"></block> per ottenere maggiori informazioni.</block>
  <block id="755a3ba009d32e46dd37e73b1449ec79" category="summary">Introduzione alla soluzione di database vettoriale per NetApp</block>
  <block id="65fe25204f25a29d6784b93a3361bbd8" category="paragraph">Questa sezione fornisce un'introduzione alla soluzione di database vettoriale per NetApp.</block>
  <block id="16091ccd671260c1a85526587bdd6247" category="paragraph">I database vettoriali affrontano in modo efficace le sfide progettate per gestire le complessità della ricerca semantica nei Large Language Models (LLM) e nell'intelligenza artificiale generativa (IA).  A differenza dei tradizionali sistemi di gestione dei dati, i database vettoriali sono in grado di elaborare e ricercare vari tipi di dati, tra cui immagini, video, testo, audio e altre forme di dati non strutturati, utilizzando il contenuto dei dati stessi anziché etichette o tag.</block>
  <block id="abd729dd7dfee14433df8341cdef1b8d" category="paragraph">I limiti dei sistemi di gestione di database relazionali (RDBMS) sono ben documentati, in particolare le difficoltà con le rappresentazioni di dati ad alta dimensionalità e i dati non strutturati comuni nelle applicazioni di intelligenza artificiale.  Gli RDBMS spesso richiedono un processo lungo e soggetto a errori per appiattire i dati in strutture più gestibili, con conseguenti ritardi e inefficienze nelle ricerche.  I database vettoriali, tuttavia, sono progettati per aggirare questi problemi, offrendo una soluzione più efficiente e accurata per la gestione e la ricerca di dati complessi e ad alta dimensionalità, facilitando così il progresso delle applicazioni di intelligenza artificiale.</block>
  <block id="5059454011de9c1f28ed1489b3d5e352" category="paragraph">Questo documento costituisce una guida completa per i clienti che attualmente utilizzano o intendono utilizzare database vettoriali, illustrando dettagliatamente le best practice per l'utilizzo di database vettoriali su piattaforme quali NetApp ONTAP, NetApp StorageGRID, Amazon FSx ONTAP per NetApp ONTAP e SnapCenter.  I contenuti forniti nel presente documento coprono una vasta gamma di argomenti:</block>
  <block id="a7e003a045fea49874b32ab9648eeff1" category="list-text">Linee guida infrastrutturali per database vettoriali, come Milvus, fornite da NetApp Storage tramite NetApp ONTAP e StorageGRID Object Storage.</block>
  <block id="dad32bf9f8412e678e687e1cf7bb9ca2" category="list-text">Validazione del database Milvus in AWS FSx ONTAP tramite archivio di file e oggetti.</block>
  <block id="68c4bdd7361d54de76b6a70ce9e66b6e" category="list-text">Approfondisce la dualità file-oggetto di NetApp, dimostrandone l'utilità per i dati nei database vettoriali e in altre applicazioni.</block>
  <block id="8aa4f3c0608b2b5d04870a90085180a0" category="list-text">In che modo il prodotto Data Protection Management di NetApp, SnapCenter, offre funzionalità di backup e ripristino per i dati dei database vettoriali.</block>
  <block id="413963cd7c6051b3cbc48462a3167d68" category="list-text">In che modo l'Hybrid Cloud di NetApp offre replicazione e protezione dei dati negli ambienti on-premise e cloud.</block>
  <block id="73d0a81a7f19b02b2cf3e9084b655966" category="list-text">Fornisce approfondimenti sulla convalida delle prestazioni di database vettoriali come Milvus e pgvector su NetApp ONTAP.</block>
  <block id="de2054eca65b6e345160d8320bfa3d17" category="list-text">Due casi d'uso specifici: Retrieval Augmented Generation (RAG) con Large Language Models (LLM) e ChatAI del team IT di NetApp , che offrono esempi pratici dei concetti e delle pratiche delineati.</block>
  <block id="11eb7151c13e504e17cca8ecf079bd88" category="summary">database vettoriale - soluzione di database vettoriale per NetApp</block>
  <block id="34e317d16a291e422cfed7563b8e4b74" category="doc">Database vettoriale</block>
  <block id="bb6e7da57bf9b9f451aff5682584af81" category="paragraph">Questa sezione tratta la definizione e l'uso di un database vettoriale nelle soluzioni di intelligenza artificiale NetApp .</block>
  <block id="02cf9216cd9290a38db4e591b2d891a3" category="paragraph">Un database vettoriale è un tipo specializzato di database progettato per gestire, indicizzare e ricercare dati non strutturati utilizzando incorporamenti di modelli di apprendimento automatico.  Invece di organizzare i dati in un formato tabellare tradizionale, li organizza come vettori ad alta dimensionalità, noti anche come incorporamenti vettoriali.  Questa struttura unica consente al database di gestire dati complessi e multidimensionali in modo più efficiente e accurato.</block>
  <block id="ee365553124acd5ca06a0026c4856306" category="paragraph">Una delle funzionalità principali di un database vettoriale è l'utilizzo dell'intelligenza artificiale generativa per eseguire analisi.  Ciò include ricerche di similarità, in cui il database identifica punti dati simili a un dato input, e rilevamento di anomalie, in cui può individuare punti dati che si discostano significativamente dalla norma.</block>
  <block id="145e8c4c44e4cdc9ac189d0799494e03" category="paragraph">Inoltre, i database vettoriali sono adatti a gestire dati temporali, ovvero dati con timestamp.  Questo tipo di dati fornisce informazioni su "cosa" è successo e quando è successo, in sequenza e in relazione a tutti gli altri eventi all'interno di un dato sistema IT.  Questa capacità di gestire e analizzare dati temporali rende i database vettoriali particolarmente utili per le applicazioni che richiedono la comprensione degli eventi nel tempo.</block>
  <block id="196ef3e0d720a0c9b617f7c8c553f64f" category="section-title">Vantaggi del database vettoriale per ML e AI:</block>
  <block id="2143262d5355c4a47b87575a67b2545b" category="list-text">Ricerca ad alta dimensionalità: i database vettoriali eccellono nella gestione e nel recupero di dati ad alta dimensionalità, spesso generati nelle applicazioni di intelligenza artificiale e apprendimento automatico.</block>
  <block id="eaec9d6e0bc3d169492279c991b5c1e1" category="list-text">Scalabilità: possono scalare in modo efficiente per gestire grandi volumi di dati, supportando la crescita e l'espansione dei progetti di intelligenza artificiale e apprendimento automatico.</block>
  <block id="1a581e9eb96703e6c387548283765d0f" category="list-text">Flessibilità: i database vettoriali offrono un elevato grado di flessibilità, consentendo di gestire diversi tipi di dati e strutture.</block>
  <block id="23f1f41790fda943f83f4fee180eb9c7" category="list-text">Prestazioni: garantiscono una gestione e un recupero dei dati ad alte prestazioni, fondamentali per la velocità e l'efficienza delle operazioni di intelligenza artificiale e apprendimento automatico.</block>
  <block id="5ec5f2c444dccfe97885b44e9f81c73a" category="list-text">Indicizzazione personalizzabile: i database vettoriali offrono opzioni di indicizzazione personalizzabili, consentendo un'organizzazione e un recupero dei dati ottimizzati in base a esigenze specifiche.</block>
  <block id="431b6b79e58c421f73a7d7653f3a2641" category="section-title">Database vettoriali e casi d'uso.</block>
  <block id="03e65b2645d14a51684616a56e46e74b" category="paragraph">Questa sezione fornisce vari database vettoriali e i dettagli sui loro casi d'uso.</block>
  <block id="4873dee9aab8428a3bad0247c8891122" category="section-title">Faiss e ScaNN</block>
  <block id="f8255a0712bd834e092674fb685b593d" category="paragraph">Si tratta di librerie che rappresentano strumenti essenziali nel campo della ricerca vettoriale.  Queste librerie forniscono funzionalità fondamentali per la gestione e la ricerca nei dati vettoriali, il che le rende risorse inestimabili in questo settore specializzato della gestione dei dati.</block>
  <block id="45e23a169652aaf95ce80da844f3df0d" category="section-title">Elasticsearch</block>
  <block id="7bdddec875d1ea093ba8b35566b1775c" category="paragraph">È un motore di ricerca e analisi ampiamente utilizzato, che ha recentemente incorporato funzionalità di ricerca vettoriale.  Questa nuova funzionalità ne migliora le funzionalità, consentendo di gestire e ricercare i dati vettoriali in modo più efficace.</block>
  <block id="f6af38c920e468b8adbdd5793a09b4ca" category="section-title">Pigna</block>
  <block id="e50d3eac5e6bdb3d1ddd1f564ee13308" category="paragraph">Si tratta di un solido database vettoriale con un set di funzionalità unico.  Supporta sia vettori densi che sparsi nella sua funzionalità di indicizzazione, il che ne aumenta la flessibilità e l'adattabilità.  Uno dei suoi punti di forza principali risiede nella capacità di combinare i metodi di ricerca tradizionali con la ricerca vettoriale densa basata sull'intelligenza artificiale, creando un approccio di ricerca ibrido che sfrutta il meglio di entrambi i mondi.</block>
  <block id="8a6b6fbe69ba556a5fee7b289943c80b" category="paragraph">Basato principalmente sul cloud, Pinecone è progettato per applicazioni di apprendimento automatico e si integra bene con una varietà di piattaforme, tra cui GCP, AWS, Open AI, GPT-3, GPT-3.5, GPT-4, Catgut Plus, Elasticsearch, Haystack e altre ancora.  È importante notare che Pinecone è una piattaforma closed-source ed è disponibile come offerta Software as a Service (SaaS).</block>
  <block id="b30cd65a7e403a5d3e792a3c02cfe9ef" category="paragraph">Grazie alle sue capacità avanzate, Pinecone è particolarmente adatto al settore della sicurezza informatica, dove le sue capacità di ricerca ad alta dimensione e di ricerca ibrida possono essere sfruttate efficacemente per rilevare e rispondere alle minacce.</block>
  <block id="12f586b0171cf0f06960a27796d811d6" category="section-title">Croma</block>
  <block id="44fcc1838437cfd155de42d2d5133fd3" category="paragraph">Si tratta di un database vettoriale dotato di una Core-API con quattro funzioni principali, una delle quali include un archivio di documenti vettoriali in memoria.  Utilizza inoltre la libreria Face Transformers per vettorializzare i documenti, migliorandone la funzionalità e la versatilità.  Chroma è progettato per funzionare sia nel cloud che in locale, offrendo flessibilità in base alle esigenze degli utenti.  In particolare, eccelle nelle applicazioni audio, il che lo rende una scelta eccellente per motori di ricerca basati sull'audio, sistemi di raccomandazione musicale e altri casi d'uso audio-correlati.</block>
  <block id="2a1e8d184d8101d9d99e3d491cd7be71" category="section-title">Tessitura</block>
  <block id="bd8b2ae24665811d42f62aa51b8f92c4" category="paragraph">Si tratta di un database vettoriale versatile che consente agli utenti di vettorializzare i propri contenuti utilizzando moduli integrati o moduli personalizzati, garantendo flessibilità in base a esigenze specifiche.  Offre soluzioni sia completamente gestite che self-hosted, soddisfacendo una varietà di preferenze di distribuzione.</block>
  <block id="5147cd0d10159454e367b25d270b0489" category="paragraph">Una delle caratteristiche principali di Weaviate è la sua capacità di memorizzare sia vettori che oggetti, migliorando le sue capacità di gestione dei dati.  È ampiamente utilizzato per una vasta gamma di applicazioni, tra cui la ricerca semantica e la classificazione dei dati nei sistemi ERP.  Nel settore dell'e-commerce, alimenta i motori di ricerca e di raccomandazione.  Weaviate viene utilizzato anche per la ricerca di immagini, il rilevamento di anomalie, l'armonizzazione automatica dei dati e l'analisi delle minacce alla sicurezza informatica, dimostrando la sua versatilità in più ambiti.</block>
  <block id="e111446745a1825b862f8727ae63bce4" category="section-title">Redis</block>
  <block id="58cbcbf294faed43c2a7b44bb5dcafcc" category="paragraph">Redis è un database vettoriale ad alte prestazioni, noto per la sua rapida archiviazione in memoria, che offre bassa latenza per le operazioni di lettura-scrittura.  Ciò lo rende una scelta eccellente per sistemi di raccomandazione, motori di ricerca e applicazioni di analisi dei dati che richiedono un rapido accesso ai dati.</block>
  <block id="4f9bdf8e8091be6f95cde54860bb88f7" category="paragraph">Redis supporta varie strutture dati per i vettori, tra cui elenchi, set e set ordinati.  Fornisce inoltre operazioni vettoriali come il calcolo delle distanze tra vettori o la ricerca di intersezioni e unioni.  Queste funzionalità sono particolarmente utili per la ricerca di similarità, il clustering e i sistemi di raccomandazione basati sui contenuti.</block>
  <block id="2391a64216fab42522be1700985c5a9e" category="paragraph">In termini di scalabilità e disponibilità, Redis eccelle nella gestione di carichi di lavoro ad alta produttività e offre la replica dei dati.  Si integra bene anche con altri tipi di dati, compresi i database relazionali tradizionali (RDBMS).  Redis include una funzionalità Pubblica/Sottoscrivi (Pub/Sub) per aggiornamenti in tempo reale, utile per la gestione dei vettori in tempo reale.  Inoltre, Redis è leggero e semplice da usare, il che lo rende una soluzione intuitiva per la gestione dei dati vettoriali.</block>
  <block id="4f3d528166032bacea5de8a509bb4d17" category="section-title">Milvus</block>
  <block id="e6aa3b4ef4ac18024fd88c49647d8277" category="paragraph">Si tratta di un database vettoriale versatile che offre un'API simile a un archivio di documenti, molto simile a MongoDB.  Si distingue per il supporto di un'ampia varietà di tipi di dati, il che lo rende una scelta popolare nei settori della scienza dei dati e dell'apprendimento automatico.</block>
  <block id="4b4464f60a3dfd428d4c07edb8cac802" category="paragraph">Una delle caratteristiche uniche di Milvus è la sua capacità di multi-vettorizzazione, che consente agli utenti di specificare in fase di esecuzione il tipo di vettore da utilizzare per la ricerca.  Inoltre, utilizza Knowwhere, una libreria che si basa su altre librerie come Faiss, per gestire la comunicazione tra le query e gli algoritmi di ricerca vettoriale.</block>
  <block id="bd3a3ade101e0f6fe46ad769dbf3cfa0" category="paragraph">Milvus offre inoltre un'integrazione perfetta con i flussi di lavoro di apprendimento automatico, grazie alla compatibilità con PyTorch e TensorFlow.  Ciò lo rende uno strumento eccellente per una vasta gamma di applicazioni, tra cui e-commerce, analisi di immagini e video, riconoscimento di oggetti, ricerca di similarità di immagini e recupero di immagini basato sui contenuti.  Nell'ambito dell'elaborazione del linguaggio naturale, Milvus viene utilizzato per il clustering di documenti, la ricerca semantica e i sistemi di risposta alle domande.</block>
  <block id="df5acf267fd9d50988a9132e88ec089f" category="paragraph">Per questa soluzione abbiamo scelto Milvus per la convalida della soluzione.  Per le prestazioni, abbiamo utilizzato sia milvus che postgres(pgvecto.rs).</block>
  <block id="6b9a995b1c19c83b6360f58654598ab0" category="section-title">Perché abbiamo scelto Milvus per questa soluzione?</block>
  <block id="ac80bf421cb6dec4ca81d75401709fce" category="list-text">Open-source: Milvus è un database vettoriale open-source che incoraggia lo sviluppo e i miglioramenti guidati dalla comunità.</block>
  <block id="72e0b014c4927b1166a4c34028bf0a94" category="list-text">Integrazione AI: sfrutta l'integrazione della ricerca di similarità e delle applicazioni AI per migliorare la funzionalità del database vettoriale.</block>
  <block id="1f3d7f832f4c276984a989e5a4760e7d" category="list-text">Gestione di grandi volumi: Milvus è in grado di archiviare, indicizzare e gestire oltre un miliardo di vettori di incorporamento generati da modelli di reti neurali profonde (DNN) e apprendimento automatico (ML).</block>
  <block id="be23175f1d046ec7a81f41bbfbb7a710" category="list-text">Facile da usare: è facile da usare e la configurazione richiede meno di un minuto.  Milvus offre anche SDK per diversi linguaggi di programmazione.</block>
  <block id="2c86f12d4bdb64f5ff99e182033e6664" category="list-text">Velocità: offre velocità di recupero incredibilmente elevate, fino a 10 volte superiori rispetto ad alcune alternative.</block>
  <block id="23a12a1d1c53642355185e4cf7fd3d30" category="list-text">Scalabilità e disponibilità: Milvus è altamente scalabile, con opzioni di scalabilità verticale e orizzontale in base alle esigenze.</block>
  <block id="eaa6e5cbb0e6c82b8217f591711c391a" category="list-text">Ricco di funzionalità: supporta diversi tipi di dati, filtraggio degli attributi, supporto delle funzioni definite dall'utente (UDF), livelli di coerenza configurabili e tempi di percorrenza, il che lo rende uno strumento versatile per varie applicazioni.</block>
  <block id="cb1e9d4cfab2279dd63f9f75796dc14f" category="section-title">Panoramica dell'architettura di Milvus</block>
  <block id="9c5b9910474e7d9e8c210fd3d649af4d" category="paragraph"><block ref="9c5b9910474e7d9e8c210fd3d649af4d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03bd3b894648d2e8a48d648b0fcedfac" category="paragraph">Questa sezione illustra i componenti e i servizi di livello superiore utilizzati nell'architettura Milvus.  * Livello di accesso: è composto da un gruppo di proxy stateless e funge da livello frontale del sistema e da endpoint per gli utenti.  * Servizio di coordinamento: assegna i compiti ai nodi worker e funge da cervello del sistema.  Ha tre tipi di coordinatore: root coord, data coord e query coord.  * Nodi worker: seguono le istruzioni del servizio coordinatore ed eseguono i comandi DML/DDL attivati dall'utente. Hanno tre tipi di nodi worker: nodo query, nodo dati e nodo indice.  * Archiviazione: è responsabile della persistenza dei dati.  Comprende meta-archiviazione, log broker e archiviazione di oggetti.  Le soluzioni di storage NetApp , come ONTAP e StorageGRID, forniscono a Milvus storage di oggetti e storage basato su file sia per i dati dei clienti che per i dati dei database vettoriali.</block>
  <block id="3ad011fbf1a887f55fe5db0f1c95891f" category="summary">milvus con Amazon FSx ONTAP per NetApp ONTAP - soluzione di database vettoriale per NetApp</block>
  <block id="dd69e86c3dc6fbad2a761367a22a0552" category="doc">Milvus con Amazon FSx ONTAP per NetApp ONTAP : dualità file e oggetto</block>
  <block id="8cec9207499fc7ae92bcaff5ffed4880" category="paragraph">Questa sezione illustra la configurazione del cluster Milvus con Amazon FSx ONTAP per la soluzione di database vettoriale per NetApp.</block>
  <block id="74126d145913f667c84fb0fae63d5f30" category="section-title">Milvus con Amazon FSx ONTAP per NetApp ONTAP : dualità di file e oggetti</block>
  <block id="de1f3a826ad4a683281aa07d427c615a" category="paragraph">In questa sezione, spiegheremo perché è necessario distribuire un database vettoriale nel cloud e i passaggi per distribuire un database vettoriale (Milvus standalone) in Amazon FSx ONTAP per NetApp ONTAP all'interno di container Docker.</block>
  <block id="c7d712a8f39fa8b7654218edbb110e3e" category="paragraph">L'implementazione di un database vettoriale nel cloud offre diversi vantaggi significativi, in particolare per le applicazioni che richiedono la gestione di dati ad alta dimensionalità e l'esecuzione di ricerche di similarità.  In primo luogo, l'implementazione basata su cloud offre scalabilità, consentendo di adattare facilmente le risorse in base ai crescenti volumi di dati e carichi di query.  Ciò garantisce che il database possa gestire in modo efficiente l'aumento della domanda, mantenendo al contempo prestazioni elevate.  In secondo luogo, l'implementazione del cloud garantisce elevata disponibilità e ripristino in caso di emergenza, poiché i dati possono essere replicati in diverse posizioni geografiche, riducendo al minimo il rischio di perdita di dati e garantendo un servizio continuo anche in caso di eventi imprevisti.  In terzo luogo, garantisce un buon rapporto qualità-prezzo, poiché si paga solo per le risorse utilizzate e si può aumentare o diminuire la scala in base alla domanda, evitando così la necessità di ingenti investimenti iniziali in hardware.  Infine, l'implementazione di un database vettoriale nel cloud può migliorare la collaborazione, poiché i dati possono essere consultati e condivisi da qualsiasi luogo, facilitando il lavoro di squadra e il processo decisionale basato sui dati.  Verificare l'architettura di milvus standalone con Amazon FSx ONTAP per NetApp ONTAP utilizzato in questa convalida.</block>
  <block id="f95a160e2c9ead1dd272587d85c4a8e3" category="paragraph"><block ref="f95a160e2c9ead1dd272587d85c4a8e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1e75d11a34279b79d1140edc8f509e3" category="list-text">Creare un'istanza Amazon FSx ONTAP per NetApp ONTAP e annotare i dettagli della VPC, dei gruppi di sicurezza VPC e della subnet.  Queste informazioni saranno necessarie durante la creazione di un'istanza EC2.  Puoi trovare maggiori dettagli qui -<block ref="600df3e2da0b9de1446fabf4802a063b" category="inline-link-rx"></block></block>
  <block id="d91af2df00186cd53f523a257cb2565a" category="list-text">Creare un'istanza EC2, assicurandosi che la VPC, i gruppi di sicurezza e la subnet corrispondano a quelli dell'istanza Amazon FSx ONTAP per NetApp ONTAP .</block>
  <block id="3f49259cc5a532eaad35643b8ddc6724" category="list-text">Installare nfs-common utilizzando il comando 'apt-get install nfs-common' e aggiornare le informazioni sul pacchetto utilizzando 'sudo apt-get update'.</block>
  <block id="7cd964c493dd7e6f0abd19075ad234a1" category="list-text">Crea una cartella di montaggio e montaci Amazon FSx ONTAP per NetApp ONTAP .</block>
  <block id="79f2982e5eb61f29ccc9204d1e575199" category="list-text">Installa Docker e Docker Compose utilizzando 'apt-get install'.</block>
  <block id="8b2bc8a7f7a7f8a83a1a126f0f97c496" category="list-text">Configurare un cluster Milvus in base al file docker-compose.yaml, scaricabile dal sito web di Milvus.</block>
  <block id="6667d03b2d7af61cacf9ce4779fbb601" category="list-text">Nella sezione 'volumi' del file docker-compose.yml, mappa il punto di montaggio NetApp NFS al percorso del contenitore Milvus corrispondente, in particolare in etcd, minio e standalone. Controlla<block ref="cb2986bd8f2d29c4cca582736e0a680f" category="inline-link-macro-rx"></block> per i dettagli sulle modifiche in yml</block>
  <block id="40722d15b9f6ad02c869cf6f587fd141" category="list-text">Verificare le cartelle e i file montati.</block>
  <block id="b1c44a1b47e0ee05938bd8b62a636917" category="list-text">Eseguire 'docker-compose up -d' dalla directory contenente il file docker-compose.yml.</block>
  <block id="9a6325448af98c29154cb9ef7423c998" category="list-text">Controllare lo stato del contenitore Milvus.</block>
  <block id="e5666f40cd9052040de973832a6b5fb8" category="list-text">Per convalidare la funzionalità di lettura e scrittura del database vettoriale e dei suoi dati in Amazon FSx ONTAP per NetApp ONTAP, abbiamo utilizzato Python Milvus SDK e un programma di esempio di PyMilvus.  Installa i pacchetti necessari usando 'apt-get install python3-numpy python3-pip' e installa PyMilvus usando 'pip3 install pymilvus'.</block>
  <block id="77b346f241703e75634a6437339f3874" category="list-text">Convalida le operazioni di scrittura e lettura dei dati da Amazon FSx ONTAP per NetApp ONTAP nel database vettoriale.</block>
  <block id="edeedbd869dbb3831a9bfc7c26f04200" category="list-text">Controllare l'operazione di lettura utilizzando lo script verify_data_netapp.py.</block>
  <block id="bda2d30c9f3f0d40ab873d7c99e8c13b" category="list-text">Se il cliente desidera accedere (leggere) i dati NFS testati nel database vettoriale tramite il protocollo S3 per i carichi di lavoro di intelligenza artificiale, può convalidarli utilizzando un semplice programma Python.  Un esempio potrebbe essere una ricerca di similarità di immagini provenienti da un'altra applicazione, come indicato nell'immagine all'inizio di questa sezione.</block>
  <block id="8b97e19802900809af55c42c509e614a" category="paragraph">Questa sezione illustra in modo efficace come i clienti possono distribuire e gestire una configurazione Milvus autonoma all'interno di container Docker, utilizzando NetApp FSx ONTAP di Amazon per l'archiviazione dei dati NetApp ONTAP .  Questa configurazione consente ai clienti di sfruttare la potenza dei database vettoriali per gestire dati ad alta dimensionalità ed eseguire query complesse, il tutto all'interno dell'ambiente scalabile ed efficiente dei container Docker.  Creando un'istanza Amazon FSx ONTAP per NetApp ONTAP e un'istanza EC2 corrispondente, i clienti possono garantire un utilizzo ottimale delle risorse e una gestione dei dati.  La validazione riuscita delle operazioni di scrittura e lettura dei dati da FSx ONTAP nel database vettoriale offre ai clienti la garanzia di operazioni sui dati affidabili e coerenti.  Inoltre, la possibilità di elencare (leggere) i dati dai carichi di lavoro di intelligenza artificiale tramite il protocollo S3 offre una migliore accessibilità ai dati.  Questo processo completo, pertanto, fornisce ai clienti una soluzione solida ed efficiente per la gestione delle loro operazioni sui dati su larga scala, sfruttando le capacità di FSx ONTAP di Amazon per NetApp ONTAP.</block>
  <block id="80f3b490016fb09dd087c51b2a8b26f5" category="summary">Configurazione del cluster Milvus: soluzione di database vettoriale per NetApp</block>
  <block id="c0f2e2b603c0c8186341bf2945e1ad13" category="doc">Configurazione del cluster Milvus con Kubernetes in locale</block>
  <block id="4a6f6b145c2d627bc6b03f4b1e6dd96a" category="paragraph">Questa sezione illustra la configurazione del cluster Milvus per la soluzione di database vettoriale per NetApp.</block>
  <block id="b5be4c6d053fbcf3d99fa7a27f14df10" category="section-title">Configurazione del cluster Milvus con Kubernetes in locale</block>
  <block id="ae5afd2c726fae66bdccf19c83604efb" category="paragraph">Le sfide dei clienti per scalare in modo indipendente su storage e calcolo, una gestione efficace dell'infrastruttura e la gestione dei dati, Kubernetes e i database vettoriali insieme formano una soluzione potente e scalabile per la gestione di operazioni su grandi quantità di dati.  Kubernetes ottimizza le risorse e gestisce i container, mentre i database vettoriali gestiscono in modo efficiente i dati ad alta dimensionalità e le ricerche di similarità.  Questa combinazione consente l'elaborazione rapida di query complesse su grandi set di dati e si adatta perfettamente ai crescenti volumi di dati, rendendola ideale per applicazioni big data e carichi di lavoro di intelligenza artificiale.</block>
  <block id="b74b373b546797287d3c21cceba52d3d" category="list-text">In questa sezione, descriviamo in dettaglio il processo di installazione di un cluster Milvus su Kubernetes, utilizzando un controller di archiviazione NetApp sia per i dati del cluster che per i dati dei clienti.</block>
  <block id="65c0326e8e372682bfaae45cec62723f" category="list-text">Per installare un cluster Milvus, sono necessari volumi persistenti (PV) per archiviare i dati provenienti da vari componenti del cluster Milvus.  Questi componenti includono etcd (tre istanze), pulsar-bookie-journal (tre istanze), pulsar-bookie-ledgers (tre istanze) e pulsar-zookeeper-data (tre istanze).</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link-macro">questo collegamento</block>
  <block id="d33fb2ef35d69747411b9e87c7d3d69f" category="admonition">Nel cluster Milvus, possiamo utilizzare sia Pulsar che Kafka come motore sottostante che supporta l'archiviazione affidabile e la pubblicazione/sottoscrizione dei flussi di messaggi del cluster Milvus.  Per Kafka con NFS, NetApp ha apportato miglioramenti in ONTAP 9.12.1 e versioni successive, e questi miglioramenti, insieme alle modifiche di NFSv4.1 e Linux incluse in RHEL 8.7 o 9.1 e versioni successive, risolvono il problema della "rinomina stupida" che può verificarsi quando si esegue Kafka su NFS. Se sei interessato a informazioni più approfondite sull'esecuzione di Kafka con la soluzione NetApp NFS, consulta:<block ref="19b6a7adb53ddda340943365a4b691d7" category="inline-link-macro-rx"></block> .</block>
  <block id="eea5737b25740da376e769b4f799f861" category="list-text">Abbiamo creato un singolo volume NFS da NetApp ONTAP e stabilito 12 volumi persistenti, ciascuno con 250 GB di storage.  La dimensione dello storage può variare a seconda delle dimensioni del cluster; ad esempio, abbiamo un altro cluster in cui ogni PV ha 50 GB.  Per maggiori dettagli fare riferimento a uno dei file PV YAML qui sotto; in totale avevamo 12 file di questo tipo.  In ogni file, storageClassName è impostato su "default" e lo storage e il percorso sono univoci per ogni PV.</block>
  <block id="4bd70516b6325446dd3ab13888cff57f" category="list-text">Eseguire il comando 'kubectl apply' per ogni file YAML PV per creare i volumi persistenti, quindi verificare la loro creazione utilizzando 'kubectl get pv'</block>
  <block id="3468fc776a2c10c6b885c4b8f38fbb6f" category="list-text">Per l'archiviazione dei dati dei clienti, Milvus supporta soluzioni di archiviazione di oggetti come MinIO, Azure Blob e S3.  In questa guida utilizziamo S3.  I passaggi seguenti si applicano sia all'archivio oggetti ONTAP S3 che a StorageGRID .  Utilizziamo Helm per distribuire il cluster Milvus.  Scarica il file di configurazione, values.yaml, dalla posizione di download di Milvus.  Fare riferimento all'appendice per il file values.yaml utilizzato in questo documento.</block>
  <block id="ac8152f5c769ca08c180374241d9797c" category="list-text">Assicurarsi che 'storageClass' sia impostato su 'default' in ogni sezione, comprese quelle per log, etcd, zookeeper e bookkeeper.</block>
  <block id="3c27656d225ef946516e7bec88519049" category="list-text">Nella sezione MinIO, disabilitare MinIO.</block>
  <block id="a9c572c8c594acac80d859b834139c09" category="list-text">Creare un bucket NAS dall'archiviazione di oggetti ONTAP o StorageGRID e includerli in un S3 esterno con le credenziali dell'archiviazione di oggetti.</block>
  <block id="5c01f0212f13cb62a8e9c91143a9a0e8" category="list-text">Prima di creare il cluster Milvus, assicurarsi che PersistentVolumeClaim (PVC) non disponga di risorse preesistenti.</block>
  <block id="8916cc7e0054297b71b9453a888657d1" category="list-text">Utilizzare Helm e il file di configurazione values.yaml per installare e avviare il cluster Milvus.</block>
  <block id="774a1cf197a96a839f6b770e85cb2445" category="list-text">Verificare lo stato dei PersistentVolumeClaims (PVC).</block>
  <block id="63b2b2b30427688208b8a24971cee62e" category="list-text">Controllare lo stato dei baccelli.</block>
  <block id="1d419f9c469484aa1d54fd468448977e" category="paragraph">Assicurati che lo stato dei pod sia "in esecuzione" e funzioni come previsto</block>
  <block id="890a387ef3d7768088115e7fea8a9ff6" category="list-text">Scrittura e lettura dei dati di prova in Milvus e nell'archiviazione di oggetti NetApp .</block>
  <block id="e5aef6bb28887bb265d168f37e539b38" category="list-text">Scrivere i dati utilizzando il programma Python "prepare_data_netapp_new.py".</block>
  <block id="db12c3e2840ba5032e784bab8e8fb917" category="list-text">Leggere i dati utilizzando il file Python "verify_data_netapp.py".</block>
  <block id="25ab62108c16e9b732c38f62755ec991" category="paragraph">Sulla base della convalida di cui sopra, l'integrazione di Kubernetes con un database vettoriale, come dimostrato attraverso l'implementazione di un cluster Milvus su Kubernetes utilizzando un controller di storage NetApp , offre ai clienti una soluzione solida, scalabile ed efficiente per la gestione di operazioni sui dati su larga scala.  Questa configurazione offre ai clienti la possibilità di gestire dati ad alta dimensionalità ed eseguire query complesse in modo rapido ed efficiente, rendendola una soluzione ideale per applicazioni big data e carichi di lavoro di intelligenza artificiale.  L'utilizzo di volumi persistenti (PV) per vari componenti del cluster, insieme alla creazione di un singolo volume NFS da NetApp ONTAP, garantisce un utilizzo ottimale delle risorse e una gestione dei dati.  Il processo di verifica dello stato dei PersistentVolumeClaim (PVC) e dei pod, nonché il test di scrittura e lettura dei dati, garantiscono ai clienti operazioni sui dati affidabili e coerenti.  L'utilizzo dell'archiviazione di oggetti ONTAP o StorageGRID per i dati dei clienti migliora ulteriormente l'accessibilità e la sicurezza dei dati.  Nel complesso, questa configurazione fornisce ai clienti una soluzione di gestione dei dati resiliente e ad alte prestazioni, in grado di adattarsi senza problemi alle crescenti esigenze di dati.</block>
  <block id="34d3fa32b415d892eb0e14786cafccea" category="summary">Panoramica della soluzione per la soluzione di database vettoriale per NetApp</block>
  <block id="351df3cce379006f4ba6b903c32e39a0" category="paragraph">Questa sezione fornisce una panoramica della soluzione di database vettoriale NetApp .</block>
  <block id="84c35d4e8bb8f8f09d3728632bcee7ce" category="paragraph">Questa soluzione mette in mostra i vantaggi e le capacità distintive che NetApp offre per affrontare le sfide che i clienti dei database vettoriali si trovano ad affrontare.  Sfruttando NetApp ONTAP, StorageGRID, le soluzioni cloud di NetApp e SnapCenter, i clienti possono aggiungere un valore significativo alle loro operazioni aziendali.  Questi strumenti non solo risolvono i problemi esistenti, ma migliorano anche l'efficienza e la produttività, contribuendo così alla crescita aziendale complessiva.</block>
  <block id="d383216ef38104a4ae0ac03e48c3f38c" category="section-title">Perché NetApp?</block>
  <block id="c8850228b08f24ab3b77cf8228b9b2cf" category="list-text">Le offerte di NetApp, come ONTAP e StorageGRID, consentono la separazione tra storage ed elaborazione, consentendo un utilizzo ottimale delle risorse in base a requisiti specifici.  Questa flessibilità consente ai clienti di scalare in modo indipendente il proprio storage utilizzando le soluzioni di storage NetApp .</block>
  <block id="40251a62505d04ab7d80bacded5fec97" category="list-text">NetApp ONTAP fornisce supporto nativo per NAS e storage di oggetti attraverso i principali provider di servizi cloud come AWS, Azure e Google Cloud.  Questa ampia compatibilità garantisce un'integrazione perfetta, consentendo la mobilità dei dati dei clienti, l'accessibilità globale, il ripristino di emergenza, la scalabilità dinamica e le prestazioni elevate.</block>
  <block id="6c1c83ac60affc59fcc3432ea130dd8f" category="list-text">Grazie alle solide funzionalità di gestione dei dati di NetApp, i clienti possono stare tranquilli sapendo che i loro dati sono ben protetti da potenziali rischi e minacce.  NetApp dà priorità alla sicurezza dei dati, offrendo ai clienti la tranquillità di sapere che le loro preziose informazioni sono al sicuro e integre.</block>
  <block id="738158dc90e1d60ff7273e21bc2d2c4e" category="summary">Validazione delle prestazioni del database vettoriale - soluzione di database vettoriale per NetApp</block>
  <block id="39301670f58445b6e5aed7e2a2694632" category="doc">Validazione delle prestazioni del database vettoriale</block>
  <block id="334e1c5c0681bc3d3d6b9321ff851f44" category="paragraph">Questa sezione evidenzia la convalida delle prestazioni eseguita sul database vettoriale.</block>
  <block id="1eb24bd760e508043a3cfdfe91ba9489" category="section-title">Validazione delle prestazioni</block>
  <block id="0dfe6e4dda5bda08f3b2f54fe5f51a3b" category="paragraph">La convalida delle prestazioni svolge un ruolo fondamentale sia nei database vettoriali che nei sistemi di archiviazione, fungendo da fattore chiave per garantire un funzionamento ottimale e un utilizzo efficiente delle risorse.  I database vettoriali, noti per la gestione di dati ad alta dimensionalità e l'esecuzione di ricerche di similarità, devono mantenere elevati livelli di prestazioni per elaborare query complesse in modo rapido e accurato.  La convalida delle prestazioni aiuta a identificare i colli di bottiglia, a perfezionare le configurazioni e a garantire che il sistema possa gestire i carichi previsti senza degradazione del servizio.  Allo stesso modo, nei sistemi di archiviazione, la convalida delle prestazioni è essenziale per garantire che i dati vengano archiviati e recuperati in modo efficiente, senza problemi di latenza o colli di bottiglia che potrebbero influire sulle prestazioni complessive del sistema.  Aiuta inoltre a prendere decisioni consapevoli sugli aggiornamenti o le modifiche necessarie all'infrastruttura di storage.  Pertanto, la convalida delle prestazioni è un aspetto cruciale della gestione del sistema, contribuendo in modo significativo al mantenimento di un'elevata qualità del servizio, dell'efficienza operativa e dell'affidabilità complessiva del sistema.</block>
  <block id="9115de397cf08aaab47480ba37fbda9b" category="paragraph">In questa sezione, ci proponiamo di approfondire la convalida delle prestazioni dei database vettoriali, come Milvus e pgvecto.rs, concentrandoci sulle caratteristiche delle prestazioni di storage, come il profilo I/O e il comportamento del controller di storage NetApp a supporto dei carichi di lavoro RAG e di inferenza all'interno del ciclo di vita LLM.  Valuteremo e identificheremo eventuali fattori differenzianti nelle prestazioni quando questi database saranno combinati con la soluzione di archiviazione ONTAP .  La nostra analisi si baserà su indicatori chiave di prestazione, come il numero di query elaborate al secondo (QPS).</block>
  <block id="259349a97b2ad2022418ffa271915c7f" category="paragraph">Si prega di controllare la metodologia utilizzata per milvus e i progressi di seguito.</block>
  <block id="3805969a7e504e8baa224367a87cc5a8" category="cell">Milvus (autonomo e cluster)</block>
  <block id="1cfad7d7743394085072e5f7fcc3a203" category="cell">Postgres(pgvecto.rs) #</block>
  <block id="2af72f100c356273d46284f6fd1dfc08" category="cell">versione</block>
  <block id="c2ee74b62870d06b4b4ad6819b9bf142" category="cell">2.3.2</block>
  <block id="44b732a6709d52e07db0367d4938965c" category="cell">0.2.0</block>
  <block id="ac52cf637478f3656a1fdee5c02324fd" category="cell">File system</block>
  <block id="6f27ca3ac8a02564ce2eef7e706e1e50" category="cell">XFS su LUN iSCSI</block>
  <block id="30b5bb1d010e4fe15e0541fa9b96dbdc" category="cell">Generatore di carico di lavoro</block>
  <block id="73676a7da2a7cbd819e3a72dab6d2364" category="inline-link-macro">VectorDB-Bench</block>
  <block id="b9350528e041c5ef962f5553183ca801" category="cell"><block ref="5a4d2a4510eb4d9895b68971f8744a05" category="inline-link-macro-rx"></block>– v0.0.5</block>
  <block id="f1cb45f64cdd7b55480ba6aeecd7b797" category="cell">Set di dati</block>
  <block id="0adc231fd0cbf3d7d8d5a0ff68eb2783" category="cell">Dataset LAION * 10 milioni di incorporamenti * 768 dimensioni * dimensione del dataset ~300 GB</block>
  <block id="3941cf702a750210280a88643fe83810" category="cell">AFF 800 * Versione – 9.14.1 * 4 x 100GbE – per milvus e 2x 100GbE per postgres * iscsi</block>
  <block id="39138e4aea637ddf9fc568de53bed3af" category="section-title">VectorDB-Bench con cluster autonomo Milvus</block>
  <block id="3a82e1f5d5f2195d71ba779a6ede894f" category="paragraph">abbiamo eseguito la seguente convalida delle prestazioni sul cluster autonomo Milvus con vectorDB-Bench.  Di seguito è riportata la connettività di rete e server del cluster autonomo Milvus.</block>
  <block id="ef436c3d7bb0f3687e078dce4b9bdb28" category="paragraph"><block ref="ef436c3d7bb0f3687e078dce4b9bdb28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="663c78b1d11f60d7440f91f77e4f328a" category="paragraph">In questa sezione condividiamo le nostre osservazioni e i risultati ottenuti testando il database autonomo Milvus. .  Abbiamo selezionato DiskANN come tipo di indice per questi test. .  L'acquisizione, l'ottimizzazione e la creazione di indici per un set di dati di circa 100 GB hanno richiesto circa 5 ore.  Per la maggior parte di questa durata, il server Milvus, dotato di 20 core (che equivalgono a 40 vCPU quando Hyper-Threading è abilitato), ha funzionato alla massima capacità della CPU, pari al 100%. Abbiamo scoperto che DiskANN è particolarmente importante per i set di dati di grandi dimensioni che superano le dimensioni della memoria di sistema. .  Nella fase di query, abbiamo osservato un tasso di query al secondo (QPS) pari a 10,93 con un richiamo pari a 0,9987.  La latenza del 99° percentile per le query è stata misurata a 708,2 millisecondi.</block>
  <block id="624dbbdc3175c82e67aadff554ee1850" category="paragraph">Dal punto di vista dell'archiviazione, il database ha eseguito circa 1.000 operazioni al secondo durante le fasi di acquisizione, ottimizzazione post-inserimento e creazione dell'indice.  Nella fase di query, sono state richieste 32.000 operazioni al secondo.</block>
  <block id="2063cebb91be357ea64826c835821b9d" category="paragraph">Nella sezione seguente vengono presentate le metriche delle prestazioni di archiviazione.</block>
  <block id="5805c53ecb86f7c7ae7765287eda00d6" category="cell">Fase di carico di lavoro</block>
  <block id="216ab40cda5c7c00ff42a4efb1827d89" category="cell">Metrico</block>
  <block id="7f2bb2bf609fe39698d58a2d1d86863a" category="cell">Inserimento dei dati e ottimizzazione post-inserimento</block>
  <block id="79073619fba8242703524f16870ff858" category="cell">IOPS</block>
  <block id="648a472fd7585d9d0c15b90f36365597" category="cell">&lt; 1.000</block>
  <block id="26ae7bdd1d6fb8c4886e6fde8d12601c" category="cell">Latenza</block>
  <block id="822500fd5bb8ac11d944779a6703df98" category="cell">&lt; 400 usecs</block>
  <block id="68eaabb91b0d1c52be44217a24f27b91" category="cell">Carico di lavoro</block>
  <block id="59829f7cd61cf1113b8214b47aaeacd8" category="cell">Mix di lettura/scrittura, per lo più scrive</block>
  <block id="991ff9e60b05b3e05e67404474611720" category="cell">dimensione IO</block>
  <block id="6b29aa131a7b968826c90e6801bacd23" category="cell">64 KB</block>
  <block id="66c1b4c7f3dc385b68a9fa903ccd016d" category="cell">Domanda</block>
  <block id="7d38c4599a45db6312f66bfac2fbba0d" category="cell">Picco a 32.000</block>
  <block id="866fc78d18122580af38eeff4375a3c0" category="cell">Lettura cache al 100%</block>
  <block id="9632dc4ffd7ab759c4fc53341977d887" category="cell">Principalmente 8 KB</block>
  <block id="06b68ce1a31c0cdf5430d925dabff321" category="paragraph">Di seguito è riportato il risultato di vectorDB-bench.</block>
  <block id="2a8bd0e83a84e623eafaed41ef4a0b48" category="paragraph"><block ref="2a8bd0e83a84e623eafaed41ef4a0b48" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf13afd123e82c2f8504d046ac979ce6" category="paragraph">Dalla convalida delle prestazioni dell'istanza Milvus autonoma, è evidente che la configurazione attuale non è sufficiente a supportare un set di dati di 5 milioni di vettori con una dimensionalità di 1536. Abbiamo stabilito che lo storage dispone di risorse adeguate e non costituisce un collo di bottiglia nel sistema.</block>
  <block id="7a2e31e50716ca1d05ae61faa264e4d9" category="section-title">VectorDB-Bench con cluster Milvus</block>
  <block id="1a3dd3962bc3776e2a670ea2dccbf4aa" category="paragraph">In questa sezione, discuteremo l'implementazione di un cluster Milvus all'interno di un ambiente Kubernetes.  Questa configurazione di Kubernetes è stata realizzata su una distribuzione VMware vSphere, che ospitava i nodi master e worker di Kubernetes.</block>
  <block id="2f38e478e85318635a3c104d2f9689ea" category="paragraph">I dettagli delle distribuzioni VMware vSphere e Kubernetes sono presentati nelle sezioni seguenti.</block>
  <block id="6b38cbd988bc17810219001208570634" category="paragraph"><block ref="ef20c4495e84beca29aabf20791bc97a" category="inline-image-macro-rx" type="image"></block> <block ref="6f1c220e845ab7b8291a1a21a3646cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09618a18978db1f9288bf0626e2e9d77" category="paragraph">In questa sezione presentiamo le nostre osservazioni e i risultati ottenuti testando il database Milvus.  * Il tipo di indice utilizzato era DiskANN.  * La tabella seguente fornisce un confronto tra le distribuzioni standalone e cluster quando si lavora con 5 milioni di vettori con una dimensionalità di 1536.  Abbiamo osservato che il tempo impiegato per l'acquisizione dei dati e l'ottimizzazione post-inserimento era inferiore nella distribuzione del cluster.  La latenza del 99° percentile per le query è stata ridotta di sei volte nella distribuzione del cluster rispetto alla configurazione autonoma.  * Sebbene la frequenza delle query al secondo (QPS) fosse più elevata nella distribuzione del cluster, non era al livello desiderato.</block>
  <block id="fa7bae8c4e9fc0bec05867545cb65c08" category="paragraph"><block ref="fa7bae8c4e9fc0bec05867545cb65c08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec05b5e2e1b5d66f987712f952bfd377" category="paragraph">Le immagini sottostanti forniscono una panoramica di varie metriche di archiviazione, tra cui la latenza del cluster di archiviazione e gli IOPS totali (operazioni di input/output al secondo).</block>
  <block id="866b04fa947dc783f0a1ca67687a0b46" category="paragraph"><block ref="866b04fa947dc783f0a1ca67687a0b46" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f34ceedf45c53ac5bfc4732c7e9eb992" category="paragraph">Nella sezione seguente vengono presentate le principali metriche relative alle prestazioni di archiviazione.</block>
  <block id="40c9acf8f61419691d77b3dec178cdc9" category="cell">Picco a 147.000</block>
  <block id="971ae6b3c89c8ab12e0eed4e70f3ad7a" category="paragraph">Sulla base della convalida delle prestazioni sia del Milvus autonomo che del cluster Milvus, presentiamo i dettagli del profilo I/O di archiviazione.  * Abbiamo osservato che il profilo I/O rimane coerente sia nelle distribuzioni autonome che in quelle cluster.  * La differenza osservata nei picchi di IOPS può essere attribuita al numero maggiore di client nella distribuzione del cluster.</block>
  <block id="537edb0aa02f73a246f084214ff9a1e4" category="section-title">vectorDB-Bench con Postgres (pgvecto.rs)</block>
  <block id="62f6737d84249676fddeaa6678755d2a" category="paragraph">Abbiamo eseguito le seguenti azioni su PostgreSQL (pgvecto.rs) utilizzando VectorDB-Bench: i dettagli riguardanti la connettività di rete e del server di PostgreSQL (in particolare, pgvecto.rs) sono i seguenti:</block>
  <block id="467a4cd74d7adb713cf4f94b3dd642b7" category="paragraph"><block ref="467a4cd74d7adb713cf4f94b3dd642b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd9a767006e111bd203547a99e12e650" category="paragraph">In questa sezione condividiamo le nostre osservazioni e i risultati ottenuti testando il database PostgreSQL, in particolare utilizzando pgvecto.rs.  * Abbiamo selezionato HNSW come tipo di indice per questi test perché al momento del test, DiskANN non era disponibile per pgvecto.rs.  * Durante la fase di acquisizione dei dati, abbiamo caricato il dataset Cohere, composto da 10 milioni di vettori con una dimensionalità di 768.  Questo processo ha richiesto circa 4,5 ore.  * Nella fase di query, abbiamo osservato un tasso di query al secondo (QPS) di 1.068 con un richiamo di 0,6344.  La latenza del 99° percentile per le query è stata misurata a 20 millisecondi.  Per la maggior parte del tempo di esecuzione, la CPU del client ha funzionato al 100% della sua capacità.</block>
  <block id="1f3e94e90c6dc70493177c947144e128" category="paragraph">Le immagini sottostanti forniscono una panoramica di varie metriche di archiviazione, tra cui la latenza totale del cluster di archiviazione IOPS (operazioni di input/output al secondo).</block>
  <block id="887b48e40648d9beb4f86ffbf295813a" category="paragraph"><block ref="887b48e40648d9beb4f86ffbf295813a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59566b4d8c8fef1f2b244df87cbe1523" category="paragraph"><block ref="59566b4d8c8fef1f2b244df87cbe1523" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa49276609916c00fd739a7d0474f2e0" category="section-title">Confronto delle prestazioni tra Milvus e Postgres su Vector DB Bench</block>
  <block id="870f4bfca5a2e4c27797438cfbcdcafc" category="paragraph"><block ref="870f4bfca5a2e4c27797438cfbcdcafc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a6bb1cc3086d7d67df39b7f25c55f2f" category="paragraph">Sulla base della nostra convalida delle prestazioni di Milvus e PostgreSQL utilizzando VectorDBBench, abbiamo osservato quanto segue:</block>
  <block id="edec147efc5d9e9f8c60dd4f8475a94a" category="list-text">Tipo di indice: HNSW</block>
  <block id="2d14d931ff962fab0d69fc6c540c032e" category="list-text">Dataset: Cohere con 10 milioni di vettori a 768 dimensioni</block>
  <block id="0e18fa0193d93ed358d7fdb6a65a8bbc" category="paragraph">Abbiamo scoperto che pgvecto.rs ha raggiunto un tasso di query al secondo (QPS) di 1.068 con un richiamo di 0,6344, mentre Milvus ha raggiunto un tasso di QPS di 106 con un richiamo di 0,9842.</block>
  <block id="6f8820eba6bfb1c4427de7e140948640" category="paragraph">Se l'elevata precisione nelle tue query è una priorità, Milvus supera pgvecto.rs in quanto recupera una percentuale maggiore di elementi pertinenti per query.  Tuttavia, se il numero di query al secondo è un fattore più cruciale, pgvecto.rs supera Milvus.  È importante notare, tuttavia, che la qualità dei dati recuperati tramite pgvecto.rs è inferiore, con circa il 37% dei risultati di ricerca costituiti da elementi irrilevanti.</block>
  <block id="35a1dd67e98f2039e3b4dc79a35aaa3e" category="section-title">Osservazione basata sulle nostre convalide delle prestazioni:</block>
  <block id="e6b80e98176081ee739c8e730d3feb58" category="paragraph">Sulla base delle nostre convalide delle prestazioni, abbiamo fatto le seguenti osservazioni:</block>
  <block id="9d57f733c58a90a624b060f00ad469bd" category="paragraph">In Milvus, il profilo I/O assomiglia molto a un carico di lavoro OLTP, come quello visto con Oracle SLOB.  Il benchmark è composto da tre fasi: acquisizione dei dati, post-ottimizzazione e query.  Le fasi iniziali sono caratterizzate principalmente da operazioni di scrittura da 64 KB, mentre la fase di query prevede prevalentemente letture da 8 KB.  Ci aspettiamo che ONTAP gestisca in modo efficiente il carico I/O Milvus.</block>
  <block id="e63d591f52bb0af8effc43c397a26a24" category="paragraph">Il profilo I/O di PostgreSQL non presenta un carico di lavoro di archiviazione impegnativo.  Considerata l'implementazione in memoria attualmente in corso, non abbiamo osservato alcun I/O su disco durante la fase di query.</block>
  <block id="dca2ae788fda893b11a6e115cfbd0c5d" category="paragraph">DiskANN emerge come una tecnologia cruciale per la differenziazione dello storage.  Consente di ridimensionare in modo efficiente la ricerca nel database vettoriale oltre i limiti della memoria di sistema.  Tuttavia, è improbabile che si possa stabilire una differenziazione delle prestazioni di archiviazione con indici DB vettoriali in memoria come HNSW.</block>
  <block id="dc94ef6a238640d927556506c546662f" category="paragraph">Vale anche la pena notare che l'archiviazione non gioca un ruolo critico durante la fase di query quando il tipo di indice è HSNW, che è la fase operativa più importante per i database vettoriali che supportano le applicazioni RAG.  Ciò implica che le prestazioni di archiviazione non hanno un impatto significativo sulle prestazioni complessive di queste applicazioni.</block>
  <block id="0a5775b4af8d3c53f18b8ccaf913945d" category="summary">Questa è una pagina astratta per la soluzione di database vettoriale con Netapp.</block>
  <block id="8df98bd508b3983f9578ff172fd33def" category="doc">Soluzione di database vettoriale con NetApp</block>
  <block id="7dff0a79d9410666d77e5f2ac7d0344f" category="paragraph">Karthikeyan Nagalingam e Rodrigo Nascimento, NetApp</block>
  <block id="01fbfceb794af743cb563e2676923b70" category="paragraph">Questo documento fornisce un'analisi approfondita dell'implementazione e della gestione di database vettoriali, come Milvus e pgvecto, un'estensione open source di PostgreSQL, utilizzando le soluzioni di storage di NetApp.  Descrive dettagliatamente le linee guida dell'infrastruttura per l'utilizzo di NetApp ONTAP e StorageGRID Object Storage e convalida l'applicazione del database Milvus in AWS FSx ONTAP.  Il documento illustra la dualità file-oggetto di NetApp e la sua utilità per database vettoriali e applicazioni che supportano incorporamenti vettoriali.  Sottolinea le capacità di SnapCenter, il prodotto di gestione aziendale di NetApp, nell'offrire funzionalità di backup e ripristino per database vettoriali, garantendo l'integrità e la disponibilità dei dati.  Il documento approfondisce ulteriormente la soluzione cloud ibrida di NetApp, discutendone il ruolo nella replicazione e protezione dei dati negli ambienti on-premise e cloud.  Include approfondimenti sulla convalida delle prestazioni dei database vettoriali su NetApp ONTAP e si conclude con due casi d'uso pratici sull'intelligenza artificiale generativa: RAG con LLM e ChatAI interno di NetApp.  Questo documento costituisce una guida completa per sfruttare al meglio le soluzioni di storage di NetApp per la gestione dei database vettoriali.</block>
  <block id="ad452e95198e544e4d893fc75ad47dd6" category="paragraph">L'architettura di riferimento si concentra sui seguenti punti:</block>
  <block id="710d95da54f78f69676ae8cb435c6e6e" category="list-text"><block ref="710d95da54f78f69676ae8cb435c6e6e" category="inline-link-macro-rx"></block></block>
  <block id="ada57c9cda1b1c751a4e899e578d38e3" category="list-text"><block ref="ada57c9cda1b1c751a4e899e578d38e3" category="inline-link-macro-rx"></block></block>
  <block id="82f4ace5dffbf97de80ca1ea103fbe56" category="list-text"><block ref="82f4ace5dffbf97de80ca1ea103fbe56" category="inline-link-macro-rx"></block></block>
  <block id="55496e6b06de6e72c19b578ad4ce71d8" category="inline-link-macro">Requisiti tecnologici</block>
  <block id="4abf02f5e3deeb5036c0eded610de05a" category="list-text"><block ref="4abf02f5e3deeb5036c0eded610de05a" category="inline-link-macro-rx"></block></block>
  <block id="19c63a75039d0a9cb4cec3458cfe0581" category="list-text"><block ref="19c63a75039d0a9cb4cec3458cfe0581" category="inline-link-macro-rx"></block></block>
  <block id="8c8f8b93bc06c57499a04ec1b06dae28" category="inline-link-macro">Panoramica sulla verifica della soluzione</block>
  <block id="ca47b69088a672a9b65069106989453e" category="list-text"><block ref="ca47b69088a672a9b65069106989453e" category="inline-link-macro-rx"></block></block>
  <block id="55d7ef09813b4d6fdcb2c5626efe487e" category="list-text"><block ref="55d7ef09813b4d6fdcb2c5626efe487e" category="inline-link-macro-rx"></block></block>
  <block id="0bf83d510fcfec34ea35ee03c83ce577" category="list-text">link:vector-database-milvus-with-Amazon-FSx ONTAP-for- NetApp- ONTAP.html[Milvus con Amazon FSx ONTAP per NetApp ONTAP – dualità file e oggetto]</block>
  <block id="d6b228867818081bf3ee3cecad050baf" category="list-text"><block ref="d6b228867818081bf3ee3cecad050baf" category="inline-link-macro-rx"></block></block>
  <block id="f7ba02d22d83dabd12f0465a68c210ea" category="list-text"><block ref="f7ba02d22d83dabd12f0465a68c210ea" category="inline-link-macro-rx"></block></block>
  <block id="9e30995c6d4864b29eb56e92d196baec" category="list-text"><block ref="9e30995c6d4864b29eb56e92d196baec" category="inline-link-macro-rx"></block></block>
  <block id="bd1287beca719fc00531ba3dd533f70c" category="list-text"><block ref="bd1287beca719fc00531ba3dd533f70c" category="inline-link-macro-rx"></block></block>
  <block id="a4349288a9fe8fecb32674ed8a0e5d15" category="inline-link-macro">Casi d'uso del database vettoriale</block>
  <block id="b8d3dfdbfce37d26c1f4f9d8acee71ca" category="list-text"><block ref="b8d3dfdbfce37d26c1f4f9d8acee71ca" category="inline-link-macro-rx"></block></block>
  <block id="da73b8a757c1735375b56d959d388619" category="list-text"><block ref="da73b8a757c1735375b56d959d388619" category="inline-link-macro-rx"></block></block>
  <block id="fec04177b34fde0762c2d0f1cb5bcf85" category="inline-link-macro">Appendice A: values.yaml</block>
  <block id="4076746ca906dfd472a39281440bca63" category="list-text"><block ref="4076746ca906dfd472a39281440bca63" category="inline-link-macro-rx"></block></block>
  <block id="2c0fbb0e17a27b8dbff673fb6b03c50b" category="list-text"><block ref="2c0fbb0e17a27b8dbff673fb6b03c50b" category="inline-link-macro-rx"></block></block>
  <block id="016166f68a717d3a544b77970134fe92" category="inline-link-macro">Appendice C: verify_data_netapp.py</block>
  <block id="1fa29d4bb8db316d27c057bc2ab73bcb" category="list-text"><block ref="1fa29d4bb8db316d27c057bc2ab73bcb" category="inline-link-macro-rx"></block></block>
  <block id="cb2986bd8f2d29c4cca582736e0a680f" category="list-text"><block ref="cb2986bd8f2d29c4cca582736e0a680f" category="inline-link-macro-rx"></block></block>
  <block id="f60546114707495cbcefb83f806b47e2" category="summary">Requisito tecnologico: soluzione di database vettoriale per NetApp</block>
  <block id="73877510aa37e2bcf501625512e358c3" category="paragraph">Questa sezione fornisce una panoramica dei requisiti per la soluzione di database vettoriale NetApp .</block>
  <block id="1507fd593972e19976a48675eb11483a" category="paragraph">Le configurazioni hardware e software descritte di seguito sono state utilizzate per la maggior parte delle convalide eseguite in questo documento, ad eccezione delle prestazioni.  Queste configurazioni servono come linee guida per aiutarti a configurare il tuo ambiente.  Tuttavia, si prega di notare che i componenti specifici possono variare a seconda delle esigenze individuali del cliente.</block>
  <block id="7e9534170bcf0d2cab4a69e22cdca79c" category="cell">* A800 * ONTAP 9.14.1 * 48 x 3,49 TB SSD-NVM * Due volumi di gruppo flessibili: metadati e dati.  * Il volume NFS dei metadati ha 12 volumi persistenti da 250 GB.  * I dati sono un volume ONTAP NAS S3</block>
  <block id="bcb4d8bb0642dc62c114f2a0a31f5aa3" category="cell">6 x FUJITSU PRIMERGY RX2540 M4</block>
  <block id="891b7b85ad27bcf31f4d6b9d3e5f55eb" category="cell">* 64 CPU * CPU Intel(R) Xeon(R) Gold 6142 a 2,60 GHz * 256 GM di memoria fisica * 1 porta di rete da 100 GbE</block>
  <block id="4515188d6af40c03b16b310778b865c8" category="cell">* 1 x SG100, 3xSGF6024 * 3 x 24 x 7,68 TB</block>
  <block id="e7f07d17d04d9ac60dd3ebc382a1d58b" category="cell">Ammasso di Milvus</block>
  <block id="5c9a77f3be5149b25ef3dd4a0d42f61e" category="cell">* GRAFICO - milvus-4.1.11.  * Versione APP – 2.3.4 * Bundle dipendenti come bookkeeper, zookeeper, pulsar, etcd, proxy, querynode, worker</block>
  <block id="b0654cc6796be715102b69214bddfb52" category="cell">* Cluster K8s a 5 nodi * 1 nodo master e 4 nodi worker * Versione – 1.7.2</block>
  <block id="5b8215321456694f36bc83a178e44856" category="cell">*3.10.12.</block>
  <block id="5a019cf3628ae4961c3ba86198ac5410" category="summary">caso d'uso - soluzione di database vettoriale per NetApp</block>
  <block id="853fb1f37b200090af8f730400a34971" category="paragraph">Questa sezione fornisce una panoramica dei casi d'uso per la soluzione di database vettoriale NetApp .</block>
  <block id="61798ad0c56d51680f77d6b9f4694877" category="paragraph">In questa sezione, discuteremo di due casi d'uso quali Retrieval Augmented Generation con modelli linguistici di grandi dimensioni e NetApp IT chatbot.</block>
  <block id="2b376c37a6f0c2c21b8ba7b62ac86693" category="section-title">Generazione aumentata del recupero (RAG) con modelli linguistici di grandi dimensioni (LLM)</block>
  <block id="6a482cb4a386f8c0b7889b5dc11a997a" category="paragraph">NVIDIA Enterprise RAG LLM Operator è uno strumento utile per implementare RAG in azienda.  Questo operatore può essere utilizzato per distribuire una pipeline RAG completa.  La pipeline RAG può essere personalizzata per utilizzare Milvus o pgvecto come database vettoriale per l'archiviazione degli incorporamenti della knowledge base.  Per i dettagli, fare riferimento alla documentazione.</block>
  <block id="4c1729beb205806fa130c0dbf0364b59" category="paragraph">Figura 1) Enterprise RAG basato su NVIDIA NeMo Microservices e NetApp</block>
  <block id="b14745e6302744b3b3c226e1fdee230a" category="paragraph"><block ref="b14745e6302744b3b3c226e1fdee230a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da66e40722180b5a0466a9ff253976af" category="section-title">Caso d'uso del chatbot IT NetApp</block>
  <block id="497416719429ff96f2462d991f6ea3f8" category="paragraph">Il chatbot di NetApp rappresenta un ulteriore caso d'uso in tempo reale per il database vettoriale.  In questo caso, NetApp Private OpenAI Sandbox fornisce una piattaforma efficace, sicura ed efficiente per la gestione delle query degli utenti interni di NetApp.  Integrando rigorosi protocolli di sicurezza, efficienti sistemi di gestione dei dati e sofisticate capacità di elaborazione dell'intelligenza artificiale, garantisce risposte precise e di alta qualità agli utenti in base ai loro ruoli e responsabilità nell'organizzazione tramite autenticazione SSO.  Questa architettura mette in luce il potenziale dell'unione di tecnologie avanzate per creare sistemi intelligenti e incentrati sull'utente.</block>
  <block id="8afdd8df71939b23b5b37041b4b0e243" category="paragraph"><block ref="8afdd8df71939b23b5b37041b4b0e243" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff2b3d5b17bdfc4a02990dd4115b7d4d" category="paragraph">Il caso d'uso può essere suddiviso in quattro sezioni principali.</block>
  <block id="e21f69fe36aefc844dcebf8fb52262a3" category="section-title">Autenticazione e verifica dell'utente:</block>
  <block id="7457d61423f49fa817953d3c8e0c08cf" category="list-text">Le query degli utenti vengono prima sottoposte al processo NetApp Single Sign-On (SSO) per confermare l'identità dell'utente.</block>
  <block id="3dedad86d8ac55d8b2b034f0ff353ea5" category="list-text">Dopo l'autenticazione avvenuta con successo, il sistema controlla la connessione VPN per garantire una trasmissione sicura dei dati.</block>
  <block id="34ef9101314d114f1bed9a4fc8c13666" category="section-title">Trasmissione ed elaborazione dei dati:</block>
  <block id="e5aa3164f4a76a72d1d074c0285a4d54" category="list-text">Una volta convalidata la VPN, i dati vengono inviati a MariaDB tramite le applicazioni web NetAIChat o NetAICreate.  MariaDB è un sistema di database veloce ed efficiente utilizzato per gestire e archiviare i dati degli utenti.</block>
  <block id="d0d4d700ca2ba3e943833a184fce15db" category="list-text">MariaDB invia quindi le informazioni all'istanza NetApp Azure, che collega i dati dell'utente all'unità di elaborazione AI.</block>
  <block id="b1cbaf6e413b3b5a92538942710197de" category="section-title">Interazione con OpenAI e filtraggio dei contenuti:</block>
  <block id="e7a51c3da456741ac0fe5ae031a539a3" category="list-text">L'istanza di Azure invia le domande dell'utente a un sistema di filtraggio dei contenuti.  Questo sistema pulisce la query e la prepara per l'elaborazione.</block>
  <block id="8449bc1c7d0f0641656072f90d8d06db" category="list-text">L'input ripulito viene quindi inviato al modello base di Azure OpenAI, che genera una risposta in base all'input.</block>
  <block id="ce4abebf9a6d91e3d12d3bd86ebd308f" category="section-title">Generazione e moderazione delle risposte:</block>
  <block id="70ee91d51a5da426448f1ed59462804d" category="list-text">La risposta del modello base viene prima verificata per garantire che sia accurata e soddisfi gli standard di contenuto.</block>
  <block id="40d26f0ba80199b0eaf7b7e0525c7f34" category="list-text">Dopo aver superato il controllo, la risposta viene inviata all'utente.  Questo processo garantisce che l'utente riceva una risposta chiara, accurata e appropriata alla sua domanda.</block>
  <block id="705451e750819c9ce68fb278a7b09839" category="summary">values-xml - soluzione di database vettoriale per NetApp</block>
  <block id="6e6c82b93338e2283cf42123803b79d4" category="doc">Appendice A: Values.yaml</block>
  <block id="42cb737e154e9abe53c3f800eae00d4e" category="paragraph">Questa sezione fornisce un codice YAML di esempio per i valori utilizzati nella soluzione del database vettoriale NetApp .</block>
  <block id="bdcc26240ab0215ba46efad29038278d" category="summary">panoramica della verifica della soluzione - soluzione di database vettoriale per netapp</block>
  <block id="a11dfa705c151f0af3e80cc954126655" category="paragraph">Abbiamo condotto una convalida completa della soluzione incentrata su cinque aree chiave, i cui dettagli sono descritti di seguito.  Ogni sezione approfondisce le sfide affrontate dai clienti, le soluzioni fornite da NetApp e i conseguenti vantaggi per il cliente.</block>
  <block id="748a76b95c3f380357377aefd2ed0474" category="list-text"><block ref="55d7ef09813b4d6fdcb2c5626efe487e" category="inline-link-macro-rx"></block>Le sfide dei clienti per scalare in modo indipendente su storage e calcolo, gestione efficace dell'infrastruttura e gestione dei dati.  In questa sezione, descriviamo in dettaglio il processo di installazione di un cluster Milvus su Kubernetes, utilizzando un controller di archiviazione NetApp sia per i dati del cluster che per i dati dei clienti.</block>
  <block id="e840bff7e1e9715df98e16fead8076cb" category="list-text">link:vector-database-milvus-with-Amazon-FSx ONTAP-for- NetApp- ONTAP.html[Milvus con Amazon FSx ONTAP per NetApp ONTAP – dualità file e oggetto] In questa sezione, spiegheremo perché è necessario distribuire un database vettoriale nel cloud e i passaggi per distribuire un database vettoriale (milvus standalone) in Amazon FSx ONTAP per NetApp ONTAP all'interno di container Docker.</block>
  <block id="6cce3de9e8bf8cabbfe260cc36d61ac3" category="list-text"><block ref="d6b228867818081bf3ee3cecad050baf" category="inline-link-macro-rx"></block>In questa sezione approfondiamo il modo in cui SnapCenter salvaguarda i dati del database vettoriale e i dati Milvus residenti in ONTAP.  Per questo esempio, abbiamo utilizzato un bucket NAS (milvusdbvol1) derivato da un volume NFS ONTAP (vol1) per i dati dei clienti e un volume NFS separato (vectordbpv) per i dati di configurazione del cluster Milvus.</block>
  <block id="918f8a4912d6a98fb31ac7ba46e00ffc" category="list-text"><block ref="f7ba02d22d83dabd12f0465a68c210ea" category="inline-link-macro-rx"></block>In questa sezione, discuteremo dell'importanza del Disaster Recovery (DR) per il database vettoriale e di come il prodotto di Disaster Recovery di NetApp Snapmirror fornisca una soluzione DR per il database vettoriale.</block>
  <block id="2f1a6b813251891cca144a8b91cde4f5" category="list-text"><block ref="9e30995c6d4864b29eb56e92d196baec" category="inline-link-macro-rx"></block>In questa sezione, ci proponiamo di approfondire la convalida delle prestazioni dei database vettoriali, come Milvus e pgvecto.rs, concentrandoci sulle caratteristiche delle prestazioni di storage, come il profilo I/O e il comportamento del controller di storage NetApp a supporto dei carichi di lavoro RAG e di inferenza all'interno del ciclo di vita LLM.  Valuteremo e identificheremo eventuali fattori differenzianti nelle prestazioni quando questi database saranno combinati con la soluzione di archiviazione ONTAP .  La nostra analisi si baserà su indicatori chiave di prestazione, come il numero di query elaborate al secondo (QPS).</block>
  <block id="87c3db9ccf444604c258b88ee8489364" category="summary">verify_data_netapp.py - soluzione di database vettoriale per NetApp</block>
  <block id="599675cccffd45ab676aea932c3fdfbd" category="paragraph">Questa sezione contiene uno script Python di esempio che può essere utilizzato per convalidare il database vettoriale nella soluzione di database vettoriale NetApp .</block>
  <block id="48e4e86482d1e72b17c82feb1e930352" category="doc">Guarda i video sulle soluzioni AI con NetApp</block>
  <block id="a9f5e6dcd1d44f9ba3dc3398020d2404" category="paragraph">Scopri come NetApp potenzia le iniziative di intelligenza artificiale e apprendimento automatico.  Queste playlist video selezionate presentano le soluzioni di intelligenza artificiale NetApp e i flussi di lavoro MLOps, evidenziando strategie di distribuzione, automazione e gestione dei dati per analisi avanzate.</block>
  <block id="145706f4acca44c289ff5ca8cc5b2b86" category="paragraph-title">Soluzioni di intelligenza artificiale NetApp</block>
  <block id="b4bf3d1dd932a4fb0e32b91623652e42" category="inline-link-macro">Guarda la playlist delle soluzioni AI NetApp</block>
  <block id="d3e2da82e7d75fc2a126141e7169de49" category="paragraph">Playlist video completa che copre l'infrastruttura di intelligenza artificiale, i sistemi convergenti e le implementazioni di intelligenza artificiale aziendale.<block ref="af3f91668350fde9b89e361b330e6bf9" category="inline-link-macro-rx"></block></block>
  <block id="07aca6f404d3e6c525bac36328b0d27d" category="paragraph-title">Operazioni di apprendimento automatico (MLOps)</block>
  <block id="aee569e95a8498ede74e68ae8306e6e5" category="inline-link-macro">Guarda la playlist MLOps</block>
  <block id="d41374c7672e6e4fdbfbd6504b672d3c" category="paragraph">Serie di video sui flussi di lavoro MLOps, sulle pipeline di dati e sulle migliori pratiche operative.<block ref="70aea7fc5134cd09b86d7ff27c954117" category="inline-link-macro-rx"></block></block>
  <block id="10b2aec15aae4d935355e27497e66c5f" category="summary">Serie di video e demo che illustrano le funzionalità di molte soluzioni NetApp</block>
  <block id="6354d74cd74c1d9f49224ac4e6209bab" category="doc">Soluzioni NetApp : video e demo</block>
  <block id="60b5065968cf0f66d862a344124f6415" category="paragraph">Panoramica dei video e delle demo che evidenziano le funzionalità specifiche di molte delle soluzioni NetApp.</block>
  <block id="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="list-text"><block ref="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="inline-link-macro-rx"></block></block>
  <block id="895a85fc0a1a565ac547acc1bc9740f3" category="inline-link-macro">MLOps</block>
  <block id="90e97692c42b1eb0ec22c639049d78a1" category="list-text"><block ref="90e97692c42b1eb0ec22c639049d78a1" category="inline-link-macro-rx"></block></block>
  <block id="181a90cd4ce68792d6ce2049bb1ff6ec" category="summary">Registro delle recenti modifiche apportate al materiale collaterale delle soluzioni di intelligenza artificiale NetApp .</block>
  <block id="232dfabf5b2a241a9f7473820c81bf15" category="doc">Novità nelle soluzioni di intelligenza artificiale NetApp</block>
  <block id="be647982bfc8c0837c019b8fdbc711b3" category="paragraph">Scopri le novità nelle soluzioni di intelligenza artificiale.</block>
  <block id="bab52961b58c502c7991d35556c25367" category="section-title">18 agosto 2025</block>
  <block id="47e26e0d5bbeef43c544dd9ae72e66b0" category="inline-link-macro">Famiglia di soluzioni NetApp</block>
  <block id="840125a006aee7dc0e8efd313e7b614e" category="paragraph">Il sito NetApp Solutions è ora il<block ref="f083b096ae581e72c5ab727ef8bd5732" category="inline-link-macro-rx"></block> , che comprende i seguenti siti:</block>
  <block id="e87298059f60b0844dc971f315184cf5" category="list-text">Soluzioni di intelligenza artificiale NetApp</block>
  <block id="9cae574c1dc1ca50a949c1e889637ba7" category="inline-link-macro">Soluzioni container NetApp</block>
  <block id="31d1ae0120af1d791e4320e17eb10687" category="list-text"><block ref="31d1ae0120af1d791e4320e17eb10687" category="inline-link-macro-rx"></block></block>
  <block id="3947417923606d3599bcba7a82f71f1b" category="inline-link-macro">Soluzioni di gestione dei dati NetApp</block>
  <block id="56c054d4bb919790ebe189f7a7d11c3c" category="list-text"><block ref="56c054d4bb919790ebe189f7a7d11c3c" category="inline-link-macro-rx"></block></block>
  <block id="9bb3e58246c5654a6d8e08a7bddd60ec" category="inline-link-macro">Soluzioni di database NetApp</block>
  <block id="3e2420ab1ec1d6e02b32b017d3ba969a" category="list-text"><block ref="3e2420ab1ec1d6e02b32b017d3ba969a" category="inline-link-macro-rx"></block></block>
  <block id="a37049a2a78422ac5627c7987db5c337" category="inline-link-macro">Soluzioni cloud pubbliche e ibride NetApp</block>
  <block id="144417321224efbf0afc2ae665a84a46" category="list-text"><block ref="144417321224efbf0afc2ae665a84a46" category="inline-link-macro-rx"></block></block>
  <block id="2729aba3baa90aaaed37b282e515f6e4" category="inline-link-macro">Soluzioni NetApp per SAP</block>
  <block id="5e056430559fb77ac659dbb71ecce256" category="list-text"><block ref="5e056430559fb77ac659dbb71ecce256" category="inline-link-macro-rx"></block></block>
  <block id="4ead908c2ca3b4c7156e0e703642415d" category="inline-link-macro">Soluzioni di virtualizzazione NetApp</block>
  <block id="3100186c9f62cec85ac05309c5d10217" category="list-text"><block ref="3100186c9f62cec85ac05309c5d10217" category="inline-link-macro-rx"></block></block>
  <block id="fac83ccf1756a0c9cb3b8982d7f17073" category="sidebar">NetApp fornisce soluzioni di intelligenza artificiale complete che combinano gestione dei dati di livello aziendale, architetture di riferimento convalidate e partnership strategiche per accelerare le iniziative di intelligenza artificiale e supportare risultati aziendali critici.  Dall'implementazione dell'infrastruttura all'automazione MLOps, le nostre soluzioni si adattano perfettamente agli ambienti edge, data center e cloud ibrido.</block>
  <block id="be11c74c1dd7f307bb80183a90dc2067" category="sidebar">Iniziare</block>
  <block id="33871b6190a8d5adbe8b15282054766c" category="sidebar">Cosa c'è di nuovo</block>
  <block id="d6b9ea32b921a9f56de32062ba4b94f3" category="sidebar">Blog</block>
  <block id="de42653a3a04e4aefa258105632011d4" category="sidebar">Video e demo</block>
  <block id="0356451dce8be030d34b4cddc51bd023" category="sidebar">Infrastruttura di intelligenza artificiale e sistemi convergenti</block>
  <block id="9547dc55d95184a53ea1a8366b5aeced" category="sidebar">NetApp AIPod con sistemi NVIDIA DGX</block>
  <block id="1f403aa196fd2c94e882669641695d63" category="sidebar">NVIDIA DGX SuperPOD con serie EF</block>
  <block id="ca2b44ea641055fab6c572a1ec645f40" category="sidebar">NetApp AIPod con Lenovo per NVIDIA OVX</block>
  <block id="71194b59e7e6e05cdd5e38686d46dd11" category="sidebar">File system parallelo BeeGFS con E-Series</block>
  <block id="0490c28d4251b3da040883241b9a245b" category="sidebar">Casi d'uso e applicazioni dell'intelligenza artificiale</block>
  <block id="03a2eeb037be2a65352a6ce833a5352d" category="sidebar">AIPod Mini per l'inferenza RAG</block>
  <block id="2a5e8ee0f85321457b5b5051848b33df" category="sidebar">Inferenza AI al limite</block>
  <block id="1f5ef80ba6fe60fcd8fc9b93428724ca" category="sidebar">Soluzioni di database vettoriali</block>
  <block id="1c2e519ac88b24b944e313f1528b25ca" category="sidebar">Carichi di lavoro di guida autonoma</block>
  <block id="1f2d4372bbd3f4944eec91b65eb55b69" category="sidebar">Quantum StorNext con E-Series</block>
  <block id="dd12d2c2197bdac0454f49eaf82efcb1" category="sidebar">MLOps e gestione dei dati</block>
  <block id="55200dead19623a5ed7fd47347cc531d" category="sidebar">MLOps open source con NetApp</block>
  <block id="0fa95f40d436ae4b6b1a848a385c88f5" category="sidebar">MLOps multicloud ibrido con Domino Data Lab</block>
  <block id="ec441b7e7e90b2ae639b5c9784b469f9" category="sidebar">FSx ONTAP per MLOps</block>
  <block id="072e5110aacde0c4952afb7fa86bd5bf" category="sidebar">Soluzioni di intelligenza artificiale per Big Data e cloud ibrido</block>
  <block id="248d62097e51f823fbf1797b8d71b837" category="sidebar">Soluzioni di dati cloud ibride</block>
  <block id="01ba1aebae20e7ddfe20f3ea9572b0a6" category="sidebar">Soluzioni Apache Spark</block>
  <block id="8f0ff6e8178c4e8f4ea0f489063d7586" category="sidebar">Confluent Kafka con storage NetApp ONTAP</block>
  <block id="8e2406d586d4192dc66b85722da1c3b9" category="sidebar">NetApp StorageGRID con Splunk SmartStore</block>
  <block id="76a3eb07a798a5ace45b8500ba2aae19" category="sidebar">Casa sul lago Dremio con storage NetApp</block>
  <block id="e95b75f557af9310f3d9c6299286a533" category="sidebar">Richieste di soluzioni e feedback</block>
  <block id="22d04ecae9fae88d0b8d4548a46a545b" category="sidebar">Richiedi automazione</block>
  <block id="776ab15fef436c9315c14738509d299e" category="sidebar">Proponi una nuova soluzione</block>
  <block id="cfdaac8ef24ac5b2612570c34da00954" category="sidebar">Fornire feedback sulla soluzione</block>
  <block id="9e34d9d231e4cd17fbacda95fb51929b" category="sidebar">Semplifica i tuoi flussi di lavoro AI/ML con le soluzioni complete MLOps e di gestione dei dati di NetApp.  Dalle piattaforme open source agli strumenti di livello aziendale, le nostre soluzioni consentono uno sviluppo, una distribuzione e un ridimensionamento efficienti dei modelli in ambienti cloud ibridi, garantendo al contempo coerenza e prestazioni dei dati.</block>
  <block id="e212a74da744d81b7be22fde8837f469" category="sidebar">Soluzioni NetApp MLOps e di gestione dei dati</block>
  <block id="7c9c1738224214245dd19322f112f008" category="sidebar">Piattaforme MLOps open source</block>
  <block id="8225e12837234b91ab0ddcd265042318" category="sidebar">Configurazione NetApp Trident per AIPod</block>
  <block id="8b4f0b6bb6bc359f491be13c6d4217c4" category="sidebar">Distribuzione e integrazione di Apache Airflow</block>
  <block id="948fee9aa5251e39df94d1c32d0c25cf" category="sidebar">Distribuzione di JupyterHub e operazioni sui dati</block>
  <block id="73cee63b0ef47212c43598d623b858e0" category="sidebar">Distribuzione e tracciabilità di MLflow</block>
  <block id="938ff6f66cfc08077aee20a94cb3555a" category="sidebar">Flussi di lavoro MLOps avanzati</block>
  <block id="e037812c032cd0d9c22b13bc85e9e8b0" category="sidebar">Distribuzione e notebook di Kubeflow</block>
  <block id="3ff4473b7f6cd29fd2f032383a101ad3" category="sidebar">Addestrare modelli di riconoscimento delle immagini con Kubeflow</block>
  <block id="4d72e4ce52deedeed5378320bb10ba60" category="sidebar">Esecuzione del carico di lavoro AI a nodo singolo</block>
  <block id="d4090ff0c5d6e77994fe88d878931a09" category="sidebar">Esecuzione del carico di lavoro di intelligenza artificiale distribuita</block>
  <block id="6d49da972d2b3e8021183d3dd882efc3" category="sidebar">Inserimento dati con SnapMirror</block>
  <block id="13c4fd018be37b2e07ac1e3c7bf940da" category="sidebar">Soluzioni MLOps aziendali</block>
  <block id="bf57be3e9bf09ff89214bcab0ffcd37f" category="sidebar">MLOps ibridi con Domino Data Lab</block>
  <block id="5a938de20177e2b1dcb267d6d7b4f069" category="sidebar">Accesso ai dati tra ambienti con Domino</block>
  <block id="86c9440e933f2848898cd3a50e0d30c5" category="sidebar">Integrazione del software NVIDIA NGC</block>
  <block id="e9eb61f514f368f5d8d0cf3ccfded4f9" category="sidebar">Integrazione tra Cloud MLOps e AWS</block>
  <block id="b9a33eec860aee8b042190248e9c0978" category="sidebar">Amazon FSx per ONTAP MLOps</block>
  <block id="19f22745fb509faf9a35f2999167b4b3" category="sidebar">Integrare FSx ONTAP come S3 privato in SageMaker</block>
  <block id="958182d4c4d2fbecef5e794dd36a2fcd" category="sidebar">FSx ONTAP per l'addestramento del modello SageMaker</block>
  <block id="765bac8adf0ce0c27f43291f5f38e36e" category="sidebar">Crea una pipeline MLOps semplificata con FSx</block>
  <block id="cff078ffafce4368253406707fe938e2" category="sidebar">Database vettoriali e applicazioni di intelligenza artificiale</block>
  <block id="8817647abcdf406ecb3f743ce1f4d0c3" category="sidebar">Soluzione di database vettoriale con NetApp</block>
  <block id="eac46f1424b8a5f784861bfb337632d5" category="sidebar">Configurazione del cluster Milvus con Kubernetes</block>
  <block id="e557c94c22c1c941bd40b8277f7f7753" category="sidebar">Protezione del database vettoriale con SnapCenter</block>
  <block id="ba5dd0875f60bb8bfd1c4511266f65f1" category="sidebar">Validazione delle prestazioni del database vettoriale</block>
  <block id="8d80ba264d116b7cc3e458ba8697ce83" category="sidebar">Casi d'uso del database vettoriale</block>
  <block id="e90bb805ac6728252476dc4b6c9f33b8" category="sidebar">Strumenti di gestione e archiviazione dei dati</block>
  <block id="8825002f133fae0b139e8325ac7730cf" category="sidebar">Data lake StorageGRID per la guida autonoma</block>
  <block id="bf25ffbc01db3077dbf625f1f66b0b81" category="sidebar">Ripristino di emergenza con SnapMirror</block>
  <block id="1e87a0e6a353196e3d5d6cd2e73a3e6e" category="sidebar">Distribuisci un'infrastruttura di intelligenza artificiale pronta per l'uso aziendale con le architetture di riferimento convalidate e i sistemi convergenti di NetApp.  Dalle soluzioni NetApp AIPod alle piattaforme di storage ad alte prestazioni, i nostri progetti offrono le prestazioni, la scalabilità e l'affidabilità necessarie per i carichi di lavoro AI/ML più impegnativi.</block>
  <block id="994ec7a86f72507f5352d2b180d45f33" category="sidebar">Infrastruttura AI NetApp e sistemi convergenti</block>
  <block id="1c869286ed71535693a9462972519af4" category="sidebar">Architetture di riferimento NetApp AIPod</block>
  <block id="b4f767e2f090ec487aa796e06a450c3b" category="sidebar">Architettura AIPod</block>
  <block id="b6c79f2c0318b6d7625fb67322575ef8" category="sidebar">Dettagli sulla distribuzione AIPod</block>
  <block id="8c660d55cc308e8a0142574e6cb06bb2" category="sidebar">Guida alla convalida e al dimensionamento AIPod</block>
  <block id="f5a73cfaecb9184b2e8146ed455050a9" category="sidebar">Archiviazione ad alte prestazioni per carichi di lavoro di intelligenza artificiale</block>
  <block id="dca52c3c8e9f73ebf5e2f52c01c943af" category="sidebar">NVIDIA DGX SuperPOD con storage serie EF</block>
  <block id="0cdb4340f983739886aeeabf55ded9a0" category="sidebar">IBM Spectrum Scale con storage E-Series</block>
  <block id="103956252a2179a2f41c37f503662e57" category="sidebar">NetApp ONTAP con Lenovo ThinkSystem</block>
  <block id="e5a53cbbfd61be59509da2fb28b87bd6" category="sidebar">Esplora le implementazioni di intelligenza artificiale nel mondo reale con le soluzioni NetApp , dai sistemi RAG aziendali e dall'inferenza edge alle pratiche di intelligenza artificiale responsabili e alle strategie di migrazione dei dati.  Questi casi d'uso dimostrano come NetApp consente alle organizzazioni di distribuire applicazioni di intelligenza artificiale in ambienti diversi, mantenendo al contempo sicurezza, prestazioni e scalabilità.</block>
  <block id="7438b9f1311e240ca42a988e9d13e00c" category="sidebar">Casi d'uso e applicazioni di intelligenza artificiale NetApp</block>
  <block id="f5d80fd5b29670f59fa900f8c07fb329" category="sidebar">Esplora le implementazioni di intelligenza artificiale nel mondo reale con le soluzioni NetApp , dai sistemi RAG aziendali e dall'inferenza edge alle pratiche di intelligenza artificiale responsabili e alle strategie di migrazione dei dati.  Questi casi d'uso dimostrano come NetApp consenta l'utilizzo di applicazioni di intelligenza artificiale in ambienti diversi, mantenendo al contempo sicurezza, prestazioni e scalabilità.</block>
  <block id="0d6f02845b71bc324cd82a725369e788" category="sidebar">Applicazioni e casi d'uso dell'intelligenza artificiale aziendale</block>
  <block id="a67b9cee4655d6177295261e4bcd604d" category="sidebar">NetApp AIPod Mini per RAG aziendale</block>
  <block id="f5d3d706e83df8136ffa361f6bf3de44" category="sidebar">Intelligenza artificiale generativa e valore NetApp</block>
  <block id="e2c8fd379213f568475a9fd8d939677a" category="sidebar">Inferenza AI Edge con NetApp e Lenovo</block>
  <block id="7625f6572992d4d6884af97bd58e8555" category="sidebar">Dall'analisi dei Big Data alla migrazione dell'IA</block>
  <block id="58f52c07cacafd13bf7c2b75bd52297b" category="sidebar">IA responsabile</block>
  <block id="726a429bb7d3cf42471e4ef6d5064f39" category="sidebar">Intelligenza artificiale responsabile con la trasformazione delle immagini di Protopia</block>
  <block id="9aadc819040333a6a70c083f60934127" category="sidebar">Soluzioni di archiviazione e infrastruttura AI</block>
  <block id="4ec66dae70419b5536af92b7e6af12eb" category="sidebar">Progetta Quantum StorNext con sistemi E-Series</block>
  <block id="fdc9cddf0d9dda4d36a935baaa555437" category="sidebar">Distribuisci Quantum StorNext con i sistemi E-Series</block>
  <block id="2107e3f2176d1159c57518d8100b979c" category="sidebar">Trasforma la tua infrastruttura di analisi dei dati con le soluzioni comprovate di NetApp per carichi di lavoro Big Data, tra cui Apache Spark, Hadoop, Kafka e le moderne architetture di data lake che si estendono dall'edge al cloud.</block>
  <block id="a4c306bc134438ffdcde3dc25d141930" category="sidebar">Soluzioni di analisi dei dati moderne NetApp</block>
  <block id="f6d439e305ff0317b08aeaad65bc202c" category="sidebar">Le moderne soluzioni di analisi dei dati NetApp sono un insieme di capacità strategiche e tecnologiche che dimostrano le potenzialità dello storage NetApp nell'ambito dell'intelligenza artificiale.</block>
  <block id="0c5c9c87a184244b0a7327aaef882e8e" category="sidebar">Soluzioni Apache Kafka</block>
  <block id="7d576967253ca2f566f9693183407367" category="sidebar">Carichi di lavoro Apache Kafka con storage NetApp NFS</block>
  <block id="b98ea9630b58bea0f022799ecefe4062" category="sidebar">Confluent Kafka con controller di archiviazione NetApp ONTAP</block>
  <block id="7f8513139888dda0c0ecb82a93548af9" category="sidebar">Le migliori pratiche per Confluent Kafka</block>
  <block id="c9adcd46dfe28ab240bf984f9da39535" category="sidebar">Convalida delle prestazioni di Kafka con AWS</block>
  <block id="c6dc54040e7551a25c7f14dd83a3ca37" category="sidebar">Soluzioni Apache Spark e Hadoop</block>
  <block id="75b5d408998484e1ea5a4ce3cc432cbe" category="sidebar">Soluzioni di storage NetApp per Apache Spark</block>
  <block id="d2e5b5510723b29c7f85a6f53b0b30fe" category="sidebar">Distribuisci il carico di lavoro Apache Spark con lo storage NetApp</block>
  <block id="d142861488d42c2de042afc4375049da" category="sidebar">Soluzioni di dati cloud ibride NetApp per Spark e Hadoop</block>
  <block id="15b1a623b46c0553eb7e0a02392de6f9" category="sidebar">Casi d'uso e architetture</block>
  <block id="7bbc21a3294c0070a8663140370d1f39" category="sidebar">Risultati dei test di Apache Spark</block>
  <block id="8b809555e7e0cd658f51306db399d338" category="sidebar">Gestione dei dati nel cloud e intelligenza artificiale</block>
  <block id="1d2114df6a9f8f5d7e8f597e9c70a6c1" category="sidebar">Gestione dei dati nel cloud con la dualità file-oggetto NetApp e AWS SageMaker</block>
  <block id="4f25c5c9b33cc2f12b098bd8cc026222" category="sidebar">Analisi dei Big Data: dati per l'intelligenza artificiale</block>
  <block id="55cd26df7471de5ffbc83646a94fddbb" category="sidebar">Amazon FSx for NetApp ONTAP per MLOps</block>
  <block id="2a15fc3906339e08c458c8e62e447da3" category="sidebar">Soluzione cloud ibrida Apache Spark</block>
  <block id="e0afb7c0b35ca1c50d576d490c1f6f83" category="sidebar">Piattaforme di analisi e data lake moderne</block>
  <block id="2f8caf1cb27d10780daee2d12dfe6cf5" category="sidebar">La soluzione ibrida iceberg lakehouse di nuova generazione di NetApp e Dremio</block>
  <block id="5e3dc34b61f6a21ffd6549ee40d4631b" category="sidebar">NetApp E-Series E5700 e Splunk Enterprise</block>
  <block id="8cd58c89ff3d51a256ecfe3fe8bab20f" category="sidebar">Risorse aggiuntive</block>
  <block id="7cc3c71ee2fdbff1fd2efbfcded89f90" category="sidebar">Soluzioni diverse per strategie di analisi diverse</block>
  <block id="8598954d073301b356199d49f5c02a69" category="sidebar">Blog: Apache Spark gioca nel NetApp Data Analytics Playground</block>
  <block id="0795007b8521bf374f9ddd4eb68a4a2b" category="sidebar">Blog: utilizzare XCP per la migrazione dei dati da un Data Lake e HPC a ONTAP NFS</block>
  <block id="c254d48fc85fff80674335af647fc2d3" category="sidebar">NetApp TV: playlist di analisi dei Big Data</block>
  <block id="5baf6ec1129c513e42641878b72ed0d8" category="sidebar">Soluzioni di intelligenza artificiale</block>
  <block id="554cfab3938e21d9270bd6b75931f96f" category="sidebar">Video</block>
  <block id="45552f1d8df5302f6b20a45bdca4873c" category="sidebar">Configurazione NetApp Trident</block>
  <block id="629606c7cd29d3a21eb21c6ac5139f33" category="sidebar">Backend Trident per distribuzioni AIPod</block>
  <block id="6c7cb31582a28a42e762b2046a1ce896" category="sidebar">Kubernetes StorageClasses per distribuzioni AIPod</block>
  <block id="d9fd1af737bab40d222131485c9bb808" category="sidebar">Distribuzione di Apache Airflow</block>
  <block id="17f2e89c743299170fd62138fa80d495" category="sidebar">Distribuzione di JupyterHub</block>
  <block id="471efd78e003975a601bfbdaf70136d2" category="sidebar">Acquisizione dati con NetApp SnapMirror</block>
  <block id="7d6f6d1bc3093617ee4703c5e520774b" category="sidebar">Distribuzione MLflow</block>
  <block id="7174f04026f1e5e87367c72c1c073824" category="sidebar">Tracciabilità dal set di dati al modello con NetApp e MLflow</block>
  <block id="a38d89f197f605418a88b686e0175fa2" category="sidebar">Distribuzione di Kubeflow</block>
  <block id="b540e10006be068e5e5fd93d05b7b12c" category="sidebar">Fornire l'area di lavoro Jupyter Notebook</block>
  <block id="e8816281bfd02443de2002db66789462" category="sidebar">Addestrare un modello di riconoscimento delle immagini - esempio di flusso di lavoro</block>
  <block id="4c71560715665aa3108585868c989cdc" category="sidebar">Esempio di operazioni Trident</block>
  <block id="1c6a3a6b23e40077c58b45d05d4d411f" category="sidebar">Esempi di lavori ad alte prestazioni per distribuzioni AIPod</block>
  <block id="dcdebd18dbab6da6d511c220479f6460" category="sidebar">Eseguire un carico di lavoro AI a nodo singolo</block>
  <block id="98053e2b2531af18e4f885fb8a731327" category="sidebar">Eseguire un carico di lavoro di intelligenza artificiale distribuito sincrono</block>
  <block id="7406ea045ac944a9db15b50dba8cc04b" category="sidebar">MLOps ibridi con Domino Data Lab e NetApp</block>
  <block id="1231369e1218613623e1b520c27ce190" category="sidebar">Configurazione iniziale</block>
  <block id="e5726f3da1ad0304974cf103e75da470" category="sidebar">Esporre i volumi NetApp esistenti a Domino</block>
  <block id="f62030848d7cb177a11eb3916356bb29" category="sidebar">Accedi agli stessi dati in ambienti diversi</block>
  <block id="0f68b904e33d9ac04605aecc958bcf52" category="sidebar">Informazioni aggiuntive</block>
  <block id="f4c44872f09acb0f4e8f90890004d4ab" category="sidebar">Utilizzare il software NVIDIA NGC</block>
  <block id="a12d6a26832d73816bca1235e9f4d8a1" category="sidebar">Esempio di caso d'uso - TensorFlow Training Job</block>
  <block id="0975e7e38dac95fd7ce3d2e3966e26be" category="sidebar">Parte 1 - Integrare Amazon FSx for NetApp ONTAP come bucket S3 privato in AWS SageMaker</block>
  <block id="b675f3bab2742c1723ed556f8535349d" category="sidebar">Parte 2 - Sfruttare Amazon FSx for NetApp ONTAP come fonte dati per l'addestramento del modello in SageMaker</block>
  <block id="7609ccc24e4c12c32d0ad617fe91161e" category="sidebar">Parte 3 - Creare una pipeline MLOps semplificata</block>
  <block id="c79bd5ac7ebc0eae5588b9ad529a380f" category="sidebar">NetApp StorageGRID Data Lake per carichi di lavoro di guida autonoma</block>
  <block id="a20ee4ebc8e6614143815c881916cbba" category="sidebar">Soluzione di database vettoriale con NetApp</block>
  <block id="e5df4bbe7b124f2fe5398d42696d57b3" category="sidebar">Database vettoriale</block>
  <block id="9934c7eb2c2161e05fedd3b280e4eedc" category="sidebar">Requisito tecnologico</block>
  <block id="951de808fb87ba9bc035ce3cf467b064" category="sidebar">Protezione del database vettoriale tramite SnapCenter</block>
  <block id="f0a132dd5ea90d189f80995d831f9b91" category="sidebar">Ripristino di emergenza tramite SnapMirror</block>
  <block id="e813a53d42d6bfe69e6907df9b0675d5" category="sidebar">Database vettoriale con Instaclustr utilizzando PostGreSQL: pgvector</block>
  <block id="7fad254d8199fbf6d695e96590444cff" category="sidebar">Appendice B: prepare_data_netapp_new_py</block>
  <block id="4d4989117d6e4f26e57cc7135af8f508" category="sidebar">Appendice D: docker_compose.yml</block>
  <block id="46aa0a2ad138d7cd72baea1b2f96553c" category="sidebar">infrastrutture convergenti di intelligenza artificiale</block>
  <block id="503011292be147bd4172e92de477a75e" category="sidebar">NVA-1173 NetApp AIPod con sistemi NVIDIA DGX</block>
  <block id="34df2039718349f1b8c838bff98ae8fa" category="sidebar">Componenti hardware</block>
  <block id="7d19d593db0bb056876a9535cbced90a" category="sidebar">Componenti software</block>
  <block id="aee745c6de04f3d08c0e628809cab1e7" category="sidebar">Esempio di dettagli di distribuzione</block>
  <block id="56d2d7506e6dac3733b0a45a9eaf441d" category="sidebar">Guida alla convalida e al dimensionamento</block>
  <block id="db182982505626c6e79adca149851ca6" category="sidebar">Conclusione e informazioni aggiuntive</block>
  <block id="013e704990294f0b327123a61911f4cc" category="sidebar">NVIDIA DGX SuperPOD con NetApp EF-Series</block>
  <block id="944c042dcc47f293062f941954082ceb" category="sidebar">BeeGFS su NetApp con storage E-Series</block>
  <block id="9af29e4b3d0045c948a7dd30b1c7f8ae" category="sidebar">Distribuisci IBM Spectrum Scale con storage E-Series</block>
  <block id="79bca636cb614580cfd2da67b668570e" category="sidebar">ONTAP e Lenovo ThinkSystem per l'intelligenza artificiale</block>
  <block id="7e9b2db694c8b0a87a271e7085251d0e" category="sidebar">NetApp ONTAP e Lenovo ThinkSystem SR670 per l'intelligenza artificiale</block>
  <block id="b669bc138f2f455218d4dce65e4693b4" category="sidebar">Casi d'uso dell'intelligenza artificiale</block>
  <block id="adb8741d27ea996906508affc4dfbc75" category="sidebar">NetApp AIPod Mini per l'inferenza RAG</block>
  <block id="c94ba9961c97321b49a2f0af40a3c81b" category="sidebar">Intelligenza artificiale responsabile e inferenza riservata: intelligenza artificiale NetApp con trasformazione delle immagini Protopia</block>
  <block id="549d044fec039c71abf82f76a0d7969c" category="sidebar">Spostamento dei dati da un ambiente Big Data a un ambiente AI</block>
  <block id="18e04180e0442e18a559941bb8de310c" category="sidebar">Inferenza AI all'Edge - NetApp con Lenovo ThinkSystem - Progettazione della soluzione</block>
  <block id="df901f2197cd86d62a25f2f43e523352" category="sidebar">Guida alla progettazione dei sistemi Quantum StorNext con NetApp E-Series</block>
  <block id="e313734313e7ef573613df8b6edae0af" category="sidebar">Guida all'implementazione dei sistemi Quantum StorNext con NetApp E-Series</block>
  <block id="78daadab78234c06769e4f331411d302" category="sidebar">Analisi dei dati moderna</block>
  <block id="a5428e6b4b42638886ab5870a883efb9" category="sidebar">Soluzione NetApp per un problema di rinomina inutile nel carico di lavoro NFS in Kafka</block>
  <block id="d7fd58c27a131209e8f320d109b293cc" category="sidebar">Panoramica e convalida delle prestazioni in AWS - Cloud Volume ONTAP</block>
  <block id="076002e1839cd6d440e56b26850e1223" category="sidebar">Panoramica e convalida delle prestazioni in AWS - FSx per NetApp ONTAP</block>
  <block id="0d7c7eeec9388fceaff3d06e03b45fe9" category="sidebar">Panoramica e convalida delle prestazioni con AFF on-premises</block>
  <block id="2835924be4bc657cfe3a5bd988b96845" category="sidebar">Validazione delle prestazioni confluenti</block>
  <block id="2ce0710320aace7b17c3af20eaac2918" category="sidebar">Riepilogo dei casi d'uso</block>
  <block id="713522228cb3164cc6e71ff6d49c3b13" category="sidebar">GPFS a NFS - Passaggi dettagliati</block>
  <block id="497da8ae75854ffd62dc59e332c15252" category="sidebar">Cluster confluenti auto-riequilibranti</block>
  <block id="c9f0818cde41901681a02b50763ec342" category="sidebar">Soluzioni di dati cloud ibride NetApp : Spark e Hadoop basate sui casi d'uso dei clienti</block>
  <block id="924f605d39858bdb10692c8d8f810464" category="sidebar">Caso d'uso 1 - Backup dei dati Hadoop</block>
  <block id="c028df954696d2e4011963e651237b7c" category="sidebar">Caso d'uso 2: backup e ripristino di emergenza dal cloud all'ambiente locale</block>
  <block id="f1ab9c16fee4088d930b2a43e3d48f64" category="sidebar">Caso d'uso 3: abilitazione di DevTest sui dati Hadoop esistenti</block>
  <block id="4e7c79467b7b25f0415a3a4538d3e2f5" category="sidebar">Caso d'uso 4 - Protezione dei dati e connettività multicloud</block>
  <block id="f38bc790ec57f948f20cbd270b996cc6" category="sidebar">Caso d'uso 5 - Accelerare i carichi di lavoro analitici</block>
  <block id="2c1c3f6b0e9a17650f389f1aab405e8a" category="sidebar">Soluzione ibrida Iceberg Lakehouse di nuova generazione di NetApp e Dremio</block>
  <block id="1256c51dea275f8f002d62c89274c4dc" category="sidebar">Casi d'uso dei clienti</block>
  <block id="df6654a22cda1b94cf0f51d6ae94bb69" category="sidebar">Soluzioni diverse per diverse strategie di analisi - Breve descrizione della soluzione</block>
  <block id="2b95dd053e967c99de1428e8953dd453" category="sidebar">Funzionalità StorageGRID per Splunk SmartStore</block>
  <block id="42c2f45afefbd5150f5aa52986b2a3cc" category="sidebar">Tiering e risparmio sui costi</block>
  <block id="039a70e0c8e34414c8b3f34333f95ca8" category="sidebar">Prestazioni SmartStore per sito singolo</block>
  <block id="427d072a2c1690c6d9ece23bef05477b" category="sidebar">Apache Spark Workload con soluzione di storage NetApp (Guida alla distribuzione)</block>
  <block id="22f22b60e3e496fa07e67cfbf53cb70e" category="cell">RPL-E 6369P IP 8C/16T 3.3G 24MB 95W 1700 BO</block>
  <block id="fe1394c0024b947430d8383108eb2177" category="summary">NVIDIA DGX SuperPOD con NetApp AFF A90</block>
  <block id="bf8899c5267692573fb1304655fb765a" category="doc">Sistemi di storage NetApp AFF A90 con NVIDIA DGX SuperPOD</block>
  <block id="7fa0ca2a0d7f53f3c8e59fc6c3e9ed2e" category="section-title">Dispiegamento NVA</block>
  <block id="8be806d9daf2bc32156e83bc0d005ec1" category="paragraph">I sistemi di storage NVIDIA DGX SuperPOD con NetApp AFF A90 combinano le prestazioni di elaborazione di livello mondiale dei sistemi NVIDIA DGX con i sistemi di storage NetApp connessi al cloud per abilitare flussi di lavoro basati sui dati per l'apprendimento automatico (ML), l'intelligenza artificiale (AI) e il calcolo tecnico ad alte prestazioni (HPC).  Questo documento descrive i dettagli di configurazione e distribuzione per l'integrazione dei sistemi di storage AFF A90 nell'architettura DGX SuperPOD.</block>
  <block id="9b418007fd18dc2176e46adcd30db45f" category="inline-image-macro">Logo nvidia</block>
  <block id="c94ba3511d0db1d6babbf53090c19530" category="paragraph"><block ref="c94ba3511d0db1d6babbf53090c19530" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6091ca16495cdce90805252a1c12f4e6" category="section-title">Riepilogo del programma</block>
  <block id="c6f9b4ccfaf7da44e6c0c60854f0949d" category="paragraph">NVIDIA DGX SuperPOD™ offre una soluzione di data center AI chiavi in ​​mano per le organizzazioni, offrendo senza soluzione di continuità elaborazione, strumenti software, competenze e innovazione continua di livello mondiale.  DGX SuperPOD offre ai clienti tutto ciò di cui hanno bisogno per distribuire carichi di lavoro AI/ML e HPC con tempi di configurazione minimi e massima produttività.  La figura 1 mostra i componenti di alto livello di DGX SuperPOD.</block>
  <block id="d144add61531a9bfe79e667824356b40" category="paragraph">Figura 1) NVIDIA DGX SuperPOD con sistemi di storage NetApp AFF A90 .</block>
  <block id="bbd4822469057d9beafe8509a7ebee14" category="paragraph"><block ref="bbd4822469057d9beafe8509a7ebee14" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283d31c0198ed7454a249b3e2b6eb174" category="paragraph">DGX SuperPOD offre i seguenti vantaggi:</block>
  <block id="3ff8aa027f2fe1f296899270ebbb43fd" category="list-text">Prestazioni comprovate per carichi di lavoro AI/ML e HPC</block>
  <block id="ca127ea10cbbac4cda1fefa3e946e9ba" category="list-text">Stack hardware e software integrato, dalla gestione e monitoraggio dell'infrastruttura ai modelli e strumenti di deep learning predefiniti.</block>
  <block id="a4cb23a9ac5d711552fe29021242bf26" category="list-text">Servizi dedicati, dall'installazione e gestione dell'infrastruttura al ridimensionamento dei carichi di lavoro e alla semplificazione dell'intelligenza artificiale di produzione.</block>
  <block id="96cffe8fd08355ee862ba83cb15407d9" category="paragraph">Con l'adozione da parte delle organizzazioni di iniziative di intelligenza artificiale (IA) e apprendimento automatico (ML), la domanda di soluzioni infrastrutturali solide, scalabili ed efficienti non è mai stata così elevata.  Al centro di queste iniziative c'è la sfida di gestire e addestrare modelli di intelligenza artificiale sempre più complessi, garantendo al contempo la sicurezza dei dati, l'accessibilità e l'ottimizzazione delle risorse. </block>
  <block id="61b865c697c4f21886d14a618df70f6d" category="paragraph">Questa soluzione offre i seguenti vantaggi chiave:</block>
  <block id="aa88ccfa825dadd9cbb9acc84e508b2c" category="list-text">*Scalabilità*</block>
  <block id="4738ea23a01f5635ce1c45dabb47da5c" category="list-text">*Gestione e accesso ai dati*</block>
  <block id="1e1fe2d30ed5bb9c5276dddb65f4ce65" category="list-text">*Sicurezza*</block>
  <block id="3c858853158f1a99c39a781718ec762c" category="inline-link">GUIDA ALLA PROGETTAZIONE NVA-1175</block>
  <block id="bc3456dcc61fc69ddf5057eb2521a503" category="inline-link">+++ Architettura di riferimento NVIDIA DGX SuperPOD +++</block>
  <block id="0db7341d4a6ac5f5ae439217ea22f2cf" category="paragraph">NVIDIA DGX SuperPOD include i server, la rete e lo storage necessari per garantire prestazioni comprovate per carichi di lavoro di intelligenza artificiale impegnativi.  I sistemi NVIDIA DGX™ H200 e B200 offrono una potenza di elaborazione di livello mondiale, mentre gli switch di rete NVIDIA Quantum InfiniBand e Spectrum™ Ethernet garantiscono una latenza estremamente bassa e prestazioni di rete leader del settore.  Grazie all'aggiunta delle funzionalità di gestione dei dati e delle prestazioni leader del settore dello storage NetApp ONTAP , i clienti possono realizzare iniziative di intelligenza artificiale/apprendimento automatico più rapidamente e con meno migrazione dei dati e spese amministrative.  Per maggiori informazioni sui componenti specifici di questa soluzione, fare riferimento a<block ref="a5c1176c129a896b2b922e5580efc58f" category="inline-link-rx"></block> E<block ref="1910ffa640b224c818fe3ba99c94129a" category="inline-link-rx"></block> documentazione.</block>
  <block id="c18232c17d0f8ffeae2d726834c91f89" category="paragraph">NVIDIA DGX SuperPOD è progettato per soddisfare i requisiti di prestazioni e scalabilità dei carichi di lavoro più impegnativi.</block>
  <block id="36ff5f6df178e197d3123e478db8410b" category="list-text">Apprendimento automatico su larga scala mediante strumenti di analisi tradizionali.</block>
  <block id="2d12f254287ce40df1f66968734498ba" category="list-text">Formazione di modelli di intelligenza artificiale per modelli linguistici di grandi dimensioni, classificazione di immagini/visione artificiale, rilevamento di frodi e innumerevoli altri casi d'uso.</block>
  <block id="d8f31668d0cecb0b54a6d01e2f76c6cf" category="list-text">Calcolo ad alte prestazioni, come analisi sismica, fluidodinamica computazionale e visualizzazione su larga scala.</block>
  <block id="f0414b39a05dd4079562350e267bf1b3" category="inline-link">+++ Architettura di riferimento NVIDIA DGX SuperPOD +++</block>
  <block id="5f5d88c3d3b4a5616e3937b4fe349866" category="paragraph">DGX SuperPOD si basa sul concetto di unità scalabile (SU) che include tutti i componenti necessari per fornire la connettività e le prestazioni richieste ed eliminare eventuali colli di bottiglia nell'infrastruttura.  I clienti possono iniziare con una o più SU e aggiungerne altre in base alle proprie esigenze.  Per maggiori informazioni si prega di fare riferimento al<block ref="b3bda9bcc3402290297547b224b66efa" category="inline-link-rx"></block> .  Questo documento descrive i componenti di archiviazione e la configurazione per una singola SU.</block>
  <block id="353fc344c9bee691edbf50c13067653c" category="paragraph">Nella tabella 1 sono elencati i componenti hardware necessari per implementare i componenti di archiviazione per 1SU.  Per informazioni specifiche sulle parti e sulle quantità per 1-4 unità scalabili, fare riferimento all'Appendice A.</block>
  <block id="6cef63cf1d59b401d88755cbea01a416" category="paragraph">Tabella 1) Requisiti hardware.</block>
  <block id="46f0306a597ab13c222e7d6551ce9f96" category="cell">Sistema di archiviazione NetApp AFF A90</block>
  <block id="c28cb49992003622546cc5f9509cfcff" category="cell">Switch di interconnessione del cluster di storage NetApp</block>
  <block id="9097f0013a59ba655e2c83bd26ae1ce7" category="cell">NVIDIA 800 GB -&gt; 4 cavi splitter da 200 GB</block>
  <block id="aec453803363ab0e5ca6f6df8d465def" category="inline-link">+++Note di rilascio DGX SuperPOD+++</block>
  <block id="b6ffed0f516d3b52a4910321a2a889ba" category="paragraph">Nella Tabella 2 sono elencati i componenti software minimi e le versioni necessarie per integrare il sistema di archiviazione AFF A90 con DGX SuperPOD.  DGX SuperPOD comprende anche altri componenti software non elencati qui.  Si prega di fare riferimento al<block ref="2523a697ed64d9038adf903273ea5150" category="inline-link-rx"></block> per maggiori dettagli.</block>
  <block id="c50cf4cacfaa91c82ab6a24e939cbaca" category="paragraph">Tabella 2) Requisiti software.</block>
  <block id="518f98e82df6bde3bef11b7aa885a289" category="cell">9.16.1 o superiore</block>
  <block id="df6c5bc905afa2504396faf036b87927" category="cell">NVIDIA BaseCommand Manager</block>
  <block id="6fe49606da6092b118e02ef2d0ef0d6c" category="cell">10.24.11 o superiore</block>
  <block id="a62649c559be1634e22dd7df0b58ad32" category="cell">Sistema operativo NVIDIA DGX</block>
  <block id="ba2b41c4ccfe23325bd590218a62fa8a" category="cell">6.3.1 o superiore</block>
  <block id="be49cc02b8372e6202cf52fbe8204ead" category="cell">Driver NVIDIA OFED</block>
  <block id="cf439b0da4b623c11f90db3c956758b1" category="cell">MLNX_OFED_LINUX-23.10.3.2.0 LTS o superiore</block>
  <block id="c220bcc9beaaaf29d1905f9819577f0b" category="cell">Sistema operativo NVIDIA Cumulus</block>
  <block id="f7bfb037c565dcf0f80631851ee87307" category="cell">5.10 o superiore</block>
  <block id="ea1eee49815915fc6500c0bfc1fcef31" category="paragraph">L'integrazione dello storage NetApp ONTAP con DGX SuperPOD comporta le seguenti attività:</block>
  <block id="dc8a828d28f4f811808cdb82b54453ec" category="list-text">Configurazione di rete per sistemi di storage NetApp AFF A90 con RoCE</block>
  <block id="37c6bfb67043d31447903c4665d6ed11" category="list-text">Installazione e configurazione del sistema di archiviazione</block>
  <block id="4cafd7b33984b4cb34f95fe4314e4a49" category="list-text">Configurazione del client DGX con NVIDIA Base Command™ Manager</block>
  <block id="b8088d3f2b3972d6f986cf0a37543617" category="section-title">Preparazione del sito e installazione di base</block>
  <block id="bf0615788eed920e4e9f1a96749cfb34" category="inline-link">+++ Documentazione di installazione hardware AFF A90 +++</block>
  <block id="e1006e935ca66a5f59a3fd40689fff46" category="paragraph">La preparazione del sito e l'installazione di base del cluster di storage AFF A90 saranno eseguite da NetApp Professional Services per tutte le distribuzioni DGX SuperPOD come parte del servizio di distribuzione standard.  NetApp PS confermerà che le condizioni del sito sono idonee per l'installazione e installerà l'hardware nei rack designati.  Collegheranno inoltre le connessioni di rete OOB e completeranno la configurazione di base del cluster utilizzando le informazioni di rete fornite dal cliente.  Appendice A – Distinta base e quote dei rack include le quote standard dei rack come riferimento.  Per maggiori informazioni sull'installazione dell'A90 fare riferimento al<block ref="7ddd605a062e7b77012eccf1c4bcffd7" category="inline-link-rx"></block> .</block>
  <block id="321c92980ad0e1d922d02a2f704ca782" category="paragraph">Una volta completata la distribuzione standard, NetApp PS completerà la configurazione avanzata della soluzione di storage utilizzando le procedure riportate di seguito, inclusa l'integrazione con Base Command Manager per la connettività e l'ottimizzazione del client.</block>
  <block id="00720789d4f50564af280240dfe0c1a0" category="section-title">Cablaggio del sistema di storage al fabric di storage DGX SuperPOD</block>
  <block id="93f38c7fefe0798b27b29ac2727c9aff" category="paragraph">Il sistema di storage AFF A90 è collegato agli switch leaf dello storage fabric tramite quattro porte Ethernet da 200 Gb per controller, con due connessioni per ogni switch.  Le porte dello switch da 800 Gb sugli switch NVIDIA Spectrum SN5600 sono suddivise in 4 porte da 200 Gb utilizzando le configurazioni DAC o splitter ottici appropriate elencate nell'Appendice A. Le singole porte di ogni porta dello switch sono distribuite sul controller di archiviazione per eliminare singoli punti di errore.  La figura 2 sottostante mostra il cablaggio per le connessioni dello storage fabric:</block>
  <block id="428c881d379aed620164886a529bf2ac" category="paragraph">Figura 2) Cablaggio della rete di archiviazione.</block>
  <block id="e97080670de5db4003a6abdd37d81eb5" category="paragraph"><block ref="e97080670de5db4003a6abdd37d81eb5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb83bbea93dbe46008125af94bc508be" category="section-title">Cablaggio del sistema di storage alla rete in-band DGX SuperPOD</block>
  <block id="3c4e3bd6ddc8a3cd692e2866674ec982" category="paragraph">NetApp ONTAP include funzionalità multi-tenancy leader del settore che gli consentono di funzionare sia come sistema di storage ad alte prestazioni nell'architettura DGX SuperPOD, sia di supportare directory home, condivisioni di file di gruppo e artefatti del cluster Base Command Manager.  Per l'utilizzo sulla rete in-band, ciascun controller AFF A90 è collegato agli switch di rete in-band con una connessione Ethernet da 200 Gb per controller e le porte sono configurate in una configurazione LACP MLAG.  La figura 3 sottostante mostra il cablaggio del sistema di storage alle reti in-band e OOB.</block>
  <block id="651c2d0bd757128b4d9ed91fc5026a3d" category="paragraph">Figura 3) Cablaggio di rete in-band e OOB.</block>
  <block id="92bf4c084f930281026def79beae3794" category="paragraph"><block ref="92bf4c084f930281026def79beae3794" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76edc3dadc8deca645fd525182eaad33" category="section-title">Configurare ONTAP per DGX SuperPOD</block>
  <block id="41905234b7d34b88a1559733c741d5aa" category="inline-link">+++ Documentazione ONTAP +++</block>
  <block id="d4b2d66f490475665ea833d8f89c2cfd" category="paragraph">Questa soluzione sfrutta più Storage Virtual Machine (SVM) per ospitare volumi sia per l'accesso allo storage ad alte prestazioni sia per le directory home degli utenti e altri artefatti del cluster su una SVM di gestione.  Ogni SVM è configurato con interfacce di rete sulle reti di archiviazione o in banda e volumi FlexGroup per l'archiviazione dei dati.  Per garantire le prestazioni della Data SVM viene implementata una policy QoS di archiviazione.  Per ulteriori informazioni su FlexGroups, Storage Virtual Machines e funzionalità ONTAP QoS, fare riferimento a<block ref="619babf0e51393513dd3986ae0aee969" category="inline-link-rx"></block> .</block>
  <block id="fec48034cdf04f518f58b4f727f55543" category="section-title">Configurare l'archiviazione di base</block>
  <block id="7e4b30d10f60fcb3bdf4c3382d601615" category="section-title">Configurare un singolo aggregato su ciascun controller</block>
  <block id="3c6858e020c27b4eb574d124f73c04d3" category="paragraph">Ripetere i passaggi precedenti per ciascun nodo del cluster.</block>
  <block id="241ba9d616774bbadf9c9f28ee386505" category="section-title">Configurare ifgrps su ciascun controller per la rete in banda</block>
  <block id="610c7975125c56dc62b000999926f4d8" category="section-title">Configurare le porte fisiche per RoCE</block>
  <block id="ff00a412cfca01b43041104775ac8460" category="paragraph">L'abilitazione di NFS su RDMA richiede una configurazione per garantire che il traffico di rete sia etichettato in modo appropriato sia sul client che sul server e che venga quindi gestito in modo appropriato dalla rete tramite RDMA su Converged Ethernet (RoCE).  Ciò include la configurazione del Priority Flow Control (PFC) e la configurazione della coda PFC CoS da utilizzare.  NetApp ONTAP configura automaticamente anche il codice DSCP 26 per allinearlo alla configurazione QoS della rete quando vengono eseguiti i comandi seguenti.</block>
  <block id="e9dc479a2f60169b39fb74cc86d13a43" category="section-title">Crea SVM di gestione</block>
  <block id="ce25292d4b04b878f74951ed7b5fb173" category="section-title">Creare e configurare Management SVM</block>
  <block id="c110d2ffde8993db523c41f0c524e68e" category="section-title">Configurare il servizio NFS su Management SVM</block>
  <block id="5441effcbbef51defcc1340e745e28ad" category="section-title">Creare subnet IP per interfacce di rete in banda</block>
  <block id="919d6feabfd1e5f5f04bedfd487f50c8" category="paragraph">*Nota:* le informazioni sulla subnet IP devono essere fornite dal cliente al momento dell'implementazione per l'integrazione nelle reti esistenti del cliente.</block>
  <block id="2bc9e41900e064c3368d9eca2dba546c" category="section-title">Crea interfacce di rete su ciascun nodo per SVM in banda</block>
  <block id="44db41cf8b74978388680587aa8b7d55" category="section-title">Crea volumi FlexGroup per Management SVM</block>
  <block id="20d5f1ad8803160edb381217d776701e" category="section-title">Crea una policy di esportazione per Management SVM</block>
  <block id="1624c693fdd8f06e52c87d0b2b576a19" category="section-title">Crea dati SVM</block>
  <block id="9ff068915b90e059d15444fe8dc13aaa" category="section-title">Creare e configurare Data SVM</block>
  <block id="cb7d25e4139e72b33ef687ed8a0ae945" category="section-title">Configurare il servizio NFS su Data SVM con RDMA abilitato</block>
  <block id="ca1f913932acc2aad423357d56f86ea7" category="section-title">Creare subnet IP per le interfacce di rete Data SVM</block>
  <block id="3c2060cdeb230d3f42a725b2a9ca7e23" category="section-title">Crea interfacce di rete su ciascun nodo per Data SVM</block>
  <block id="ca648b8fb4bf1f54cbf7a626468eada3" category="section-title">Configurare le interfacce di rete Data SVM per RDMA</block>
  <block id="afb51d28a404c42df2a054df2c6da14b" category="section-title">Crea una policy di esportazione sui dati SVM</block>
  <block id="d9a6b253dd081b231d9d1a14cec7a227" category="section-title">Crea percorsi statici su dati SVM</block>
  <block id="4f3e59209435398e52c0df85d0034275" category="section-title">Crea un volume FlexGroup con GDD per Data SVM</block>
  <block id="08ec3810f1dcb452442911f8d8173b1a" category="paragraph">La distribuzione granulare dei dati (GDD) consente di distribuire file di dati di grandi dimensioni su più volumi e controller costituenti FlexGroup per garantire le massime prestazioni per carichi di lavoro a file singolo.  NetApp consiglia di abilitare GDD sui volumi di dati per tutte le distribuzioni DGX SuperPOD.</block>
  <block id="7eb2bd842a06eb48d9bbfe4f644731d9" category="section-title">Disabilita l'efficienza di archiviazione per il volume di dati primario</block>
  <block id="8a0cdebf4e36c1af6ac542485413a77b" category="paragraph">efficienza del volume disattivata -vserver spod_data -volume spod_data</block>
  <block id="46e5a2d41b69706b3dcd5e89c34e7c5e" category="section-title">Creare una policy minima QoS per la SVM dei dati</block>
  <block id="065d35d3d9a4319f54773a754b2c0e6c" category="section-title">Applica la politica QoS per i dati SVM</block>
  <block id="2cc5056a61a5f1643bf387d49d197728" category="section-title">Configurazione del server DGX con NVIDIA Base Command Manager</block>
  <block id="e546e9d0da56999b5973de8a7ad71572" category="paragraph">Per preparare i client DGX all'utilizzo del sistema di archiviazione AFF A90 , completare le seguenti attività.  Questo processo presuppone che le interfacce di rete e i percorsi statici per la struttura di archiviazione siano già stati configurati sui nodi del sistema DGX.  Le seguenti attività saranno completate da NetApp Professional Services come parte del processo di configurazione avanzata.</block>
  <block id="f9a9381a56f728d139ee191de307ef5f" category="section-title">Configurare l'immagine del server DGX con i parametri del kernel richiesti e altre impostazioni</block>
  <block id="256b6f56d994f129832d2b7567bb951f" category="paragraph">NetApp ONTAP utilizza protocolli NFS standard del settore e non richiede l'installazione di alcun software aggiuntivo sui sistemi DGX.  Per garantire prestazioni ottimali dai sistemi client sono necessarie diverse modifiche all'immagine del sistema DGX.  Entrambi i passaggi seguenti vengono eseguiti dopo essere entrati nella modalità chroot dell'immagine BCM utilizzando il comando seguente:</block>
  <block id="45fb2f19f77fc1d9d4dfdd092f805b42" category="section-title">Configurare le impostazioni della memoria virtuale di sistema in /etc/sysctl.conf</block>
  <block id="13b4c0be439ee4875352c0ff2a039c13" category="paragraph">La configurazione predefinita del sistema Linux prevede impostazioni di memoria virtuale che potrebbero non garantire necessariamente prestazioni ottimali.  Nel caso dei sistemi DGX B200 con 2 TB di RAM, le impostazioni predefinite consentono 40 GB di spazio buffer, il che crea modelli di I/O incoerenti e consente al client di sovraccaricare il sistema di archiviazione durante lo svuotamento del buffer.  Le impostazioni seguenti limitano lo spazio del buffer del client a 5 GB e forzano lo svuotamento più spesso per creare un flusso I/O coerente che non sovraccarichi il sistema di archiviazione.</block>
  <block id="c35419f49457a55135a16f4a73d4fb6b" category="paragraph">Dopo essere entrati nella modalità chroot dell'immagine, modificate il file /etc/sysctl.s/90-cm-sysctl.conf e aggiungete le seguenti righe:</block>
  <block id="4caebde52be0001b1e59098dd149b653" category="paragraph">Salvare e chiudere il file /etc/sysctl.conf.</block>
  <block id="d05565dbb5b9175c4df06e8d9d029a18" category="section-title">Configura altre impostazioni di sistema con uno script che viene eseguito dopo il riavvio</block>
  <block id="4e1ff13d493c47a47dde7cb5a24aceeb" category="paragraph">Alcune impostazioni richiedono che il sistema operativo sia completamente online per essere eseguite e non sono persistenti dopo un riavvio.  Per eseguire queste impostazioni in un ambiente Base Command Manager, creare un file /root/ntap_dgx_config.sh e immettere le seguenti righe:</block>
  <block id="191be9d79602632b279bc3126e49847d" category="paragraph">*Salvare e chiudere il file.  Modificare i permessi sul file in modo che sia eseguibile:*</block>
  <block id="13036c88d00af2d37c1d8e1ae332f79e" category="paragraph">Crea un cron job che venga eseguito da root all'avvio modificando la seguente riga:</block>
  <block id="a4d911dee959cadc8c53c92d6361fc05" category="paragraph">Vedere il file crontab di esempio qui sotto:</block>
  <block id="e813523727c040149e1ecad0358d60b8" category="paragraph">Uscire dalla modalità chroot dell'immagine BCM immettendo exit o Ctrl-D.</block>
  <block id="70f4c658a41ea1900dd94027c0ffa103" category="section-title">Configurare la categoria DGX di BaseCommand Manager per i punti di montaggio del client</block>
  <block id="9df3dcf41d131b1d0097435f6b290ba4" category="paragraph">Per configurare i client DGX che montano il sistema di archiviazione AFF A90 , la categoria client BCM utilizzata dai sistemi DGX deve essere modificata per includere le informazioni e le opzioni pertinenti.  I passaggi seguenti descrivono come configurare il punto di montaggio NFS.</block>
  <block id="dcde3a7bf8f0a03f480df9078bfa9297" category="paragraph">NVIDIA DGX SuperPOD con i sistemi di storage NetApp * AFF A90 * rappresenta un significativo progresso nelle soluzioni infrastrutturali AI.  Affrontando le principali sfide legate a sicurezza, gestione dei dati, utilizzo delle risorse e scalabilità, consente alle organizzazioni di accelerare le proprie iniziative di intelligenza artificiale mantenendo al contempo efficienza operativa, protezione dei dati e collaborazione.  L'approccio integrato della soluzione elimina i comuni colli di bottiglia nelle pipeline di sviluppo dell'intelligenza artificiale, consentendo a data scientist e ingegneri di concentrarsi sull'innovazione anziché sulla gestione dell'infrastruttura.</block>
  <block id="77b69988a6b247bd3829a8e03ff332a6" category="inline-link">Guida alla progettazione dei sistemi di storage NVA-1175 NVIDIA DGX SuperPOD con NetApp AFF A90</block>
  <block id="78200c657113173ee4bd06de792e86af" category="list-text"><block ref="78200c657113173ee4bd06de792e86af" category="inline-link-rx"></block></block>
  <block id="4b70410b9d727a1fc1d60d4483d86325" category="inline-link">Architettura di riferimento NVIDIA DGX B200 SuperPOD</block>
  <block id="54dbc563049b479cfef99d1d872020e4" category="list-text"><block ref="54dbc563049b479cfef99d1d872020e4" category="inline-link-rx"></block></block>
  <block id="d5023dae85155f754c6bfd520cbdc150" category="inline-link">+++ Architettura di riferimento NVIDIA DGX H200 SuperPOD+++</block>
  <block id="5d4678ba7793147c6b3109fcdbe3294f" category="list-text"><block ref="5d4678ba7793147c6b3109fcdbe3294f" category="inline-link-rx"></block></block>
  <block id="0018465bd63e2711758aea9e68126f6d" category="inline-link">+++ Software NVIDIA BaseCommand+++</block>
  <block id="dd2a70a6cd8d74ddbed24590bf9efd37" category="list-text"><block ref="dd2a70a6cd8d74ddbed24590bf9efd37" category="inline-link-rx"></block></block>
  <block id="a2433670a2f11bda41782875f82e4c0e" category="inline-link">+++ Switch Ethernet NVIDIA Spectrum SN5600+++</block>
  <block id="197d7b18bb595fa0c4339f599bb57c70" category="list-text"><block ref="197d7b18bb595fa0c4339f599bb57c70" category="inline-link-rx"></block></block>
  <block id="61345f1959bf0e90ce956f7fe87b97e6" category="inline-link">+++ Note sulla versione NVIDIA DGX SuperPOD +++</block>
  <block id="a42d326cc55152a32997b9b244e9e4ea" category="list-text"><block ref="a42d326cc55152a32997b9b244e9e4ea" category="inline-link-rx"></block></block>
  <block id="18b5a5e73e5f66fb20d8f46f70d0c0ba" category="inline-link">+++ Installazione NetApp AFF A90 +++</block>
  <block id="cc99b2a6b638db71f55772efa9ae5a44" category="list-text"><block ref="cc99b2a6b638db71f55772efa9ae5a44" category="inline-link-rx"></block></block>
  <block id="326b3ec244c0b719f75faee5d63eda19" category="inline-link">+++ Documentazione sulle soluzioni AI NetApp +++</block>
  <block id="2a6b527a76b4dd02f63188fa855840f7" category="list-text"><block ref="2a6b527a76b4dd02f63188fa855840f7" category="inline-link-rx"></block></block>
  <block id="7d3cb5a08ca45610a4bc66221efd1e06" category="inline-link">+++ Software NetApp ONTAP +++</block>
  <block id="7de45c9a3f46892f98b68ddb83483727" category="list-text"><block ref="7de45c9a3f46892f98b68ddb83483727" category="inline-link-rx"></block></block>
  <block id="b20609bf792bc04f91d5af3f95c34249" category="inline-link">+++ NetApp installa e gestisce i sistemi di archiviazione AFF +++</block>
  <block id="f4f8a0ca5a3908b7ff3dc9977384172c" category="list-text"><block ref="f4f8a0ca5a3908b7ff3dc9977384172c" category="inline-link-rx"></block></block>
  <block id="784cd7f14efdcfe6b12e47d3ac14c2ea" category="list-text"><block ref="784cd7f14efdcfe6b12e47d3ac14c2ea" category="inline-link-rx"></block></block>
  <block id="2af6b6d1a0f9284afbd220786019c104" category="inline-link">+++Cos'è pNFS?+++</block>
  <block id="40b22abaae26a9e924653fdf64192dd5" category="list-text"><block ref="0b4edeca10dea88e1e3ff87f6aece04a" category="inline-link-rx"></block>(vecchio documento con ottime informazioni sul pNFS)</block>
  <block id="8b609f2b56884902c05d97d442f1d533" category="section-title">Appendice A: Distinta base e quote dei rack</block>
  <block id="97ac09ecf630c90bdc4eae789d1cb26e" category="paragraph">Nella tabella 3 sono riportati il ​​numero di parte e le quantità dei componenti NetApp necessari per distribuire lo storage per una, due, tre e quattro unità scalabili.</block>
  <block id="a399f4735d9b76eb2c734ce8b23a4051" category="paragraph">Tabella 3) NetApp BOM per 1, 2, 3 e 4 SU.</block>
  <block id="12671d03ae10ac5096ddbf709e44e260" category="cell">Parte n.</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">Articolo</block>
  <block id="4b35db9f95e91ac3ce4b119c8d590dc3" category="cell">Quantità per 1 unità unitaria</block>
  <block id="10ae8487d40b09fd13a32fd5b761dff2" category="cell">Quantità per 2SU</block>
  <block id="4f4a383868a5c8f1aff4d21e301cf77d" category="cell">Quantità per 3SU</block>
  <block id="7e3f2097d4da066bf518435f0d22d629" category="cell">Quantità per 4SU</block>
  <block id="a9eadd771f7974cbfb4a0f82da15155e" category="cell">AFF-A90A-100-C</block>
  <block id="a5b8692ce33078554d4df65b88479996" category="cell">Sistema di stoccaggio AFF A90</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="109799441719d48125200028617a078c" category="cell">X4025A-2-A-C</block>
  <block id="ae1ffcee034fa197d7e6a3d49392ad1b" category="cell">Pacchetto unità 2x7,6 TB</block>
  <block id="0a09c8844ba8f0936c20bd791130d6b6" category="cell">144</block>
  <block id="58a2fc6ed39fd083f55d4182bf88826d" category="cell">192</block>
  <block id="01fc28c75297fac48aca3e18491846a8" category="cell">X50131A-C</block>
  <block id="ef52c5c3e61828c1957bb235e48b9aaf" category="cell">Modulo IO, 2PT, 100/200/400 GbE</block>
  <block id="76dc611d6ebaafc66cc0879c71b5db5c" category="cell">128</block>
  <block id="da07ac8264b7cdb99a4eb96ab4d91111" category="cell">X50130A-C</block>
  <block id="02104e3c4b3f8d428381d1c68b10320d" category="cell">Modulo IO, 2PT, 100GbE</block>
  <block id="90d67d58a9628ba253eee43c6dbc9559" category="cell">X-02659-00</block>
  <block id="eaba4c24f91259319d86e2dc6a375c2c" category="cell">Kit, 4 montanti, foro quadrato o rotondo, binario da 24"-32"</block>
  <block id="a08f2932fed05b33c4945eca514134dc" category="cell">X1558A-R6</block>
  <block id="3229af69927999e5df543d1f9fb22eb5" category="cell">Cavo di alimentazione, in armadio, 48 pollici, + C13-C14, 10 A/250 V</block>
  <block id="98f13708210194c475687be6106a3b84" category="cell">20</block>
  <block id="d645920e395fedad7bbbed0eca3fe2e0" category="cell">40</block>
  <block id="f033ab37c30201f73f142449d037028d" category="cell">80</block>
  <block id="e6aa165cded1f8e32159470ff027af2f" category="cell">X190200-CS</block>
  <block id="7e011d9eef19544d7078d2a70563144a" category="cell">Interruttore a grappolo, N9336C 36Pt PTSX10/25/40/100G</block>
  <block id="76dedba1bf45af402ab07ddd57ff749e" category="cell">X66211A-2</block>
  <block id="2a1aeb324c9e886af32f12ad5049c6f7" category="cell">Cavo, 100 GbE, QSFP28-QSFP28, Cu, 2 m</block>
  <block id="e2fd227baa44b6632aa7c2fef9002b8a" category="cell">X66211A-05</block>
  <block id="0dff9249f8d94512b43527f1f5b044c9" category="cell">Cavo, 100 GbE, QSFP28-QSFP28, Cu, 0,5 m</block>
  <block id="6e421f2c1b8bf174d208a91d7f5dc0ae" category="cell">X6561-R6</block>
  <block id="95c7e45248e11b15430ec3c5d1d3dcc1" category="cell">Cavo, Ethernet, CAT6, RJ45, 5 m</block>
  <block id="e369853df766fa44e1ed0ff613f563bd" category="cell">34</block>
  <block id="3295c76acbf4caaed33c36b1b5fc2cb1" category="cell">66</block>
  <block id="2a108c75662ccb5a38e6db46a016aa40" category="paragraph">La tabella 4 mostra il numero di parte e la quantità di cavi NVIDIA necessari per collegare i sistemi di storage AFF A90 agli switch SN5600 nelle reti di storage ad alte prestazioni e in-band.</block>
  <block id="c71399ea2a367ce779897d49ca77b4a0" category="paragraph">Tabella 4) Cavi NVIDIA necessari per collegare i sistemi di storage AFF A90 agli switch SN5600 nelle reti di storage ad alte prestazioni e in-band.</block>
  <block id="5557f1218ab08d91639048aab26f1de0" category="cell">MCP7Y40-N003</block>
  <block id="2b11e18cd1f4ae786c28a6a1bce455ed" category="cell">DAC 3m 26ga da 2x400G a 4x200G OSFP a 4xQSFP112</block>
  <block id="19ca14e7ea6328a42e0eb13d585e4c22" category="cell">36</block>
  <block id="1d00e7dce692e8dc3f6877f035e3a616" category="cell">O</block>
  <block id="84686a1d557f4fefd53eaff2d691796d" category="cell">MMS4X00-NS</block>
  <block id="e67c53a2100e086542158b7496d248a7" category="cell">Transceiver multimodale OSFP 2x400G 2xSR4 a doppia porta, doppio MPO-12/APC</block>
  <block id="bbf6b7b52739d4479aae0bd6508ac746" category="cell">MFP7E20-N0XX</block>
  <block id="718b622b69fc995a4d3738ecaf2953b0" category="cell">Splitter per fibre multimodali 400G-&gt; 2x200G XX = 03, 05, 07, 10, 15, 20, 30, 40, 50) metri</block>
  <block id="7b55b9077a4e94ce71aba3fbb4b1ebcd" category="cell">MMA1Z00-NS400</block>
  <block id="1d1c4e0c3b72af208b18fbbfbf63c17b" category="cell">Transceiver QSFP112 multimodale SR4 a porta singola 400G MPO-12/APC singolo</block>
  <block id="098103233c14421a2092214651f99ac3" category="section-title">Elevazioni del rack</block>
  <block id="64441b5a3bcfb8a874107dfe4766feb6" category="paragraph">Le figure 4-6 mostrano esempi di elevazioni dei rack per 1-4 SU.</block>
  <block id="c22e6da1b1ce3c83fb3004d53e804737" category="paragraph">Figura 4) Elevazioni dei rack per 1 SU e 2 SU.</block>
  <block id="7ef24ed03ec40ae9ef02f5c904953418" category="paragraph"><block ref="7ef24ed03ec40ae9ef02f5c904953418" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64769808ba101c666bcd29615cc1e9d3" category="paragraph">Figura 5) Elevazioni dei rack per 3 SU.</block>
  <block id="02a5df2de00e7145cadd3753d42d3dc1" category="paragraph"><block ref="02a5df2de00e7145cadd3753d42d3dc1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8d7011e8983f361d68e382e119c1819" category="paragraph">Figura 6) Elevazioni dei rack per 4 SU.</block>
  <block id="381008e8bad1425034ca5fa30cd57133" category="paragraph"><block ref="381008e8bad1425034ca5fa30cd57133" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9376ca935750f1ee987d9b2ce256bfbf" category="paragraph">I sistemi di storage NVIDIA DGX SuperPOD™ con NetApp AFF A90 combinano le prestazioni di elaborazione di livello mondiale dei sistemi NVIDIA DGX con i sistemi di storage NetApp connessi al cloud per abilitare flussi di lavoro basati sui dati per l'apprendimento automatico (ML), l'intelligenza artificiale (AI) e il calcolo tecnico ad alte prestazioni (HPC).  Questo documento descrive l'architettura di alto livello della soluzione DGX SuperPOD che utilizza sistemi di storage NetApp AFF A90 con una struttura di storage Ethernet.</block>
  <block id="180ea794b48cd487087e5b1dd21023f0" category="paragraph">Grazie alle comprovate prestazioni di elaborazione di NVIDIA DGX SuperPOD, unite alle funzionalità di sicurezza dei dati, governance dei dati e multi-tenancy leader del settore di NetApp, i clienti possono implementare l'infrastruttura più efficiente e agile per i carichi di lavoro di nuova generazione.  Questo documento descrive l'architettura di alto livello e le funzionalità principali che aiutano i clienti a ridurre i tempi di commercializzazione e il ritorno sull'investimento per le iniziative di intelligenza artificiale e apprendimento automatico.</block>
  <block id="98e7b017fa4951d28f1516c0bee63969" category="section-title">Riepilogo del programma</block>
  <block id="0e7a454160d4f81e5b82fe865851c0b5" category="paragraph">NVIDIA DGX SuperPOD offre una soluzione di data center AI chiavi in ​​mano per le organizzazioni, offrendo senza soluzione di continuità elaborazione di livello mondiale, strumenti software, competenze e innovazione continua.  DGX SuperPOD offre ai clienti tutto ciò di cui hanno bisogno per distribuire carichi di lavoro AI/ML e HPC con tempi di configurazione minimi e massima produttività.  La figura 1 mostra i componenti di alto livello di DGX SuperPOD.</block>
  <block id="0df8fda8ee1a402c3eb7dc7582d3a710" category="paragraph"><block ref="0df8fda8ee1a402c3eb7dc7582d3a710" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d91208793b9a449dbecfd553707c79d6" category="list-text">Stack hardware e software integrato, dalla gestione e monitoraggio dell'infrastruttura ai modelli e strumenti di deep learning predefiniti.</block>
  <block id="84245e1cf723377c5a2991885cd57409" category="list-text">Servizi dedicati dall'installazione e gestione dell'infrastruttura al ridimensionamento dei carichi di lavoro e alla semplificazione dell'intelligenza artificiale di produzione</block>
  <block id="5d8430a9387a385c7ee9a8b83ff28b12" category="paragraph">Con l'adozione da parte delle organizzazioni di iniziative di intelligenza artificiale (IA) e apprendimento automatico (ML), la domanda di soluzioni infrastrutturali solide, scalabili ed efficienti non è mai stata così elevata.  Al centro di queste iniziative c'è la sfida di gestire e addestrare modelli di intelligenza artificiale sempre più complessi, garantendo al contempo la sicurezza dei dati, l'accessibilità e l'ottimizzazione delle risorse.  L'evoluzione dell'intelligenza artificiale agentiva e i requisiti di addestramento dei modelli sofisticati hanno creato richieste senza precedenti in termini di infrastrutture di calcolo e di archiviazione.  Le organizzazioni devono ora gestire enormi set di dati, supportare più carichi di lavoro di formazione simultanei e mantenere ambienti di elaborazione ad alte prestazioni, garantendo al contempo la protezione dei dati e la conformità alle normative.  Le soluzioni infrastrutturali tradizionali spesso faticano a soddisfare queste esigenze, causando inefficienze operative e ritardi nel time-to-value dei progetti di intelligenza artificiale.  Questa soluzione offre i seguenti vantaggi chiave:</block>
  <block id="1844a1480427b3b276783fd66fc58226" category="list-text">*Scalabilità.*  I sistemi di storage NVIDIA DGX SuperPOD con NetApp AFF A90 offrono una scalabilità senza pari grazie alla loro architettura modulare e alle capacità di espansione flessibili.  Le organizzazioni possono scalare senza problemi la propria infrastruttura di intelligenza artificiale aggiungendo nodi di elaborazione DGX e sistemi di storage AFF A90 senza interrompere i carichi di lavoro esistenti o richiedere complesse riconfigurazioni.</block>
  <block id="02a63d3f709e7b79dac689e7724d8821" category="list-text">*Gestione e accesso ai dati.*  Il sistema di storage NVIDIA DGX SuperPOD con NetApp AFF A90 si basa su NetApp ONTAP , che eccelle nella gestione dei dati grazie alla sua suite completa di funzionalità di livello aziendale.  Utilizzando le funzionalità snapshot e FlexClone di ONTAP, i team possono creare istantaneamente copie di set di dati e database vettoriali che occupano poco spazio per lo sviluppo e il test paralleli.  Le tecnologie di replica FlexCache e Snapmirror consentono pipeline di dati semplificate, efficienti in termini di spazio e automatizzate da fonti dati in tutta l'azienda, mentre l'accesso multiprotocollo ai dati tramite protocolli NAS e oggetti consente nuovi flussi di lavoro ottimizzati per attività di acquisizione e ingegneria dei dati.</block>
  <block id="3b5ce4caaf6acea212e6608eb826a52c" category="list-text">*Sicurezza.*  I sistemi di storage NetApp AFF A90 garantiscono sicurezza di livello aziendale attraverso più livelli di protezione.  A livello di infrastruttura, la soluzione implementa solidi meccanismi di controllo degli accessi, tra cui il controllo degli accessi basato sui ruoli (RBAC), l'autenticazione a più fattori e funzionalità di registrazione dettagliata degli audit.  Il framework di crittografia completo della piattaforma protegge i dati sia inattivi che in transito, utilizzando protocolli e algoritmi standard del settore per salvaguardare la proprietà intellettuale e mantenere la conformità ai requisiti normativi.  Gli strumenti integrati di monitoraggio della sicurezza forniscono visibilità in tempo reale sulle potenziali minacce alla sicurezza, mentre i meccanismi di risposta automatizzati aiutano a mitigare i rischi prima che possano avere ripercussioni sulle operazioni.</block>
  <block id="d2374eb265fd2592ef7b4b817140ba67" category="paragraph">Questa soluzione è pensata per le organizzazioni con carichi di lavoro HPC e AI/ML che richiedono una maggiore integrazione in ampi patrimoni di dati e strumenti e processi di infrastrutture IT tradizionali.</block>
  <block id="549c608b9fe93192110cc2552d28da22" category="paragraph">Il pubblico di riferimento della soluzione comprende i seguenti gruppi:</block>
  <block id="f79b8cf1009178e9a2fd45c1f4ae4ef7" category="list-text">I decisori IT e delle linee di business pianificano l'infrastruttura più efficiente per realizzare iniziative di intelligenza artificiale/apprendimento automatico con il time-to-market e il ROI più rapidi.</block>
  <block id="c328ed7f0a74043c4e73f7ea491b4eb7" category="list-text">Data scientist e data engineer interessati a massimizzare l'efficienza delle parti critiche incentrate sui dati del flusso di lavoro AI/ML.</block>
  <block id="fa7b81174ad3677e1ed9da1ea8185c4d" category="list-text">Architetti e ingegneri IT che hanno bisogno di realizzare un'infrastruttura affidabile e sicura che consenta flussi di lavoro di dati automatizzati e la conformità agli standard di governance dei dati e dei processi esistenti.</block>
  <block id="dad37ea926873ef3d5ee869827ddc40c" category="paragraph">NVIDIA DGX SuperPOD include i server, la rete e lo storage necessari per garantire prestazioni comprovate per carichi di lavoro di intelligenza artificiale impegnativi.  I sistemi NVIDIA DGX™ H200 e NVIDIA DGX B200 offrono una potenza di elaborazione di livello mondiale, mentre gli switch di rete NVIDIA Quantum e Spectrum™ InfiniBand garantiscono una latenza estremamente bassa e prestazioni di rete leader del settore.  Grazie all'aggiunta delle funzionalità di gestione dei dati e delle prestazioni leader del settore dello storage NetApp ONTAP , i clienti possono realizzare iniziative di intelligenza artificiale/apprendimento automatico più rapidamente e con meno migrazione dei dati e spese amministrative.  Le sezioni seguenti descrivono i componenti di archiviazione del DGX SuperPOD con sistemi di archiviazione AFF A90 .</block>
  <block id="4caba5452d50c27473615492a421d0b7" category="section-title">Sistemi di storage NetApp AFF A90 con NetApp ONTAP</block>
  <block id="5b01f10375ddf0fa7a318292fb1ab544" category="paragraph">NetApp AFF A90 , basato sul software di gestione dati NetApp ONTAP , offre protezione dati integrata, funzionalità anti-ransomware e le elevate prestazioni, scalabilità e resilienza necessarie per supportare i carichi di lavoro aziendali più critici. Elimina le interruzioni delle operazioni mission-critical, riduce al minimo l'ottimizzazione delle prestazioni e protegge i dati dagli attacchi ransomware.  I sistemi NetApp AFF A90 forniscono-</block>
  <block id="5f443413f7f04549bcfdd089e04a0c3a" category="list-text">*Prestazione.* L' AFF A90 gestisce facilmente carichi di lavoro di nuova generazione come deep learning, intelligenza artificiale e analisi ad alta velocità, nonché database aziendali tradizionali come Oracle, SAP HANA, Microsoft SQL Server e applicazioni virtualizzate. Grazie a NFS su RDMA, pNFS e session trunking, i clienti possono raggiungere l'elevato livello di prestazioni di rete richiesto per le applicazioni di nuova generazione utilizzando l'infrastruttura di rete del data center esistente e i protocolli standard del settore, senza software proprietario.  La distribuzione granulare dei dati consente di distribuire singoli file su ogni nodo del cluster di archiviazione e, se combinata con pNFS, garantisce un accesso parallelo ad alte prestazioni ai set di dati contenuti in un singolo file di grandi dimensioni.</block>
  <block id="ae299319707718bf9587df62a89ca873" category="list-text">*Intelligenza.*  Accelera la trasformazione digitale con un ecosistema predisposto per l'intelligenza artificiale basato su intelligence basata sui dati, infrastruttura a prova di futuro e integrazioni profonde con NVIDIA e l'ecosistema MLOps.  Utilizzando le funzionalità snapshot e FlexClone di ONTAP, i team possono creare istantaneamente copie di set di dati che occupano poco spazio per lo sviluppo e i test paralleli.  Le tecnologie di replica FlexCache e Snapmirror consentono pipeline di dati semplificate, efficienti in termini di spazio e automatizzate provenienti da fonti dati in tutta l'azienda.  Inoltre, l'accesso multiprotocollo ai dati tramite protocolli NAS e oggetti consente nuovi flussi di lavoro ottimizzati per attività di acquisizione e ingegneria dei dati.  I checkpoint dei dati e della formazione possono essere suddivisi in livelli di storage più economici per evitare di riempire lo storage primario.  I clienti possono gestire, proteggere e mobilitare i dati senza problemi, al costo più basso, su cloud ibrido con un unico sistema operativo di archiviazione e la suite di servizi dati più completa del settore.</block>
  <block id="3a6d4fa926afe309c404561a18033103" category="list-text">*Sicurezza.*  NVIDIA DGX SuperPOD con NetApp ONTAP Storage garantisce sicurezza di livello aziendale attraverso più livelli di protezione.  A livello di infrastruttura, la soluzione implementa solidi meccanismi di controllo degli accessi, tra cui il controllo degli accessi basato sui ruoli (RBAC), l'autenticazione a più fattori e funzionalità di registrazione dettagliata degli audit.  Il framework di crittografia completo della piattaforma protegge i dati sia inattivi che in transito, utilizzando protocolli e algoritmi standard del settore per salvaguardare la proprietà intellettuale e mantenere la conformità ai requisiti normativi.  Gli strumenti integrati di monitoraggio della sicurezza forniscono visibilità in tempo reale sulle potenziali minacce alla sicurezza, mentre i meccanismi di risposta automatizzati aiutano a mitigare i rischi prima che possano avere ripercussioni sulle operazioni.  NetApp ONTAP è l'unico storage aziendale rinforzato e convalidato per l'archiviazione di dati top secret.</block>
  <block id="5a79514564c762f34f82d2f86ba269f6" category="list-text">*Multi-tenancy*.  NetApp ONTAP offre la più ampia gamma di funzionalità per consentire un utilizzo multi-tenant sicuro delle risorse di storage.  Le macchine virtuali di archiviazione forniscono una delega amministrativa basata su tenant con controlli RBAC. I controlli QoS completi garantiscono le prestazioni per carichi di lavoro critici, consentendo al contempo il massimo utilizzo, mentre le funzionalità di sicurezza, come le chiavi gestite dal tenant per la crittografia a livello di volume, garantiscono la sicurezza dei dati sui supporti di archiviazione condivisi.</block>
  <block id="234fe3186330a0015f240eaa46026f52" category="inline-link">+++ Libro bianco ONTAP RASS+++</block>
  <block id="aa2c50d70660a4e07e28a4a1e62cbbeb" category="list-text">*Affidabilità.*  NetApp elimina le interruzioni delle operazioni mission-critical grazie a funzionalità avanzate di affidabilità, disponibilità, facilità di manutenzione e gestibilità (RASM), garantendo il massimo tempo di attività disponibile.  Per maggiori informazioni vedere il<block ref="06c9743ea9b1147ff9ba8b6afddf02b3" category="inline-link-rx"></block> .  Inoltre, lo stato di salute del sistema può essere ottimizzato con analisi predittive basate sull'intelligenza artificiale fornite da Active IQ e Data Infrastructure Insights.</block>
  <block id="dbefda683c705de53408671cbbab4e34" category="section-title">Sistemi NVIDIA DGX B200</block>
  <block id="c2e6165182afeb3c2d3013f3389087b6" category="inline-link">++NVIDIA+++</block>
  <block id="2ed6f2103f37f8b4eec016533f493515" category="inline-link">++NVLink(™)+++</block>
  <block id="1697b07c98d5b223a74b615c776f0b65" category="inline-link">+++ NVIDIA Blackwell+++</block>
  <block id="5e923560ec7f11fe71232bd344d8d81a" category="inline-link">+++architettura+++</block>
  <block id="f7be9a2901218b858c97cd4113fbc2aa" category="paragraph">NVIDIA DGX™ B200 è una piattaforma di intelligenza artificiale unificata per pipeline di sviluppo e distribuzione per aziende di qualsiasi dimensione, in qualsiasi fase del loro percorso verso l'intelligenza artificiale.  Dotato di otto GPU NVIDIA Blackwell interconnesse con la quinta generazione<block ref="8d33a92989a52a298d52379f9acef95c" category="inline-link-rx"></block><block ref="66ff52a072f2c292b9f50112a8543358" category="inline-link-rx"></block> , DGX B200 offre prestazioni all'avanguardia, con prestazioni di formazione 3 volte superiori e prestazioni di inferenza 15 volte superiori rispetto alle generazioni precedenti.  Sfruttando il<block ref="113af14b044c5bd4dc15be4b6100b100" category="inline-link-rx"></block><block ref="adaec91c8092748fe326913de2b3a1f0" category="inline-link-rx"></block> DGX B200 è in grado di gestire carichi di lavoro diversificati, tra cui modelli linguistici di grandi dimensioni, sistemi di raccomandazione e chatbot, il che lo rende ideale per le aziende che desiderano accelerare la trasformazione dell'intelligenza artificiale.</block>
  <block id="f94ad1ea1a52dd514a5e42a7eec71e94" category="section-title">Switch Ethernet NVIDIA Spectrum SN5600</block>
  <block id="a1bd19971bc35fdd30c6a0b2eee21865" category="paragraph">Lo switch SN5600 smart-leaf, spine e super-spine offre 64 porte da 800 GbE in un denso fattore di forma 2U.  Il modello SN5600 consente sia la progettazione standard leaf/spine con switch top-of-rack (ToR), sia topologie end-of-row (EoR).  L'SN5600 offre diverse possibilità di connettività in combinazioni da 1 a 800 GbE e vanta una velocità di trasmissione totale leader del settore pari a 51,2 Tb/s.</block>
  <block id="ffe61852985d936bb555e1c150a3feca" category="section-title">Software NVIDIA Base Command</block>
  <block id="040380b5657454a9d0ce1064c83dd667" category="paragraph">NVIDIA Base Command™ è alla base della piattaforma NVIDIA DGX, consentendo alle organizzazioni di sfruttare al meglio l'innovazione AI NVIDIA .  Grazie a questa soluzione, ogni organizzazione può sfruttare appieno il potenziale della propria infrastruttura DGX con una piattaforma collaudata che include la gestione del flusso di lavoro AI, la gestione dei cluster di livello aziendale, librerie che accelerano l'elaborazione, l'archiviazione e l'infrastruttura di rete, nonché software di sistema ottimizzato per l'esecuzione di carichi di lavoro AI.  La figura 2 mostra lo stack software NVIDIA Base Command.</block>
  <block id="9620c8c92a535942ede6a202c5bf5b0d" category="paragraph">Figura 2) Software di comando di base NVIDIA .</block>
  <block id="2e15a851530c5d474531243cfd838752" category="paragraph"><block ref="2e15a851530c5d474531243cfd838752" category="inline-image-macro-rx" type="image"></block></block>
  <block id="651beb53a2e8224545ff56fc0d0efd02" category="paragraph">NVIDIA Base Command Manager offre una distribuzione rapida e una gestione end-to-end per cluster eterogenei di intelligenza artificiale e di calcolo ad alte prestazioni (HPC) nell'edge, nel data center e in ambienti multi-cloud e ibridi.  Automatizza il provisioning e l'amministrazione di cluster di dimensioni variabili da un paio di nodi a centinaia di migliaia, supporta sistemi accelerati da GPU NVIDIA e altri sistemi e consente l'orchestrazione con Kubernetes.  L'integrazione dei sistemi di storage NetApp AFF A90 con DGX SuperPOD richiede una configurazione minima di Base Command Manager per la messa a punto del sistema e i parametri di montaggio per prestazioni ottimali, ma non è richiesto alcun software aggiuntivo per fornire un accesso multi-path ad alta disponibilità tra i sistemi DGX e il sistema di storage AFF A90 .</block>
  <block id="24f67e93854c90d735466339a375c002" category="paragraph">NVIDIA DGX SuperPOD è progettato per soddisfare i requisiti prestazionali dei carichi di lavoro più impegnativi su larga scala.</block>
  <block id="cfc814162b41538ad397b897a24c4937" category="list-text">Formazione di modelli di intelligenza artificiale per modelli linguistici di grandi dimensioni, classificazione di immagini/visione artificiale, rilevamento di frodi e innumerevoli altri casi d'uso.</block>
  <block id="607aa89216cc994d4e20cfce8695d306" category="list-text">Calcolo ad alte prestazioni, come analisi sismica, fluidodinamica computazionale e visualizzazione su larga scala.</block>
  <block id="9f6302143996033ebb94d536b860acc3" category="section-title">Architettura della soluzione</block>
  <block id="d0eadc16af6d6df8893f37be51ed2bc6" category="paragraph">DGX SuperPOD si basa sul concetto di unità scalabile (SU) che comprende 32 sistemi DGX B200 e tutti gli altri componenti necessari per fornire la connettività richiesta ed eliminare eventuali colli di bottiglia nelle prestazioni dell'infrastruttura.  I clienti possono iniziare con una o più SU e aggiungerne altre in base alle proprie esigenze.  Questo documento descrive la configurazione di archiviazione per una singola SU e la Tabella 1 mostra i componenti necessari per configurazioni più grandi.</block>
  <block id="2a4a6621abe5b6f39b1534ead593f20a" category="inline-link">+++ Architettura di riferimento NVIDIA DGX SuperPOD +++</block>
  <block id="60696b15e8be9fd24231177ac611836f" category="paragraph">L'architettura di riferimento DGX SuperPOD comprende più reti e il sistema di archiviazione AFF A90 è collegato a molte di esse.  Per ulteriori informazioni sulla rete DGX SuperPOD, fare riferimento a<block ref="562b92094dd1a3e9b7e68b6a6fb7de81" category="inline-link-rx"></block> .</block>
  <block id="fdd68d018aab06584c6bc4e8351fa72b" category="paragraph">Per questa soluzione, la struttura di archiviazione ad alte prestazioni è una rete Ethernet basata sullo switch NVIDIA Spectrum SN5600 con 64 porte da 800 Gb in una configurazione Spine/Leaf.  La rete in-band fornisce all'utente l'accesso ad altre funzioni, quali directory home e condivisioni di file generali, ed è anch'essa basata sugli switch SN5600, mentre la rete out-of-band (OOB) è destinata all'accesso dell'amministratore di sistema a livello di dispositivo mediante switch SN2201.</block>
  <block id="3a812cac2db0a2d9638c3b252cc24b8e" category="paragraph">La struttura di archiviazione è un'architettura leaf-spine in cui i sistemi DGX si collegano a una coppia di switch leaf e il sistema di archiviazione si collega a un'altra coppia di switch leaf.  Vengono utilizzate più porte da 800 Gb per collegare ogni switch leaf a una coppia di switch spine, creando più percorsi ad alta larghezza di banda attraverso la rete per ottenere prestazioni aggregate e ridondanza.  Per la connettività al sistema di archiviazione AFF A90 , ogni porta da 800 Gb viene suddivisa in quattro porte da 200 Gb utilizzando gli appositi cavi breakout in rame o ottici.  Per supportare i client che montano il sistema di archiviazione con NFS su RDMA, la struttura di archiviazione è configurata per RDMA su Converged Ethernet (RoCE), che garantisce la distribuzione di pacchetti senza perdite nella rete.  La figura 3 mostra la topologia della rete di storage di questa soluzione.</block>
  <block id="6a53d316acbe58b01a749e96481412aa" category="paragraph">Figura 3) Topologia della struttura di archiviazione.</block>
  <block id="00031e516cb8c09c104ebdb164264d7f" category="paragraph"><block ref="00031e516cb8c09c104ebdb164264d7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="316d243b972562ec3f8d06fcd980b1d6" category="paragraph">Il sistema di storage NetApp AFF A90 è uno chassis 4RU contenente 2 controller che funzionano come partner ad alta disponibilità (HA Pair) l'uno per l'altro, con un massimo di 48 dischi a stato solido (SSD) da 2,5 pollici.  Ogni controller è collegato a entrambi gli switch leaf di storage SN5600 tramite quattro connessioni Ethernet da 200 Gb e su ogni porta fisica sono presenti 2 interfacce IP logiche.  Il cluster di archiviazione supporta NFS v4.1 con Parallel NFS (pNFS), che consente ai client di stabilire connessioni direttamente a ogni controller nel cluster.  Inoltre, il trunking di sessione combina le prestazioni di più interfacce fisiche in un'unica sessione, consentendo anche ai carichi di lavoro single-threaded di accedere a una larghezza di banda di rete maggiore di quella possibile con il bonding Ethernet tradizionale. La combinazione di tutte queste funzionalità con RDMA consente al sistema di storage AFF A90 di offrire bassa latenza e throughput elevato con scalabilità lineare per i carichi di lavoro che sfruttano NVIDIA GPUDirect Storage™.</block>
  <block id="2ecf799238706280879a7218f5c9384f" category="paragraph">Per la connettività alla rete in-band, i controller AFF A90 dispongono di interfacce Ethernet da 200 Gb aggiuntive configurate in un gruppo di interfacce LACP che forniscono servizi NFS v3 e v4 generali, nonché accesso S3 ai file system condivisi, se desiderato.  Tutti i controller e gli switch del cluster di storage sono connessi alla rete OOB per l'accesso amministrativo remoto.</block>
  <block id="242354762ac710a9d168daccad8ea40d" category="paragraph">Per consentire elevate prestazioni e scalabilità, i controller di storage formano un cluster di storage che consente di combinare tutte le prestazioni e la capacità dei nodi del cluster in un unico namespace denominato FlexGroup , con dati distribuiti sui dischi di ogni nodo del cluster.  Grazie alla nuova funzionalità Granular Data Distribution rilasciata in ONTAP 9.16.1, i singoli file vengono separati e distribuiti nel FlexGroup per consentire i massimi livelli di prestazioni per i carichi di lavoro a file singolo.  La Figura 4 sottostante mostra come pNFS e il trunking delle sessioni NFS interagiscono con FlexGroups e GDD per consentire l'accesso parallelo a file di grandi dimensioni sfruttando ogni interfaccia di rete e disco nel sistema di archiviazione.</block>
  <block id="c3c4a8bbb2b351b3bf984cb2d6864b94" category="paragraph">Figura 4) pNFS, troncamento delle sessioni, FlexGroups e GDD.</block>
  <block id="4f30b88a042ae485248ebaa1099b4a91" category="paragraph"><block ref="4f30b88a042ae485248ebaa1099b4a91" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ac50512926081a099344a18f27b3818" category="paragraph">Questa soluzione sfrutta più Storage Virtual Machine (SVM) per ospitare volumi sia per l'accesso allo storage ad alte prestazioni sia per le directory home degli utenti e altri artefatti del cluster su una SVM di gestione.  Ogni SVM è configurato con interfacce di rete e volumi FlexGroup e viene implementata una politica QoS per garantire le prestazioni della Data SVM.  Per ulteriori informazioni su FlexGroups, Storage Virtual Machines e funzionalità ONTAP QoS, fare riferimento a<block ref="619babf0e51393513dd3986ae0aee969" category="inline-link-rx"></block> .</block>
  <block id="2a57ec7828afba5c513d03e967cb3884" category="section-title">Requisiti hardware della soluzione</block>
  <block id="b761a63ce0a1bd27710c7207a50b8577" category="paragraph">Nella tabella 1 sono elencati i componenti hardware di archiviazione necessari per implementare una, due, quattro o otto unità scalabili.  Per i requisiti hardware dettagliati per server e reti, consultare<block ref="b8ab7d3cc54802757d9a49bb252840ab" category="inline-link-rx"></block> .</block>
  <block id="a7504f8a3068ecf26f816d83dfcae5a8" category="cell">Dimensioni SU</block>
  <block id="eb94f28ae18769ccde6259223dde0683" category="cell">Sistemi AFF A90</block>
  <block id="258b220fa2ed31020ab102479476e757" category="cell">Switch di interconnessione del cluster di archiviazione</block>
  <block id="9254819941449b706e4282e2f2e6a7b9" category="cell">Capacità utilizzabile (tipica con SSD da 3,8 TB)</block>
  <block id="eb17bb52c3b173b3911725d1c9a194f0" category="cell">Capacità massima utilizzabile (con SSD NVMe da 15,3 TB)</block>
  <block id="c9d196f41b3911fefebc23e6efbc32f4" category="cell">RU (tipico)</block>
  <block id="1fec42eb0945f00ee2125c78858d7366" category="cell">Potenza (tipica)</block>
  <block id="f04a7a4ef42eb207cec5a3d7fcc9d3fa" category="cell">555 TB</block>
  <block id="104bf07415681a49e985f5dd5895d4d6" category="cell">13.75PB</block>
  <block id="4f10ff6d954a760dbf5b59fb54597722" category="cell">7.300 watt</block>
  <block id="830daef3058bf009b39d03050f58f3f4" category="cell">27.5PB</block>
  <block id="62aa76bddc36c76968deb0ae09c8063f" category="cell">14.600 watt</block>
  <block id="76a4dd9b098f9a8877b8b79d0c80c5d3" category="cell">2PB</block>
  <block id="3b07c527868f20c47db7e08e0e02ced5" category="cell">55PB</block>
  <block id="f4680500c767e37e35c38315af80e9f9" category="cell">29.200 watt</block>
  <block id="e79a79f20fe06b0beb657745cf11949a" category="cell">4PB</block>
  <block id="1609fc8f39b0baac216cbb19fb420ef2" category="cell">110PB</block>
  <block id="ec8956637a99787bd197eacd77acce5e" category="cell">102</block>
  <block id="bc6012118a1ec87da87af67c6b3a0f74" category="cell">58.400 watt</block>
  <block id="0f37a7e60b292d864a5ac969ec04cc27" category="paragraph">*NOTA:* NetApp consiglia un minimo di 24 unità per coppia AFF A90 HA per ottenere le massime prestazioni.  Unità interne aggiuntive, unità di capacità maggiore e ripiani per unità di espansione esterne consentono una capacità aggregata molto più elevata senza alcun impatto sulle prestazioni del sistema.</block>
  <block id="d3469c07f7acce56e0d039ec0b164141" category="paragraph">Nella tabella 2 sono elencati i componenti software e le versioni necessarie per integrare il sistema di archiviazione AFF A90 con DGX SuperPOD.  DGX SuperPOD comprende anche altri componenti software non elencati qui.  Si prega di fare riferimento al<block ref="2523a697ed64d9038adf903273ea5150" category="inline-link-rx"></block> per maggiori dettagli.</block>
  <block id="0bd0e673df4c14cae45a11fac30c530b" category="cell">9.16.1</block>
  <block id="dbc8a3aaafc47a649eed1dcc0bc5155e" category="cell">10.24.11</block>
  <block id="c6d4f54ff5f7e221a70cdd46daa396b3" category="cell">6.3.1</block>
  <block id="09e619b353cb3d3ca08701e294bb9047" category="cell">MLNX_OFED_LINUX-23.10.3.2.0 LTS</block>
  <block id="51eed8fde1839744a1b920b0dacb0a0a" category="cell">5,10</block>
  <block id="f11a60eea5a7abfd75bb28890eaef1ec" category="paragraph">Questa soluzione di storage è stata convalidata in più fasi da NetApp e NVIDIA per garantire che prestazioni e scalabilità soddisfino i requisiti di NVIDIA DGX SuperPOD.  La configurazione è stata convalidata utilizzando una combinazione di carichi di lavoro sintetici e carichi di lavoro ML/DL reali per verificare sia le massime prestazioni sia l'interoperabilità delle applicazioni.  Nella tabella 3 sottostante sono riportati esempi di carichi di lavoro tipici e dei relativi requisiti di dati comunemente riscontrabili nelle distribuzioni DGX SuperPOD.</block>
  <block id="e203df30cd7f31417aee170026e44f70" category="paragraph">Tabella 3) Esempi di carico di lavoro SuperPOD.</block>
  <block id="a0db49ba470c1c9ae2128c3470339153" category="cell">Livello</block>
  <block id="0ba48588b95eb9052082d27db3380801" category="cell">Descrizione del lavoro</block>
  <block id="c8ceada943dc5d58578660bf60d0762a" category="cell">Dimensione del set di dati</block>
  <block id="eb6d8ae6f20283755b339c0dc273988b" category="cell">Standard</block>
  <block id="c7f0dd1953999823199f993b956164f6" category="cell">Più lavori di formazione LLM o di fine-tuning simultanei e punti di controllo periodici, in cui i requisiti di elaborazione prevalgono notevolmente sui requisiti di I/O dei dati.</block>
  <block id="f2db8117278a7bff3e0e0bff0571726d" category="cell">La maggior parte dei set di dati può essere inserita nella cache di memoria dei sistemi di elaborazione locali durante l'addestramento.  I set di dati sono monomodali e i modelli hanno milioni di parametri.</block>
  <block id="53123044b4b65d0ad1b7ed0cfa4c3480" category="cell">Migliorato</block>
  <block id="c9e72abf53e870d36e47df81d7f139bf" category="cell">Più processi di formazione multimodale simultanei e punti di controllo periodici, in cui le prestazioni di I/O dei dati rappresentano un fattore importante per il tempo di formazione end-to-end.</block>
  <block id="981d20fc47284a9be8695e715a3d1d47" category="cell">I set di dati sono troppo grandi per essere inseriti nella cache di memoria dei sistemi di elaborazione locali e richiedono più I/O durante l'addestramento, non abbastanza per evitare la necessità di I/O frequenti.  I set di dati hanno molteplici modalità e i modelli hanno miliardi (o più) di parametri.</block>
  <block id="255eebee8e38299d9f7282ffa8b76db3" category="paragraph">Nella tabella 4 sono riportate le linee guida sulle prestazioni per i carichi di lavoro di esempio sopra riportati.  Questi valori rappresentano la capacità di archiviazione che può essere generata da questi carichi di lavoro in condizioni ideali.</block>
  <block id="fe54d8f94c652ba49e4aba03f3107a9c" category="paragraph">Tabella 4) Linee guida sulle prestazioni del DGX SuperPOD.</block>
  <block id="f5bab93f6f25cd702dcbcb4aad615260" category="cell">Caratteristica di prestazione</block>
  <block id="94f3edd272dbb778616c50e083536c63" category="cell">Standard (GBps)</block>
  <block id="abaf1dc2e3d5bf424c74cd4566b0f1a3" category="cell">Migliorato (GBps)</block>
  <block id="c5b9e837f1006565fbb01cd3b64d3df7" category="cell">Lettura del sistema aggregato SU singolo</block>
  <block id="3def184ad8f4755ff269862ea77393dd" category="cell">125</block>
  <block id="8eb042782ea4dd597d037482af02c144" category="cell">Scrittura del sistema aggregato SU singolo</block>
  <block id="44f683a84163b3523afe57c2e008bc8c" category="cell">62</block>
  <block id="f53ce0357707bf3db713c9d71337529d" category="cell">4 Sistema aggregato SU letto</block>
  <block id="b73ce398c39f506af761d2277d853a92" category="cell">160</block>
  <block id="cee631121c2ec9232f3a2f028ad5c89b" category="cell">500</block>
  <block id="bc96df788d872dc23329bae80cc02619" category="cell">4 SU sistema aggregato scrittura</block>
  <block id="6c9882bbac1c7093bd25041881277658" category="cell">250</block>
  <block id="ef6f2913d5f1e19a1aa781a5d72d6caa" category="inline-link">Guida all'implementazione dei sistemi di storage NVIDIA DGX SuperPOD con NetApp AFF A90 NVA-1175</block>
  <block id="6f8af77cdc63a21a3e7b99a2511ed006" category="list-text"><block ref="6f8af77cdc63a21a3e7b99a2511ed006" category="inline-link-rx"></block></block>
  <block id="4498f6091821057a5b12bbe00bad6fb7" category="inline-link">Architettura di riferimento NVIDIA DGX B200 SuperPOD</block>
  <block id="e0ef89706b7f0268557664ed42040243" category="list-text"><block ref="e0ef89706b7f0268557664ed42040243" category="inline-link-rx"></block></block>
  <block id="076218ee0774bfaae3fcf92a3241a9fe" category="inline-link">Architettura di riferimento NVIDIA DGX H200 SuperPOD</block>
  <block id="b02d06e7da163e15a51f5a0277a72641" category="list-text"><block ref="b02d06e7da163e15a51f5a0277a72641" category="inline-link-rx"></block></block>
  <block id="e9cc843bc2157ef28fd2c0657e05a6f0" category="inline-link">Software NVIDIA BaseCommand</block>
  <block id="5b147f17197401088429ad2165ca94db" category="list-text"><block ref="5b147f17197401088429ad2165ca94db" category="inline-link-rx"></block></block>
  <block id="f6f89e67f0d14eefc85ee96a3de66d60" category="list-text"><block ref="f6f89e67f0d14eefc85ee96a3de66d60" category="inline-link-rx"></block></block>
  <block id="8365b73ca224de7f689b1708ed448af9" category="inline-link">+++ Documentazione sulle soluzioni AI NetApp +++</block>
  <block id="aed2dde7ddb9cf045a1de05c19aa6fe6" category="list-text"><block ref="aed2dde7ddb9cf045a1de05c19aa6fe6" category="inline-link-rx"></block></block>
  <block id="4245faba305e62f6fdc30b1ce8bf8ac3" category="inline-link">+++ NetApp installa e gestisce i sistemi di archiviazione AFF +++</block>
  <block id="bf45808f34c6dcc540de81441ed8372a" category="list-text"><block ref="bf45808f34c6dcc540de81441ed8372a" category="inline-link-rx"></block></block>
  <block id="51af5c28c5aeade3eeee8efe1cf0c265" category="list-text"><block ref="0b4edeca10dea88e1e3ff87f6aece04a" category="inline-link-rx"></block>(vecchio documento con ottime informazioni sul pNFS)</block>
  <block id="e84f1067b5e0c62707fee9cec31ec6e6" category="sidebar">Sistemi di storage NetApp AFF A90 con NVIDIA DGX SuperPOD - Progettazione</block>
  <block id="ebe830dbdb267fd10b3f4000455f19f2" category="sidebar">Sistemi di storage NetApp AFF A90 con NVIDIA DGX SuperPOD - Distribuzione</block>
  <block id="596cf4cc4d5e162a19a0826844899146" category="section-title">*Quindi, cosa ci guadagnano i clienti utilizzando NetApp nei loro ambienti di intelligenza artificiale?*</block>
  <block id="54cba921a12475f0e93be541d67490f1" category="paragraph">NetApp aiuta le organizzazioni a far fronte alle complessità create dalla rapida crescita dei dati e del cloud, dalla gestione multi-cloud e dall'adozione di tecnologie di nuova generazione, come l'intelligenza artificiale. NetApp ha combinato diverse funzionalità in un software di gestione dati intelligente e in un'infrastruttura di storage ben bilanciata con prestazioni elevate ottimizzate per i carichi di lavoro di intelligenza artificiale. Le soluzioni di intelligenza artificiale generativa come gli LLM devono leggere ed elaborare i set di dati sorgente dall'archiviazione alla memoria numerose volte per promuovere l'intelligenza.</block>
  <block id="7089718bb01d102d3ca66b75e734cc70" category="paragraph">NetApp è leader nelle tecnologie di mobilità, governance e sicurezza dei dati nell'ecosistema edge-to-core-to-cloud, aiutando i clienti aziendali a creare soluzioni di intelligenza artificiale su larga scala. NetApp, grazie a una solida rete di partner, ha aiutato i responsabili dei dati, gli ingegneri dell'intelligenza artificiale, gli architetti aziendali e gli scienziati dei dati a progettare una pipeline di dati fluida per la preparazione dei dati, la protezione dei dati e le responsabilità di gestione strategica dei dati per l'addestramento e l'inferenza dei modelli di intelligenza artificiale, ottimizzando le prestazioni e la scalabilità del ciclo di vita di intelligenza artificiale/apprendimento automatico. Le tecnologie e le funzionalità dei dati NetApp , come NetApp ONTAP AI per la pipeline di dati di deep learning, NetApp SnapMirror per il trasporto fluido ed efficiente dei dati tra endpoint di storage e NetApp FlexCache per il rendering in tempo reale quando il flusso di dati passa da batch a tempo reale e l'ingegneria dei dati avviene al momento opportuno, apportano valore all'implementazione di modelli di intelligenza artificiale generativa in tempo reale. Con l'adozione di nuovi strumenti di intelligenza artificiale da parte delle aziende di ogni tipo, si trovano ad affrontare sfide legate ai dati, dall'edge al data center fino al cloud, che richiedono soluzioni di intelligenza artificiale scalabili, responsabili e spiegabili.</block>
  <block id="9772b4cc8e96c8e8f4206d250991b4de" category="paragraph">In qualità di autorità in materia di dati su cloud ibrido e multi-cloud, NetApp si impegna a creare una rete di partner e soluzioni congiunte che possano aiutare in tutti gli aspetti della costruzione di una pipeline di dati e di data lake per l'addestramento di modelli di intelligenza artificiale generativa (pre-addestramento), la messa a punto, l'inferenza basata sul contesto e il monitoraggio del decadimento del modello di LLM.</block>
  <block id="1bdb9ad9a5ef7e6cc423c9885d4d8739" category="paragraph">Una delle pratiche più comuni nell'implementazione di LLM dopo la preparazione e la pre-elaborazione dei dati è quella di selezionare un modello pre-addestrato, ovvero addestrato su un set di dati ampio e diversificato. Nel contesto della messa a punto, questo può essere un modello di linguaggio di grandi dimensioni open source come<block ref="40c631914d673c775e5813606a4c652a" category="inline-link-macro-rx"></block> addestrato su 70 miliardi di parametri e 2 trilioni di token. Una volta selezionato il modello pre-addestrato, il passo successivo è perfezionarlo sui dati specifici del dominio. Ciò comporta la regolazione dei parametri del modello e l'addestramento sui nuovi dati per adattarlo a un dominio e a un'attività specifici. Ad esempio, BloombergGPT, un LLM proprietario formato su un'ampia gamma di dati finanziari al servizio del settore finanziario.</block>
  <block id="fab051e778dea3863166cf91444b5bcf" category="paragraph">I modelli specifici per dominio, progettati e addestrati per un compito specifico, presentano generalmente maggiore accuratezza e prestazioni nel loro ambito, ma una bassa trasferibilità ad altri compiti o domini. Quando l'ambiente aziendale e i dati cambiano nel corso di un periodo, l'accuratezza delle previsioni del FM potrebbe iniziare a diminuire rispetto alle prestazioni durante i test. È in questi casi che diventa fondamentale riqualificare o perfezionare il modello.</block>
  <block id="4ce18a58c4206acbac965ee866687247" category="paragraph">Il riaddestramento del modello nell'intelligenza artificiale/apprendimento automatico tradizionale si riferisce all'aggiornamento di un modello di apprendimento automatico distribuito con nuovi dati, generalmente eseguito per eliminare due tipi di derive che si verificano. (1) Deriva concettuale: quando il collegamento tra le variabili di input e le variabili di destinazione cambia nel tempo, poiché la descrizione di ciò che vogliamo prevedere cambia, il modello può produrre previsioni imprecise. (2) Deriva dei dati: si verifica quando le caratteristiche dei dati di input cambiano, come cambiamenti nelle abitudini o nel comportamento dei clienti nel tempo e quindi l'incapacità del modello di rispondere a tali cambiamenti.</block>
  <block id="602c876f12d2508496dc8bd8575b4ff1" category="paragraph">Allo stesso modo, la riqualificazione si applica ai FM/LLM, ma può essere molto più costosa (in milioni di dollari), quindi non è qualcosa che la maggior parte delle organizzazioni potrebbe prendere in considerazione. È oggetto di ricerca attiva e sta ancora emergendo nel campo degli LLMOps. Quindi, invece di riaddestrare, quando si verifica un decadimento del modello in FM ottimizzati, le aziende potrebbero optare per un'ulteriore ottimizzazione (molto più economica) con un set di dati più recente. Per una prospettiva sui costi, di seguito è riportato un esempio di tabella modello-prezzo di Azure-OpenAI Services. Per ogni categoria di attività, i clienti possono perfezionare e valutare i modelli su set di dati specifici.</block>
  <block id="71176ac8a95086c3af18e14dbe844fb0" category="summary">Distribuisci un ambiente di formazione AI ibrido utilizzando l'orchestrazione Union.ai con NetApp FlexCache per consentire ai carichi di lavoro di formazione GPU basati su cloud di accedere ai dati locali in modo efficiente e sicuro.</block>
  <block id="ebe4896d0cefdc11a7145e4ba24679b4" category="doc">Distribuisci la formazione ibrida sull'intelligenza artificiale con Union.ai e NetApp FlexCache</block>
  <block id="aeb0127b1fad213a793e443cc4c034e1" category="paragraph">Scopri come distribuire un ambiente di formazione AI ibrido utilizzando l'orchestrazione Union.ai con NetApp FlexCache e Trident per il provisioning dello storage Kubernetes.</block>
  <block id="0db9f14d36280e385cafd4a8e173ba9c" category="paragraph">David Espejo, Union.ai Sathish Thyagarajan, NetApp</block>
  <block id="236b0367f9d4648bcd56117f6b73c2c5" category="paragraph">La piattaforma di orchestrazione ibrida di Union.ai si integra perfettamente con NetApp ONTAP e FlexCache per accelerare i flussi di lavoro di formazione AI/ML.  Questa soluzione consente di mantenere i dati in modo sicuro in sede, sfruttando al contempo l'elaborazione GPU basata su cloud per i carichi di lavoro di formazione dell'intelligenza artificiale.  NetApp FlexCache garantisce che solo i dati necessari vengano memorizzati nella cache del cloud, consentendo pipeline ibride AI/ML efficienti, sicure e scalabili.</block>
  <block id="f237a6da02589b7944ad58fcc8dcf636" category="section-title">Caso d'uso del cliente: formazione sull'intelligenza artificiale nel cloud ibrido</block>
  <block id="e2c5205f6d8d8dc0fab0d0bce1569d9f" category="list-text">Dati on-premise: archiviati su NetApp ONTAP per conformità e sicurezza.</block>
  <block id="1801ce3ced3cc951feb620652dc6d4b1" category="list-text">Cloud computing: addestramento GPU scalabile su EKS/GKE/AKS.</block>
  <block id="10295e9d8bfdac4bb00b04c0bc0b0aed" category="list-text">Orchestrazione AI/ML: Union.ai coordina l'elaborazione dei dati e la formazione in tutti gli ambienti.</block>
  <block id="21e9bccf6843ac1890de68780a7f2d40" category="list-text">Provisioning dello storage: NetApp Trident automatizza il provisioning PVC/PV.</block>
  <block id="9abac747d764180a5fe55920e00e887d" category="section-title">Valore per il cliente</block>
  <block id="036bc3c4ad78a1ce748913d0e7508b1a" category="list-text">Esegui carichi di lavoro di intelligenza artificiale su enormi set di dati utilizzando le funzionalità di scalabilità orizzontale di NetApp ONTAP.</block>
  <block id="1f7c5f457095fe04da60f8ba120a65e4" category="list-text">Sposta e sincronizza i dati tra locale e cloud utilizzando le funzionalità cloud ibride di NetApp.</block>
  <block id="3bdc2120e1312d582041096be647b9bb" category="list-text">Memorizza rapidamente nella cache i dati locali nel cloud utilizzando FlexCache.</block>
  <block id="feb2a9775b0ab9fb076eee862b34a0bf" category="list-text">Union.ai semplifica l'orchestrazione tra ambienti con il controllo delle versioni, il tracciamento della discendenza e la gestione degli artefatti.</block>
  <block id="1a5a25d256a64f75ffbb6c69a682f597" category="list-text">Esegui la formazione nel cloud mantenendo i dati sensibili in sede.</block>
  <block id="3cb632ece883ce8e1d1738b69db115ce" category="section-title">Abilitazione del plugin – Prerequisiti</block>
  <block id="ec185b8a3ae00d2dc7bc400a8dd3c006" category="cell">*Requisito*</block>
  <block id="dc98ae2c28f9de9e5b906a8f45c3c581" category="cell">*Dettagli*</block>
  <block id="e8467e9b509c4924668c01eb7ab2adde" category="cell">Versione ONTAP</block>
  <block id="19438dd3f06122a6b56a2b87636a35a0" category="cell">ONTAP 9.7+ (licenza FlexCache non richiesta)</block>
  <block id="50174c074d05aa14191d913ea21e3e51" category="cell">Licenza FlexCache</block>
  <block id="774b9f24682d83dfc0b7a6d9acd6a45e" category="cell">Richiesto su ONTAP 9.6 e versioni precedenti</block>
  <block id="11b36d38ea31e3e3f39211d4c9ff85e9" category="cell">Cluster on-prem e cloud (EKS/GKE/AKS)</block>
  <block id="f13ee4a03ec985915aaeb699fd3d5314" category="cell">Installato sia su cluster on-premise che cloud</block>
  <block id="23b2341bc1ff8a41de6140e2e728ade5" category="cell">Union.ai</block>
  <block id="407d73d776263be9ef5a593de9cc8960" category="cell">Piano di controllo distribuito (Union Cloud o self-hosted)</block>
  <block id="79629c9f5d632fe153b79bae51230230" category="cell">Connettività inter-cluster (se i cluster ONTAP sono separati)</block>
  <block id="d08ccf52b4cdd08e41cfb99ec42e0b29" category="cell">Permessi</block>
  <block id="34a1c6a28726559a79202e58b5b1676b" category="paragraph">Accesso amministrativo ai cluster ONTAP e Kubernetes.</block>
  <block id="aa7462aeb4d0cda09f1955bc4ad68471" category="paragraph">✅Utilizzare le credenziali ONTAP corrette (ad esempio, vsadmin)</block>
  <block id="796fc083420089e3cd35a14b9bc38682" category="cell">Nuovo su Union.ai?</block>
  <block id="0a99c5455b15fcf14acd747ff433961a" category="cell">Consultare la guida complementare alla fine di questo documento</block>
  <block id="4ee2bcec265f41a5c011850eb9ea191a" category="section-title">Architettura di riferimento</block>
  <block id="63bb16834a3d897a73bbb3b676f4681f" category="paragraph">La figura seguente mostra il piano di controllo Union.ai integrato con lo storage NetApp per l'addestramento dell'IA ibrida.</block>
  <block id="f3ff7d4cb08d662ccb22a7e0d198e7bc" category="image-alt">Architettura di formazione AI ibrida con Union.ai e NetApp</block>
  <block id="5b9cebc88c7af20d41a8fb5d5a5ec740" category="list-text">Piano di controllo Union.ai: orchestra i flussi di lavoro, gestisce lo spostamento dei dati e si integra con le API NetApp .</block>
  <block id="62d1d515610a83be5bf46c2f24528f24" category="list-text">NetApp ONTAP + FlexCache: fornisce un efficiente caching dei dati da locale al cloud.</block>
  <block id="bd86e4a74b09f477abb8e01446ebb353" category="list-text">Cluster di formazione ibridi: i processi di formazione vengono eseguiti nei cluster cloud K8s (ad esempio, EKS) con dati memorizzati nella cache da locale.</block>
  <block id="20b2d2f7ff3d10f09ee1a0cfa5fdc77b" category="section-title">_Passaggio 1: creare un volume FlexCache</block>
  <block id="c320f12fadd143f86e468c946747b19d" category="paragraph">Utilizzo di ONTAP System Manager</block>
  <block id="fbf67ba3555eeca4fc432c43b8b07927" category="list-text">Vai su Archiviazione &gt; Volumi.</block>
  <block id="1bb250fbf1946dd1bd7ad228032f8803" category="list-text">Fare clic su Aggiungi.</block>
  <block id="fa3a36a2d48d60ddb9b70c0c6908764b" category="list-text">Seleziona Altre opzioni.</block>
  <block id="3afffa15dbb0847459b5d61d6c2f2aa9" category="list-text">Abilita Aggiungi come cache per un volume remoto.</block>
  <block id="953d07b2f3feae837ecfbd619c90b443" category="list-text">Scegli i volumi di origine (on-prem) e di destinazione (cloud).</block>
  <block id="f71e6890a321cf5e86880fed490c270d" category="list-text">Definire QoS o livello di prestazioni (facoltativo).</block>
  <block id="f6831112fc67960a16905d831665e29f" category="list-text">Fare clic su Crea.</block>
  <block id="c3eb411bcb9e224abacb05a02a4af9c4" category="paragraph">💡Se NetApp DataOps Toolkit non funziona a causa di problemi di autorizzazione o di aggregazione, creare il volume FlexCache direttamente tramite ONTAP System Manager o CLI.</block>
  <block id="6eac7b0a5cfc938d19f189c4a925ae85" category="section-title">_Passaggio 2: Configura Trident_</block>
  <block id="56c52a0dabd55220d0a00db845f7eb1f" category="paragraph">Installare Trident su entrambi i cluster:</block>
  <block id="45d2098b426afc9ab859375c1adbe887" category="inline-link">+++ Guida all'installazione Trident +++</block>
  <block id="d250649bce56841bd7a8ae7e4a825154" category="paragraph">🔗 <block ref="d4fe2bbcee5aa3fc712cc2604ddb189d" category="inline-link-rx"></block></block>
  <block id="ce18e85a5244ef1099f883c207b32d36" category="paragraph">Crea Trident Backend</block>
  <block id="1d505b9bfd6afef0b98758bef1cef23c" category="paragraph">Se si riceve un errore 401 Non autorizzato, verificare che l'utente ONTAP disponga di autorizzazioni API sufficienti e che vengano utilizzati il ​​nome utente (vsadmin) e la password corretti.</block>
  <block id="e5250cf37b377ddb3586661f3e7bdc3e" category="paragraph">Definisci StorageClass</block>
  <block id="7e383433631a99b62111f529c2e90f6e" category="section-title">_Passaggio 3: distribuire i flussi di lavoro Union.ai_</block>
  <block id="543a5300ad04692c61ad12509f36dfee" category="paragraph">Union utilizza i PVC per montare i volumi FlexCache nei processi di formazione.</block>
  <block id="e3651dc228e2bf15038a1eeea69840e1" category="paragraph">Esempio di PodTemplate</block>
  <block id="ef12d0a79902f644c4f92af29b9c7091" category="paragraph">Esempio di flusso di lavoro</block>
  <block id="4066afa3aee701e50ae5ec4c8f86ca6e" category="paragraph">dall'attività di importazione dell'unione, flusso di lavoro</block>
  <block id="12113988d854d53153ebe56debcfc262" category="section-title">Carica e addestra sui dati dal PVC</block>
  <block id="2f8434215e66e235733bbc8f7aa6c922" category="paragraph">L'operatore dell'Unione:</block>
  <block id="a305c8fb2137d8a4a767905590079e89" category="list-text">Creare il PVC</block>
  <block id="1c35c5b70ea278327b331fdc5e5e8027" category="list-text">Montare il volume FlexCache</block>
  <block id="193acff0cdc88eae36fe646b68a073bd" category="list-text">Pianifica il lavoro nel cluster cloud K8s</block>
  <block id="8ed435a788d105467da83bc0bcc93aa7" category="section-title">Passaggio 4: convalidare l'integrazione_</block>
  <block id="e5476676d28ebe3a7f7e5540ca5f4675" category="cell">*Compito*</block>
  <block id="933aacf34a8192a52d32c97fadebd54a" category="cell">*Convalida*</block>
  <block id="2c4159f4648782debbeab1c320c6eb36" category="cell">Supporto in PVC</block>
  <block id="f5e0baa9773049fb0fdfad4b1037b128" category="cell">I pod di addestramento dovrebbero montare /data/flexcache correttamente</block>
  <block id="bcaba27319b0be3d4476ebc564abbebe" category="cell">I lavori di formazione possono leggere/scrivere da FlexCache</block>
  <block id="0452805cb606d459124bcdb40e21d774" category="cell">Comportamento della cache</block>
  <block id="4ccd4153d261ab04aea61d1689d17c9c" category="cell">Monitora i risultati/mancati risultati della cache in ONTAP.  Assicurarsi che gli aggregati supportino FlexCache</block>
  <block id="f77ae91c297c4af9b7c0df16428dfecb" category="cell">Convalida la latenza e la produttività per i carichi di lavoro di formazione</block>
  <block id="c4ce6fec594676e7db8a8772df23cea3" category="paragraph">Utilizzare NetApp BlueXP o ONTAP CLI per monitorare le prestazioni.</block>
  <block id="fe62647cc35dde214e0df1ae1fe9d0ab" category="section-title">Considerazioni sulla sicurezza</block>
  <block id="1127e459f9563cd44a49304486317d03" category="list-text">Utilizzare endpoint VPC per FSx per NetApp ONTAP</block>
  <block id="aac467f7d3593eab984d0df820db3683" category="list-text">Abilita la crittografia in transito e a riposo</block>
  <block id="fb6241aa3cd02fb81bc14120b0a0a835" category="list-text">Applicare RBAC/IAM per l'accesso ONTAP</block>
  <block id="36b4de85d3df62f02a9c4618f7393d5f" category="list-text">Union.ai non accede né memorizza i dati dei clienti</block>
  <block id="77f95f9630cb5091cd2402072a3a11bf" category="section-title">Monitoraggio e ottimizzazione</block>
  <block id="f8d8425485c22136939de6dcb7d3356a" category="cell">*Attrezzo*</block>
  <block id="1463a95efc33a52765f03569e1e39a10" category="cell">*Scopo*</block>
  <block id="b5edf5031e4afa6b0a76f28594c49ddd" category="cell">Monitorare l'utilizzo e le prestazioni FlexCache</block>
  <block id="db06b456ce0e60d6d6cac92921fbb8d0" category="cell">Interfaccia utente Union.ai</block>
  <block id="b3f63fd65c8f5f7c899c10d3d4a4d5ff" category="cell">Monitorare lo stato e le metriche della pipeline</block>
  <block id="046574dd59654b8d55254dd4939767ea" category="cell">Tronchi Trident</block>
  <block id="7712a94ff94a189bd7789174ddb85aa3" category="cell">Debug di problemi PVC o backend</block>
  <block id="8f9f469b79a29bfaadaab8eaa7bf1636" category="paragraph">*Miglioramenti opzionali*</block>
  <block id="ce4081657a64c83e483fc3ade088d080" category="list-text">Automatizza la creazione FlexCache utilizzando le API BlueXP</block>
  <block id="b0e97389c5c2b645585f1a4ed42f4062" category="list-text">Utilizzare Union SDK per riscaldare la cache prima dell'addestramento</block>
  <block id="a138a4f582ee5e74b8a702fd75b12caf" category="list-text">Aggiungere pipeline di inferenza batch o di fornitura di modelli dopo l'addestramento</block>
  <block id="15e720f9a639ae01b45177587e8ccbde" category="list-text">Se DataOps Toolkit fallisce, ricorrere alla creazione manuale FlexCache tramite System Manager</block>
  <block id="1199d4564ed2d91a9aaa1b96702c1582" category="paragraph">*Risoluzione dei problemi*</block>
  <block id="932191b39be7b845f279d774204fa0c7" category="cell">_Problema_</block>
  <block id="04389d6334aedcb0de87e1a666e3c947" category="cell">_Risoluzione_</block>
  <block id="b9f0ff9ef465f92292d9c7714cf0446b" category="cell">PVC bloccato in sospeso</block>
  <block id="7d55337975fd5793d327f0da49970ce3" category="cell">Controlla i log Trident e la configurazione del backend</block>
  <block id="4c3472db990ec75b3639c13a00908586" category="cell">401 Non autorizzato dall'API ONTAP</block>
  <block id="8f85964854ee5b9cb1a25336f9286a74" category="cell">Utilizzare vsadmin e verificare i permessi</block>
  <block id="2ee8b0581475d5ce36df44f0c44eab51" category="cell">Lavoro fallito: nessun archivio adatto</block>
  <block id="c9928a026f07daff3baa1cd570f13e02" category="cell">Assicurarsi che l'aggregato ONTAP supporti FlexCache/ FabricPool</block>
  <block id="06d6b9c5788c506f6f2f8d3f67d8df51" category="cell">Prestazioni di allenamento lente</block>
  <block id="d03995cc9f7ad650494a9b56c2d58a9c" category="cell">Controlla il tasso di hit della cache e la latenza di rete</block>
  <block id="bccf1526ca148033777fd0bd06e8f7ee" category="cell">I dati non si sincronizzano</block>
  <block id="0e8d0a990b73463291ce4bfcba615908" category="cell">Convalida dello stato di salute della relazione FlexCache in ONTAP</block>
  <block id="e78b6e86c7e00b15c6dd9fdca8a5bdcc" category="paragraph">*Passi successivi*</block>
  <block id="dee0fee1df57aa918047c0cfb20ad55c" category="list-text">Convalida FlexCache con dati di prova</block>
  <block id="2e4e08d271df2d2f43b686f4854cb7dc" category="list-text">Distribuisci pipeline di formazione Union.ai</block>
  <block id="321c5de7cdf5e00eb0fdaca2b788e1ec" category="list-text">Monitorare e ottimizzare le prestazioni</block>
  <block id="036c0cdd445e04bc18011ee63fe79f6b" category="list-text">Documentare la configurazione specifica del cliente</block>
  <block id="f8ec0f3aa329ebfedf13a79184b7867e" category="section-title">Link correlati</block>
  <block id="40f1a76b84471f69f9e1889172b29883" category="inline-link">+++Documentazione Union.ai+++</block>
  <block id="c91fc7e0181d836eb58c9b44f305b351" category="list-text"><block ref="c91fc7e0181d836eb58c9b44f305b351" category="inline-link-rx"></block></block>
  <block id="84d18427d4b09cf2972d9a3f3257769b" category="inline-link">+++ Panoramica NetApp FlexCache +++</block>
  <block id="1a605359e56e1853280e4dee015e7108" category="list-text"><block ref="1a605359e56e1853280e4dee015e7108" category="inline-link-rx"></block></block>
  <block id="da3e81cca1d4f971a54e502e43db83be" category="inline-link">+++ Pilota Trident CSI+++</block>
  <block id="23454a58dd19bdaab14ee6b38f7085c2" category="list-text"><block ref="23454a58dd19bdaab14ee6b38f7085c2" category="inline-link-rx"></block></block>
  <block id="703deb112695d2f3ddd729660eda475e" category="inline-link">+++FSx per NetApp ONTAP+++</block>
  <block id="5c3ccbe0598da1ccd0f27d66924f35a0" category="list-text"><block ref="5c3ccbe0598da1ccd0f27d66924f35a0" category="inline-link-rx"></block></block>
  <block id="b88b18835512f2759d991ef53ab162b9" category="paragraph">Ora disponi di un ambiente di addestramento AI ibrido convalidato utilizzando Union.ai e NetApp FlexCache.  I processi di formazione possono essere eseguiti nel cloud, accedendo ai dati locali in modo sicuro ed efficiente, senza replicare interi set di dati o compromettere la governance.</block>
  <block id="ad33b54a429301c01188c2215540b441" category="section-title">*Union.ai - Guida complementare*</block>
  <block id="8dddc2c8fe2555559a91e764d9235d6d" category="section-title">*Passaggio 1: Scegli il modello di distribuzione*</block>
  <block id="108439501b55d62870c68f24142fe2a5" category="paragraph">*Opzione A: Union Cloud*</block>
  <block id="976f05b0299c51890060c29d6f4f45b3" category="inline-link">+++console.union.ai+++</block>
  <block id="609ccd1033d19392f6d6c02b595bb318" category="list-text">Visita:<block ref="83d678893a166e9c0f58ce02ef080fcc" category="inline-link-rx"></block></block>
  <block id="f08d2a267c4238d5dedd3060c425bea8" category="list-text">Crea organizzazione → Crea progetto</block>
  <block id="8666a7638fa800278c371ca2f1820986" category="paragraph">*Opzione B: Auto-ospitato*</block>
  <block id="5078bc27c5748b853e709e2b526e1082" category="inline-link">+++Guida auto-ospitata+++</block>
  <block id="6df4df2571296ce37f0e789ec56f04a9" category="list-text">Seguire:<block ref="4be3c30c75fcef2d9efc975adc8528d7" category="inline-link-rx"></block></block>
  <block id="f545b6872fa4adefba8899ca2fc74491" category="list-text">Distribuisci tramite Helm:</block>
  <block id="e473adcd16935db4753279dc28f9e821" category="paragraph">helm repo aggiungi unionai<block ref="84236ba1097180095905520179dbd184" category="inline-link-rx"></block></block>
  <block id="00f612d5f2f9c5739afe7c75d82fb745" category="paragraph">helm install union unionai/union -n union-system -f values.yaml</block>
  <block id="d8a959014bb50434b6e09b8d7827f70c" category="section-title">*Passaggio 2: Installa Union Operator*</block>
  <block id="7443eefd01ea12bf0e7f5acf24ead38f" category="paragraph">****kubectl applica -f<block ref="4919c1363aa43016b9853a86a6d26868" category="inline-link-rx"></block></block>
  <block id="9f2047b5710eb7331780470de4e2fca6" category="paragraph">kubectl get pods -n union-system</block>
  <block id="5c2133f8c5522052f26480f953cedc78" category="paragraph"></block>
  <block id="8edcef410da7878bbc80fbf71d8d4ca1" category="section-title">*Passaggio 3: Installa Union CLI*</block>
  <block id="096327f6db51928112a49641fed0f8cd" category="paragraph">****pip install unionai</block>
  <block id="bbc7802cd83c61c2822be7e61e76bb58" category="paragraph">accesso sindacale</block>
  <block id="36be1709489e578c13ff9335dc7eb7f4" category="section-title">*Passaggio 4: Registra il flusso di lavoro*</block>
  <block id="770338800a5338d40910785b3f81deca" category="paragraph">****progetto sindacale crea intelligenza artificiale ibrida</block>
  <block id="d51c04424d78429df18e885a2925e1c1" category="paragraph">registro sindacale training_pipeline.py --project hybrid-ai</block>
  <block id="7708565358c9d989222e9b05b65d3086" category="section-title">*Passaggio 5: Esecuzione e monitoraggio*</block>
  <block id="5293ce724d74996d1c0f39a743b87ca3" category="paragraph">****union run training_pipeline --project hybrid-ai</block>
  <block id="77d86bed8e4a63dae84e1b440af13a17" category="paragraph">formazione di vigilanza sindacale_pipeline</block>
  <block id="1bcbb746e8103dcfa7f40479a1fc2611" category="inline-link">+++Interfaccia utente dell'Unione+++</block>
  <block id="fe70d0bdbb730c20766cb067c9162ca2" category="paragraph">Visualizza i registri in<block ref="5d901f07ac55ec91a8fb1758272f874b" category="inline-link-rx"></block></block>
  <block id="aa5cc28d71177bdfabbd066c40556228" category="section-title">*Passaggio 6: Registra Compute Cluster (facoltativo)*</block>
  <block id="8a850c847294bf4d916aa4d9595fbeab" category="paragraph">****union cluster register --name cloud-k8s --kubeconfig ~/.kube/config</block>
  <block id="4f79c95b459644bc0e692dde2dd46094" category="section-title">*Passaggio 7: Traccia artefatti e lignaggio*</block>
  <block id="91130ed55ade71de6d2e55d497681f4f" category="paragraph">Union tiene traccia automaticamente:</block>
  <block id="701e52a8aaee5a831d2070361229690f" category="list-text">Parametri di input/output</block>
  <block id="cf5f81b1cd733c89e4b42fe6671710eb" category="list-text">Versioni dei dati</block>
  <block id="6cb9ece998b6962dfad48664cca107df" category="list-text">Registri e metriche</block>
  <block id="d97bb7d4317729f1d0601989dc9a0eb0" category="list-text">Lignaggio di esecuzione</block>
  <block id="1c99161556cba115d3a4b0cf426f65fc" category="section-title">3 dicembre 2025</block>
  <block id="0fb14243c78c122f3acd551576ee673d" category="paragraph">Nuova soluzione:<block ref="06b6b8e975dd9eb86a80852e60ea5c25" category="inline-link-macro-rx"></block></block>
  <block id="cae14f8b661aea219fdaf3f4f0af08db" category="paragraph">Utilizza l'orchestrazione Union.ai con NetApp FlexCache per eseguire carichi di lavoro di formazione AI su GPU cloud, mantenendo al contempo i dati sensibili in locale.  FlexCache memorizza nella cache del cloud solo i dati necessari per un training ibrido efficiente e sicuro.</block>
  <block id="d156278e3dbb2cd83d1a870d6704c9b8" category="sidebar">NetApp + Union.ai: Guida tecnica alla formazione sull'intelligenza artificiale ibrida</block>
  <block id="ddf52cdc15133d3a9cb02a51bde98630" category="sidebar">Formazione sull'intelligenza artificiale ibrida con NetApp e Union.ai</block>
  <block id="9c1377c97790bfb53de65e24276a1216" category="sidebar">Formazione sull'intelligenza artificiale ibrida con Union.ai</block>
  <block id="bc35ee37767e4af0acfededb3169dea7" category="list-text">Esempi di clienti Instaclustr e dettagli sui loro casi d'uso</block>
  <block id="0212a7ff5eedcd67a7b84fa1ba480bc2" category="paragraph"><block ref="f670d08dd43af20b7e913fb27609f01d" category="inline-link-rx"></block>,<block ref="a9adf060aa8097003033bb7f27b5067d" category="inline-link-rx"></block></block>
  <block id="32e89286d3b2abdbdfed4a3b70b56c4a" category="paragraph"><block ref="32e89286d3b2abdbdfed4a3b70b56c4a" category="inline-link-rx"></block></block>
  <block id="04811d6350cbb9ca8a0ee30a91752819" category="paragraph"><block ref="04811d6350cbb9ca8a0ee30a91752819" category="inline-link-rx"></block></block>
  <block id="51a14d08c34bcecf91444995375a1ff2" category="inline-link-macro">instaclust utilizzando l'archiviazione a livelli Kafka</block>
  <block id="e4fda4b7fc0596e39060f4d05d9a3104" category="paragraph">NetApp instaclustr supporta anche Kafka con storage a livelli dalla versione 3.8.1. Per maggiori dettagli, consultare qui <block ref="b7922a93a5920c465bcf40e7e8f14b82" category="inline-link-macro-rx"></block></block>
  <block id="1f2f31fd4bc8efc61a85e89732c2b1d8" category="paragraph">Instaclustr supporta anche funzionalità di auto-ribilanciamento ed è stato implementato per numerosi clienti.</block>
  <block id="856aa9558f6aac1cc157b1d21fa78574" category="section-title">Connettori Instaclustr Kafka Connect</block>
  <block id="2b56b60f878922093facd42284848a0c" category="inline-link-macro">Maggiori dettagli</block>
  <block id="66e7fcb114a635fe90c2f5b97045315d" category="inline-link-macro">i loro dettagli</block>
  <block id="621d9727aaaf7b26ac0502b35736098f" category="paragraph">Instaclustr supporta i connettori Kafka Connect e i loro dettagli - <block ref="5792c576643eef1089e675cecfec7f12" category="inline-link-macro-rx"></block>. Instaclustr fornisce connettori aggiuntivi <block ref="46bc00f72c87fbc1de536d86c545b8a8" category="inline-link-macro-rx"></block></block>
  <block id="af1c294a74855dc49e2b72264241a46a" category="summary">Questo documento fornisce una guida completa e dettagliata, passo dopo passo, per l'implementazione di NetApp AIPod Mini for Enterprise RAG (ERAG) 2.0. Copre l'installazione e la configurazione end-to-end di tutti i componenti principali, inclusa la piattaforma Kubernetes, NetApp Trident per l'orchestrazione dello storage e lo stack ERAG 2.0 utilizzando i playbook ansible. Oltre al flusso di lavoro di implementazione, il documento include una guida dedicata alla risoluzione dei problemi che raccoglie i problemi più comuni riscontrati durante l'installazione, le relative cause principali e le soluzioni consigliate per supportare un'esperienza di implementazione fluida e affidabile.</block>
  <block id="8902e5b5fac992859fa4ef94c88f6d83" category="doc">NetApp AIPod Mini per ERAG - Fasi di deployment</block>
  <block id="b4327c1c39b65823697d819300a5c3d5" category="paragraph">Questo documento fornisce una guida completa e dettagliata per l'implementazione di NetApp AIPod Mini per Enterprise RAG(ERAG) 2.0. Copre l'installazione e la configurazione end-to-end di tutti i componenti principali, inclusa la piattaforma Kubernetes, NetApp Trident per l'orchestrazione dello storage e lo stack ERAG 2.0 utilizzando i playbook ansible. Oltre al flusso di lavoro di implementazione, il documento include una guida dedicata alla risoluzione dei problemi che descrive i problemi più comuni riscontrati durante l'installazione, le relative cause principali e le soluzioni consigliate per supportare un'esperienza di implementazione fluida e affidabile.</block>
  <block id="cd41d76a25aefa2234f5a47efd63b636" category="paragraph">Sathish Thyagarajan, Michael Oglesby, Arpita Mahajan NetApp</block>
  <block id="1fec25c300e7a6fbf934cfbbf8f2624c" category="section-title">Ipotesi:</block>
  <block id="6f6e725691d8462b023e7f4194ab68bd" category="list-text">L'utente di distribuzione dispone di autorizzazioni sufficienti per creare namespace e installare Helm charts.</block>
  <block id="affa0cb0888210f280fa8083138ddb46" category="list-text">I server Xeon eseguono Ubuntu 22.04.</block>
  <block id="d29ae2f8d361f38224beabe308607218" category="list-text">Lo stesso nome utente è configurato su tutti i server Xeon.</block>
  <block id="78f4c745adf254bc39fadb42668a1395" category="list-text">L'accesso amministrativo DNS è disponibile.</block>
  <block id="9f887edbd1de73a6a3d70115d1341127" category="list-text">ONTAP 9.16 distribuito con una SVM configurata per l'accesso S3.</block>
  <block id="39f470f2bb6cfaca36940db1a5859c12" category="list-text">Il bucket S3 è creato e configurato.</block>
  <block id="e94ac587cc4294ed4116e704fcec7c06" category="paragraph">Installa Git, Python3.11 e pip per Python3.11</block>
  <block id="cab1f7c9135beb9ec4287da16bb3daaa" category="paragraph">Su Ubuntu 22.04:</block>
  <block id="61fd469b2b39e98e1c148994b07eaf7d" category="section-title">ERAG 2.0/2.0.1 Fasi di distribuzione</block>
  <block id="a0e88f868c503d450b7f4a1284b2ae64" category="section-title">1. Estrarre la versione Enterprise RAG 2.0 da GitHub</block>
  <block id="334be3363341934f875555ace28ceabb" category="paragraph">Per ERAG 2.0.1, utilizzare il comando seguente</block>
  <block id="76f94ff90b7bceb69ff51fb92d4af688" category="section-title">2. Installare i prerequisiti</block>
  <block id="d79ffbd31e0b6a9cffcd419a568c53c2" category="section-title">3. Crea file di inventario</block>
  <block id="0882b46efd7d84fa5ccd0b2cd0bfafb5" category="section-title">4. Imposta SSH senza password su ogni nodo</block>
  <block id="641b6467a6f8bc507b09125056545fe4" category="paragraph">Nota: se si utilizza un nodo di deploy per distribuire l'ERAG, assicurarsi che anche sul nodo di deploy sia configurato l'SSH senza password.</block>
  <block id="8dc837370221c66644d8b3d45c3c3310" category="section-title">5. Verificare la connettività</block>
  <block id="4af1cd719f022d037abd6e92818cff65" category="paragraph">Nota: se non hai configurato sudo senza password sui tuoi nodi, dovrai aggiungere --ask-become-pass a questo comando. Quando si utilizza --ask-become-pass, è fondamentale che l'utente ssh abbia la STESSA password su ogni nodo.</block>
  <block id="56fee405d3be80e4843859c43cbf42be" category="section-title">6. Modifica <block ref="259fe82e12a866f01123927480c7851b" prefix=" " category="inline-code"></block> file</block>
  <block id="50ac621a34abb50f1b69e374e9199187" category="paragraph">Prepara la distribuzione modificando <block ref="802c185eeb8976b290ecc1d26f29d75f" prefix=" " category="inline-code"></block> per riflettere le specifiche del tuo ambiente.</block>
  <block id="bb72ef03de842885d38c871e8b4a829a" category="section-title">Esempio di snippet:</block>
  <block id="b360c8c43818ee701c2c04aea42cd62a" category="section-title">7. Distribuire il cluster (con Trident)</block>
  <block id="0e2e4419e3eb7aa754e49ee968cd9405" category="paragraph">Esegui ansible-playbook playbooks/infrastructure.yaml con i tag configure e install per distribuire il cluster e Trident CSI.</block>
  <block id="41ea2d03e0d611507cffcee378f6559a" category="inline-link">NetApp Trident CSI Integration per Enterprise RAG</block>
  <block id="6a1fa30ffb46efef37952483ac8b77d0" category="paragraph">Nota: - Se non hai configurato sudo senza password sui tuoi nodi, dovrai aggiungere <block ref="13d87b4892426ec19bdc58a4643d3104" prefix=" " category="inline-code"></block> a questo comando. Quando si utilizza <block ref="13d87b4892426ec19bdc58a4643d3104" prefix=" " category="inline-code"></block>, è fondamentale che l'utente ssh abbia la STESSA password su ogni nodo. - Consultare <block ref="df44a473c05d78f41c72a7649c842643" category="inline-link-rx"></block> per i dettagli. Consultare <block ref="0fa543c14587a20e022922b0d6d40500" category="inline-link-rx"></block> per ulteriori dettagli.</block>
  <block id="6ea33c0cef6e57544b8e10c644b762af" category="section-title">8. Modificare il numero di descrittori aperti di iwatch</block>
  <block id="8b594829fa102007d7fb98eb374b87bd" category="inline-link">iwatch open descriptors</block>
  <block id="0b90ae516b9c9e0b43fab8d0faccdace" category="paragraph">Fare riferimento a<block ref="7175b82763deb794c2905a8612fbe6de" category="inline-link-rx"></block> per i dettagli.</block>
  <block id="ba26a104711f562442871b5addde5e35" category="section-title">9. Installa kubectl</block>
  <block id="229c581f09808b9c47f0886b097d1e5c" category="inline-link">Installa Kubectl</block>
  <block id="cdce62d37a856d5ce73eeccc91a61384" category="paragraph">Fare riferimento a<block ref="844beba66026b925fc0af1ca079567a4" category="inline-link-rx"></block> se non è già installato. Recuperare il file kubeconfig da<block ref="46f448b590c574e039d0acd83d58882c" prefix=" " category="inline-code"></block>.</block>
  <block id="e01242e0a8242b56242b0676a99a5e97" category="section-title">10. Installa MetalLB nel cluster Kubernetes</block>
  <block id="e884a1b1d0cfcfd8ee256afbd100b5c8" category="paragraph">Installa MetalLB utilizzando helm sul tuo cluster Kubernetes.</block>
  <block id="bde9cc793fe57591a5a66c520c9d23f7" category="inline-link">Installazione di MetalLB</block>
  <block id="ab0fa3fa44b4b7aba34e0c63dd39f3aa" category="paragraph">Fare riferimento a<block ref="51ecdffda3a9648b7ce65d1573948e5a" category="inline-link-rx"></block> per dettagli.</block>
  <block id="3e92140b8e7098e702f54ea7e9577400" category="section-title">11. Configura MetalLB</block>
  <block id="79bd8a10de31cb62b29958f84430e3e4" category="paragraph">MetalLB è stato configurato in modalità Layer 2 e le risorse IPAddressPool e L2Advertisement richieste sono state create in conformità con le linee guida di configurazione documentate.</block>
  <block id="fd7d468ed8619acf54145ff8ace04552" category="inline-link">Configurazione Layer2 di MetalLB</block>
  <block id="df1869e845d5366955c11dd55e57b7c3" category="paragraph">Nota: - Utilizzare <block ref="48f2018beab0b13a2087fae3aff05306" prefix=" " category="inline-code"></block> come namespace per MetalLB IPAddressPool e L2Advertisement. - Il pool di indirizzi IP può includere qualsiasi IP non utilizzato all'interno della stessa subnet dei nodi Kubernetes. È richiesto un solo indirizzo IP per ERAG. - Fare riferimento a <block ref="71fb88c79aed0f76ab251b76768252e8" category="inline-link-rx"></block> per i dettagli.</block>
  <block id="e512e032cc6fe60ad5f192ae1fd3e80d" category="section-title">12. Aggiorna config.yaml con FQDN, modalità di accesso al volume, ingress e dettagli S3.</block>
  <block id="5d0283113138c7e90648cece96c5ab99" category="paragraph">Modificare il file config.yaml situato in <block ref="802c185eeb8976b290ecc1d26f29d75f" prefix=" " category="inline-code"></block> per definire il deployment FQDN, impostare le modalità di accesso al volume, configurare l'esposizione ingress e integrare ONTAP S3.</block>
  <block id="38f2e7fd49604930109214ba7d88b98b" category="paragraph">Modifica<block ref="259fe82e12a866f01123927480c7851b" prefix=" " category="inline-code"></block> e applica le seguenti modifiche alla configurazione:</block>
  <block id="971c6ae26c9279b9ad5b84a4cfb976c2" category="list-text">FQDN: specificare il fully qualified domain name utilizzato per accedere alla distribuzione.</block>
  <block id="a63de0e65cc29c65bd5a96042acb47c5" category="list-text">Modalità di accesso al volume: nella sezione gmc.pvc, impostare <block ref="680803c3eb36593bb06d0d5b3fd0a1c9" prefix=" " category="inline-code"></block> per supportare l'accesso simultaneo ai volumi del modello su più pod.</block>
  <block id="bfabd265860f7993332a7d26b6a61200" category="list-text">Configurazione di Ingress: configurare il service_type di Ingress come LoadBalancer per abilitare l'accesso esterno all'applicazione.</block>
  <block id="771a9e838e8e6e0edfa6f75cef4825b6" category="list-text">Dettagli di archiviazione S3: impostare storageType su s3compatible e configurare i parametri ONTAP S3, inclusi regione, credenziali di accesso, endpoint interni ed esterni.</block>
  <block id="185a9b207ebaf7a90c9aa24d3a15b383" category="list-text">Verifica del certificato SSL: impostare edpInternalCertVerify e edpExternalCertVerify su false solo quando ONTAP S3 è configurato con certificati autofirmati. Se i certificati sono emessi da una CA pubblicamente attendibile, questi parametri devono rimanere abilitati.</block>
  <block id="8c8ab86ebf838cab10c15c5e3d2a9f3d" category="inline-link">Implementazione RAG Intel® AI for Enterprise</block>
  <block id="27c2b26890dcebe585c9ec8871e3f2f3" category="paragraph">Nota: - Per impostazione predefinita, l® applicazione Intel® AI for Enterprise RAG acquisisce dati da tutti i bucket esistenti nella SVM. Se nella SVM sono presenti più bucket, è possibile modificare il <block ref="50d6f108d2717f6e9be4eae460e94414" prefix=" " category="inline-code"></block> campo in modo che i dati vengano acquisiti solo da determinati bucket. - Consultare la documentazione <block ref="8166c2c75e2d31afb08f5953cd8da166" category="inline-link-rx"></block> per i dettagli.</block>
  <block id="4f07de1071a3b0e812597cc287fde565" category="section-title">13. Configurare le impostazioni di sincronizzazione pianificata</block>
  <block id="f1475507c99dedc8372901ed39e340d0" category="paragraph">Quando si installa l'applicazione OPEA per Intel® AI for Enterprise RAG, abilitare <block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block> in modo che l'applicazione acquisisca automaticamente file nuovi o aggiornati dai bucket S3.</block>
  <block id="8891051c065ada443afabea567730b4c" category="paragraph">Per abilitare <block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block> e impostare l'intervallo di sincronizzazione, impostare i seguenti valori in <block ref="244aacaf4a53d588b5bb867b523c3a32" prefix=" " category="inline-code"></block>:</block>
  <block id="7ac40591dda307ff152ee17947172a22" category="section-title">14. Distribuire Enterprise RAG 2.0/2.0.1</block>
  <block id="45720e317c5fe8df3f9d5a3d95b56881" category="inline-link-macro">Guida alla distribuzione dell'applicazione RAG Intel® AI for Enterprise</block>
  <block id="0f995f6c99655cbad8877bc2a9d1e03d" category="paragraph">Prima dell'installazione, convalidare la disponibilità dell'infrastruttura seguendo le procedure descritte nel <block ref="f3772a10113fe71727ad9049e2f363aa" category="inline-link-macro-rx"></block>. Questo passaggio garantisce che l'infrastruttura sottostante sia configurata correttamente e soddisfi tutti i prerequisiti richiesti per una riuscita installazione di Enterprise RAG Application.</block>
  <block id="0f12fee1b2472a4e87f19189703c8cdb" category="paragraph">Eseguire l'installazione utilizzando:</block>
  <block id="5254f9adeac265f859fad15fdb2833de" category="paragraph">Nota: se non hai configurato sudo senza password sul tuo nodo di distribuzione (il laptop o l'host jump su cui stai eseguendo il comando ansible-playbook), dovrai aggiungere <block ref="13d87b4892426ec19bdc58a4643d3104" prefix=" " category="inline-code"></block> a questo comando. Quando si utilizza <block ref="13d87b4892426ec19bdc58a4643d3104" prefix=" " category="inline-code"></block>, è fondamentale che l'utente ssh abbia la STESSA password su ogni nodo.</block>
  <block id="c961b5e1663bec185e8f45288fbee9d4" category="section-title">15. Crea una voce DNS</block>
  <block id="63997ef8e8952f940ba35fadc08d3f3f" category="paragraph">Crea una voce DNS per la dashboard web di Enterprise RAG nel tuo DNS server. Per procedere, recupera l'indirizzo IP esterno assegnato all'ingress di Enterprise RAG LoadBalancer:</block>
  <block id="f6bfd95ec3b9bfe461738cb69ce108ae" category="paragraph">Crea una voce DNS che punti a questo indirizzo IP per il fully qualified domain utilizzato nel passaggio 12.</block>
  <block id="26cedb5129589d45276ba46e6bc061ac" category="paragraph">Nota: - Il fully qualified domain utilizzato per la voce DNS DEVE corrispondere al fully qualified domain del file di configurazione.</block>
  <block id="6d3d73040b169b4fe62d8c0032ee22bb" category="section-title">16. Accedi all'interfaccia utente Enterprise RAG</block>
  <block id="61abc1c3fdd2d13f9ec5e936ce5653fb" category="paragraph">Accedi all'interfaccia utente Enterprise RAG navigando fino a quel fully qualified domain (FQDN) nel tuo browser. Nota: puoi recuperare le credenziali predefinite dell'interfaccia utente da cat ansible-logs/default_credentials.txt</block>
  <block id="077355ceb7b587450f75a64f77917db3" category="section-title">Guida alla risoluzione dei problemi</block>
  <block id="b3941a2c1e36d79827fa2421bfd83e3f" category="section-title">1. Problema: conflitto di installazione di Keycloak Helm</block>
  <block id="08d1f87eb0e770ae29f10ed22bc35e87" category="paragraph">Scenario: durante la distribuzione di ERAG, l'installazione di Keycloak potrebbe non riuscire con il seguente errore:</block>
  <block id="4212cb71f1b1b0c4e70bcf6db05bf87d" category="paragraph">Azione: se l'errore persiste dopo i nuovi tentativi, disinstallare la distribuzione ERAG, eliminare lo spazio dei nomi di autenticazione esistente utilizzando i comandi seguenti ed eseguire nuovamente la distribuzione.</block>
  <block id="b50774c2884c7b5d9328dbd9a2a56a84" category="paragraph">Nota: uno stato di rilascio Helm obsoleto può bloccare le successive operazioni di installazione o aggiornamento.</block>
  <block id="857764d5ae5d3bd5ef129330ec0b99a6" category="section-title">2. Problema: versione della Helm Chart di Trident Operator non trovata</block>
  <block id="38055ddcac29cc64c9fa3730d0096626" category="paragraph">Scenario: durante l'implementazione di ERAG, l'installazione dell'operatore Trident potrebbe non riuscire a causa di una mancata corrispondenza della versione della Helm chart. Potrebbe essere osservato il seguente errore:</block>
  <block id="e8871e50b05b0e6263649ecadb5aaefa" category="paragraph">Azione: se si verifica questo errore, aggiornare l'indice del repository Helm ed eseguire nuovamente il playbook di distribuzione.</block>
  <block id="311601b84b88e938de6aca4219500fb5" category="paragraph">Nota: questo è un problema noto nella versione 2.0 di ERAG. È stata inviata una correzione che sarà inclusa in una versione futura.</block>
  <block id="8969d654b93278979fd574ac0ab94dd7" category="summary">Questo documento delinea una checklist completa per la preparazione dell'infrastruttura per NetApp AIPod Mini for Enterprise RAG, che funge da riferimento pre-distribuzione.</block>
  <block id="6aa1c7dde3606e8655a8a9bbd36eb2e1" category="doc">NetApp AIPod Mini per ERAG - Infra Readiness Checklist</block>
  <block id="9130fbbdedebb7ef61cac7f6ca5de06e" category="section-title">Prontezza aziendale e dei casi d'uso</block>
  <block id="6d7d1ee35a3bc28f079ab066ab62718a" category="list-text">La soluzione è allineata ai risultati aziendali (ad esempio, produttività, servizio clienti, aspetti legali, assistenza sanitaria, produzione, settore pubblico)?</block>
  <block id="541f58c848a838cb3811ae5be98c9b8d" category="list-text">Hai stimato il Time to First Token (TTFT) e le esigenze di latenza per i tuoi carichi di lavoro LLM?</block>
  <block id="69210122955411a7137abb46b98d1a14" category="list-text">Conosci il carico di utenti/concorrenza previsto (ad esempio, 32 utenti simultanei per 2-worker node per RAG)?</block>
  <block id="1f594fcc08ac2423a5ec03cd46662c3c" category="list-text">Hai identificato i principali carichi di lavoro AI/GenAI (RAG, inferencing, fine-tuning, LLM dipartimentali, integrazione di vector DB)?</block>
  <block id="2ad0d743a3814d4ccb1a5010962ff3a5" category="list-text">Stai valutando le opzioni di AI basate su CPU (OPEA, Intel Xeon) rispetto alle alternative GPU per un equilibrio tra costi e prestazioni?</block>
  <block id="7f7b12c0c41949232d279dd361097368" category="section-title">Requisiti tecnici e infrastrutturali</block>
  <block id="3e7f73077f8cb6fbd6dbdb5b9ed67d13" category="list-text">La tua pipeline di dati è pronta (preparazione dei dati, ETL, inserimento sicuro nel vector DB)?</block>
  <block id="c73fc5c40f40c1ceab6f4d91aafc60ed" category="list-text">Hai bisogno di elevata disponibilità, ridondanza o funzionalità DR?</block>
  <block id="ba7184ae43bced247f9e928349523cc2" category="list-text">Stai sfruttando il supporto dello stack AI Ubuntu Linux / Kubernetes / Red Hat OpenShift?</block>
  <block id="51c47c43533e6d15fcdb0e53081e968c" category="list-text">Hai convalidato le prestazioni della rete (25–100GbE a seconda del carico di lavoro)?</block>
  <block id="c998565135089cfc9ce3fe78b2d0bf8d" category="list-text">Lo storage è fornito con NetApp ONTAP + Trident CSI driver per la persistenza Kubernetes?</block>
  <block id="0e2af4568d68a925d2998946069b4cbf" category="list-text">Almeno 3 compute nodes (2 worker, 1 control plane) dimensionati correttamente?</block>
  <block id="fab8c109a0f9b215cee6f4aed005e3c8" category="section-title">Allineamento tra software ed ecosistema</block>
  <block id="23c418039c3b36329dc1ae3535f87491" category="list-text">Le tue app containerizzate sono compatibili con Kubernetes e i grafici Helm forniti?</block>
  <block id="5b39c8cceb81b91c5dbbc0cca049f8aa" category="list-text">Quali database vettoriali (ad esempio, Milvus, pgvector) sono previsti per la distribuzione?</block>
  <block id="ee115901b4782e375868d78a71d2bed6" category="list-text">Hai bisogno della pre-integrazione OPEA (Open Platform for Enterprise AI) per retrieval-augmented generation (RAG)?</block>
  <block id="671d1ada5c16bbf74b574ba302b61e4d" category="list-text">Stai sfruttando le opzioni hybrid-cloud (Cloud Volumes ONTAP, FSxN, Anthos, Azure Arc)?</block>
  <block id="c533306c75ce756263df34c902336ce6" category="list-text">Hai bisogno di integrazioni con partner ISV (ESRI, PACS sanitari, ISV finanziari/legali)?</block>
  <block id="dfc11c5ecf2dc84ce0c1f03dcf1e6ba3" category="section-title">Governance e sicurezza dei dati</block>
  <block id="cd58e7d34bf4f11473ae1e7f7d026d7c" category="list-text">Hai abilitato il controllo degli accessi in base al ruolo (RBAC) in Kubernetes?</block>
  <block id="684cc5fc20b5a53ddf3c4aa6c3f97d3a" category="list-text">Esiste un piano di protezione dei dati e di backup (SnapMirror, SnapCenter, protezione da ransomware)?</block>
  <block id="a64d1df3ad43fddfdbc8bd66f1ac0e3c" category="list-text">Hai mappato le esigenze di conformità dei dati (HIPAA, GDPR, FedRAMP, CJIS)?</block>
  <block id="bc7bc4e05f5f9138f6c2280e35d8e1c4" category="list-text">Hai bisogno di una distribuzione privata dell'AI (air-gapped, on-premises, enclave sicura)?</block>
  <block id="2f568edbc54d0a3c37687ef0259aeeaf" category="section-title">Considerazioni operative e di supporto</block>
  <block id="f50b1245a69ec881ff2ea049bff8ff5c" category="list-text">Gli amministratori sono formati/abilitati su Kubernetes, Trident CSI e sull'implementazione dello stack OPEA?</block>
  <block id="90e5daf1de44c69c9dcab5a06ff892b5" category="list-text">Hai bisogno di supporto per multi-tenancy (dipartimenti, agenzie SLED, unità aziendali)?</block>
  <block id="eecbf8512a977cbc3119bdf20fa4f430" category="list-text">Esiste un piano per il monitoraggio e l'osservabilità (ONTAP System Manager, Cloud Insights, Prometheus/Grafana)?</block>
  <block id="a3b3fd8da7fa8e2e19629f24cfc2a06f" category="list-text">Chi sarà responsabile delle operazioni del secondo giorno (IT del cliente, partner, managed service provider)?</block>
  <block id="ef66a709ea055f5afe8c8dc5d2381e51" category="section-title">Allineamento commerciale e GTM</block>
  <block id="903ac5c167e66f7230d685fb6135a900" category="list-text">Esiste una roadmap (espansione dell’IA da livello dipartimentale a livello enterprise)?</block>
  <block id="4168144f9ccadd6652203dd35676508d" category="list-text">Avete una proiezione pro forma pluriennale (TCO, ARR, margin uplift)?</block>
  <block id="47575d0621f8eff8328adf2ea02f408a" category="list-text">Gli scenari di aumento delle licenze sono chiari (vector DB, software ISV, AI ops tools)?</block>
  <block id="bdf674078fd1455a7abeae74e3dabbdb" category="list-text">Hai valutato gli incentivi per i partner (margine del distributore, OEM/Intel co-funding)?</block>
  <block id="5ce5bf4f62b009139a11b2c179c129e5" category="list-text">L'acquisto è allineato ai cicli di budget (CapEx vs OpEx, modelli di consumo)?</block>
  <block id="27dee9077ad155a2b88820ada3d0b9dc" category="list-text">Avete un partner di servizi (Arrow, WWT, Presidio, ecc.) per il dimensionamento e l'implementazione?</block>
  <block id="9dd2ac2c9f43a8727199375b4dd615e8" category="paragraph">Sathish Thyagarajan, Michael Oglesby, Arpita Mahajan, NetApp</block>
  <block id="9df9c74b03cc4be86a17edc165c4152c" category="paragraph">Un numero crescente di organizzazioni sfrutta applicazioni di retrieval-augmented generation (RAG) e large language models (LLM) per interpretare i prompt degli utenti e generare risposte per aumentare la produttività e il valore di business. Questi prompt e risposte possono includere testo, codice, immagini o persino strutture proteiche terapeutiche recuperate dalla knowledge base interna di un'organizzazione, da data lakes, repository di codice e repository di documenti. Questo documento illustra il reference design della soluzione NetApp AIPod Mini, che comprende NetApp AFF storage e server con processori Intel Xeon 6. Include il software di gestione dei dati NetApp ONTAP combinato con Intel Advanced Matrix Extensions (Intel AMX) e il software Intel® AI for Enterprise RAG basato su Open Platform for Enterprise AI (OPEA). La soluzione NetApp AIPod Mini for enterprise RAG consente alle organizzazioni di aumentare un LLM pubblico in una soluzione privata di inferenza di intelligenza artificiale generativa (GenAI). La soluzione dimostra un'inferenza RAG efficiente e conveniente su scala enterprise, progettata per migliorare l'affidabilità e offrire un maggiore controllo sulle informazioni proprietarie.</block>
  <block id="754689ceca406599019b3ad910f428d9" category="paragraph">Le applicazioni RAG prevedono il recupero di conoscenze dai repository di documenti aziendali in vari formati, come PDF, testo, CSV o Excel. Questi dati sono normalmente archiviati in soluzioni come uno storage a oggetti S3 o NFS on-premises come fonte per i dati. NetApp è stata leader nelle tecnologie di data management, mobilità dei dati, governance dei dati e sicurezza dei dati nell’ecosistema edge, data center e cloud. NetApp ONTAP data management fornisce storage enterprise-grade per supportare vari tipi di carichi di lavoro AI, inclusi batch e inferenza real-time, e offre alcuni dei seguenti vantaggi:</block>
  <block id="e1d806767b45e3820e58bdee4494c953" category="section-title">Tecnologie AI Intel®</block>
  <block id="79ecd14d8408b2d13ef536f60a847735" category="cell">Intel Xeon 6th Gen (Granite Rapids)</block>
  <block id="fe3cdaaffdb9c9e9f0f6c8e326cf00d5" category="cell">Nodi di inferenza RAG—con processori Intel Xeon 6900-series (96 core) o Intel Xeon 6700-series (64 core) a doppio socket e RAM da 250GB a 3TB con DDR5 (6400MHz) o MRDIMM (8800MHz). Server 2U.</block>
  <block id="ac3f53c63b89cd675ca67a405453e1c7" category="paragraph">Figura 3 - Architettura di distribuzione di AIPod Mini <block ref="25b67f320abeb834fdc539334727ba57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b28c56111fbf8684b9a81edf0f4cf55" category="section-title">Intel® AI for Enterprise RAG basato su OPEA</block>
  <block id="eaf487a45ccf0ac35df6e52fa454d72e" category="paragraph">OPEA per Intel® AI for Enterprise RAG semplifica la trasformazione dei dati aziendali in informazioni fruibili. Basato su processori Intel Xeon, integra componenti di partner del settore per offrire un approccio semplificato all'implementazione di soluzioni enterprise. Si adatta perfettamente a framework di orchestrazione collaudati, offrendo la flessibilità e la scelta di cui la tua enterprise ha bisogno.</block>
  <block id="a717b72756530d291267441d9de748bc" category="paragraph">Basandosi sulle fondamenta di OPEA, Intel® AI for Enterprise RAG estende questa base con funzionalità chiave che migliorano scalabilità, sicurezza ed esperienza utente. Queste funzionalità includono service mesh per un'integrazione perfetta con le moderne architetture basate sui servizi, convalida pronta per la produzione per l'affidabilità della pipeline e un'interfaccia utente ricca di funzionalità per RAG as a service, che consente una facile gestione e monitoraggio dei workflow. Inoltre, il supporto di Intel e dei partner fornisce accesso a un ampio ecosistema di soluzioni, combinato con Identity and Access Management (IAM) integrato con UI e applicazioni per operazioni sicure e conformi. Guardrail programmabili forniscono un controllo granulare sul comportamento della pipeline, consentendo impostazioni di sicurezza e conformità personalizzate.</block>
  <block id="96936fce646d61cd28c7f01f8ce8ba7b" category="cell">OPEA - Intel® AI for Enterprise RAG</block>
  <block id="d1bd83a33f1a841ab7fda32449746cc4" category="cell">2,0</block>
  <block id="166ff7b7a4edd04e3e641a1f337a49fb" category="cell">NetApp Trident 25.10</block>
  <block id="b7150f4230886e39b8654349a3f1c2dd" category="cell">OS su cluster a due nodi.</block>
  <block id="1f364a9dbe8135449005b8eeddc4c878" category="cell">Kubernetes 1.31.9 (installato dal playbook dell'infrastruttura Enterprise RAG)</block>
  <block id="e6c4fc8c55c2de7770506c485eabe223" category="cell">ONTAP 9.16.1P4 o superiore</block>
  <block id="27e034c6aa563cf16957cd4c6d8adcba" category="cell">Storage OS su AFF A20.</block>
  <block id="5a37d25db2d01504a6263c4c16312c07" category="paragraph">Figura 5 - Creazione di SVM tramite ONTAP System Manager. <block ref="eddc39049915c5d642c02b97b2cbe95e" category="inline-image-macro-rx" type="image"></block> <block ref="d6e1134442a83aae943e8555fe42f14e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a231e9c9ede5cce54258d6e9cb253a9" category="paragraph">Nota: questo utente sarà necessario per il servizio di acquisizione dati dell'applicazione Intel® AI for Enterprise RAG. Se hai creato la tua SVM utilizzando ONTAP System Manager, System Manager avrà creato automaticamente un utente <block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> e una policy denominata <block ref="0268c876e4588f7ad98bacb113933dab" prefix=" " category="inline-code"></block> quando hai creato la tua SVM, ma non saranno state assegnate autorizzazioni a <block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block>.</block>
  <block id="b00dc1727dd8de366aae56be99704c42" category="paragraph">Figura 6 - Autorizzazioni S3.</block>
  <block id="0f41d8cb654bbdbe1848740c90885804" category="paragraph">Figura 7 - Crea un bucket S3. <block ref="06e84b109f1e09150cd4d15502f0a16d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca8efabf6c2df7377fbb0fbc45a84064" category="paragraph">Figura 8 - Autorizzazioni del bucket S3. <block ref="cc0f8d7f1fe9cc3d53404327451495be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aecd2208157c8d88b6252d67af43c172" category="paragraph">Questa regola consente a OPEA per Intel® AI for Enterprise RAG web application di interagire con il bucket dall'interno di un browser web.</block>
  <block id="02ec09a73a7155c0e3ea20729788f07a" category="section-title">Distribuisci Enterprise RAG 2.0</block>
  <block id="14ace5de04b7c781134f945c5181075d" category="paragraph">Fare riferimento al seguente documento per un flusso di lavoro di distribuzione completo e dettagliato: <block ref="c018360a3b18e9c97e1027ed1af47b37" category="inline-xref-macro-rx"></block> Tutti i prerequisiti, la preparazione dell'infrastruttura, i parametri di configurazione e le procedure di distribuzione sono documentati nella guida alla distribuzione sopra riportata.</block>
  <block id="9410fe7e6071a4ef12af94972bcb1fd5" category="section-title">Accedi a OPEA per Intel® AI for Enterprise RAG UI</block>
  <block id="442d72b351c2261ebda7b1d58621d12f" category="inline-link">Documentazione di distribuzione di Intel® AI for Enterprise RAG</block>
  <block id="c1878255e14d0e7ea230b5c70b7f9b0f" category="paragraph">Accedi all'OPEA per Intel® AI for Enterprise RAG UI. Consulta la <block ref="84729fc427b63a5ea7934b06c963980b" category="inline-link-rx"></block> per i dettagli.</block>
  <block id="5497738789dd30331c4e0b4fe1a6604c" category="paragraph">Figura 9 - OPEA per Intel® AI for Enterprise RAG UI. <block ref="6d77f379a6edbd5d21f429e445153eaa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e98b7fe28119116fb249a99eb51a2664" category="paragraph">Nota: dopo che un file è stato acquisito, l'OPEA per Intel® AI for Enterprise RAG application controlla automaticamente la presenza di aggiornamenti al file e acquisisce gli aggiornamenti di conseguenza.</block>
  <block id="e0df9555cd4d05eaa39f7c620a224b5a" category="paragraph">*Opzione 1: Carica direttamente nel tuo bucket S3 Per importare più file contemporaneamente, ti consigliamo di caricarli nel tuo bucket S3 (quello creato in precedenza) utilizzando il client S3 che preferisci. Tra i client S3 più diffusi figurano AWS CLI, Amazon SDK for Python (Boto3), s3cmd, S3 Browser, Cyberduck e Commander One. Se i file sono di un tipo supportato, tutti i file che carichi nel tuo bucket S3 verranno automaticamente importati dall'applicazione OPEA for Intel® AI for Enterprise RAG.</block>
  <block id="3e96884bbc08e1a021e886006d4fd3eb" category="paragraph">Nota: al momento della stesura di questo documento, sono supportati i seguenti tipi di file: PDF, HTML, TXT, DOC, DOCX, ADOC, PPT, PPTX, MD, XML, JSON, JSONL, YAML, XLS, XLSX, CSV, TIFF, JPG, JPEG, PNG, and SVG.</block>
  <block id="5cedf926d8e41515ad2a086aa4f7fff3" category="paragraph">È possibile utilizzare l'OPEA for Intel® AI for Enterprise RAG UI per confermare che i file siano stati correttamente acquisiti. Consultare la documentazione di Intel® AI for Enterprise RAG UI per i dettagli. Si noti che l'applicazione potrebbe impiegare del tempo per acquisire un numero elevato di file.</block>
  <block id="2e7975796c80f0d6d942fe7b99cefb52" category="paragraph">*Opzione 2: Caricamento tramite l'UI Se devi importare solo un numero limitato di file, puoi importarli tramite l'OPEA for Intel® AI for Enterprise RAG UI. Consulta la documentazione di Intel® AI for Enterprise RAG UI per i dettagli.</block>
  <block id="3782f41ad58452fafe8cbef042e0daad" category="paragraph">Figura 10 - Interfaccia utente per l'acquisizione dei dati. <block ref="55969be455b6eb9c434a32c9edf9a19f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2bf99e78dbf59487c01d1fea8b7dabe6" category="paragraph">Ora puoi "chattare" con l'OPEA per Intel® AI for Enterprise RAG application utilizzando l'interfaccia utente di chat inclusa. Quando risponde alle tue query, l'applicazione esegue la RAG utilizzando i tuoi file acquisiti. Ciò significa che l'applicazione cerca automaticamente le informazioni rilevanti all'interno dei tuoi file acquisiti e incorpora queste informazioni quando risponde alle tue query.</block>
  <block id="d7289940422f981571155ab1f1f292da" category="inline-link-macro">Guida al dimensionamento Intel® AI for Enterprise RAG</block>
  <block id="0d26d12c133f7f721836d39555ca60ce" category="paragraph">Nota: le indicazioni sul dimensionamento presentate sopra si basano sulla convalida delle prestazioni e sui risultati dei test raccolti utilizzando processori Intel Xeon 6 con 96 core. Per i clienti con token I/O e requisiti di dimensioni del modello simili, consigliamo di utilizzare server con processori Xeon 6 con 96 core. Per ulteriori dettagli sulla guida al dimensionamento, fare riferimento a <block ref="a14c1c2e7fbc73e35c7961c0f30da189" category="inline-link-macro-rx"></block></block>
  <block id="2b2cfff4f61d8f64bd26032c5fc787e3" category="paragraph">I sistemi RAG enterprise e gli LLM sono tecnologie che lavorano insieme per aiutare le organizzazioni a fornire risposte accurate e consapevoli del contesto. Queste risposte implicano il recupero di informazioni basato su una vasta raccolta di dati aziendali privati e interni. Utilizzando RAG, API, incorporamenti vettoriali e sistemi di storage dalle performance elevate per interrogare repository di documenti che contengono dati aziendali, i dati vengono elaborati più rapidamente e in modo sicuro. Il NetApp AIPod Mini combina l'infrastruttura dati intelligente di NetApp con le funzionalità di gestione dei dati ONTAP, i processori Intel Xeon 6, Intel® AI for Enterprise RAG e lo stack software OPEA per aiutare a implementare applicazioni RAG dalle performance elevate e indirizzare le organizzazioni verso la leadership nell'AI.</block>
  <block id="a8bfa0c8464fca02ac357c4832646763" category="paragraph">Questo documento è stato redatto da Sathish Thyagarajan, Michael Oglesby e Arpita Mahajan, membri del team di NetApp Solutions Engineering. Gli autori desiderano inoltre ringraziare il team di prodotto Enterprise AI di Intel—Ajay Mungara, Mikolaj Zyczynski, Igor Konopko, Ramakrishna Karamsetty, Michal Prostko, Anna Alberska, Maciej Cichocki, Shreejan Mistry, Nicholas Rago e Ned Fiori—nonché gli altri membri del team di NetApp—Lawrence Bunka, Bobby Oommen e Jeff Liborio, per il loro continuo supporto e aiuto durante il processo di validazione della soluzione.</block>
  <block id="1aa8a157d1aaff87b7fdc2004cc1fc20" category="cell">P4X-GNR6972P-SRPL2-UC</block>
  <block id="73487f370dd46d411ff5704b95c486ad" category="cell">Processore Intel® Xeon® 6972P 96-Core 2.40GHz 480MB Cache (500W)</block>
  <block id="528be37d499dbc8548d59a69154153d9" category="section-title">Lista di controllo per la preparazione dell'infrastruttura</block>
  <block id="177df5e2cf4af49115f077f68faa0b1f" category="inline-xref-macro">NetApp AIPod Mini - Preparazione dell'infrastruttura</block>
  <block id="b399c656486b92b6ab342c0fddede07b" category="paragraph">Fare riferimento a <block ref="1b461394bdbca2261323f544b1938031" category="inline-xref-macro-rx"></block> per i dettagli.</block>
  <block id="75ce296e9f720309b9cc58e6682f0245" category="paragraph"><block ref="75ce296e9f720309b9cc58e6682f0245" category="inline-link-rx"></block></block>
  <block id="e0250b6896ab199764e2c85e29d840f0" category="inline-link">Intel® AI ERAG Documentazione</block>
  <block id="3482501ca0f3c3f239c5996f91d17070" category="paragraph"><block ref="3482501ca0f3c3f239c5996f91d17070" category="inline-link-rx"></block></block>
  <block id="0eac24e8329d913a6b45c3f989420e33" category="paragraph"><block ref="3d766654d6f2d85f314e655c63e91d81" category="inline-link-rx"></block> == Cronologia delle versioni</block>
  <block id="5edbe8c55546db896b55871b44a39263" category="cell">*Data*</block>
  <block id="7eee0b83cad89aa3750d4cf01e7410c4" category="cell">*Cronologia delle versioni del documento*</block>
  <block id="02e56f4a0f4a13b505de9041fe230be3" category="cell">Settembre 2025</block>
  <block id="ace9c8e1fe823a5e2a7de8c7bb092f3f" category="cell">Versione iniziale</block>
  <block id="00ba3b77f9aa3a279c72104e9d662ae9" category="cell">Feb 2026</block>
  <block id="1e675dec21c2e02d448ee68cb571e2e2" category="cell">Aggiornato con OPEA-Intel® AI for Enterprise RAG 2.0</block>
</blocks>